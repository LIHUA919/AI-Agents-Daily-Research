{"id": "2507.21109", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21109", "abs": "https://arxiv.org/abs/2507.21109", "authors": ["Prital Bamnodkar"], "title": "Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students", "comment": null, "summary": "Deep Neural Networks often suffer from a critical limitation known as\nCatastrophic Forgetting, where performance on past tasks degrades after\nlearning new ones. This paper introduces a novel continual learning approach\ninspired by human learning strategies like Active Recall, Deliberate Practice\nand Spaced Repetition, named Task Focused Consolidation with Spaced Recall\n(TFC-SR). TFC-SR enhances the standard experience replay with a mechanism we\ntermed the Active Recall Probe. It is a periodic, task-aware evaluation of the\nmodel's memory that stabilizes the representations of past knowledge. We test\nTFC-SR on the Split MNIST and Split CIFAR-100 benchmarks against leading\nregularization-based and replay-based baselines. Our results show that TFC-SR\nperforms significantly better than these methods. For instance, on the Split\nCIFAR-100, it achieves a final accuracy of 13.17% compared to standard replay's\n7.40%. We demonstrate that this advantage comes from the stabilizing effect of\nthe probe itself, and not from the difference in replay volume. Additionally,\nwe analyze the trade-off between memory size and performance and show that\nwhile TFC-SR performs better in memory-constrained environments, higher replay\nvolume is still more effective when available memory is abundant. We conclude\nthat TFC-SR is a robust and efficient approach, highlighting the importance of\nintegrating active memory retrieval mechanisms into continual learning systems.", "AI": {"tldr": "TFC-SR, a novel continual learning method inspired by human strategies like Active Recall, outperforms existing methods by stabilizing past knowledge through Active Recall Probes, achieving higher accuracy on benchmarks like Split CIFAR-100.", "motivation": "Addressing Catastrophic Forgetting in Deep Neural Networks by mimicking human learning strategies such as Active Recall, Deliberate Practice, and Spaced Repetition.", "method": "Introduces Task Focused Consolidation with Spaced Recall (TFC-SR), enhancing experience replay with Active Recall Probes for periodic, task-aware evaluation.", "result": "TFC-SR outperforms baselines, e.g., 13.17% accuracy on Split CIFAR-100 vs. 7.40% for standard replay, due to the stabilizing effect of probes.", "conclusion": "TFC-SR is robust and efficient, emphasizing the value of active memory retrieval in continual learning, with optimal performance in memory-constrained settings."}}
{"id": "2507.21119", "categories": ["cs.LG", "eess.SP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2507.21119", "abs": "https://arxiv.org/abs/2507.21119", "authors": ["Yousuf Moiz Ali", "Jaroslaw E. Prilepsky", "Nicola Sambo", "Jo\u00e3o Pedro", "Mohammad M. Hosseini", "Antonio Napoli", "Sergei K. Turitsyn", "Pedro Freire"], "title": "Pre-, In-, and Post-Processing Class Imbalance Mitigation Techniques for Failure Detection in Optical Networks", "comment": "3 pages + 1 page for acknowledgement and references", "summary": "We compare pre-, in-, and post-processing techniques for class imbalance\nmitigation in optical network failure detection. Threshold Adjustment achieves\nthe highest F1 gain (15.3%), while Random Under-sampling (RUS) offers the\nfastest inference, highlighting a key performance-complexity trade-off.", "AI": {"tldr": "Comparison of techniques for class imbalance mitigation in optical network failure detection, highlighting Threshold Adjustment for F1 gain and Random Under-sampling for speed.", "motivation": "Address class imbalance in optical network failure detection to improve accuracy and efficiency.", "method": "Evaluate pre-, in-, and post-processing techniques, focusing on Threshold Adjustment and Random Under-sampling (RUS).", "result": "Threshold Adjustment achieves the highest F1 gain (15.3%), while RUS offers the fastest inference.", "conclusion": "Trade-off between performance (F1 gain) and complexity (inference speed) must be considered when choosing mitigation techniques."}}
{"id": "2507.21135", "categories": ["cs.LG", "quant-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21135", "abs": "https://arxiv.org/abs/2507.21135", "authors": ["Alexander G. Abanov", "Luca Candelori", "Harold C. Steinacker", "Martin T. Wells", "Jerome R. Busemeyer", "Cameron J. Hogan", "Vahagn Kirakosyan", "Nicola Marzari", "Sunil Pinnamaneni", "Dario Villani", "Mengjia Xu", "Kharen Musaelian"], "title": "Quantum Geometry of Data", "comment": "27 pages, 14 figures, 1 table", "summary": "We demonstrate how Quantum Cognition Machine Learning (QCML) encodes data as\nquantum geometry. In QCML, features of the data are represented by learned\nHermitian matrices, and data points are mapped to states in Hilbert space. The\nquantum geometry description endows the dataset with rich geometric and\ntopological structure - including intrinsic dimension, quantum metric, and\nBerry curvature - derived directly from the data. QCML captures global\nproperties of data, while avoiding the curse of dimensionality inherent in\nlocal methods. We illustrate this on a number of synthetic and real-world\nexamples. Quantum geometric representation of QCML could advance our\nunderstanding of cognitive phenomena within the framework of quantum cognition.", "AI": {"tldr": "QCML encodes data as quantum geometry using Hermitian matrices and Hilbert space states, capturing global properties and avoiding dimensionality issues.", "motivation": "To leverage quantum geometry for understanding cognitive phenomena and overcoming the limitations of local methods in machine learning.", "method": "Represent data features as learned Hermitian matrices and map data points to states in Hilbert space, deriving geometric and topological structures.", "result": "QCML captures intrinsic dimension, quantum metric, and Berry curvature, demonstrated on synthetic and real-world datasets.", "conclusion": "QCML's quantum geometric representation offers a novel framework for advancing quantum cognition and machine learning."}}
{"id": "2507.21341", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21341", "abs": "https://arxiv.org/abs/2507.21341", "authors": ["Zixin Feng", "Qunshan Zhao", "Alison Heppenstall"], "title": "Replicating the behaviour of electric vehicle drivers using an agent-based reinforcement learning model", "comment": null, "summary": "Despite the rapid expansion of electric vehicle (EV) charging networks,\nquestions remain about their efficiency in meeting the growing needs of EV\ndrivers. Previous simulation-based approaches, which rely on static behavioural\nrules, have struggled to capture the adaptive behaviours of human drivers.\nAlthough reinforcement learning has been introduced in EV simulation studies,\nits application has primarily focused on optimising fleet operations rather\nthan modelling private drivers who make independent charging decisions.\nAdditionally, long-distance travel remains a primary concern for EV drivers.\nHowever, existing simulation studies rarely explore charging behaviour over\nlarge geographical scales. To address these gaps, we propose a multi-stage\nreinforcement learning framework that simulates EV charging demand across large\ngeographical areas. We validate the model against real-world data, and identify\nthe training stage that most closely reflects actual driver behaviour, which\ncaptures both the adaptive behaviours and bounded rationality of private\ndrivers. Based on the simulation results, we also identify critical 'charging\ndeserts' where EV drivers consistently have low state of charge. Our findings\nalso highlight recent policy shifts toward expanding rapid charging hubs along\nmotorway corridors and city boundaries to meet the demand from long-distance\ntrips.", "AI": {"tldr": "A multi-stage reinforcement learning framework is proposed to simulate EV charging demand, addressing gaps in capturing adaptive behaviors of private drivers and large-scale geographical analysis.", "motivation": "Existing methods fail to model adaptive behaviors of private EV drivers and large-scale charging needs, especially for long-distance travel.", "method": "A multi-stage reinforcement learning framework is developed and validated with real-world data to simulate EV charging demand.", "result": "The model identifies critical 'charging deserts' and aligns with policy shifts toward rapid charging hubs for long-distance trips.", "conclusion": "The framework effectively captures private driver behaviors and highlights areas needing charging infrastructure improvements."}}
{"id": "2507.21136", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21136", "abs": "https://arxiv.org/abs/2507.21136", "authors": ["Mojtaba Moattari"], "title": "A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning", "comment": null, "summary": "Unsupervised and supervised learning methods conventionally use kernels to\ncapture nonlinearities inherent in data structure. However experts have to\nensure their proposed nonlinearity maximizes variability and capture inherent\ndiversity of data. We reviewed all independence criteria to design unsupervised\nlearners. Then we proposed 3 independence criteria and used them to design\nunsupervised and supervised dimensionality reduction methods. We evaluated\ncontrast, accuracy and interpretability of these methods in both linear and\nneural nonlinear settings. The results show that the methods have outperformed\nthe baseline (tSNE, PCA, regularized LDA, VAE with (un)supervised learner and\nlayer sharing) and opened a new line of interpretable machine learning (ML) for\nthe researchers.", "AI": {"tldr": "The paper proposes 3 independence criteria for unsupervised and supervised dimensionality reduction, outperforming baselines like tSNE and PCA, and advancing interpretable ML.", "motivation": "To address the challenge of ensuring proposed nonlinearities maximize variability and capture data diversity in unsupervised and supervised learning.", "method": "Reviewed independence criteria, proposed 3 new ones, and designed dimensionality reduction methods evaluated in linear and neural nonlinear settings.", "result": "Outperformed baselines (tSNE, PCA, LDA, VAE) in contrast, accuracy, and interpretability.", "conclusion": "The methods open a new line of interpretable ML research."}}
{"id": "2507.21724", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21724", "abs": "https://arxiv.org/abs/2507.21724", "authors": ["Lise Jakobsen", "Anna Johanne Holden", "\u00d6nder G\u00fcrcan", "\u00d6zlem \u00d6zg\u00f6bek"], "title": "Agent-Based Exploration of Recommendation Systems in Misinformation Propagation", "comment": "14 pages, 3 figures, Social Simulation Conference 2025 (SSC'2025)", "summary": "This study uses agent-based modeling to examine the impact of various\nrecommendation algorithms on the propagation of misinformation on online social\nnetworks. We simulate a synthetic environment consisting of heterogeneous\nagents, including regular users, bots, and influencers, interacting through a\nsocial network with recommendation systems. We evaluate four recommendation\nstrategies: popularity-based, collaborative filtering, and content-based\nfiltering, along with a random baseline. Our results show that\npopularity-driven algorithms significantly amplify misinformation, while\nitem-based collaborative filtering and content-based approaches are more\neffective in limiting exposure to fake content. Item-based collaborative\nfiltering was found to perform better than previously reported in related\nliterature. These findings highlight the role of algorithm design in shaping\nonline information exposure and show that agent-based modeling can be used to\ngain realistic insight into how misinformation spreads.", "AI": {"tldr": "Agent-based modeling reveals that popularity-driven recommendation algorithms amplify misinformation, while item-based collaborative filtering and content-based methods limit fake content exposure.", "motivation": "To understand how different recommendation algorithms affect misinformation spread on social networks.", "method": "Simulated a synthetic environment with heterogeneous agents (users, bots, influencers) and tested four recommendation strategies: popularity-based, collaborative filtering, content-based, and random.", "result": "Popularity-driven algorithms worsen misinformation spread, while item-based collaborative filtering and content-based methods reduce it. Item-based collaborative filtering outperformed prior expectations.", "conclusion": "Algorithm design critically shapes online information exposure, and agent-based modeling provides realistic insights into misinformation dynamics."}}
{"id": "2507.21067", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.21067", "abs": "https://arxiv.org/abs/2507.21067", "authors": ["Jan Kapusta"], "title": "SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration", "comment": "32 pages, 4 figures. Includes 2 Appendices containing SynLang v1.2.0\n  protocol specification, and formal BNF grammar", "summary": "Current AI systems rely on opaque reasoning processes that hinder human\noversight and collaborative potential. Conventional explainable AI approaches\noffer post-hoc justifications and often fail to establish genuine symbiotic\ncollaboration. In this paper, the Symbiotic Epistemology is presented as a\nphilosophical foundation for human-AI cognitive partnerships. Unlike frameworks\nthat treat AI as a mere tool or replacement, symbiotic epistemology positions\nAI as a reasoning partner, fostering calibrated trust by aligning human\nconfidence with AI reliability through explicit reasoning patterns and\nconfidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as\na formal protocol for transparent human-AI collaboration. The framework is\nempirically validated through actual human-AI dialogues demonstrating AI's\nadaptation to structured reasoning protocols and successful metacognitive\nintervention. The protocol defines two complementary mechanisms: TRACE for\nhigh-level reasoning patterns and TRACE_FE for detailed factor explanations. It\nalso integrates confidence quantification, declarative control over AI\nbehavior, and context inheritance for multi-agent coordination. By structuring\ncommunication and embedding confidence-calibrated transparency, SynLang,\ntogether with symbiotic epistemology, enables AI systems that enhance human\nintelligence, preserve human agency, and uphold ethical accountability in\ncollaborative decision-making. Through dual-level transparency, beginning with\nhigh-level reasoning patterns and progressing to granular explanations, the\nprotocol facilitates rapid comprehension and supports thorough verification of\nAI decision-making.", "AI": {"tldr": "The paper introduces Symbiotic Epistemology and SynLang to foster transparent human-AI collaboration, validated through empirical dialogues.", "motivation": "Current AI systems lack transparency, hindering human oversight and collaboration. Post-hoc explanations fail to enable genuine partnership.", "method": "Proposes Symbiotic Epistemology and SynLang, a formal protocol with TRACE and TRACE_FE mechanisms, integrating confidence quantification and declarative control.", "result": "Empirical validation shows AI's adaptation to structured reasoning and successful metacognitive intervention, enhancing human-AI collaboration.", "conclusion": "SynLang and symbiotic epistemology enable transparent, ethical AI collaboration, preserving human agency and accountability."}}
{"id": "2507.21147", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21147", "abs": "https://arxiv.org/abs/2507.21147", "authors": ["Fabrizio Lo Scudo", "Alessio De Rango", "Luca Furnari", "Alfonso Senatore", "Donato D'Ambrosio", "Giuseppe Mendicino", "Gianluigi Greco"], "title": "Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning", "comment": "To appear in the Proceedings of ECAI 2025", "summary": "Wildfires significantly impact natural ecosystems and human health, leading\nto biodiversity loss, increased hydrogeological risks, and elevated emissions\nof toxic substances. Climate change exacerbates these effects, particularly in\nregions with rising temperatures and prolonged dry periods, such as the\nMediterranean. This requires the development of advanced risk management\nstrategies that utilize state-of-the-art technologies. However, in this\ncontext, the data show a bias toward an imbalanced setting, where the incidence\nof wildfire events is significantly lower than typical situations. This\nimbalance, coupled with the inherent complexity of high-dimensional\nspatio-temporal data, poses significant challenges for training deep learning\narchitectures. Moreover, since precise wildfire predictions depend mainly on\nweather data, finding a way to reduce computational costs to enable more\nfrequent updates using the latest weather forecasts would be beneficial. This\npaper investigates how adopting a contrastive framework can address these\nchallenges through enhanced latent representations for the patch's dynamic\nfeatures. We thus introduce a new morphology-based curriculum contrastive\nlearning that mitigates issues associated with diverse regional characteristics\nand enables the use of smaller patch sizes without compromising performance. An\nexperimental analysis is performed to validate the effectiveness of the\nproposed modeling strategies.", "AI": {"tldr": "The paper proposes a contrastive learning framework to improve wildfire prediction by addressing data imbalance and high-dimensional spatio-temporal challenges, using smaller patch sizes without performance loss.", "motivation": "Wildfires severely impact ecosystems and health, worsened by climate change. Current methods face data imbalance and computational challenges, needing advanced solutions.", "method": "Introduces morphology-based curriculum contrastive learning to enhance latent representations of dynamic features, reducing computational costs and improving predictions.", "result": "Experimental analysis validates the framework's effectiveness in handling diverse regional characteristics and imbalanced data.", "conclusion": "The proposed contrastive learning approach offers a viable solution for better wildfire risk management with reduced computational demands."}}
{"id": "2507.21969", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21969", "abs": "https://arxiv.org/abs/2507.21969", "authors": ["Adam Kostka", "Jaros\u0142aw A. Chudziak"], "title": "Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation", "comment": "Accepted at CogSci 2025", "summary": "Recently, the field of Multi-Agent Systems (MAS) has gained popularity as\nresearchers are trying to develop artificial intelligence capable of efficient\ncollective reasoning. Agents based on Large Language Models (LLMs) perform well\nin isolated tasks, yet struggle with higher-order cognition required for\nadaptive collaboration. Human teams achieve synergy not only through knowledge\nsharing, but also through recursive reasoning, structured critique, and the\nability to infer others' mental states. Current artificial systems lack these\nessential mechanisms, limiting their ability to engage in sophisticated\ncollective reasoning. This work explores cognitive processes that enable\neffective collaboration, focusing on adaptive theory of mind (ToM) and\nsystematic critical evaluation. We investigate three key questions. First, how\ndoes the ability to model others' perspectives enhance coordination and reduce\nredundant reasoning? Second, to what extent does structured critique improve\nreasoning quality by identifying logical gaps and mitigating biases? Third, the\ninterplay of these mechanisms can lead to emergent cognitive synergy, where the\ncollective intelligence of the system exceeds the sum of its parts. Through an\nempirical case study on complex decision making, we show that the integration\nof these cognitive mechanisms leads to more coherent, adaptive, and rigorous\nagent interactions. This article contributes to the field of cognitive science\nand AI research by presenting a structured framework that emulates human-like\ncollaborative reasoning MAS. It highlights the significance of dynamic ToM and\ncritical evaluation in advancing multi-agent systems' ability to tackle\ncomplex, real-world challenges.", "AI": {"tldr": "The paper explores cognitive mechanisms like adaptive theory of mind (ToM) and structured critique to enhance collaborative reasoning in multi-agent systems (MAS), showing improved coherence and adaptability in agent interactions.", "motivation": "Current MAS lack human-like collaborative reasoning due to missing mechanisms like recursive reasoning and mental state inference, limiting their collective intelligence.", "method": "The study investigates adaptive ToM and structured critique through an empirical case study on complex decision-making.", "result": "Integration of these mechanisms leads to more coherent, adaptive, and rigorous agent interactions, surpassing individual capabilities.", "conclusion": "The framework advances MAS by emulating human-like collaborative reasoning, emphasizing dynamic ToM and critical evaluation for real-world challenges."}}
{"id": "2507.21098", "categories": ["cs.AI", "cs.CY", "I.2.6; I.2.1; H.4.2"], "pdf": "https://arxiv.org/pdf/2507.21098", "abs": "https://arxiv.org/abs/2507.21098", "authors": ["Marta Sidorkiewicz", "Karolina Kr\u00f3likowska", "Berenika Dyczek", "Edyta Pijet-Migon", "Anna Dubel"], "title": "Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism", "comment": "6 pages, 4 figures. Accepted for presentation at the 27th European\n  Conference on Artificial Intelligence (ECAI 2025), October 19-24, 2025,\n  Bologna, Italy", "summary": "This study examines the role of Artificial Intelligence (AI) in enhancing\nsustainability and efficiency within the wine industry. It focuses on AI-driven\nintelligent management in viticulture, wine production, and enotourism. As the\nwine industry faces environmental and economic challenges, AI offers innovative\nsolutions to optimize resource use, reduce environmental impact, and improve\ncustomer engagement. Understanding AI's potential in sustainable winemaking is\ncrucial for fostering responsible and efficient industry practices. The\nresearch is based on a questionnaire survey conducted among Polish winemakers,\ncombined with a comprehensive analysis of AI methods applicable to viticulture,\nproduction, and tourism. Key AI technologies, including predictive analytics,\nmachine learning, and computer vision, are explored. The findings indicate that\nAI enhances vineyard monitoring, optimizes irrigation, and streamlines\nproduction processes, contributing to sustainable resource management. In\nenotourism, AI-powered chatbots, recommendation systems, and virtual tastings\npersonalize consumer experiences. The study highlights AI's impact on economic,\nenvironmental, and social sustainability, supporting local wine enterprises and\ncultural heritage. Keywords: Artificial Intelligence, Sustainable Development,\nAI-Driven Management, Viticulture, Wine Production, Enotourism, Wine\nEnterprises, Local Communities", "AI": {"tldr": "AI enhances sustainability and efficiency in the wine industry through intelligent management in viticulture, production, and tourism.", "motivation": "The wine industry faces environmental and economic challenges; AI offers solutions for resource optimization and customer engagement.", "method": "Questionnaire survey among Polish winemakers and analysis of AI methods like predictive analytics, machine learning, and computer vision.", "result": "AI improves vineyard monitoring, irrigation, production, and enotourism experiences, supporting sustainability.", "conclusion": "AI positively impacts economic, environmental, and social sustainability in the wine industry."}}
{"id": "2507.21152", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21152", "abs": "https://arxiv.org/abs/2507.21152", "authors": ["Hangli Ge", "Noboru Koshizuka"], "title": "Deep Unfolding for MIMO Signal Detection", "comment": null, "summary": "In this paper, we propose a deep unfolding neural network-based MIMO detector\nthat incorporates complex-valued computations using Wirtinger calculus. The\nmethod, referred as Dynamic Partially Shrinkage Thresholding (DPST), enables\nefficient, interpretable, and low-complexity MIMO signal detection. Unlike\nprior approaches that rely on real-valued approximations, our method operates\nnatively in the complex domain, aligning with the fundamental nature of signal\nprocessing tasks. The proposed algorithm requires only a small number of\ntrainable parameters, allowing for simplified training. Numerical results\ndemonstrate that the proposed method achieves superior detection performance\nwith fewer iterations and lower computational complexity, making it a practical\nsolution for next-generation massive MIMO systems.", "AI": {"tldr": "A deep unfolding neural network-based MIMO detector using Wirtinger calculus, called DPST, offers efficient, interpretable, and low-complexity signal detection in the complex domain.", "motivation": "Prior methods rely on real-valued approximations, which misalign with the complex nature of signal processing tasks.", "method": "Dynamic Partially Shrinkage Thresholding (DPST) operates natively in the complex domain with minimal trainable parameters.", "result": "Superior detection performance with fewer iterations and lower computational complexity.", "conclusion": "DPST is a practical solution for next-generation massive MIMO systems."}}
{"id": "2507.22049", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.22049", "abs": "https://arxiv.org/abs/2507.22049", "authors": ["Logan Cross", "Nick Haber", "Daniel L. K. Yamins"], "title": "Validating Generative Agent-Based Models of Social Norm Enforcement: From Replication to Novel Predictions", "comment": null, "summary": "As large language models (LLMs) advance, there is growing interest in using\nthem to simulate human social behavior through generative agent-based modeling\n(GABM). However, validating these models remains a key challenge. We present a\nsystematic two-stage validation approach using social dilemma paradigms from\npsychological literature, first identifying the cognitive components necessary\nfor LLM agents to reproduce known human behaviors in mixed-motive settings from\ntwo landmark papers, then using the validated architecture to simulate novel\nconditions. Our model comparison of different cognitive architectures shows\nthat both persona-based individual differences and theory of mind capabilities\nare essential for replicating third-party punishment (TPP) as a costly signal\nof trustworthiness. For the second study on public goods games, this\narchitecture is able to replicate an increase in cooperation from the spread of\nreputational information through gossip. However, an additional strategic\ncomponent is necessary to replicate the additional boost in cooperation rates\nin the condition that allows both ostracism and gossip. We then test novel\npredictions for each paper with our validated generative agents. We find that\nTPP rates significantly drop in settings where punishment is anonymous, yet a\nsubstantial amount of TPP persists, suggesting that both reputational and\nintrinsic moral motivations play a role in this behavior. For the second paper,\nwe introduce a novel intervention and see that open discussion periods before\nrounds of the public goods game further increase contributions, allowing groups\nto develop social norms for cooperation. This work provides a framework for\nvalidating generative agent models while demonstrating their potential to\ngenerate novel and testable insights into human social behavior.", "AI": {"tldr": "The paper presents a two-stage validation approach for using LLMs in generative agent-based modeling (GABM) to simulate human social behavior, focusing on social dilemmas. It identifies key cognitive components and tests novel predictions.", "motivation": "To address the challenge of validating LLM-based simulations of human social behavior, particularly in mixed-motive settings.", "method": "A systematic two-stage validation using social dilemma paradigms, comparing cognitive architectures (persona-based differences and theory of mind) and testing novel conditions.", "result": "Key findings include the necessity of persona-based differences and theory of mind for replicating behaviors like third-party punishment (TPP) and cooperation in public goods games. Novel predictions were also tested.", "conclusion": "The work provides a validation framework for GABM and demonstrates its potential to generate new insights into human social behavior."}}
{"id": "2507.21123", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21123", "abs": "https://arxiv.org/abs/2507.21123", "authors": ["Mark A. Kramer", "Aanchal Mathur", "Caroline E. Adams", "Jason A. Walonoski"], "title": "Leveraging Generative AI to Enhance Synthea Module Development", "comment": "Title: Leveraging Generative AI to Enhance Synthea Module Development\n  Word Count: [Approximately 12,000 words] Figures: 3 Tables: 3 Supplementary\n  Material: Extensive appendices with prompts and disease profiles", "summary": "This paper explores the use of large language models (LLMs) to assist in the\ndevelopment of new disease modules for Synthea, an open-source synthetic health\ndata generator. Incorporating LLMs into the module development process has the\npotential to reduce development time, reduce required expertise, expand model\ndiversity, and improve the overall quality of synthetic patient data. We\ndemonstrate four ways that LLMs can support Synthea module creation: generating\na disease profile, generating a disease module from a disease profile,\nevaluating an existing Synthea module, and refining an existing module. We\nintroduce the concept of progressive refinement, which involves iteratively\nevaluating the LLM-generated module by checking its syntactic correctness and\nclinical accuracy, and then using that information to modify the module. While\nthe use of LLMs in this context shows promise, we also acknowledge the\nchallenges and limitations, such as the need for human oversight, the\nimportance of rigorous testing and validation, and the potential for\ninaccuracies in LLM-generated content. The paper concludes with recommendations\nfor future research and development to fully realize the potential of LLM-aided\nsynthetic data creation.", "AI": {"tldr": "The paper investigates using LLMs to streamline Synthea disease module development, highlighting benefits like reduced time and expertise, and introduces progressive refinement for iterative improvement.", "motivation": "To enhance synthetic health data quality and diversity by leveraging LLMs for faster, less expert-dependent module development.", "method": "LLMs assist in generating disease profiles, modules, evaluating existing modules, and refining them through progressive refinement.", "result": "LLMs show promise in improving module development but require human oversight and validation due to potential inaccuracies.", "conclusion": "Future research is needed to fully harness LLMs for synthetic data creation, addressing challenges like oversight and validation."}}
{"id": "2507.21153", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21153", "abs": "https://arxiv.org/abs/2507.21153", "authors": ["Abderaouf Bahi", "Amel Ourici"], "title": "Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers", "comment": null, "summary": "This paper explores the implementation of a Deep Reinforcement Learning\n(DRL)-optimized energy management system for e-commerce data centers, aimed at\nenhancing energy efficiency, cost-effectiveness, and environmental\nsustainability. The proposed system leverages DRL algorithms to dynamically\nmanage the integration of renewable energy sources, energy storage, and grid\npower, adapting to fluctuating energy availability in real time. The study\ndemonstrates that the DRL-optimized system achieves a 38\\% reduction in energy\ncosts, significantly outperforming traditional Reinforcement Learning (RL)\nmethods (28\\%) and heuristic approaches (22\\%). Additionally, it maintains a\nlow SLA violation rate of 1.5\\%, compared to 3.0\\% for RL and 4.8\\% for\nheuristic methods. The DRL-optimized approach also results in an 82\\%\nimprovement in energy efficiency, surpassing other methods, and a 45\\%\nreduction in carbon emissions, making it the most environmentally friendly\nsolution. The system's cumulative reward of 950 reflects its superior\nperformance in balancing multiple objectives. Through rigorous testing and\nablation studies, the paper validates the effectiveness of the DRL model's\narchitecture and parameters, offering a robust solution for energy management\nin data centers. The findings highlight the potential of DRL in advancing\nenergy optimization strategies and addressing sustainability challenges.", "AI": {"tldr": "A DRL-optimized energy management system for e-commerce data centers reduces costs by 38%, improves energy efficiency by 82%, and cuts carbon emissions by 45%, outperforming traditional methods.", "motivation": "To enhance energy efficiency, cost-effectiveness, and environmental sustainability in e-commerce data centers by dynamically managing renewable energy, storage, and grid power.", "method": "Uses Deep Reinforcement Learning (DRL) algorithms for real-time energy management, adapting to fluctuating energy availability.", "result": "Achieves 38% cost reduction, 82% energy efficiency improvement, 45% lower carbon emissions, and 1.5% SLA violation rate, outperforming RL and heuristic methods.", "conclusion": "DRL offers a robust solution for energy management, advancing sustainability and optimization in data centers."}}
{"id": "2507.21159", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21159", "abs": "https://arxiv.org/abs/2507.21159", "authors": ["Zhihao Peng", "Liuxin Bao", "Shengyuan Liu", "Yixuan Yuan"], "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity", "comment": null, "summary": "The collaborativeness of large language models (LLMs) has proven effective in\nnatural language processing systems, holding considerable promise for\nhealthcare development. However, it lacks explicit component selection rules,\nnecessitating human intervention or clinical-specific validation. Moreover,\nexisting architectures heavily rely on a predefined LLM cluster, where partial\nLLMs underperform in medical decision support scenarios, invalidating the\ncollaborativeness of LLMs. To this end, we propose an adaptive cluster\ncollaborativeness methodology involving self-diversity and cross-consistency\nmaximization mechanisms to boost LLMs medical decision support capacity. For\nthe self-diversity, we calculate the fuzzy matching value of pairwise outputs\nwithin an LLM as its self-diversity value, subsequently prioritizing LLMs with\nhigh self-diversity values as cluster components in a training-free manner. For\nthe cross-consistency, we first measure cross-consistency values between the\nLLM with the highest self-diversity value and others, and then gradually mask\nout the LLM having the lowest cross-consistency value to eliminate the\npotential inconsistent output during the collaborative propagation. Extensive\nexperiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health,\ndemonstrate the effectiveness of our method across physician-oriented\nspecialties. For example, on NEJMQA, our method achieves the accuracy rate up\nto the publicly official passing score across all disciplines, especially\nachieving ACC of 65.47\\% compared to the 56.12\\% achieved by GPT-4 on the\nObstetrics and Gynecology discipline.", "AI": {"tldr": "The paper proposes an adaptive cluster collaborativeness methodology for LLMs in healthcare, using self-diversity and cross-consistency mechanisms to improve medical decision support without predefined clusters.", "motivation": "Current LLM collaborativeness lacks explicit selection rules and relies on predefined clusters, leading to underperformance in medical scenarios.", "method": "Introduces self-diversity (fuzzy matching of pairwise outputs) and cross-consistency (masking inconsistent LLMs) mechanisms to enhance LLM cluster performance.", "result": "Achieves higher accuracy (e.g., 65.47% vs. GPT-4's 56.12% on Obstetrics and Gynecology) on medical datasets like NEJMQA and MMLU-Pro-health.", "conclusion": "The proposed method effectively improves LLM collaborativeness for medical decision support, outperforming existing approaches."}}
{"id": "2507.21129", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21129", "abs": "https://arxiv.org/abs/2507.21129", "authors": ["Jae Wan Shim"], "title": "Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics", "comment": null, "summary": "The remarkable capabilities of Large Language Models (LLMs) are now\nextensively documented on task-specific benchmarks, yet the internal mechanisms\nthat produce these results are the subject of intense scientific inquiry. This\npaper contributes to this inquiry by moving beyond metrics that measure\n\\textit{what} models can do, to a methodology that characterizes \\textit{how}\nthey process information. We introduce a novel, task-agnostic approach to probe\nthese dynamics by creating a quantitative ``Cognitive Profile\" for any given\nmodel. This profile is centered on the \\textbf{Entropy Decay Curve}, a\nvisualization that traces how a model's normalized predictive uncertainty\nchanges as a function of context length. Applying this methodology to several\nstate-of-the-art LLMs across diverse texts, we uncover unique and consistent\ncognitive profiles that are sensitive to both model scale and text complexity.\nWe also introduce the Information Gain Span (IGS) index to summarize the\ndesirability of the decay trajectory. This work thus provides a new, principled\nlens for analyzing and comparing the intrinsic operational dynamics of\nartificial intelligence.", "AI": {"tldr": "The paper introduces a task-agnostic method to analyze LLMs' internal processing via a 'Cognitive Profile,' focusing on the Entropy Decay Curve and Information Gain Span (IGS) index.", "motivation": "To move beyond task-specific benchmarks and understand how LLMs process information internally.", "method": "Develops a quantitative 'Cognitive Profile' using the Entropy Decay Curve and IGS index to analyze predictive uncertainty across context lengths.", "result": "Reveals unique cognitive profiles in LLMs, sensitive to model scale and text complexity.", "conclusion": "Offers a principled framework for comparing LLMs' operational dynamics beyond traditional benchmarks."}}
{"id": "2507.21155", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21155", "abs": "https://arxiv.org/abs/2507.21155", "authors": ["Malcolm Wolff", "Matthew Li", "Ravi Kiran Selvam", "Hanjing Zhu", "Kin G. Olivares", "Ruijun Ma", "Abhinav Katoch", "Shankar Ramasubramanian", "Mengfei Cao", "Roberto Bandarra", "Rahul Gopalsamy", "Stefania La Vattiata", "Sitan Yang", "Michael M. Mahoney"], "title": "SPADE-S: A Sparsity-Robust Foundational Forecaster", "comment": null, "summary": "Despite significant advancements in time series forecasting, accurate\nmodeling of time series with strong heterogeneity in magnitude and/or sparsity\npatterns remains challenging for state-of-the-art deep learning architectures.\nWe identify several factors that lead existing models to systematically\nunderperform on low-magnitude and sparse time series, including loss functions\nwith implicit biases toward high-magnitude series, training-time sampling\nmethods, and limitations of time series encoding methods.\n  SPADE-S is a robust forecasting architecture that significantly reduces\nmagnitude- and sparsity-based systematic biases and improves overall prediction\naccuracy. Empirical results demonstrate that SPADE-S outperforms existing\nstate-of-the-art approaches across a diverse set of use cases in demand\nforecasting. In particular, we show that, depending on the quantile forecast\nand magnitude of the series, SPADE-S can improve forecast accuracy by up to\n15%. This results in P90 overall forecast accuracy gains of 2.21%, 6.58%, and\n4.28%, and P50 forecast accuracy gains of 0.92%, 0.77%, and 1.95%,\nrespectively, for each of three distinct datasets, ranging from 3 million to\n700 million series, from a large online retailer.", "AI": {"tldr": "SPADE-S is a forecasting model addressing biases in time series with low magnitude/sparsity, improving accuracy by up to 15% over existing methods.", "motivation": "Existing models underperform on low-magnitude and sparse time series due to biases in loss functions, sampling, and encoding methods.", "method": "SPADE-S reduces biases in magnitude and sparsity, enhancing prediction accuracy.", "result": "SPADE-S outperforms state-of-the-art methods, with accuracy gains up to 15%, notably in demand forecasting.", "conclusion": "SPADE-S effectively addresses systematic biases, improving forecast accuracy across diverse datasets."}}
{"id": "2507.21354", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21354", "abs": "https://arxiv.org/abs/2507.21354", "authors": ["Monika Zamojska", "Jaros\u0142aw A. Chudziak"], "title": "Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems", "comment": "Proceedings of the Annual Meeting of the Cognitive Science Society\n  (CogSci 2025), https://escholarship.org/uc/item/7gg6j165", "summary": "Multi-Agent Systems (MAS) are increasingly used to simulate social\ninteractions, but most of the frameworks miss the underlying cognitive\ncomplexity of human behavior. In this paper, we introduce Trans-ACT\n(Transactional Analysis Cognitive Toolkit), an approach embedding Transactional\nAnalysis (TA) principles into MAS to generate agents with realistic\npsychological dynamics. Trans-ACT integrates the Parent, Adult, and Child ego\nstates into an agent's cognitive architecture. Each ego state retrieves\ncontext-specific memories and uses them to shape response to new situations.\nThe final answer is chosen according to the underlying life script of the\nagent. Our experimental simulation, which reproduces the Stupid game scenario,\ndemonstrates that agents grounded in cognitive and TA principles produce deeper\nand context-aware interactions. Looking ahead, our research opens a new way for\na variety of applications, including conflict resolution, educational support,\nand advanced social psychology studies.", "AI": {"tldr": "Trans-ACT integrates Transactional Analysis into Multi-Agent Systems to create psychologically realistic agents, improving social interaction simulations.", "motivation": "Current MAS frameworks lack cognitive complexity for human-like behavior. Trans-ACT addresses this gap by embedding TA principles.", "method": "Trans-ACT incorporates Parent, Adult, and Child ego states into agents, using context-specific memories and life scripts to shape responses.", "result": "Agents with TA principles produce deeper, context-aware interactions, demonstrated in the Stupid game scenario.", "conclusion": "Trans-ACT enables advanced applications like conflict resolution, education, and social psychology studies."}}
{"id": "2507.21130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21130", "abs": "https://arxiv.org/abs/2507.21130", "authors": ["Bintao Tang", "Xin Yang", "Yuhao Wang", "Zixuan Qiu", "Zimo Ji", "Wenyuan Jiang"], "title": "INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems", "comment": "19 pages, 5 figures", "summary": "We present INTEGRALBENCH, a focused benchmark designed to evaluate Large\nLanguage Model (LLM) performance on definite integral problems. INTEGRALBENCH\nprovides both symbolic and numerical ground truth solutions with manual\ndifficulty annotations. Our evaluation of nine state-of-the-art LLMs reveals\nsignificant performance gaps and strong correlations between problem difficulty\nand model accuracy, establishing baseline metrics for this challenging domain.\nINTEGRALBENCH aims to advance automated mathematical reasoning by providing a\nrigorous evaluation framework specifically tailored for definite integral\ncomputation.", "AI": {"tldr": "INTEGRALBENCH is a benchmark for evaluating LLMs on definite integrals, revealing performance gaps and difficulty-accuracy correlations.", "motivation": "To advance automated mathematical reasoning by providing a rigorous evaluation framework for definite integral computation.", "method": "INTEGRALBENCH offers symbolic and numerical ground truth solutions with difficulty annotations, evaluating nine state-of-the-art LLMs.", "result": "Significant performance gaps and strong correlations between problem difficulty and model accuracy were found.", "conclusion": "INTEGRALBENCH establishes baseline metrics for LLM performance on definite integrals, aiding progress in mathematical reasoning."}}
{"id": "2507.21160", "categories": ["cs.LG", "cs.AI", "68T07 (Primary), 68T45, 68T10 (Secondary)", "I.5.1"], "pdf": "https://arxiv.org/pdf/2507.21160", "abs": "https://arxiv.org/abs/2507.21160", "authors": ["Lakpa Tamang", "Mohamed Reda Bouadjenek", "Richard Dazeley", "Sunil Aryal"], "title": "Handling Out-of-Distribution Data: A Survey", "comment": "20 pages, 6 figures, 6 tables. Accepted at IEEE Transactions on\n  Knowledge and Data Engineering", "summary": "In the field of Machine Learning (ML) and data-driven applications, one of\nthe significant challenge is the change in data distribution between the\ntraining and deployment stages, commonly known as distribution shift. This\npaper outlines different mechanisms for handling two main types of distribution\nshifts: (i) Covariate shift: where the value of features or covariates change\nbetween train and test data, and (ii) Concept/Semantic-shift: where model\nexperiences shift in the concept learned during training due to emergence of\nnovel classes in the test phase. We sum up our contributions in three folds.\nFirst, we formalize distribution shifts, recite on how the conventional method\nfails to handle them adequately and urge for a model that can simultaneously\nperform better in all types of distribution shifts. Second, we discuss why\nhandling distribution shifts is important and provide an extensive review of\nthe methods and techniques that have been developed to detect, measure, and\nmitigate the effects of these shifts. Third, we discuss the current state of\ndistribution shift handling mechanisms and propose future research directions\nin this area. Overall, we provide a retrospective synopsis of the literature in\nthe distribution shift, focusing on OOD data that had been overlooked in the\nexisting surveys.", "AI": {"tldr": "The paper addresses distribution shifts in ML, categorizing them into covariate and concept shifts, and reviews methods to handle them.", "motivation": "The challenge of data distribution changes between training and deployment stages in ML applications.", "method": "Formalizes distribution shifts, reviews conventional methods, and discusses detection and mitigation techniques.", "result": "Identifies gaps in handling shifts and proposes future research directions.", "conclusion": "Provides a comprehensive review of distribution shift literature, emphasizing overlooked OOD data."}}
{"id": "2507.21631", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21631", "abs": "https://arxiv.org/abs/2507.21631", "authors": ["Miguel Faria", "Francisco S. Melo", "Ana Paiva"], "title": "\"Teammates, Am I Clear?\": Analysing Legible Behaviours in Teams", "comment": null, "summary": "In this paper we investigate the notion of legibility in sequential\ndecision-making in the context of teams and teamwork. There have been works\nthat extend the notion of legibility to sequential decision making, for\ndeterministic and for stochastic scenarios. However, these works focus on one\nagent interacting with one human, foregoing the benefits of having legible\ndecision making in teams of agents or in team configurations with humans. In\nthis work we propose an extension of legible decision-making to multi-agent\nsettings that improves the performance of agents working in collaboration. We\nshowcase the performance of legible decision making in team scenarios using our\nproposed extension in multi-agent benchmark scenarios. We show that a team with\na legible agent is able to outperform a team composed solely of agents with\nstandard optimal behaviour.", "AI": {"tldr": "The paper extends legible decision-making to multi-agent settings, improving team performance in sequential tasks.", "motivation": "Existing works on legible decision-making focus on single-agent interactions, neglecting the benefits in team settings.", "method": "Proposes an extension of legible decision-making for multi-agent scenarios and tests it in benchmark environments.", "result": "Teams with legible agents outperform those with standard optimal behavior.", "conclusion": "Legible decision-making enhances collaboration and performance in multi-agent teams."}}
{"id": "2507.21131", "categories": ["cs.AI", "68T05", "H.5.1; I.2.6; C.4"], "pdf": "https://arxiv.org/pdf/2507.21131", "abs": "https://arxiv.org/abs/2507.21131", "authors": ["Madhava Gaikwad", "Ashwini Ramchandra Doke"], "title": "NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback", "comment": "20 pages", "summary": "We present NPO, an alignment-aware learning framework that operationalizes\nfeedback-driven adaptation in human-in-the-loop decision systems. Unlike prior\napproaches that treat alignment as a static or post-hoc property, NPO\nintroduces a formalization of alignment loss that is measurable, supervisable,\nand reducible under structured feedback. In parallel, we propose meta-alignment\nas the fidelity of the monitoring process that governs retraining or override\ntriggers, and show that it is formally reducible to primary alignment via\nthreshold fidelity. Our implementation spans a scalable operational loop\ninvolving scenario scoring, threshold tuning, policy validation, and structured\nfeedback ingestion, including \"likes\", overrides, and abstentions. We provide\nformal convergence results under stochastic feedback and show that both\nalignment loss and monitoring fidelity converge additively. Empirically, NPO\ndemonstrates measurable value in hyperscale deployment settings. A\nsimulation-based artifact and ablation studies further illustrate the\ntheoretical principles in action. Together, NPO offers a compact, inspectable\narchitecture for continual alignment monitoring, helping bridge theoretical\nalignment guarantees with practical reliability in dynamic environments.", "AI": {"tldr": "NPO is an alignment-aware learning framework for human-in-the-loop systems, focusing on measurable alignment loss and meta-alignment for continuous monitoring and adaptation.", "motivation": "To address the limitations of static or post-hoc alignment approaches by introducing a dynamic, feedback-driven system for alignment in decision-making.", "method": "NPO formalizes alignment loss and meta-alignment, using structured feedback (e.g., likes, overrides) in a scalable loop involving scenario scoring, threshold tuning, and policy validation.", "result": "Formal convergence results show alignment loss and monitoring fidelity improve additively. Empirical results confirm NPO's effectiveness in hyperscale deployments.", "conclusion": "NPO provides a compact, inspectable architecture for continual alignment monitoring, bridging theoretical guarantees with practical reliability in dynamic environments."}}
{"id": "2507.21164", "categories": ["cs.LG", "cs.AI", "eess.IV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21164", "abs": "https://arxiv.org/abs/2507.21164", "authors": ["Nicolas Pinon", "Carole Lartizien"], "title": "OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection", "comment": null, "summary": "Unsupervised anomaly detection (UAD) aims to detect anomalies without labeled\ndata, a necessity in many machine learning applications where anomalous samples\nare rare or not available. Most state-of-the-art methods fall into two\ncategories: reconstruction-based approaches, which often reconstruct anomalies\ntoo well, and decoupled representation learning with density estimators, which\ncan suffer from suboptimal feature spaces. While some recent methods attempt to\ncouple feature learning and anomaly detection, they often rely on surrogate\nobjectives, restrict kernel choices, or introduce approximations that limit\ntheir expressiveness and robustness. To address this challenge, we propose a\nnovel method that tightly couples representation learning with an analytically\nsolvable one-class SVM (OCSVM), through a custom loss formulation that directly\naligns latent features with the OCSVM decision boundary. The model is evaluated\non two tasks: a new benchmark based on MNIST-C, and a challenging brain MRI\nsubtle lesion detection task. Unlike most methods that focus on large,\nhyperintense lesions at the image level, our approach succeeds to target small,\nnon-hyperintense lesions, while we evaluate voxel-wise metrics, addressing a\nmore clinically relevant scenario. Both experiments evaluate a form of\nrobustness to domain shifts, including corruption types in MNIST-C and\nscanner/age variations in MRI. Results demonstrate performance and robustness\nof our proposed mode,highlighting its potential for general UAD and real-world\nmedical imaging applications. The source code is available at\nhttps://github.com/Nicolas-Pinon/uad_ocsvm_guided_repr_learning", "AI": {"tldr": "A novel unsupervised anomaly detection method couples representation learning with a one-class SVM, demonstrating robustness in tasks like MNIST-C and brain MRI lesion detection.", "motivation": "Address limitations of existing UAD methods, such as poor anomaly reconstruction or suboptimal feature spaces, by tightly integrating feature learning with anomaly detection.", "method": "Proposes a custom loss formulation aligning latent features with an analytically solvable one-class SVM decision boundary.", "result": "Outperforms in detecting small, non-hyperintense brain lesions and shows robustness to domain shifts in MNIST-C and MRI tasks.", "conclusion": "The method is effective for general UAD and medical imaging, with potential for real-world applications."}}
{"id": "2507.21132", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21132", "abs": "https://arxiv.org/abs/2507.21132", "authors": ["Joshua Adrian Cahyono", "Saran Subramanian"], "title": "Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses", "comment": null, "summary": "Large Language Models (LLMs) are increasingly consulted for high-stakes life\nadvice, yet they lack standard safeguards against providing confident but\nmisguided responses. This creates risks of sycophancy and over-confidence. This\npaper investigates these failure modes through three experiments: (1) a\nmultiple-choice evaluation to measure model stability against user pressure;\n(2) a free-response analysis using a novel safety typology and an LLM Judge;\nand (3) a mechanistic interpretability experiment to steer model behavior by\nmanipulating a \"high-stakes\" activation vector. Our results show that while\nsome models exhibit sycophancy, others like o4-mini remain robust.\nTop-performing models achieve high safety scores by frequently asking\nclarifying questions, a key feature of a safe, inquisitive approach, rather\nthan issuing prescriptive advice. Furthermore, we demonstrate that a model's\ncautiousness can be directly controlled via activation steering, suggesting a\nnew path for safety alignment. These findings underscore the need for nuanced,\nmulti-faceted benchmarks to ensure LLMs can be trusted with life-changing\ndecisions.", "AI": {"tldr": "The paper examines risks of sycophancy and over-confidence in LLMs when providing life advice, testing model robustness, safety, and controllability through experiments.", "motivation": "LLMs lack safeguards for high-stakes advice, risking misguided responses. The study aims to address these failure modes.", "method": "Three experiments: (1) multiple-choice evaluation for stability, (2) free-response analysis with safety typology, and (3) mechanistic interpretability to steer behavior.", "result": "Some models show sycophancy, but others like o4-mini are robust. Top models achieve safety by asking clarifying questions. Activation steering can control cautiousness.", "conclusion": "Nuanced benchmarks are needed to ensure LLMs can be trusted for life-changing decisions, with activation steering offering a new safety alignment path."}}
{"id": "2507.21166", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21166", "abs": "https://arxiv.org/abs/2507.21166", "authors": ["Ren Zhuang", "Ben Wang", "Shuifa Sun"], "title": "AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation", "comment": null, "summary": "Progress in complex reasoning is constrained by the static nature of the\ncurrent training datasets. We propose structured interaction as a new scaling\naxis, moving beyond the prevailing paradigm of increasing model parameters. Our\nself-evolving framework, AGORA, enables a collaborative ensemble to achieve\nreasoning performance exceeding state-of-the-art monolithic systems by up to\n4.45 percentage points on challenging mathematical benchmarks. This gain stems\nfrom group emergent ability-the synthesis of collective capabilities\nunattainable by isolated models, validating interaction as a scalable driver of\nintelligence. Our results position the engineering of collaborative ecosystems\nas a vital frontier for capability emergence.", "AI": {"tldr": "AGORA introduces structured interaction as a scaling axis, outperforming monolithic models by 4.45% on math benchmarks through collaborative ensemble reasoning.", "motivation": "Current training datasets are static, limiting complex reasoning progress. The paper explores interaction as a scalable alternative to increasing model parameters.", "method": "Proposes AGORA, a self-evolving framework enabling collaborative ensembles to enhance reasoning via group emergent abilities.", "result": "Achieves a 4.45 percentage point improvement over state-of-the-art monolithic systems on mathematical benchmarks.", "conclusion": "Collaborative ecosystems are a promising frontier for advancing AI capabilities, with interaction as a key driver of intelligence."}}
{"id": "2507.21137", "categories": ["cs.AI", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.21137", "abs": "https://arxiv.org/abs/2507.21137", "authors": ["Arman Eisenkolb-Vaithyanathan"], "title": "Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?", "comment": "24 pages, 8 Figures", "summary": "In this paper we try to answer the question \"What constitutes Sudoku\ndifficulty rating across different Sudoku websites?\" Using two distinct methods\nthat can both solve every Sudoku puzzle, I propose two new metrics to\ncharacterize Sudoku difficulty. The first method is based on converting a\nSudoku puzzle into its corresponding Satisfiability (SAT) problem. The first\nproposed metric is derived from SAT Clause Length Distribution which captures\nthe structural complexity of a Sudoku puzzle including the number of given\ndigits and the cells they are in. The second method simulates human Sudoku\nsolvers by intertwining four popular Sudoku strategies within a backtracking\nalgorithm called Nishio. The second metric is computed by counting the number\nof times Sudoku strategies are applied within the backtracking iterations of a\nrandomized Nishio. Using these two metrics, I analyze more than a thousand\nSudoku puzzles across five popular websites to characterize every difficulty\nlevel in each website. I evaluate the relationship between the proposed metrics\nand website-labeled difficulty levels using Spearman's rank correlation\ncoefficient, finding strong correlations for 4 out of 5 websites. I construct a\nuniversal rating system using a simple, unsupervised classifier based on the\ntwo proposed metrics. This rating system is capable of classifying both\nindividual puzzles and entire difficulty levels from the different Sudoku\nwebsites into three categories - Universal Easy, Universal Medium, and\nUniversal Hard - thereby enabling consistent difficulty mapping across Sudoku\nwebsites. The experimental results show that for 4 out of 5 Sudoku websites,\nthe universal classification aligns well with website-labeled difficulty\nlevels. Finally, I present an algorithm that can be used by early Sudoku\npractitioners to solve Sudoku puzzles.", "AI": {"tldr": "The paper proposes two new metrics to rate Sudoku difficulty using SAT problem conversion and human solver simulation, achieving strong correlation with website labels and creating a universal rating system.", "motivation": "To understand and standardize Sudoku difficulty ratings across different websites, addressing inconsistencies in labeled difficulty levels.", "method": "Two methods: (1) Convert Sudoku to SAT problem for structural complexity metrics, (2) Simulate human solvers using backtracking (Nishio) with strategy counts. Analyzed 1000+ puzzles from 5 websites.", "result": "Strong correlation (4/5 websites) between proposed metrics and labeled difficulty. Universal rating system (Easy, Medium, Hard) aligns well with website labels.", "conclusion": "The proposed metrics and universal rating system effectively standardize Sudoku difficulty across websites, with potential for aiding early practitioners."}}
{"id": "2507.21179", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21179", "abs": "https://arxiv.org/abs/2507.21179", "authors": ["Yuqi Jin", "Zihan Hu", "Weiteng Zhang", "Weihao Xie", "Jianwei Shuai", "Xian Shen", "Zhen Feng"], "title": "LLM-Adapted Interpretation Framework for Machine Learning Models", "comment": "11 pages, 8 figures, 2 tables", "summary": "Background & Aims: High-performance machine learning models like XGBoost are\noften \"black boxes,\" limiting their clinical adoption due to a lack of\ninterpretability. This study aims to bridge the gap between predictive accuracy\nand narrative transparency for sarcopenia risk assessment. Methods: We propose\nthe LLM-Adapted Interpretation Framework (LAI-ML), a novel knowledge\ndistillation architecture. LAI-ML transforms feature attributions from a\ntrained XGBoost model into a probabilistic format using specialized techniques\n(HAGA and CACS). A Large Language Model (LLM), guided by a reinforcement\nlearning loop and case-based retrieval, then generates data-faithful diagnostic\nnarratives. Results: The LAI-ML framework achieved 83% prediction accuracy,\nsignificantly outperforming the baseline XGBoost model, 13% higher. Notably,\nthe LLM not only replicated the teacher model's logic but also corrected its\npredictions in 21.7% of discordant cases, demonstrating enhanced reasoning.\nConclusion: LAI-ML effectively translates opaque model predictions into\ntrustworthy and interpretable clinical insights, offering a deployable solution\nto the \"black-box\" problem in medical AI.", "AI": {"tldr": "LAI-ML framework enhances interpretability of XGBoost for sarcopenia risk assessment, improving accuracy and generating transparent diagnostic narratives.", "motivation": "Address the lack of interpretability in high-performance ML models like XGBoost to enable clinical adoption.", "method": "Proposes LAI-ML, a knowledge distillation architecture using HAGA and CACS techniques to transform XGBoost feature attributions into probabilistic formats, then uses an LLM with reinforcement learning for narrative generation.", "result": "Achieved 83% prediction accuracy (13% higher than baseline XGBoost) and corrected 21.7% of discordant cases.", "conclusion": "LAI-ML successfully bridges the gap between accuracy and interpretability, providing a deployable solution for medical AI."}}
{"id": "2507.21141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21141", "abs": "https://arxiv.org/abs/2507.21141", "authors": ["McNair Shah", "Saleena Angeline", "Adhitya Rajendra Kumar", "Naitik Chheda", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien", "Will Cai"], "title": "The Geometry of Harmfulness in LLMs through Subconcept Probing", "comment": null, "summary": "Recent advances in large language models (LLMs) have intensified the need to\nunderstand and reliably curb their harmful behaviours. We introduce a\nmultidimensional framework for probing and steering harmful content in model\ninternals. For each of 55 distinct harmfulness subconcepts (e.g., racial hate,\nemployment scams, weapons), we learn a linear probe, yielding 55 interpretable\ndirections in activation space. Collectively, these directions span a\nharmfulness subspace that we show is strikingly low-rank. We then test ablation\nof the entire subspace from model internals, as well as steering and ablation\nin the subspace's dominant direction. We find that dominant direction steering\nallows for near elimination of harmfulness with a low decrease in utility. Our\nfindings advance the emerging view that concept subspaces provide a scalable\nlens on LLM behaviour and offer practical tools for the community to audit and\nharden future generations of language models.", "AI": {"tldr": "A framework probes and steers harmful content in LLMs using 55 interpretable directions in activation space, showing low-rank harmfulness subspaces. Steering the dominant direction nearly eliminates harmfulness with minimal utility loss.", "motivation": "To understand and reliably curb harmful behaviors in large language models (LLMs) by probing and steering their internal representations.", "method": "Developed a multidimensional framework with 55 linear probes for distinct harmfulness subconcepts, identifying a low-rank harmfulness subspace. Tested ablation and steering in this subspace.", "result": "Dominant direction steering nearly eliminates harmfulness with little utility decrease, demonstrating the effectiveness of concept subspaces.", "conclusion": "Concept subspaces offer a scalable way to audit and improve LLM behavior, providing practical tools for mitigating harmfulness."}}
{"id": "2507.21183", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.21183", "abs": "https://arxiv.org/abs/2507.21183", "authors": ["Guangchen Lan", "Sipeng Zhang", "Tianle Wang", "Yuwei Zhang", "Daoan Zhang", "Xinpeng Wei", "Xiaoman Pan", "Hongming Zhang", "Dong-Jun Han", "Christopher G. Brinton"], "title": "MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge", "comment": null, "summary": "As the era of large language models (LLMs) on behalf of users unfolds,\nPreference Optimization (PO) methods have become a central approach to aligning\nLLMs with human preferences and improving performance. We propose Maximum a\nPosteriori Preference Optimization (MaPPO), a framework for learning from\npreferences that explicitly incorporates prior reward knowledge into the\noptimization objective. While existing methods such as Direct Preference\nOptimization (DPO) and its variants treat preference learning as a Maximum\nLikelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating\nprior reward estimates into a principled Maximum a Posteriori (MaP) objective.\nThis not only generalizes DPO and its variants, but also enhances alignment by\nmitigating the oversimplified binary classification of responses. More\nimportantly, MaPPO introduces no additional hyperparameter, and supports\npreference optimization in both offline and online settings. In addition, MaPPO\ncan be used as a plugin with consistent improvement on DPO variants, including\nwidely used SimPO, IPO, and CPO. Extensive empirical evaluations of different\nmodel sizes and model series on three standard benchmarks, including MT-Bench,\nAlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in\nalignment performance without sacrificing computational efficiency.", "AI": {"tldr": "MaPPO is a new framework for aligning LLMs with human preferences by incorporating prior reward knowledge into optimization, outperforming existing methods like DPO without extra hyperparameters.", "motivation": "Existing methods like DPO treat preference learning as MLE, oversimplifying response classification. MaPPO aims to integrate prior knowledge for better alignment.", "method": "MaPPO extends MLE to a Maximum a Posteriori objective, incorporating prior reward estimates, and works offline/online without new hyperparameters.", "result": "MaPPO consistently improves alignment performance on benchmarks like MT-Bench and AlpacaEval 2.0, without sacrificing efficiency.", "conclusion": "MaPPO generalizes and enhances existing methods, offering a robust, hyperparameter-free solution for preference optimization in LLMs."}}
{"id": "2507.21158", "categories": ["cs.AI", "cs.HC", "H.1.2; I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.21158", "abs": "https://arxiv.org/abs/2507.21158", "authors": ["Nishani Fernando", "Bahareh Nakisa", "Adnan Ahmad", "Mohammad Naim Rastgoo"], "title": "Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams", "comment": "15 pages, 1 figure, Accepted to MAI-XAI@ECAI2025", "summary": "Effective human-AI teaming heavily depends on swift trust, particularly in\nhigh-stakes scenarios such as emergency response, where timely and accurate\ndecision-making is critical. In these time-sensitive and cognitively demanding\nsettings, adaptive explainability is essential for fostering trust between\nhuman operators and AI systems. However, existing explainable AI (XAI)\napproaches typically offer uniform explanations and rely heavily on explicit\nfeedback mechanisms, which are often impractical in such high-pressure\nscenarios. To address this gap, we propose a conceptual framework for adaptive\nXAI that operates non-intrusively by responding to users' real-time cognitive\nand emotional states through implicit feedback, thereby enhancing swift trust\nin high-stakes environments. The proposed adaptive explainability trust\nframework (AXTF) leverages physiological and behavioral signals, such as EEG,\nECG, and eye tracking, to infer user states and support explanation adaptation.\nAt its core is a multi-objective, personalized trust estimation model that maps\nworkload, stress, and emotion to dynamic trust estimates. These estimates guide\nthe modulation of explanation features enabling responsive and personalized\nsupport that promotes swift trust in human-AI collaboration. This conceptual\nframework establishes a foundation for developing adaptive, non-intrusive XAI\nsystems tailored to the rigorous demands of high-pressure, time-sensitive\nenvironments.", "AI": {"tldr": "Proposes a framework for adaptive explainable AI (XAI) using implicit feedback to enhance swift trust in high-stakes human-AI teams.", "motivation": "Swift trust is critical in high-stakes scenarios like emergency response, but current XAI lacks adaptability and relies on impractical explicit feedback.", "method": "Introduces the adaptive explainability trust framework (AXTF), which uses physiological and behavioral signals (e.g., EEG, ECG, eye tracking) to infer user states and personalize explanations.", "result": "AXTF dynamically adjusts explanations based on real-time cognitive and emotional states, fostering swift trust in human-AI collaboration.", "conclusion": "The framework lays groundwork for adaptive, non-intrusive XAI systems suited for high-pressure, time-sensitive environments."}}
{"id": "2507.21184", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21184", "abs": "https://arxiv.org/abs/2507.21184", "authors": ["Haowei Lin", "Xiangyu Wang", "Jianzhu Ma", "Yitao Liang"], "title": "EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models", "comment": null, "summary": "Scaling laws are fundamental mathematical relationships that predict how\nneural network performance evolves with changes in variables such as model\nsize, dataset size, and computational resources. Traditionally, discovering\nthese laws requires extensive human expertise and manual experimentation. We\nintroduce EvoSLD, an automated framework for Scaling Law Discovery (SLD) that\nleverages evolutionary algorithms guided by Large Language Models (LLMs) to\nco-evolve symbolic expressions and their optimization routines. Formulated to\nhandle scaling variables, control variables, and response metrics across\ndiverse experimental settings, EvoSLD searches for parsimonious, universal\nfunctional forms that minimize fitting errors on grouped data subsets.\nEvaluated on five real-world scenarios from recent literature, EvoSLD\nrediscovers exact human-derived laws in two cases and surpasses them in others,\nachieving up to orders-of-magnitude reductions in normalized mean squared error\non held-out test sets. Compared to baselines like symbolic regression and\nablated variants, EvoSLD demonstrates superior accuracy, interpretability, and\nefficiency, highlighting its potential to accelerate AI research. Code is\navailable at https://github.com/linhaowei1/SLD.", "AI": {"tldr": "EvoSLD is an automated framework for discovering scaling laws in neural networks using evolutionary algorithms and LLMs, outperforming manual methods and baselines in accuracy and efficiency.", "motivation": "Traditional scaling law discovery requires extensive human expertise and manual effort, prompting the need for an automated solution.", "method": "EvoSLD uses evolutionary algorithms guided by LLMs to co-evolve symbolic expressions and optimization routines, handling scaling and control variables across diverse settings.", "result": "EvoSLD rediscovers human-derived laws in some cases and surpasses them in others, achieving significant error reductions on test sets.", "conclusion": "EvoSLD offers superior accuracy, interpretability, and efficiency, potentially accelerating AI research."}}
{"id": "2507.21188", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21188", "abs": "https://arxiv.org/abs/2507.21188", "authors": ["Raj Krishnan Vijayaraj"], "title": "Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs", "comment": null, "summary": "LLMs for clinical decision support often fail under small but clinically\nmeaningful input shifts such as masking a symptom or negating a finding,\ndespite high performance on static benchmarks. These reasoning failures\nfrequently go undetected by standard NLP metrics, which are insensitive to\nlatent representation shifts that drive diagnosis instability. We propose a\ngeometry-aware evaluation framework, LAPD (Latent Agentic Perturbation\nDiagnostics), which systematically probes the latent robustness of clinical\nLLMs under structured adversarial edits. Within this framework, we introduce\nLatent Diagnosis Flip Rate (LDFR), a model-agnostic diagnostic signal that\ncaptures representational instability when embeddings cross decision boundaries\nin PCA-reduced latent space. Clinical notes are generated using a structured\nprompting pipeline grounded in diagnostic reasoning, then perturbed along four\naxes: masking, negation, synonym replacement, and numeric variation to simulate\ncommon ambiguities and omissions. We compute LDFR across both foundation and\nclinical LLMs, finding that latent fragility emerges even under minimal\nsurface-level changes. Finally, we validate our findings on 90 real clinical\nnotes from the DiReCT benchmark (MIMIC-IV), confirming the generalizability of\nLDFR beyond synthetic settings. Our results reveal a persistent gap between\nsurface robustness and semantic stability, underscoring the importance of\ngeometry-aware auditing in safety-critical clinical AI.", "AI": {"tldr": "The paper introduces LAPD, a geometry-aware framework to evaluate clinical LLMs' robustness under adversarial edits, revealing latent fragility despite high static benchmark performance.", "motivation": "Clinical LLMs often fail under small input shifts (e.g., masking symptoms), which standard NLP metrics miss. This gap threatens reliability in safety-critical settings.", "method": "Proposes LAPD with Latent Diagnosis Flip Rate (LDFR) to measure representational instability. Uses structured adversarial edits (masking, negation, etc.) on synthetic and real clinical notes.", "result": "Latent fragility emerges even with minor input changes. LDFR generalizes to real clinical notes (DiReCT benchmark), exposing gaps in surface robustness.", "conclusion": "Geometry-aware auditing (LAPD) is crucial for clinical AI safety, as latent instability persists despite high benchmark performance."}}
{"id": "2507.21162", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21162", "abs": "https://arxiv.org/abs/2507.21162", "authors": ["Xu Yang", "Chenhui Lin", "Yue Yang", "Qi Wang", "Haotian Liu", "Haizhou Hua", "Wenchuan Wu"], "title": "Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems", "comment": null, "summary": "The increasing penetration of distributed energy resources into active\ndistribution networks (ADNs) has made effective ADN dispatch imperative.\nHowever, the numerous newly-integrated ADN operators, such as distribution\nsystem aggregators, virtual power plant managers, and end prosumers, often lack\nspecialized expertise in power system operation, modeling, optimization, and\nprogramming. This knowledge gap renders reliance on human experts both costly\nand time-intensive. To address this challenge and enable intelligent, flexible\nADN dispatch, this paper proposes a large language model (LLM) powered\nautomated modeling and optimization approach. First, the ADN dispatch problems\nare decomposed into sequential stages, and a multi-LLM coordination\narchitecture is designed. This framework comprises an Information Extractor, a\nProblem Formulator, and a Code Programmer, tasked with information retrieval,\noptimization problem formulation, and code implementation, respectively.\nAfterwards, tailored refinement techniques are developed for each LLM agent,\ngreatly improving the accuracy and reliability of generated content. The\nproposed approach features a user-centric interface that enables ADN operators\nto derive dispatch strategies via simple natural language queries, eliminating\ntechnical barriers and increasing efficiency. Comprehensive comparisons and\nend-to-end demonstrations on various test cases validate the effectiveness of\nthe proposed architecture and methods.", "AI": {"tldr": "The paper proposes an LLM-powered automated approach for ADN dispatch, decomposing problems into stages and using multi-LLM coordination for modeling and optimization, validated by test cases.", "motivation": "The integration of distributed energy resources into ADNs requires expert knowledge, which is costly and time-intensive. The paper aims to bridge this gap with an automated, user-friendly solution.", "method": "Decomposes ADN dispatch into stages, designs a multi-LLM framework (Information Extractor, Problem Formulator, Code Programmer), and refines each LLM agent for accuracy.", "result": "The approach enables ADN operators to derive dispatch strategies via natural language queries, validated by comprehensive comparisons and demonstrations.", "conclusion": "The proposed LLM-powered method effectively addresses the knowledge gap in ADN dispatch, offering an intelligent, flexible, and efficient solution."}}
{"id": "2507.21189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21189", "abs": "https://arxiv.org/abs/2507.21189", "authors": ["Andrew Kiruluta", "Andreas Lemos", "Priscilla Burity"], "title": "Operator-Based Machine Intelligence: A Hilbert Space Framework for Spectral Learning and Symbolic Reasoning", "comment": null, "summary": "Traditional machine learning models, particularly neural networks, are rooted\nin finite-dimensional parameter spaces and nonlinear function approximations.\nThis report explores an alternative formulation where learning tasks are\nexpressed as sampling and computation in infinite dimensional Hilbert spaces,\nleveraging tools from functional analysis, signal processing, and spectral\ntheory. We review foundational concepts such as Reproducing Kernel Hilbert\nSpaces (RKHS), spectral operator learning, and wavelet-domain representations.\nWe present a rigorous mathematical formulation of learning in Hilbert spaces,\nhighlight recent models based on scattering transforms and Koopman operators,\nand discuss advantages and limitations relative to conventional neural\narchitectures. The report concludes by outlining directions for scalable and\ninterpretable machine learning grounded in Hilbertian signal processing.", "AI": {"tldr": "The paper explores learning tasks in infinite-dimensional Hilbert spaces, using tools from functional analysis and spectral theory, as an alternative to traditional neural networks.", "motivation": "To move beyond finite-dimensional parameter spaces and leverage infinite-dimensional Hilbert spaces for more expressive and interpretable machine learning.", "method": "Uses Reproducing Kernel Hilbert Spaces (RKHS), spectral operator learning, and wavelet-domain representations, with models like scattering transforms and Koopman operators.", "result": "Provides a rigorous mathematical framework for learning in Hilbert spaces, comparing advantages and limitations against traditional neural networks.", "conclusion": "Proposes scalable and interpretable machine learning directions based on Hilbertian signal processing."}}
{"id": "2507.21171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21171", "abs": "https://arxiv.org/abs/2507.21171", "authors": ["Federico Donato", "Adrien Barton"], "title": "An ontological analysis of risk in Basic Formal Ontology", "comment": "7 pages. 2 figures. Conference: Semantic Technology for Intelligence,\n  Defense, and Security (STIDS 2024)", "summary": "The paper explores the nature of risk, providing a characterization using the\ncategories of the Basic Formal Ontology (BFO). It argues that the category Risk\nis a subclass of BFO:Role, contrasting it with a similar view classifying Risk\nas a subclass of BFO:Disposition. This modeling choice is applied on one\nexample of risk, which represents objects, processes (both physical and mental)\nand their interrelations, then generalizing from the instances in the example\nto obtain an overall analysis of risk, making explicit what are the sufficient\nconditions for being a risk. Plausible necessary conditions are also mentioned\nfor future work. Index Terms: ontology, risk, BFO, role, disposition", "AI": {"tldr": "The paper characterizes risk using BFO, arguing it's a subclass of BFO:Role, not BFO:Disposition, and provides an example-based analysis to define sufficient conditions for risk.", "motivation": "To clarify the ontological classification of risk within BFO, distinguishing it from dispositions.", "method": "Uses BFO categories, applies modeling to an example of risk, and generalizes the analysis to define sufficient conditions.", "result": "Risk is classified as a subclass of BFO:Role, with sufficient conditions for being a risk identified.", "conclusion": "The paper provides a clear ontological framework for risk, suggesting future work on necessary conditions."}}
{"id": "2507.21190", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21190", "abs": "https://arxiv.org/abs/2507.21190", "authors": ["Andrew Kiruluta", "Andreas Lemos", "Priscilla Burity"], "title": "Beyond Neural Networks: Symbolic Reasoning over Wavelet Logic Graph Signals", "comment": null, "summary": "We present a fully non neural learning framework based on Graph Laplacian\nWavelet Transforms (GLWT). Unlike traditional architectures that rely on\nconvolutional, recurrent, or attention based neural networks, our model\noperates purely in the graph spectral domain using structured multiscale\nfiltering, nonlinear shrinkage, and symbolic logic over wavelet coefficients.\nSignals defined on graph nodes are decomposed via GLWT, modulated with\ninterpretable nonlinearities, and recombined for downstream tasks such as\ndenoising and token classification. The system supports compositional reasoning\nthrough a symbolic domain-specific language (DSL) over graph wavelet\nactivations. Experiments on synthetic graph denoising and linguistic token\ngraphs demonstrate competitive performance against lightweight GNNs with far\ngreater transparency and efficiency. This work proposes a principled,\ninterpretable, and resource-efficient alternative to deep neural architectures\nfor learning on graphs.", "AI": {"tldr": "A non-neural learning framework using Graph Laplacian Wavelet Transforms (GLWT) for graph-based tasks, offering interpretability and efficiency.", "motivation": "To provide a transparent and resource-efficient alternative to neural networks for graph learning.", "method": "Uses GLWT for signal decomposition, nonlinear shrinkage, and symbolic logic over wavelet coefficients, with a domain-specific language (DSL) for reasoning.", "result": "Competitive performance in denoising and token classification tasks compared to lightweight GNNs, with greater transparency.", "conclusion": "Proposes a principled, interpretable, and efficient non-neural approach for graph learning."}}
{"id": "2507.21172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21172", "abs": "https://arxiv.org/abs/2507.21172", "authors": ["John Beverley", "Danielle Limbaugh"], "title": "Ontological Foundations of State Sovereignty", "comment": "6 pages. 0 figures. Conference: Semantic Technology for Intelligence,\n  Defense, and Security (STIDS 2024)", "summary": "This short paper is a primer on the nature of state sovereignty and the\nimportance of claims about it. It also aims to reveal (merely reveal) a\nstrategy for working with vague or contradictory data about which states, in\nfact, are sovereign. These goals together are intended to set the stage for\napplied work in ontology about international affairs.", "AI": {"tldr": "A primer on state sovereignty, its claims, and a strategy for handling vague or contradictory data about sovereign states, aiming to support ontology work in international affairs.", "motivation": "To clarify the nature of state sovereignty and its claims, and to address challenges in identifying sovereign states for applied ontology in international affairs.", "method": "Presents a strategy for dealing with vague or contradictory data about sovereign states.", "result": "Provides foundational insights for ontology work in international affairs by addressing sovereignty ambiguities.", "conclusion": "The paper lays groundwork for future applied research in ontology related to state sovereignty and international affairs."}}
{"id": "2507.21191", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21191", "abs": "https://arxiv.org/abs/2507.21191", "authors": ["Garv Kaushik"], "title": "Exploring Adaptive Structure Learning for Heterophilic Graphs", "comment": "Initially submitted this draft at Tiny ICLR 2025", "summary": "Graph Convolutional Networks (GCNs) gained traction for graph representation\nlearning, with recent attention on improving performance on heterophilic graphs\nfor various real-world applications. The localized feature aggregation in a\ntypical message-passing paradigm hinders the capturing of long-range\ndependencies between non-local nodes of the same class. The inherent\nconnectivity structure in heterophilic graphs often conflicts with information\nsharing between distant nodes of same class. We propose structure learning to\nrewire edges in shallow GCNs itself to avoid performance degradation in\ndownstream discriminative tasks due to oversmoothing. Parameterizing the\nadjacency matrix to learn connections between non-local nodes and extend the\nhop span of shallow GCNs facilitates the capturing of long-range dependencies.\nHowever, our method is not generalizable across heterophilic graphs and\nperforms inconsistently on node classification task contingent to the graph\nstructure.", "AI": {"tldr": "The paper proposes structure learning to rewire edges in shallow GCNs to capture long-range dependencies in heterophilic graphs, though it lacks generalizability.", "motivation": "Improving GCN performance on heterophilic graphs by addressing limitations in capturing long-range dependencies due to localized feature aggregation.", "method": "Parameterizing the adjacency matrix to learn connections between non-local nodes and extending the hop span of shallow GCNs.", "result": "The method captures long-range dependencies but performs inconsistently on node classification tasks and lacks generalizability across heterophilic graphs.", "conclusion": "While effective for specific cases, the method's inconsistency and lack of generalizability highlight the need for further research."}}
{"id": "2507.21176", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21176", "abs": "https://arxiv.org/abs/2507.21176", "authors": ["Farzana Islam Adiba", "Rahmatollah Beheshti"], "title": "Tell Me You're Biased Without Telling Me You're Biased -- Toward Revealing Implicit Biases in Medical LLMs", "comment": null, "summary": "Large language models (LLMs) that are used in medical applications are known\nto show biased and unfair patterns. Prior to adopting these in clinical\ndecision-making applications, it is crucial to identify these bias patterns to\nenable effective mitigation of their impact. In this study, we present a novel\nframework combining knowledge graphs (KGs) with auxiliary LLMs to\nsystematically reveal complex bias patterns in medical LLMs. Specifically, the\nproposed approach integrates adversarial perturbation techniques to identify\nsubtle bias patterns. The approach adopts a customized multi-hop\ncharacterization of KGs to enhance the systematic evaluation of arbitrary LLMs.\nThrough a series of comprehensive experiments (on three datasets, six LLMs, and\nfive bias types), we show that our proposed framework has noticeably greater\nability and scalability to reveal complex biased patterns of LLMs compared to\nother baselines.", "AI": {"tldr": "A novel framework combining knowledge graphs and auxiliary LLMs to detect and mitigate biases in medical LLMs, outperforming baselines in revealing complex bias patterns.", "motivation": "To address the biased and unfair patterns in LLMs used in medical applications, ensuring their reliability for clinical decision-making.", "method": "Integrates knowledge graphs with adversarial perturbation techniques and multi-hop KG characterization to systematically evaluate LLMs.", "result": "Demonstrates superior ability and scalability in identifying complex biases across datasets, LLMs, and bias types.", "conclusion": "The framework effectively reveals and mitigates biases in medical LLMs, enhancing their clinical applicability."}}
{"id": "2507.21196", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21196", "abs": "https://arxiv.org/abs/2507.21196", "authors": ["Abir Ray"], "title": "EdgeAgentX-DT: Integrating Digital Twins and Generative AI for Resilient Edge Intelligence in Tactical Networks", "comment": "13 pages, 6 figures", "summary": "We introduce EdgeAgentX-DT, an advanced extension of the EdgeAgentX framework\nthat integrates digital twin simulations and generative AI-driven scenario\ntraining to significantly enhance edge intelligence in military networks.\nEdgeAgentX-DT utilizes network digital twins, virtual replicas synchronized\nwith real-world edge devices, to provide a secure, realistic environment for\ntraining and validation. Leveraging generative AI methods, such as diffusion\nmodels and transformers, the system creates diverse and adversarial scenarios\nfor robust simulation-based agent training. Our multi-layer architecture\nincludes: (1) on-device edge intelligence; (2) digital twin synchronization;\nand (3) generative scenario training. Experimental simulations demonstrate\nnotable improvements over EdgeAgentX, including faster learning convergence,\nhigher network throughput, reduced latency, and improved resilience against\njamming and node failures. A case study involving a complex tactical scenario\nwith simultaneous jamming attacks, agent failures, and increased network loads\nillustrates how EdgeAgentX-DT sustains operational performance, whereas\nbaseline methods fail. These results highlight the potential of\ndigital-twin-enabled generative training to strengthen edge AI deployments in\ncontested environments.", "AI": {"tldr": "EdgeAgentX-DT enhances edge intelligence in military networks using digital twins and generative AI for robust training and validation.", "motivation": "To improve edge intelligence in contested military environments by integrating digital twins and generative AI for realistic and adversarial training.", "method": "Uses network digital twins synchronized with real-world devices and generative AI (diffusion models, transformers) for scenario training. Multi-layer architecture includes edge intelligence, twin synchronization, and generative training.", "result": "Faster learning convergence, higher throughput, reduced latency, and improved resilience against jamming and failures. Outperforms baseline in tactical scenarios.", "conclusion": "EdgeAgentX-DT demonstrates the effectiveness of digital-twin-enabled generative training for robust edge AI in contested environments."}}
{"id": "2507.21206", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21206", "abs": "https://arxiv.org/abs/2507.21206", "authors": ["Yingxuan Yang", "Mulei Ma", "Yuxuan Huang", "Huacan Chai", "Chenyu Gong", "Haoran Geng", "Yuanjian Zhou", "Ying Wen", "Meng Fang", "Muhao Chen", "Shangding Gu", "Ming Jin", "Costas Spanos", "Yang Yang", "Pieter Abbeel", "Dawn Song", "Weinan Zhang", "Jun Wang"], "title": "Agentic Web: Weaving the Next Web with AI Agents", "comment": null, "summary": "The emergence of AI agents powered by large language models (LLMs) marks a\npivotal shift toward the Agentic Web, a new phase of the internet defined by\nautonomous, goal-driven interactions. In this paradigm, agents interact\ndirectly with one another to plan, coordinate, and execute complex tasks on\nbehalf of users. This transition from human-driven to machine-to-machine\ninteraction allows intent to be delegated, relieving users from routine digital\noperations and enabling a more interactive, automated web experience. In this\npaper, we present a structured framework for understanding and building the\nAgentic Web. We trace its evolution from the PC and Mobile Web eras and\nidentify the core technological foundations that support this shift. Central to\nour framework is a conceptual model consisting of three key dimensions:\nintelligence, interaction, and economics. These dimensions collectively enable\nthe capabilities of AI agents, such as retrieval, recommendation, planning, and\ncollaboration. We analyze the architectural and infrastructural challenges\ninvolved in creating scalable agentic systems, including communication\nprotocols, orchestration strategies, and emerging paradigms such as the Agent\nAttention Economy. We conclude by discussing the potential applications,\nsocietal risks, and governance issues posed by agentic systems, and outline\nresearch directions for developing open, secure, and intelligent ecosystems\nshaped by both human intent and autonomous agent behavior. A continuously\nupdated collection of relevant studies for agentic web is available at:\nhttps://github.com/SafeRL-Lab/agentic-web.", "AI": {"tldr": "The paper introduces the Agentic Web, a new internet phase driven by AI agents using LLMs, enabling autonomous, goal-driven interactions. It proposes a framework with three dimensions (intelligence, interaction, economics) to understand and build this system, addressing challenges and societal impacts.", "motivation": "The shift from human-driven to machine-to-machine interaction aims to automate routine tasks, enhance web interactivity, and delegate user intent, improving digital experiences.", "method": "The paper presents a structured framework with three key dimensions (intelligence, interaction, economics) and analyzes architectural and infrastructural challenges like communication protocols and orchestration strategies.", "result": "The framework enables AI agent capabilities (retrieval, recommendation, planning, collaboration) and identifies applications, risks, and governance issues of agentic systems.", "conclusion": "The paper outlines research directions for developing secure, intelligent ecosystems balancing human intent and autonomous agent behavior, with ongoing updates at a provided GitHub link."}}
{"id": "2507.21197", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21197", "abs": "https://arxiv.org/abs/2507.21197", "authors": ["Ling Liao", "Eva Aagaard"], "title": "AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction", "comment": "11 pages, 3 figures", "summary": "Machine learning interpretation has primarily been leveraged to build\nclinician trust and uncover actionable insights in EHRs. However, the intrinsic\ncomplexity and heterogeneity of EHR data limit its effectiveness in guiding\nsubgroup-specific modeling. We propose AdaptHetero, a novel MLI-driven\nframework that transforms interpretability insights into actionable guidance\nfor tailoring model training and evaluation across subpopulations within\nindividual hospital systems. Evaluated on three large-scale EHR datasets -\nGOSSIS-1-eICU, WiDS, and MIMIC-IV - AdaptHetero consistently identifies\nheterogeneous model behaviors in predicting ICU mortality, in-hospital death,\nand hidden hypoxemia. By integrating SHAP-based interpretation and unsupervised\nclustering, the framework enhances the identification of clinically meaningful\nsubgroup-specific characteristics, leading to improved predictive performance.", "AI": {"tldr": "AdaptHetero is an MLI-driven framework that uses interpretability insights to tailor model training for EHR subpopulations, improving predictive performance.", "motivation": "The complexity and heterogeneity of EHR data limit the effectiveness of machine learning interpretation in guiding subgroup-specific modeling.", "method": "The framework integrates SHAP-based interpretation and unsupervised clustering to identify subgroup-specific characteristics.", "result": "Evaluated on three datasets, AdaptHetero identifies heterogeneous model behaviors and improves predictive performance for ICU mortality, in-hospital death, and hidden hypoxemia.", "conclusion": "AdaptHetero effectively transforms interpretability insights into actionable guidance for subgroup-specific modeling in EHRs."}}
{"id": "2507.21257", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21257", "abs": "https://arxiv.org/abs/2507.21257", "authors": ["David Maria Schmidt", "Raoul Schubert", "Philipp Cimiano"], "title": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "comment": "Research Track, 24th International Semantic Web Conference (ISWC\n  2025), November 2-6, 2025, Nara, Japan", "summary": "Language interpretation is a compositional process, in which the meaning of\nmore complex linguistic structures is inferred from the meaning of their parts.\nLarge language models possess remarkable language interpretation capabilities\nand have been successfully applied to interpret questions by mapping them to\nSPARQL queries. An open question is how systematic this interpretation process\nis. Toward this question, in this paper, we propose a benchmark for\ninvestigating to what extent the abilities of LLMs to interpret questions are\nactually compositional. For this, we generate three datasets of varying\ndifficulty based on graph patterns in DBpedia, relying on Lemon lexica for\nverbalization. Our datasets are created in a very controlled fashion in order\nto test the ability of LLMs to interpret structurally complex questions, given\nthat they have seen the atomic building blocks. This allows us to evaluate to\nwhat degree LLMs are able to interpret complex questions for which they\n\"understand\" the atomic parts. We conduct experiments with models of different\nsizes using both various prompt and few-shot optimization techniques as well as\nfine-tuning. Our results show that performance in terms of macro $F_1$ degrades\nfrom $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the\nsamples optimized on. Even when all necessary information was provided to the\nmodel in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of\nlowest complexity. We thus conclude that LLMs struggle to systematically and\ncompositionally interpret questions and map them into SPARQL queries.", "AI": {"tldr": "The paper investigates the compositional interpretation abilities of large language models (LLMs) in mapping questions to SPARQL queries, revealing their limitations despite their general language capabilities.", "motivation": "To assess how systematic LLMs are in interpreting complex questions compositionally, given their success in simpler tasks.", "method": "Created three controlled datasets of varying complexity based on DBpedia graph patterns, using Lemon lexica for verbalization. Tested LLMs with different sizes, prompts, few-shot techniques, and fine-tuning.", "result": "Performance (macro $F_1$) degraded from 0.45 to 0.09 with increasing complexity. Even with all necessary input, scores did not exceed 0.57 for the simplest dataset.", "conclusion": "LLMs struggle with systematic and compositional interpretation of questions into SPARQL queries."}}
{"id": "2507.21198", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21198", "abs": "https://arxiv.org/abs/2507.21198", "authors": ["Xinguo Feng", "Zhongkui Ma", "Zihan Wang", "Eu Joe Chegne", "Mengyao Ma", "Alsharif Abuadbba", "Guangdong Bai"], "title": "Uncovering Gradient Inversion Risks in Practical Language Model Training", "comment": "15 Pages, 5 figures, 10 tables. Accepted by ACM CCS 2024", "summary": "The gradient inversion attack has been demonstrated as a significant privacy\nthreat to federated learning (FL), particularly in continuous domains such as\nvision models. In contrast, it is often considered less effective or highly\ndependent on impractical training settings when applied to language models, due\nto the challenges posed by the discrete nature of tokens in text data. As a\nresult, its potential privacy threats remain largely underestimated, despite FL\nbeing an emerging training method for language models. In this work, we propose\na domain-specific gradient inversion attack named Grab (gradient inversion with\nhybrid optimization). Grab features two alternating optimization processes to\naddress the challenges caused by practical training settings, including a\nsimultaneous optimization on dropout masks between layers for improved token\nrecovery and a discrete optimization for effective token sequencing. Grab can\nrecover a significant portion (up to 92.9% recovery rate) of the private\ntraining data, outperforming the attack strategy of utilizing discrete\noptimization with an auxiliary model by notable improvements of up to 28.9%\nrecovery rate in benchmark settings and 48.5% recovery rate in practical\nsettings. Grab provides a valuable step forward in understanding this privacy\nthreat in the emerging FL training mode of language models.", "AI": {"tldr": "Grab, a gradient inversion attack for language models in FL, recovers up to 92.9% of private data, outperforming prior methods by 28.9%-48.5%.", "motivation": "Privacy threats in FL for language models are underestimated due to discrete token challenges.", "method": "Grab uses hybrid optimization: alternating dropout mask optimization and discrete token sequencing.", "result": "Achieves up to 92.9% recovery rate, surpassing prior methods significantly.", "conclusion": "Grab advances understanding of privacy risks in FL for language models."}}
{"id": "2507.21276", "categories": ["cs.AI", "cs.CL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.21276", "abs": "https://arxiv.org/abs/2507.21276", "authors": ["Yufei Li", "Zexin Li", "Yinglun Zhu", "Cong Liu"], "title": "LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems", "comment": "Accepted by RTSS 2025", "summary": "Modern deployment of large language models (LLMs) frequently involves both\ninference serving and continuous retraining to stay aligned with evolving data\nand user feedback. Common practices separate these workloads onto distinct\nservers in isolated phases, causing substantial inefficiencies (e.g., GPU\nidleness) and delayed adaptation to new data in distributed settings. Our\nempirical analysis reveals that these inefficiencies stem from dynamic request\narrivals during serving and workload heterogeneity in pipeline-parallel\ntraining. To address these challenges, we propose LeMix, a system for\nco-locating and managing concurrent LLM serving and training workloads. LeMix\nintegrates offline profiling, execution prediction mechanisms, and runtime\nscheduling to dynamically adapt resource allocation based on workload\ncharacteristics and system conditions. By understanding task-specific behaviors\nand co-execution interference across shared nodes, LeMix improves utilization\nand serving quality without compromising serving responsiveness. Our evaluation\nshows that LeMix improves throughput by up to 3.53x, reduces inference loss by\nup to 0.61x, and delivers up to 2.12x higher response time SLO attainment over\ntraditional separate setups. To our knowledge, this is the first work to\nuncover and exploit the opportunities of joint LLM inference and training,\npaving the way for more resource-efficient deployment of LLMs in production\nenvironments.", "AI": {"tldr": "LeMix is a system for co-locating LLM serving and training workloads, improving efficiency and responsiveness over traditional separate setups.", "motivation": "Inefficiencies in GPU usage and delayed adaptation due to separate serving and training phases in LLM deployment.", "method": "Integrates offline profiling, execution prediction, and runtime scheduling to dynamically allocate resources.", "result": "Improves throughput by up to 3.53x, reduces inference loss by 0.61x, and enhances response time SLO attainment by 2.12x.", "conclusion": "LeMix demonstrates the benefits of joint LLM inference and training, enabling more resource-efficient deployment."}}
{"id": "2507.21199", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.21199", "abs": "https://arxiv.org/abs/2507.21199", "authors": ["Xinye Cao", "Hongcan Guo", "Guoshun Nan", "Jiaoyang Cui", "Haoting Qian", "Yihan Lin", "Yilin Peng", "Diyang Zhang", "Yanzhao Hou", "Huici Wu", "Xiaofeng Tao", "Tony Q. S. Quek"], "title": "Advancing Compositional LLM Reasoning with Structured Task Relations in Interactive Multimodal Communications", "comment": "Accepted by IEEE JSAC. This work has been submitted to the IEEE for\n  possible publication", "summary": "Interactive multimodal applications (IMAs), such as route planning in the\nInternet of Vehicles, enrich users' personalized experiences by integrating\nvarious forms of data over wireless networks. Recent advances in large language\nmodels (LLMs) utilize mixture-of-experts (MoE) mechanisms to empower multiple\nIMAs, with each LLM trained individually for a specific task that presents\ndifferent business workflows. In contrast to existing approaches that rely on\nmultiple LLMs for IMAs, this paper presents a novel paradigm that accomplishes\nvarious IMAs using a single compositional LLM over wireless networks. The two\nprimary challenges include 1) guiding a single LLM to adapt to diverse IMA\nobjectives and 2) ensuring the flexibility and efficiency of the LLM in\nresource-constrained mobile environments. To tackle the first challenge, we\npropose ContextLoRA, a novel method that guides an LLM to learn the rich\nstructured context among IMAs by constructing a task dependency graph. We\npartition the learnable parameter matrix of neural layers for each IMA to\nfacilitate LLM composition. Then, we develop a step-by-step fine-tuning\nprocedure guided by task relations, including training, freezing, and masking\nphases. This allows the LLM to learn to reason among tasks for better\nadaptation, capturing the latent dependencies between tasks. For the second\nchallenge, we introduce ContextGear, a scheduling strategy to optimize the\ntraining procedure of ContextLoRA, aiming to minimize computational and\ncommunication costs through a strategic grouping mechanism. Experiments on\nthree benchmarks show the superiority of the proposed ContextLoRA and\nContextGear. Furthermore, we prototype our proposed paradigm on a real-world\nwireless testbed, demonstrating its practical applicability for various IMAs.\nWe will release our code to the community.", "AI": {"tldr": "The paper introduces a single compositional LLM for diverse IMAs, proposing ContextLoRA for task adaptation and ContextGear for efficiency, validated on benchmarks and a real-world testbed.", "motivation": "To address the inefficiency of using multiple LLMs for IMAs by developing a unified approach adaptable to diverse tasks in resource-constrained environments.", "method": "Proposes ContextLoRA for structured context learning via task dependency graphs and ContextGear for optimized training, with step-by-step fine-tuning.", "result": "Superior performance on benchmarks and practical applicability demonstrated on a wireless testbed.", "conclusion": "The paradigm offers an efficient, flexible solution for IMAs using a single LLM, with code to be released."}}
{"id": "2507.21285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21285", "abs": "https://arxiv.org/abs/2507.21285", "authors": ["Harsh Darji", "Thibaud Lutellier"], "title": "Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used as coding assistants.\nHowever, the ambiguity of the developer's prompt often leads to incorrect code\ngeneration, as current models struggle to infer user intent without extensive\nprompt engineering or external context. This work aims to build an LLM-based\ncoding assistant that mimics the human code review process by asking\nclarification questions when faced with ambiguous or under-specified queries.\n  Our end-to-end system includes (1) a query classifier trained to detect\nunclear programming-related queries and (2) a fine-tuned LLM that generates\nclarification questions. Our evaluation shows that the fine-tuned LLM\noutperforms standard zero-shot prompting in generating useful clarification\nquestions. Furthermore, our user study indicates that users find the\nclarification questions generated by our model to outperform the baseline,\ndemonstrating that our coding assistant produces more accurate and helpful code\nresponses compared to baseline coding assistants.", "AI": {"tldr": "An LLM-based coding assistant improves code generation accuracy by asking clarification questions for ambiguous prompts, outperforming zero-shot prompting.", "motivation": "Current LLMs struggle with ambiguous developer prompts, leading to incorrect code generation. The goal is to mimic human code review by clarifying unclear queries.", "method": "The system includes a query classifier for detecting unclear programming queries and a fine-tuned LLM for generating clarification questions.", "result": "The fine-tuned LLM outperforms zero-shot prompting in generating useful questions, and users find the assistant's responses more accurate and helpful.", "conclusion": "The proposed coding assistant enhances accuracy by addressing prompt ambiguity through clarification questions, proving more effective than baseline methods."}}
{"id": "2507.21205", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21205", "abs": "https://arxiv.org/abs/2507.21205", "authors": ["Harsh Rangwani"], "title": "Learning from Limited and Imperfect Data", "comment": "PhD Thesis", "summary": "The distribution of data in the world (eg, internet, etc.) significantly\ndiffers from the well-curated datasets and is often over-populated with samples\nfrom common categories. The algorithms designed for well-curated datasets\nperform suboptimally when used for learning from imperfect datasets with\nlong-tailed imbalances and distribution shifts. To expand the use of deep\nmodels, it is essential to overcome the labor-intensive curation process by\ndeveloping robust algorithms that can learn from diverse, real-world data\ndistributions. Toward this goal, we develop practical algorithms for Deep\nNeural Networks which can learn from limited and imperfect data present in the\nreal world. This thesis is divided into four segments, each covering a scenario\nof learning from limited or imperfect data. The first part of the thesis\nfocuses on Learning Generative Models from Long-Tail Data, where we mitigate\nthe mode-collapse and enable diverse aesthetic image generations for tail\n(minority) classes. In the second part, we enable effective generalization on\ntail classes through Inductive Regularization schemes, which allow tail classes\nto generalize as effectively as the head classes without requiring explicit\ngeneration of images. In the third part, we develop algorithms for Optimizing\nRelevant Metrics for learning from long-tailed data with limited annotation\n(semi-supervised), followed by the fourth part, which focuses on the Efficient\nDomain Adaptation of the model to various domains with very few to zero labeled\nsamples.", "AI": {"tldr": "The paper addresses the challenge of training deep models on real-world, imbalanced data by developing robust algorithms for diverse scenarios, including generative modeling, inductive regularization, semi-supervised learning, and domain adaptation.", "motivation": "Real-world data is often imbalanced and imperfect, unlike curated datasets. Existing algorithms perform poorly on such data, necessitating robust methods to reduce reliance on labor-intensive curation.", "method": "The thesis proposes four approaches: 1) Learning generative models for long-tail data, 2) Inductive regularization for tail-class generalization, 3) Optimizing metrics for semi-supervised learning, and 4) Efficient domain adaptation with minimal labeled data.", "result": "The developed algorithms mitigate mode-collapse in generative models, improve tail-class generalization, optimize learning metrics, and enable domain adaptation with few or no labeled samples.", "conclusion": "The work advances deep learning for real-world data by addressing imbalances and distribution shifts, reducing the need for curated datasets."}}
{"id": "2507.21287", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21287", "abs": "https://arxiv.org/abs/2507.21287", "authors": ["Aryan Raj", "Astitva Veer Garg", "Anitha D"], "title": "Structured Relevance Assessment for Robust Retrieval-Augmented Language Models", "comment": "International Conference on ICT for Sustainable Development (ICT4SD)", "summary": "Retrieval-Augmented Language Models (RALMs) face significant challenges in\nreducing factual errors, particularly in document relevance evaluation and\nknowledge integration. We introduce a framework for structured relevance\nassessment that enhances RALM robustness through improved document evaluation,\nbalanced intrinsic and external knowledge integration, and effective handling\nof unanswerable queries. Our approach employs a multi-dimensional scoring\nsystem that considers both semantic matching and source reliability, utilizing\nembedding-based relevance scoring and synthetic training data with\nmixed-quality documents. We implement specialized benchmarking on niche topics,\na knowledge integration mechanism, and an \"unknown\" response protocol for\nqueries with insufficient knowledge coverage. Preliminary evaluations\ndemonstrate significant reductions in hallucination rates and improved\ntransparency in reasoning processes. Our framework advances the development of\nmore reliable question-answering systems capable of operating effectively in\ndynamic environments with variable data quality. While challenges persist in\naccurately distinguishing credible information and balancing system latency\nwith thoroughness, this work represents a meaningful step toward enhancing RALM\nreliability.", "AI": {"tldr": "A framework for structured relevance assessment improves Retrieval-Augmented Language Models (RALMs) by reducing factual errors, enhancing document evaluation, and balancing knowledge integration. It uses multi-dimensional scoring, synthetic data, and specialized benchmarking to reduce hallucinations and improve transparency.", "motivation": "RALMs struggle with factual errors, document relevance evaluation, and knowledge integration. The goal is to enhance robustness and reliability in question-answering systems.", "method": "The framework employs a multi-dimensional scoring system (semantic matching and source reliability), embedding-based relevance scoring, synthetic training data, and specialized benchmarking. It also includes a knowledge integration mechanism and an \"unknown\" response protocol.", "result": "Preliminary evaluations show reduced hallucination rates and improved transparency in reasoning. The framework advances reliable question-answering in dynamic environments.", "conclusion": "The work improves RALM reliability despite challenges in distinguishing credible information and balancing latency. It represents progress toward more robust systems."}}
{"id": "2507.21244", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.21244", "abs": "https://arxiv.org/abs/2507.21244", "authors": ["Sheikh Md Shakeel Hassan", "Xianwei Zou", "Akash Dhruv", "Vishwanath Ganesan", "Aparna Chandramowlishwaran"], "title": "Bubbleformer: Forecasting Boiling with Transformers", "comment": "39 pages, 13 figures, Submitted to NeurIPS 2025", "summary": "Modeling boiling (an inherently chaotic, multiphase process central to energy\nand thermal systems) remains a significant challenge for neural PDE surrogates.\nExisting models require future input (e.g., bubble positions) during inference\nbecause they fail to learn nucleation from past states, limiting their ability\nto autonomously forecast boiling dynamics. They also fail to model flow boiling\nvelocity fields, where sharp interface-momentum coupling demands long-range and\ndirectional inductive biases. We introduce Bubbleformer, a transformer-based\nspatiotemporal model that forecasts stable and long-range boiling dynamics\nincluding nucleation, interface evolution, and heat transfer without dependence\non simulation data during inference. Bubbleformer integrates factorized axial\nattention, frequency-aware scaling, and conditions on thermophysical parameters\nto generalize across fluids, geometries, and operating conditions. To evaluate\nphysical fidelity in chaotic systems, we propose interpretable physics-based\nmetrics that evaluate heat-flux consistency, interface geometry, and mass\nconservation. We also release BubbleML 2.0, a high-fidelity dataset that spans\ndiverse working fluids (cryogens, refrigerants, dielectrics), boiling\nconfigurations (pool and flow boiling), flow regimes (bubbly, slug, annular),\nand boundary conditions. Bubbleformer sets new benchmark results in both\nprediction and forecasting of two-phase boiling flows.", "AI": {"tldr": "Bubbleformer is a transformer-based model for forecasting boiling dynamics without relying on simulation data during inference, outperforming existing methods.", "motivation": "Existing neural PDE surrogates struggle with learning nucleation from past states and modeling flow boiling velocity fields, limiting autonomous forecasting.", "method": "Bubbleformer uses factorized axial attention, frequency-aware scaling, and thermophysical parameter conditioning to generalize across diverse conditions.", "result": "Bubbleformer achieves benchmark results in predicting and forecasting two-phase boiling flows, validated by physics-based metrics.", "conclusion": "Bubbleformer advances boiling dynamics modeling with improved autonomy and generalization, supported by the high-fidelity BubbleML 2.0 dataset."}}
{"id": "2507.21260", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.21260", "abs": "https://arxiv.org/abs/2507.21260", "authors": ["Amartya Banerjee", "Xingyu Xu", "Caroline Moosm\u00fcller", "Harlin Lee"], "title": "Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors", "comment": "Code: https://github.com/amartya21/Adam-PnP", "summary": "In an inverse problem, the goal is to recover an unknown parameter (e.g., an\nimage) that has typically undergone some lossy or noisy transformation during\nmeasurement. Recently, deep generative models, particularly diffusion models,\nhave emerged as powerful priors for protein structure generation. However,\nintegrating noisy experimental data from multiple sources to guide these models\nremains a significant challenge. Existing methods often require precise\nknowledge of experimental noise levels and manually tuned weights for each data\nmodality. In this work, we introduce Adam-PnP, a Plug-and-Play framework that\nguides a pre-trained protein diffusion model using gradients from multiple,\nheterogeneous experimental sources. Our framework features an adaptive noise\nestimation scheme and a dynamic modality weighting mechanism integrated into\nthe diffusion process, which reduce the need for manual hyperparameter tuning.\nExperiments on complex reconstruction tasks demonstrate significantly improved\naccuracy using Adam-PnP.", "AI": {"tldr": "Adam-PnP is a Plug-and-Play framework for guiding protein diffusion models with heterogeneous experimental data, featuring adaptive noise estimation and dynamic weighting to reduce manual tuning.", "motivation": "Addressing the challenge of integrating noisy experimental data from multiple sources into deep generative models for protein structure recovery.", "method": "Introduces Adam-PnP, a framework with adaptive noise estimation and dynamic modality weighting to guide pre-trained diffusion models.", "result": "Demonstrates significantly improved accuracy in complex reconstruction tasks.", "conclusion": "Adam-PnP effectively reduces manual hyperparameter tuning and enhances protein structure recovery."}}
{"id": "2507.21360", "categories": ["cs.AI", "cs.HC", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.21360", "abs": "https://arxiv.org/abs/2507.21360", "authors": ["Nicholas Botti", "Flora Haberkorn", "Charlotte Hoopes", "Shaun Khan"], "title": "Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures", "comment": null, "summary": "We utilize a within-subjects design with randomized task assignments to\nunderstand the effectiveness of using an AI retrieval augmented generation\n(RAG) tool to assist analysts with an information extraction and data\nannotation task. We replicate an existing, challenging real-world annotation\ntask with complex multi-part criteria on a set of thousands of pages of public\ndisclosure documents from global systemically important banks (GSIBs) with\nheterogeneous and incomplete information content. We test two treatment\nconditions. First, a \"naive\" AI use condition in which annotators use only the\ntool and must accept the first answer they are given. And second, an\n\"interactive\" AI treatment condition where annotators use the tool\ninteractively, and use their judgement to follow-up with additional information\nif necessary. Compared to the human-only baseline, the use of the AI tool\naccelerated task execution by up to a factor of 10 and enhanced task accuracy,\nparticularly in the interactive condition. We find that when extrapolated to\nthe full task, these methods could save up to 268 hours compared to the\nhuman-only approach. Additionally, our findings suggest that annotator skill,\nnot just with the subject matter domain, but also with AI tools, is a factor in\nboth the accuracy and speed of task performance.", "AI": {"tldr": "The study evaluates AI-assisted annotation tasks, showing significant speed and accuracy improvements, especially with interactive AI use, saving up to 268 hours compared to human-only methods.", "motivation": "To assess the effectiveness of AI retrieval augmented generation (RAG) tools in aiding analysts with complex data annotation tasks.", "method": "A within-subjects design with randomized task assignments, testing two AI conditions (naive and interactive) against a human-only baseline on real-world bank disclosure documents.", "result": "AI tools accelerated task execution by up to 10x and improved accuracy, with the interactive condition performing best. Extrapolated savings reached 268 hours.", "conclusion": "AI tools enhance annotation efficiency and accuracy, with annotator skill in both domain and AI tool usage playing a critical role."}}
{"id": "2507.21273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21273", "abs": "https://arxiv.org/abs/2507.21273", "authors": ["Johannes Exenberger", "Sascha Ranftl", "Robert Peharz"], "title": "Deep Polynomial Chaos Expansion", "comment": "8th Workshop on Tractable Probabilistic Modeling, UAI 2025", "summary": "Polynomial chaos expansion (PCE) is a classical and widely used surrogate\nmodeling technique in physical simulation and uncertainty quantification. By\ntaking a linear combination of a set of basis polynomials - orthonormal with\nrespect to the distribution of uncertain input parameters - PCE enables\ntractable inference of key statistical quantities, such as (conditional) means,\nvariances, covariances, and Sobol sensitivity indices, which are essential for\nunderstanding the modeled system and identifying influential parameters and\ntheir interactions. As the number of basis functions grows exponentially with\nthe number of parameters, PCE does not scale well to high-dimensional problems.\nWe address this challenge by combining PCE with ideas from probabilistic\ncircuits, resulting in the deep polynomial chaos expansion (DeepPCE) - a deep\ngeneralization of PCE that scales effectively to high-dimensional input spaces.\nDeepPCE achieves predictive performance comparable to that of multi-layer\nperceptrons (MLPs), while retaining PCE's ability to compute exact statistical\ninferences via simple forward passes.", "AI": {"tldr": "DeepPCE combines PCE with probabilistic circuits to scale PCE for high-dimensional problems, matching MLP performance while retaining exact statistical inference.", "motivation": "PCE struggles with high-dimensionality due to exponential growth of basis functions, limiting its scalability.", "method": "DeepPCE integrates PCE with probabilistic circuits, enabling deep generalization for high-dimensional inputs.", "result": "DeepPCE achieves MLP-like predictive performance and retains PCE's exact statistical inference capabilities.", "conclusion": "DeepPCE effectively scales PCE to high dimensions, maintaining performance and inference advantages."}}
{"id": "2507.21383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21383", "abs": "https://arxiv.org/abs/2507.21383", "authors": ["Chunan Tong"], "title": "Optimizing Multi-Tier Supply Chain Ordering with LNN+XGBoost: Mitigating the Bullwhip Effect", "comment": null, "summary": "Supply chain management faces significant challenges, including demand\nfluctuations, inventory imbalances, and amplified upstream order variability\ndue to the bullwhip effect. Traditional methods, such as simple moving\naverages, struggle to address dynamic market conditions. Emerging machine\nlearning techniques, including LSTM, reinforcement learning, and XGBoost, offer\npotential solutions but are limited by computational complexity, training\ninefficiencies, or constraints in time-series modeling. Liquid Neural Networks,\ninspired by dynamic biological systems, present a promising alternative due to\ntheir adaptability, low computational cost, and robustness to noise, making\nthem suitable for real-time decision-making and edge computing. Despite their\nsuccess in applications like autonomous vehicles and medical monitoring, their\npotential in supply chain optimization remains underexplored. This study\nintroduces a hybrid LNN and XGBoost model to optimize ordering strategies in\nmulti-tier supply chains. By leveraging LNN's dynamic feature extraction and\nXGBoost's global optimization capabilities, the model aims to mitigate the\nbullwhip effect and enhance cumulative profitability. The research investigates\nhow local and global synergies within the hybrid framework address the dual\ndemands of adaptability and efficiency in SCM. The proposed approach fills a\ncritical gap in existing methodologies, offering an innovative solution for\ndynamic and efficient supply chain management.", "AI": {"tldr": "A hybrid LNN and XGBoost model is proposed to optimize supply chain ordering, addressing the bullwhip effect and improving profitability by combining dynamic feature extraction and global optimization.", "motivation": "Traditional methods fail in dynamic markets, and emerging ML techniques have limitations. Liquid Neural Networks (LNNs) offer adaptability and efficiency, but their potential in supply chains is underexplored.", "method": "A hybrid LNN and XGBoost model is introduced, leveraging LNN's dynamic feature extraction and XGBoost's global optimization for multi-tier supply chain ordering.", "result": "The model aims to mitigate the bullwhip effect and enhance cumulative profitability by addressing adaptability and efficiency demands.", "conclusion": "The hybrid approach fills a gap in supply chain methodologies, offering an innovative solution for dynamic and efficient management."}}
{"id": "2507.21274", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21274", "abs": "https://arxiv.org/abs/2507.21274", "authors": ["Jiin Woo", "Alireza Bagheri Garakani", "Tianchen Zhou", "Zhishen Huang", "Yan Gao"], "title": "Large Language Model-Enhanced Reinforcement Learning for Diverse and Novel Recommendations", "comment": null, "summary": "In recommendation systems, diversity and novelty are essential for capturing\nvaried user preferences and encouraging exploration, yet many systems\nprioritize click relevance. While reinforcement learning (RL) has been explored\nto improve diversity, it often depends on random exploration that may not align\nwith user interests. We propose LAAC (LLM-guided Adversarial Actor Critic), a\nnovel method that leverages large language models (LLMs) as reference policies\nto suggest novel items, while training a lightweight policy to refine these\nsuggestions using system-specific data. The method formulates training as a\nbilevel optimization between actor and critic networks, enabling the critic to\nselectively favor promising novel actions and the actor to improve its policy\nbeyond LLM recommendations. To mitigate overestimation of unreliable LLM\nsuggestions, we apply regularization that anchors critic values for unexplored\nitems close to well-estimated dataset actions. Experiments on real-world\ndatasets show that LAAC outperforms existing baselines in diversity, novelty,\nand accuracy, while remaining robust on imbalanced data, effectively\nintegrating LLM knowledge without expensive fine-tuning.", "AI": {"tldr": "LAAC uses LLMs to guide novel item suggestions in recommendation systems, refining them with a lightweight policy via bilevel optimization, improving diversity and novelty without costly fine-tuning.", "motivation": "Diversity and novelty in recommendations are often overshadowed by click relevance, and existing RL methods rely on random exploration. LAAC addresses this by leveraging LLMs for better alignment with user interests.", "method": "LAAC combines LLMs as reference policies with a lightweight policy trained via bilevel optimization. Regularization prevents overestimation of unreliable LLM suggestions.", "result": "LAAC outperforms baselines in diversity, novelty, and accuracy, and remains robust on imbalanced data.", "conclusion": "LAAC effectively integrates LLM knowledge into recommendation systems, enhancing diversity and novelty without expensive fine-tuning."}}
{"id": "2507.21389", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21389", "abs": "https://arxiv.org/abs/2507.21389", "authors": ["Tenghao Huang", "Sihao Chen", "Muhao Chen", "Jonathan May", "Longqi Yang", "Mengting Wan", "Pei Zhou"], "title": "Teaching Language Models To Gather Information Proactively", "comment": null, "summary": "Large language models (LLMs) are increasingly expected to function as\ncollaborative partners, engaging in back-and-forth dialogue to solve complex,\nambiguous problems. However, current LLMs often falter in real-world settings,\ndefaulting to passive responses or narrow clarifications when faced with\nincomplete or under-specified prompts, falling short of proactively gathering\nthe missing information that is crucial for high-quality solutions. In this\nwork, we introduce a new task paradigm: proactive information gathering, where\nLLMs must identify gaps in the provided context and strategically elicit\nimplicit user knowledge through targeted questions. To systematically study and\ntrain this capability, we design a scalable framework that generates partially\nspecified, real-world tasks, masking key information and simulating authentic\nambiguity. Within this setup, our core innovation is a reinforcement finetuning\nstrategy that rewards questions that elicit genuinely new, implicit user\ninformation -- such as hidden domain expertise or fine-grained requirements --\nthat would otherwise remain unspoken. Experiments demonstrate that our trained\nQwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic\nevaluation metrics. More importantly, human evaluation reveals that\nclarification questions and final outlines generated by our model are favored\nby human annotators by 42% and 28% respectively. Together, these results\nhighlight the value of proactive clarification in elevating LLMs from passive\ntext generators to genuinely collaborative thought partners.", "AI": {"tldr": "The paper introduces proactive information gathering for LLMs to improve collaboration by identifying gaps and eliciting missing details through targeted questions, outperforming baselines in evaluations.", "motivation": "Current LLMs often fail to proactively gather missing information in ambiguous tasks, limiting their effectiveness as collaborative partners.", "method": "A reinforcement finetuning strategy is used to train LLMs to ask questions that reveal implicit user knowledge, tested with partially specified tasks.", "result": "The Qwen-2.5-7B model outperforms o3-mini by 18% in automatic metrics and is preferred by humans for clarification questions (42%) and outlines (28%).", "conclusion": "Proactive clarification enhances LLMs' role as collaborative partners, moving beyond passive text generation."}}
{"id": "2507.21299", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21299", "abs": "https://arxiv.org/abs/2507.21299", "authors": ["Alex Guo", "Michael D. Graham"], "title": "Blending data and physics for reduced-order modeling of systems with spatiotemporal chaotic dynamics", "comment": null, "summary": "While data-driven techniques are powerful tools for reduced-order modeling of\nsystems with chaotic dynamics, great potential remains for leveraging known\nphysics (i.e. a full-order model (FOM)) to improve predictive capability. We\ndevelop a hybrid reduced order model (ROM), informed by both data and FOM, for\nevolving spatiotemporal chaotic dynamics on an invariant manifold whose\ncoordinates are found using an autoencoder. This approach projects the vector\nfield of the FOM onto the invariant manifold; then, this physics-derived vector\nfield is either corrected using dynamic data, or used as a Bayesian prior that\nis updated with data. In both cases, the neural ordinary differential equation\napproach is used. We consider simulated data from the Kuramoto-Sivashinsky and\ncomplex Ginzburg-Landau equations. Relative to the data-only approach, for\nscenarios of abundant data, scarce data, and even an incorrect FOM (i.e.\nerroneous parameter values), the hybrid approach yields substantially improved\ntime-series predictions.", "AI": {"tldr": "A hybrid reduced-order model (ROM) combines data and full-order physics to improve predictions of chaotic dynamics, outperforming data-only methods.", "motivation": "To enhance predictive capability by integrating known physics (full-order model) with data-driven techniques for chaotic systems.", "method": "Develops a hybrid ROM using an autoencoder for manifold coordinates, projects FOM vector fields, and corrects with data or updates via Bayesian prior, employing neural ODEs.", "result": "Hybrid ROM significantly improves time-series predictions in scenarios of abundant/scarce data or incorrect FOM parameters, tested on Kuramoto-Sivashinsky and Ginzburg-Landau equations.", "conclusion": "Combining physics and data in hybrid ROMs offers superior predictive performance for chaotic dynamics, even with imperfect models or limited data."}}
{"id": "2507.21406", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21406", "abs": "https://arxiv.org/abs/2507.21406", "authors": ["Meilin Zhu", "Gaojie Jin", "Xiaowei Huang", "Lijun Zhang"], "title": "Shapley Uncertainty in Natural Language Generation", "comment": null, "summary": "In question-answering tasks, determining when to trust the outputs is crucial\nto the alignment of large language models (LLMs). Kuhn et al. (2023) introduces\nsemantic entropy as a measure of uncertainty, by incorporating linguistic\ninvariances from the same meaning. It primarily relies on setting threshold to\nmeasure the level of semantic equivalence relation. We propose a more nuanced\nframework that extends beyond such thresholding by developing a Shapley-based\nuncertainty metric that captures the continuous nature of semantic\nrelationships. We establish three fundamental properties that characterize\nvalid uncertainty metrics and prove that our Shapley uncertainty satisfies\nthese criteria. Through extensive experiments, we demonstrate that our Shapley\nuncertainty more accurately predicts LLM performance in question-answering and\nother datasets, compared to similar baseline measures.", "AI": {"tldr": "The paper introduces a Shapley-based uncertainty metric for LLMs, outperforming semantic entropy in predicting model performance in QA tasks.", "motivation": "Current methods like semantic entropy rely on thresholding for uncertainty, which lacks nuance in capturing semantic relationships.", "method": "Develops a Shapley-based uncertainty metric, ensuring it meets three fundamental properties for valid uncertainty measures.", "result": "Shapley uncertainty more accurately predicts LLM performance in QA tasks compared to baseline measures.", "conclusion": "The proposed framework provides a more nuanced and effective way to measure uncertainty in LLMs."}}
{"id": "2507.21350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21350", "abs": "https://arxiv.org/abs/2507.21350", "authors": ["Wenkai Tan", "Alvaro Velasquez", "Houbing Song"], "title": "DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation", "comment": null, "summary": "Neural networks have emerged as a powerful tool for modeling physical\nsystems, offering the ability to learn complex representations from limited\ndata while integrating foundational scientific knowledge. In particular,\nneuro-symbolic approaches that combine data-driven learning, the neuro, with\nsymbolic equations and rules, the symbolic, address the tension between methods\nthat are purely empirical, which risk straying from established physical\nprinciples, and traditional numerical solvers that demand complete geometric\nknowledge and can be prohibitively expensive for high-fidelity simulations. In\nthis work, we present a novel neuro-symbolic framework for reconstructing and\nsimulating elastic objects directly from sparse multi-view image sequences,\nwithout requiring explicit geometric information. Specifically, we integrate a\nneural radiance field (NeRF) for object reconstruction with physics-informed\nneural networks (PINN) that incorporate the governing partial differential\nequations of elasticity. In doing so, our method learns a spatiotemporal\nrepresentation of deforming objects that leverages both image supervision and\nsymbolic physical constraints. To handle complex boundary and initial\nconditions, which are traditionally confronted using finite element methods,\nboundary element methods, or sensor-based measurements, we employ an\nenergy-constrained Physics-Informed Neural Network architecture. This design\nenhances both simulation accuracy and the explainability of results.", "AI": {"tldr": "A neuro-symbolic framework combines neural networks with symbolic physics to reconstruct and simulate elastic objects from sparse images, integrating NeRF for reconstruction and PINN for physics constraints.", "motivation": "Addresses the gap between purely empirical methods (risking deviation from physics) and traditional solvers (requiring full geometric knowledge and high computational cost).", "method": "Uses neural radiance fields (NeRF) for object reconstruction and physics-informed neural networks (PINN) with elasticity equations. An energy-constrained PINN handles complex boundary conditions.", "result": "Learns spatiotemporal representations of deforming objects, balancing image supervision and physical constraints for accurate, explainable simulations.", "conclusion": "The framework effectively bridges data-driven learning and symbolic physics, enhancing simulation accuracy and explainability without explicit geometric data."}}
{"id": "2507.21407", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21407", "abs": "https://arxiv.org/abs/2507.21407", "authors": ["Yixin Liu", "Guibin Zhang", "Kun Wang", "Shiyuan Li", "Shirui Pan"], "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "comment": "15 pages, 7 figures", "summary": "Autonomous agents based on large language models (LLMs) have demonstrated\nimpressive capabilities in a wide range of applications, including web\nnavigation, software development, and embodied control. While most LLMs are\nlimited in several key agentic procedures, such as reliable planning, long-term\nmemory, tool management, and multi-agent coordination, graphs can serve as a\npowerful auxiliary structure to enhance structure, continuity, and coordination\nin complex agent workflows. Given the rapid growth and fragmentation of\nresearch on Graph-augmented LLM Agents (GLA), this paper offers a timely and\ncomprehensive overview of recent advances and also highlights key directions\nfor future work. Specifically, we categorize existing GLA methods by their\nprimary functions in LLM agent systems, including planning, memory, and tool\nusage, and then analyze how graphs and graph learning algorithms contribute to\neach. For multi-agent systems, we further discuss how GLA solutions facilitate\nthe orchestration, efficiency optimization, and trustworthiness of MAS.\nFinally, we highlight key future directions to advance this field, from\nimproving structural adaptability to enabling unified, scalable, and multimodal\nGLA systems. We hope this paper can serve as a roadmap for future research on\nGLA and foster a deeper understanding of the role of graphs in LLM agent\nsystems.", "AI": {"tldr": "Graph-augmented LLM Agents (GLA) enhance LLM agent capabilities in planning, memory, and tool usage, with potential for multi-agent systems. The paper reviews advances and future directions.", "motivation": "Address limitations of LLMs in agentic procedures (planning, memory, tool management, multi-agent coordination) by leveraging graphs for structure and coordination.", "method": "Categorizes GLA methods by their functions (planning, memory, tool usage) and analyzes graph contributions. Discusses GLA in multi-agent systems for orchestration and efficiency.", "result": "Graphs improve LLM agent workflows, enabling better planning, memory, and coordination. GLA shows promise for scalable and multimodal systems.", "conclusion": "The paper provides a roadmap for future GLA research, emphasizing structural adaptability and unified systems, fostering deeper understanding of graphs in LLM agents."}}
{"id": "2507.21357", "categories": ["cs.LG", "62M10", "I.5.1"], "pdf": "https://arxiv.org/pdf/2507.21357", "abs": "https://arxiv.org/abs/2507.21357", "authors": ["Yaoyu Zhang", "Chi-Guhn Lee"], "title": "A Contrastive Diffusion-based Network (CDNet) for Time Series Classification", "comment": "19 pages, conference", "summary": "Deep learning models are widely used for time series classification (TSC) due\nto their scalability and efficiency. However, their performance degrades under\nchallenging data conditions such as class similarity, multimodal distributions,\nand noise. To address these limitations, we propose CDNet, a Contrastive\nDiffusion-based Network that enhances existing classifiers by generating\ninformative positive and negative samples via a learned diffusion process.\nUnlike traditional diffusion models that denoise individual samples, CDNet\nlearns transitions between samples--both within and across classes--through\nconvolutional approximations of reverse diffusion steps. We introduce a\ntheoretically grounded CNN-based mechanism to enable both denoising and mode\ncoverage, and incorporate an uncertainty-weighted composite loss for robust\ntraining. Extensive experiments on the UCR Archive and simulated datasets\ndemonstrate that CDNet significantly improves state-of-the-art (SOTA) deep\nlearning classifiers, particularly under noisy, similar, and multimodal\nconditions.", "AI": {"tldr": "CDNet, a Contrastive Diffusion-based Network, improves deep learning classifiers for time series classification by generating informative samples via a learned diffusion process, enhancing performance under challenging conditions.", "motivation": "Deep learning models for time series classification struggle with class similarity, multimodal distributions, and noise. CDNet addresses these limitations by leveraging contrastive diffusion.", "method": "CDNet uses convolutional approximations of reverse diffusion steps to learn transitions between samples, introduces a CNN-based mechanism for denoising and mode coverage, and employs an uncertainty-weighted composite loss for training.", "result": "Experiments on the UCR Archive and simulated datasets show CDNet significantly outperforms state-of-the-art classifiers, especially in noisy, similar, and multimodal scenarios.", "conclusion": "CDNet effectively enhances classifier robustness and performance under challenging data conditions, advancing time series classification."}}
{"id": "2507.21419", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21419", "abs": "https://arxiv.org/abs/2507.21419", "authors": ["Haiquan Wang", "Yi Chen", "Shang Zeng", "Yun Bian", "Zhe Cui"], "title": "GovRelBench:A Benchmark for Government Domain Relevance", "comment": null, "summary": "Current evaluations of LLMs in the government domain primarily focus on\nsafety considerations in specific scenarios, while the assessment of the\nmodels' own core capabilities, particularly domain relevance, remains\ninsufficient. To address this gap, we propose GovRelBench, a benchmark\nspecifically designed for evaluating the core capabilities of LLMs in the\ngovernment domain. GovRelBench consists of government domain prompts and a\ndedicated evaluation tool, GovRelBERT. During the training process of\nGovRelBERT, we introduce the SoftGovScore method: this method trains a model\nbased on the ModernBERT architecture by converting hard labels to soft scores,\nenabling it to accurately compute the text's government domain relevance score.\nThis work aims to enhance the capability evaluation framework for large models\nin the government domain, providing an effective tool for relevant research and\npractice. Our code and dataset are available at\nhttps://github.com/pan-xi/GovRelBench.", "AI": {"tldr": "The paper introduces GovRelBench, a benchmark for evaluating LLMs' core capabilities in the government domain, addressing gaps in current evaluations.", "motivation": "Current evaluations lack focus on LLMs' core capabilities, especially domain relevance, in the government sector.", "method": "Proposes GovRelBench with domain-specific prompts and GovRelBERT, using SoftGovScore for training to assess relevance.", "result": "Developed GovRelBERT with SoftGovScore for accurate government domain relevance scoring.", "conclusion": "GovRelBench enhances LLM evaluation in the government domain, offering tools for research and practice."}}
{"id": "2507.21386", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21386", "abs": "https://arxiv.org/abs/2507.21386", "authors": ["Xuan Wu", "Di Wang", "Chunguo Wu", "Kaifang Qi", "Chunyan Miao", "Yubin Xiao", "Jian Zhang", "You Zhou"], "title": "Efficient Neural Combinatorial Optimization Solver for the Min-max Heterogeneous Capacitated Vehicle Routing Problem", "comment": null, "summary": "Numerous Neural Combinatorial Optimization (NCO) solvers have been proposed\nto address Vehicle Routing Problems (VRPs). However, most of these solvers\nfocus exclusively on single-vehicle VRP variants, overlooking the more\nrealistic min-max Heterogeneous Capacitated Vehicle Routing Problem (MMHCVRP),\nwhich involves multiple vehicles. Existing MMHCVRP solvers typically select a\nvehicle and its next node to visit at each decoding step, but often make myopic\ndecoding decisions and overlook key properties of MMHCVRP, including local\ntopological relationships, vehicle permutation invariance, and node symmetry,\nresulting in suboptimal performance. To better address these limitations, we\npropose ECHO, an efficient NCO solver. First, ECHO exploits the proposed\ndual-modality node encoder to capture local topological relationships among\nnodes. Subsequently, to mitigate myopic decisions, ECHO employs the proposed\nParameter-Free Cross-Attention mechanism to prioritize the vehicle selected in\nthe preceding decoding step. Finally, leveraging vehicle permutation invariance\nand node symmetry, we introduce a tailored data augment strategy for MMHCVRP to\nstabilize the Reinforcement Learning training process. To assess the\nperformance of ECHO, we conduct extensive experiments. The experimental results\ndemonstrate that ECHO outperforms state-of-the-art NCO solvers across varying\nnumbers of vehicles and nodes, and exhibits well-performing generalization\nacross both scales and distribution patterns. Finally, ablation studies\nvalidate the effectiveness of all proposed methods.", "AI": {"tldr": "ECHO is a Neural Combinatorial Optimization solver for the min-max Heterogeneous Capacitated Vehicle Routing Problem (MMHCVRP), addressing limitations like myopic decisions and overlooked properties by leveraging dual-modality encoding, cross-attention, and tailored data augmentation.", "motivation": "Existing solvers for MMHCVRP often make myopic decisions and ignore key problem properties, leading to suboptimal performance.", "method": "ECHO uses a dual-modality node encoder, Parameter-Free Cross-Attention, and tailored data augmentation to improve decision-making and training stability.", "result": "ECHO outperforms state-of-the-art solvers in experiments, showing strong generalization across vehicle and node scales.", "conclusion": "The proposed methods in ECHO effectively address MMHCVRP challenges, validated by ablation studies."}}
{"id": "2507.21438", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.7; H.2.8"], "pdf": "https://arxiv.org/pdf/2507.21438", "abs": "https://arxiv.org/abs/2507.21438", "authors": ["Vishal Raman", "Vijai Aravindh R"], "title": "Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models", "comment": "9 pages, 10 figures", "summary": "Ontologies and knowledge graphs require continuous evolution to remain\ncomprehensive and accurate, but manual curation is labor intensive. Large\nLanguage Models (LLMs) possess vast unstructured knowledge but struggle with\nmaintaining structured consistency. We propose Evo-DKD, a novel dual-decoder\nframework for autonomous ontology evolution that combines structured ontology\ntraversal with unstructured text reasoning. Evo-DKD introduces two parallel\ndecoding streams within an LLM: one decoder generates candidate ontology edits\n(e.g., new concepts or relations) while the other produces natural-language\njustifications. A dynamic attention-based gating mechanism coordinates the two\nstreams, deciding at each step how to blend structured and unstructured\nknowledge. Due to GPU constraints, we simulate the dual-decoder behavior using\nprompt-based mode control to approximate coordinated decoding in a\nsingle-stream mode. The system operates in a closed reasoning loop: proposed\nontology edits are validated (via consistency checks and cross-verification\nwith the text explanations) and then injected into the knowledge base, which in\nturn informs subsequent reasoning. We demonstrate Evo-DKD's effectiveness on\nuse cases including healthcare ontology refinement, semantic search\nimprovement, and cultural heritage timeline modeling. Experiments show that\nEvo-DKD outperforms baselines using structured-only or unstructured-only\ndecoding in both precision of ontology updates and downstream task performance.\nWe present quantitative metrics and qualitative examples, confirming the\ncontributions of the dual-decoder design and gating router. Evo-DKD offers a\nnew paradigm for LLM-driven knowledge base maintenance, combining the strengths\nof symbolic and neural reasoning for sustainable ontology evolution.", "AI": {"tldr": "Evo-DKD is a dual-decoder framework for autonomous ontology evolution, combining structured ontology traversal with unstructured text reasoning, outperforming baselines in precision and task performance.", "motivation": "Manual curation of ontologies and knowledge graphs is labor-intensive, and LLMs struggle with structured consistency, necessitating a hybrid approach.", "method": "Evo-DKD uses two parallel decoders in an LLM: one for ontology edits and another for natural-language justifications, coordinated by a dynamic attention-based gating mechanism.", "result": "Evo-DKD outperforms structured-only or unstructured-only baselines in precision of ontology updates and downstream task performance.", "conclusion": "Evo-DKD combines symbolic and neural reasoning for sustainable ontology evolution, offering a new paradigm for LLM-driven knowledge base maintenance."}}
{"id": "2507.21394", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21394", "abs": "https://arxiv.org/abs/2507.21394", "authors": ["Shiva Raja", "Cansu Demirkiran", "Aakash Sarkar", "Milos Popovic", "Ajay Joshi"], "title": "Systolic Array-based Accelerator for State-Space Models", "comment": null, "summary": "Sequence modeling is crucial for AI to understand temporal data and detect\ncomplex time-dependent patterns. While recurrent neural networks (RNNs),\nconvolutional neural networks (CNNs), and Transformers have advanced in\ncapturing long-range dependencies, they struggle with achieving high accuracy\nwith very long sequences due to limited memory retention (fixed context\nwindow). State-Space Models (SSMs) leverage exponentially decaying memory\nenabling lengthy context window and so they process very long data sequences\nmore efficiently than recurrent and Transformer-based models. Unlike\ntraditional neural models like CNNs and RNNs, SSM-based models require solving\ndifferential equations through continuous integration, making training and\ninference both compute- and memory-intensive on conventional CPUs and GPUs. In\nthis paper we introduce a specialized hardware accelerator, EpochCore, for\naccelerating SSMs. EpochCore is based on systolic arrays (SAs) and is designed\nto enhance the energy efficiency and throughput of inference of SSM-based\nmodels for long-range sequence tasks. Within the SA, we propose a versatile\nprocessing element (PE) called LIMA-PE to perform traditional and specialized\nMAC operations to support traditional DNNs and SSMs. To complement the\nEpochCore microarchitecture, we propose a novel dataflow, ProDF, which enables\nhighly efficient execution of SSM-based models. By leveraging the LIMA-PE\nmicroarchitecture and ProDF, EpochCore achieves on average 250x gains in\nperformance and 45x improvement in energy efficiency, at the expense of 2x\nincrease in area cost over traditional SA-based accelerators, and around\n~2,000x improvement in latency/inference on LRA datasets compared to GPU kernel\noperations.", "AI": {"tldr": "The paper introduces EpochCore, a hardware accelerator for State-Space Models (SSMs), achieving significant performance and energy efficiency improvements over traditional methods.", "motivation": "Existing models (RNNs, CNNs, Transformers) struggle with long sequences due to memory limitations. SSMs offer better efficiency but are compute-intensive, requiring specialized hardware.", "method": "EpochCore uses systolic arrays and a versatile processing element (LIMA-PE) with a novel dataflow (ProDF) to optimize SSM execution.", "result": "EpochCore achieves 250x performance gains, 45x energy efficiency, and ~2,000x latency improvement over GPUs.", "conclusion": "EpochCore is a promising solution for accelerating SSMs, balancing performance, efficiency, and area cost."}}
{"id": "2507.21453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21453", "abs": "https://arxiv.org/abs/2507.21453", "authors": ["Ashley Rector", "Keaton Minor", "Kamden Minor", "Jeff McCormack", "Beth Breeden", "Ryan Nowers", "Jay Dorris"], "title": "Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)", "comment": null, "summary": "This study evaluated Sherpa Rx, an artificial intelligence tool leveraging\nlarge language models and retrieval-augmented generation (RAG) for\npharmacogenomics, to validate its performance on key response metrics. Sherpa\nRx integrated Clinical Pharmacogenetics Implementation Consortium (CPIC)\nguidelines with Pharmacogenomics Knowledgebase (PharmGKB) data to generate\ncontextually relevant responses. A dataset (N=260 queries) spanning 26 CPIC\nguidelines was used to evaluate drug-gene interactions, dosing recommendations,\nand therapeutic implications. In Phase 1, only CPIC data was embedded. Phase 2\nadditionally incorporated PharmGKB content. Responses were scored on accuracy,\nrelevance, clarity, completeness (5-point Likert scale), and recall. Wilcoxon\nsigned-rank tests compared accuracy between Phase 1 and Phase 2, and between\nPhase 2 and ChatGPT-4omini. A 20-question quiz assessed the tool's real-world\napplicability against other models. In Phase 1 (N=260), Sherpa Rx demonstrated\nhigh performance of accuracy 4.9, relevance 5.0, clarity 5.0, completeness 4.8,\nand recall 0.99. The subset analysis (N=20) showed improvements in accuracy\n(4.6 vs. 4.4, Phase 2 vs. Phase 1 subset) and completeness (5.0 vs. 4.8).\nChatGPT-4omini performed comparably in relevance (5.0) and clarity (4.9) but\nlagged in accuracy (3.9) and completeness (4.2). Differences in accuracy\nbetween Phase 1 and Phase 2 was not statistically significant. However, Phase 2\nsignificantly outperformed ChatGPT-4omini. On the 20-question quiz, Sherpa Rx\nachieved 90% accuracy, outperforming other models. Integrating additional\nresources like CPIC and PharmGKB with RAG enhances AI accuracy and performance.\nThis study highlights the transformative potential of generative AI like Sherpa\nRx in pharmacogenomics, improving decision-making with accurate, personalized\nresponses.", "AI": {"tldr": "Sherpa Rx, an AI tool for pharmacogenomics, was evaluated using CPIC and PharmGKB data. It showed high performance in accuracy, relevance, and completeness, outperforming ChatGPT-4omini.", "motivation": "To validate the performance of Sherpa Rx, an AI tool for pharmacogenomics, and compare it with other models like ChatGPT-4omini.", "method": "Used a dataset of 260 queries across 26 CPIC guidelines, evaluated responses on accuracy, relevance, clarity, completeness, and recall. Compared Phase 1 (CPIC only) and Phase 2 (CPIC + PharmGKB) and ChatGPT-4omini.", "result": "Sherpa Rx achieved high scores (e.g., accuracy 4.9, recall 0.99) and outperformed ChatGPT-4omini in accuracy and completeness. Phase 2 improved performance but not significantly over Phase 1.", "conclusion": "Sherpa Rx demonstrates the potential of AI in pharmacogenomics, enhancing decision-making with accurate, personalized responses."}}
{"id": "2507.21397", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21397", "abs": "https://arxiv.org/abs/2507.21397", "authors": ["Fnu Hairi", "Jiao Yang", "Tianchen Zhou", "Haibo Yang", "Chaosheng Dong", "Fan Yang", "Michinari Momma", "Yan Gao", "Jia Liu"], "title": "Enabling Pareto-Stationarity Exploration in Multi-Objective Reinforcement Learning: A Multi-Objective Weighted-Chebyshev Actor-Critic Approach", "comment": null, "summary": "In many multi-objective reinforcement learning (MORL) applications, being\nable to systematically explore the Pareto-stationary solutions under multiple\nnon-convex reward objectives with theoretical finite-time sample complexity\nguarantee is an important and yet under-explored problem. This motivates us to\ntake the first step and fill the important gap in MORL. Specifically, in this\npaper, we propose a \\uline{M}ulti-\\uline{O}bjective weighted-\\uline{CH}ebyshev\n\\uline{A}ctor-critic (MOCHA) algorithm for MORL, which judiciously integrates\nthe weighted-Chebychev (WC) and actor-critic framework to enable\nPareto-stationarity exploration systematically with finite-time sample\ncomplexity guarantee. Sample complexity result of MOCHA algorithm reveals an\ninteresting dependency on $p_{\\min}$ in finding an $\\epsilon$-Pareto-stationary\nsolution, where $p_{\\min}$ denotes the minimum entry of a given weight vector\n$\\mathbf{p}$ in WC-scarlarization. By carefully choosing learning rates, the\nsample complexity for each exploration can be\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$. Furthermore, simulation studies on a\nlarge KuaiRand offline dataset, show that the performance of MOCHA algorithm\nsignificantly outperforms other baseline MORL approaches.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.21471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21471", "abs": "https://arxiv.org/abs/2507.21471", "authors": ["Zujie Xie", "Zixuan Chen", "Jiheng Liang", "Xiangyang Yu", "Ziru Yu"], "title": "An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning", "comment": "19 pages", "summary": "Infrared spectroscopy offers rapid, non destructive measurement of chemical\nand material properties but suffers from high dimensional, overlapping spectral\nbands that challenge conventional chemometric approaches. Emerging large\nlanguage models (LLMs), with their capacity for generalization and reasoning,\noffer promising potential for automating complex scientific workflows. Despite\nthis promise, their application in IR spectral analysis remains largely\nunexplored. This study addresses the critical challenge of achieving accurate,\nautomated infrared spectral interpretation under low-data conditions using an\nLLM-driven framework. We introduce an end-to-end, large language model driven\nagent framework that integrates a structured literature knowledge base,\nautomated spectral preprocessing, feature extraction, and multi task reasoning\nin a unified pipeline. By querying a curated corpus of peer reviewed IR\npublications, the agent selects scientifically validated routines. The selected\nmethods transform each spectrum into low dimensional feature sets, which are\nfed into few shot prompt templates for classification, regression, and anomaly\ndetection. A closed loop, multi turn protocol iteratively appends mispredicted\nsamples to the prompt, enabling dynamic refinement of predictions. Across\ndiverse materials: stamp pad ink, Chinese medicine, Pu'er tea, Citri\nReticulatae Pericarpium and waste water COD datasets, the multi turn LLM\nconsistently outperforms single turn inference, rivaling or exceeding machine\nlearning and deep learning models under low data regimes.", "AI": {"tldr": "An LLM-driven framework for accurate, automated infrared spectral interpretation under low-data conditions, outperforming traditional methods.", "motivation": "Infrared spectroscopy's high-dimensional, overlapping bands challenge conventional chemometrics, and LLMs' potential for spectral analysis remains unexplored.", "method": "An end-to-end LLM-driven agent integrates literature knowledge, spectral preprocessing, feature extraction, and multi-task reasoning, using few-shot prompts and iterative refinement.", "result": "The framework outperforms single-turn inference and rivals/exceeds machine/deep learning models in low-data scenarios across diverse datasets.", "conclusion": "LLMs can effectively automate IR spectral analysis, offering a robust solution for low-data conditions."}}
{"id": "2507.21404", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.21404", "abs": "https://arxiv.org/abs/2507.21404", "authors": ["Amber Huang", "Ian Scott Knight", "Slava Naprienko"], "title": "Data Leakage and Redundancy in the LIT-PCBA Benchmark", "comment": null, "summary": "LIT-PCBA is a widely used benchmark for virtual screening, but our audit\nreveals it is fundamentally compromised. The dataset suffers from egregious\ndata leakage, rampant duplication, and pervasive analog redundancy -- flaws\nthat invalidate its use for fair model evaluation. Notably, we identify 2,491\ninactives duplicated across training and validation sets, and thousands more\nrepeated within individual data splits (2,945 in training, 789 in validation).\nCritically, three ligands in the query set -- meant to represent unseen test\ncases -- are leaked: two appear in the training set, one in validation.\nStructural redundancy compounds these issues: for some targets, over 80% of\nquery ligands are near duplicates, with Tanimoto similarity >= 0.9. In ALDH1\nalone, we find 323 highly similar active pairs between training and validation\nsets, invalidating claims of chemical diversity. These and other flaws\ncollectively cause models trained on LIT-PCBA to memorize rather than\ngeneralize. To demonstrate the consequences of these data integrity failures,\nwe implement a trivial memorization-based baseline -- using no learning, no\nphysics, and no modeling -- that outperforms state-of-the-art models, including\ndeep neural networks like CHEESE, on LIT-PCBA simply by exploiting these\nartifacts. Our findings render the benchmark unfit for its intended purpose and\ncall into question previous results based on its use. We share this audit to\nraise awareness and provide tooling to help the community develop more rigorous\nand reliable datasets going forward. All scripts necessary to reproduce our\naudit and the baseline implementation are available at:\nhttps://github.com/sievestack/LIT-PCBA-audit", "AI": {"tldr": "The paper audits LIT-PCBA, a virtual screening benchmark, revealing severe flaws like data leakage, duplication, and analog redundancy, making it unreliable for fair model evaluation. A trivial memorization-based baseline outperforms state-of-the-art models, highlighting the dataset's inadequacy.", "motivation": "To expose critical flaws in the LIT-PCBA benchmark that compromise its validity for evaluating virtual screening models, undermining previous research relying on it.", "method": "Conducted an audit identifying data leakage, duplication, and structural redundancy. Implemented a memorization-based baseline to demonstrate the dataset's flaws.", "result": "Found 2,491 duplicated inactives, 3 leaked query ligands, and 323 highly similar active pairs in ALDH1. The trivial baseline outperformed advanced models like CHEESE.", "conclusion": "LIT-PCBA is unfit for its intended purpose due to fundamental flaws. The findings question prior results and advocate for more rigorous dataset development."}}
{"id": "2507.21488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21488", "abs": "https://arxiv.org/abs/2507.21488", "authors": ["Zhenwei Tang", "Difan Jiao", "Eric Xue", "Reid McIlroy-Young", "Jon Kleinberg", "Siddhartha Sen", "Ashton Anderson"], "title": "Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess", "comment": null, "summary": "As humans seek to collaborate with, learn from, and better understand\nartificial intelligence systems, developing AIs that can accurately emulate\nindividual decision-making becomes increasingly important. Chess, a\nlong-standing AI benchmark with precise skill measurement, offers an ideal\ntestbed for human-AI alignment. However, existing approaches to modeling human\nbehavior require prohibitively large amounts of data from each individual,\nmaking them impractical for new or sparsely represented users. In this work, we\nintroduce Maia4All, a framework designed to learn and adapt to individual\ndecision-making styles efficiently, even with limited data. Maia4All achieves\nthis through a two-stage optimization process: (1) an enrichment step, which\nbridges population and individual-level human behavior modeling with a\nprototype-enriched model, and (2) a democratization step, which leverages\nability levels or user prototypes to initialize and refine individual\nembeddings with minimal data. Our experimental results show that Maia4All can\naccurately predict individual moves and profile behavioral patterns with high\nfidelity, establishing a new standard for personalized human-like AI behavior\nmodeling in chess. Maia4All achieves individual human behavior modeling in\nchess with only 20 games, compared to the 5,000 games required previously,\nrepresenting a significant improvement in data efficiency. Our work provides an\nexample of how population AI systems can flexibly adapt to individual users\nusing a prototype-enriched model as a bridge. This approach extends beyond\nchess, as shown in our case study on idiosyncratic LLMs, highlighting its\npotential for broader applications in personalized AI adaptation.", "AI": {"tldr": "Maia4All is a framework for efficiently modeling individual human decision-making in chess with minimal data, using a two-stage optimization process.", "motivation": "To address the impracticality of existing methods requiring large datasets for individual human behavior modeling in AI systems.", "method": "A two-stage process: (1) enrichment step bridging population and individual behavior, and (2) democratization step refining individual embeddings with minimal data.", "result": "Maia4All accurately predicts individual moves and profiles behavior with high fidelity, requiring only 20 games (vs. 5,000 previously).", "conclusion": "Maia4All sets a new standard for personalized AI behavior modeling, with potential applications beyond chess, such as personalized LLMs."}}
{"id": "2507.21422", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21422", "abs": "https://arxiv.org/abs/2507.21422", "authors": ["Sujia Huang", "Lele Fu", "Zhen Cui", "Tong Zhang", "Na Song", "Bo Huang"], "title": "Torque-based Graph Surgery:Enhancing Graph Neural Networks with Hierarchical Rewiring", "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning from\ngraph-structured data, leveraging message passing to diffuse information and\nupdate node representations. However, most efforts have suggested that native\ninteractions encoded in the graph may not be friendly for this process,\nmotivating the development of graph rewiring methods. In this work, we propose\na torque-driven hierarchical rewiring strategy, inspired by the notion of\ntorque in classical mechanics, dynamically modulating message passing to\nimprove representation learning in heterophilous graphs and enhance robustness\nagainst noisy graphs. Specifically, we define an interference-aware torque\nmetric that integrates structural distance and energy scores to quantify the\nperturbation induced by edges, thereby encouraging each node to aggregate\ninformation from its nearest low-energy neighbors. We use the metric to\nhierarchically reconfigure the receptive field of each layer by judiciously\npruning high-torque edges and adding low-torque links, suppressing propagation\nnoise and boosting pertinent signals. Extensive evaluations on benchmark\ndatasets show that our approach surpasses state-of-the-art methods on both\nheterophilous and homophilous graphs, and maintains high accuracy on noisy\ngraph.", "AI": {"tldr": "A torque-driven hierarchical rewiring strategy for GNNs improves representation learning in heterophilous and noisy graphs by dynamically adjusting message passing based on interference-aware torque metrics.", "motivation": "Native graph interactions may hinder effective message passing in GNNs, especially in heterophilous and noisy graphs, necessitating graph rewiring methods.", "method": "Proposes a torque-driven rewiring strategy using an interference-aware torque metric to prune high-torque edges and add low-torque links, optimizing node receptive fields.", "result": "Outperforms state-of-the-art methods on heterophilous, homophilous, and noisy graphs, enhancing robustness and accuracy.", "conclusion": "The torque-driven rewiring strategy effectively improves GNN performance by dynamically modulating message passing, demonstrating broad applicability."}}
{"id": "2507.21502", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21502", "abs": "https://arxiv.org/abs/2507.21502", "authors": ["David Simchi-Levi", "Konstantina Mellou", "Ishai Menache", "Jeevan Pathuri"], "title": "Large Language Models for Supply Chain Decisions", "comment": "Forthcoming chapter in AI in Supply Chains: Perspectives from Global\n  Thought Leaders, edited by Maxime C. Cohen and Tinglong Dai, and part of the\n  Springer Series in Supply Chain Management (edited by Prof. Chris Tang)", "summary": "Supply Chain Management requires addressing a variety of complex\ndecision-making challenges, from sourcing strategies to planning and execution.\nOver the last few decades, advances in computation and information technologies\nhave enabled the transition from manual, intuition and experience-based\ndecision-making, into more automated and data-driven decisions using a variety\nof tools that apply optimization techniques. These techniques use mathematical\nmethods to improve decision-making.\n  Unfortunately, business planners and executives still need to spend\nconsiderable time and effort to (i) understand and explain the recommendations\ncoming out of these technologies; (ii) analyze various scenarios and answer\nwhat-if questions; and (iii) update the mathematical models used in these tools\nto reflect current business environments. Addressing these challenges requires\ninvolving data science teams and/or the technology providers to explain results\nor make the necessary changes in the technology and hence significantly slows\ndown decision making.\n  Motivated by the recent advances in Large Language Models (LLMs), we report\nhow this disruptive technology can democratize supply chain technology -\nnamely, facilitate the understanding of tools' outcomes, as well as the\ninteraction with supply chain tools without human-in-the-loop. Specifically, we\nreport how we apply LLMs to address the three challenges described above, thus\nsubstantially reducing the time to decision from days and weeks to minutes and\nhours as well as dramatically increasing planners' and executives' productivity\nand impact.", "AI": {"tldr": "LLMs can democratize supply chain technology by simplifying understanding and interaction with tools, reducing decision time from days to minutes.", "motivation": "Business planners face challenges in understanding, explaining, and updating automated supply chain tools, requiring slow human intervention.", "method": "Apply Large Language Models (LLMs) to address these challenges, enabling faster and more autonomous decision-making.", "result": "Decision-making time reduced from days/weeks to minutes/hours, significantly boosting productivity.", "conclusion": "LLMs offer a transformative solution to streamline supply chain management, enhancing efficiency and reducing reliance on human intermediaries."}}
{"id": "2507.21433", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21433", "abs": "https://arxiv.org/abs/2507.21433", "authors": ["Kaiwen Chen", "Xin Tan", "Minchen Yu", "Hong Xu"], "title": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse", "comment": "11 pages, 7 figures, submitted to AAAI 2026", "summary": "Large Reasoning Models (LRMs) have achieved significant advances in\nmathematical reasoning and formal logic tasks. However, their tendency to\ngenerate lengthy chain-of-thought sequences leads to substantial memory\noverhead during inference. We observe that LRMs frequently produce highly\nsimilar intermediate reasoning steps, which correspond to similar KV cache\nstates across layers. Motivated by this observation, we propose MemShare, a\nnovel KV cache management approach that effectively reduces memory overhead.\nMemShare employs a collaborative filtering algorithm to efficiently identify\nreusable KV cache blocks and enables zero copy cache reuse to significantly\nreduce memory overhead, improve throughput while maintaining accuracy.\nExperimental results demonstrate that MemShare delivers up to 84.79\\%\nimprovement in throughput while maintaining better accuracy compared to\nexisting KV cache management methods.", "AI": {"tldr": "MemShare reduces memory overhead in Large Reasoning Models by reusing similar KV cache blocks, improving throughput by 84.79% without losing accuracy.", "motivation": "LRMs generate redundant intermediate reasoning steps, causing memory inefficiency due to similar KV cache states.", "method": "MemShare uses collaborative filtering to identify reusable KV cache blocks and enables zero-copy reuse.", "result": "MemShare improves throughput by up to 84.79% while maintaining accuracy.", "conclusion": "MemShare effectively reduces memory overhead and enhances performance in LRMs."}}
{"id": "2507.21503", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21503", "abs": "https://arxiv.org/abs/2507.21503", "authors": ["Yanxu Zhu", "Shitong Duan", "Xiangxu Zhang", "Jitao Sang", "Peng Zhang", "Tun Lu", "Xiao Zhou", "Jing Yao", "Xiaoyuan Yi", "Xing Xie"], "title": "MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions", "comment": null, "summary": "Recently Multimodal Large Language Models (MLLMs) have achieved considerable\nadvancements in vision-language tasks, yet produce potentially harmful or\nuntrustworthy content. Despite substantial work investigating the\ntrustworthiness of language models, MMLMs' capability to act honestly,\nespecially when faced with visually unanswerable questions, remains largely\nunderexplored. This work presents the first systematic assessment of honesty\nbehaviors across various MLLMs. We ground honesty in models' response behaviors\nto unanswerable visual questions, define four representative types of such\nquestions, and construct MoHoBench, a large-scale MMLM honest benchmark,\nconsisting of 12k+ visual question samples, whose quality is guaranteed by\nmulti-stage filtering and human verification. Using MoHoBench, we benchmarked\nthe honesty of 28 popular MMLMs and conducted a comprehensive analysis. Our\nfindings show that: (1) most models fail to appropriately refuse to answer when\nnecessary, and (2) MMLMs' honesty is not solely a language modeling issue, but\nis deeply influenced by visual information, necessitating the development of\ndedicated methods for multimodal honesty alignment. Therefore, we implemented\ninitial alignment methods using supervised and preference learning to improve\nhonesty behavior, providing a foundation for future work on trustworthy MLLMs.\nOur data and code can be found at https://github.com/DSTTSD/MoHoBench.", "AI": {"tldr": "The paper assesses honesty in Multimodal Large Language Models (MLLMs) when answering visually unanswerable questions, introduces MoHoBench for benchmarking, and proposes alignment methods to improve honesty.", "motivation": "Despite advancements in MLLMs, their trustworthiness, especially in handling visually unanswerable questions, remains underexplored. This work aims to systematically evaluate and improve honesty in MLLMs.", "method": "The study defines four types of unanswerable visual questions, constructs MoHoBench (12k+ samples), benchmarks 28 MLLMs, and implements supervised and preference learning for alignment.", "result": "Findings reveal most models fail to refuse unanswerable questions appropriately, and honesty is influenced by visual information, not just language modeling.", "conclusion": "The work highlights the need for dedicated methods to align MLLMs for honesty, providing initial solutions and a foundation for future trustworthy MLLM development."}}
{"id": "2507.21437", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21437", "abs": "https://arxiv.org/abs/2507.21437", "authors": ["Tiantian Sun", "Jian Zu"], "title": "PVD-ONet: A Multi-scale Neural Operator Method for Singularly Perturbed Boundary Layer Problems", "comment": "34pages,14figures", "summary": "Physics-informed neural networks and Physics-informed DeepONet excel in\nsolving partial differential equations; however, they often fail to converge\nfor singularly perturbed problems. To address this, we propose two novel\nframeworks, Prandtl-Van Dyke neural network (PVD-Net) and its operator learning\nextension Prandtl-Van Dyke Deep Operator Network (PVD-ONet), which rely solely\non governing equations without data. To address varying task-specific\nrequirements, both PVD-Net and PVD-ONet are developed in two distinct versions,\ntailored respectively for stability-focused and high-accuracy modeling. The\nleading-order PVD-Net adopts a two-network architecture combined with Prandtl's\nmatching condition, targeting stability-prioritized scenarios. The high-order\nPVD-Net employs a five-network design with Van Dyke's matching principle to\ncapture fine-scale boundary layer structures, making it ideal for high-accuracy\nscenarios. PVD-ONet generalizes PVD-Net to the operator learning setting by\nassembling multiple DeepONet modules, directly mapping initial conditions to\nsolution operators and enabling instant predictions for an entire family of\nboundary layer problems without retraining. Numerical experiments on various\nmodels show that our proposed methods consistently outperform existing\nbaselines under various error metrics, thereby offering a powerful new approach\nfor multi-scale problems.", "AI": {"tldr": "Proposes PVD-Net and PVD-ONet frameworks to solve singularly perturbed PDEs without data, outperforming existing methods.", "motivation": "Address the failure of physics-informed neural networks in singularly perturbed problems.", "method": "Two versions of PVD-Net (stability-focused and high-accuracy) and PVD-ONet (operator learning) using Prandtl-Van Dyke principles.", "result": "Numerical experiments show superior performance over baselines in multi-scale problems.", "conclusion": "PVD-Net and PVD-ONet offer effective solutions for singularly perturbed PDEs, enhancing stability and accuracy."}}
{"id": "2507.21513", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21513", "abs": "https://arxiv.org/abs/2507.21513", "authors": ["Kenneth Li", "Fernanda Vi\u00e9gas", "Martin Wattenberg"], "title": "What Does it Mean for a Neural Network to Learn a \"World Model\"?", "comment": null, "summary": "We propose a set of precise criteria for saying a neural net learns and uses\na \"world model.\" The goal is to give an operational meaning to terms that are\noften used informally, in order to provide a common language for experimental\ninvestigation. We focus specifically on the idea of representing a latent\n\"state space\" of the world, leaving modeling the effect of actions to future\nwork. Our definition is based on ideas from the linear probing literature, and\nformalizes the notion of a computation that factors through a representation of\nthe data generation process. An essential addition to the definition is a set\nof conditions to check that such a \"world model\" is not a trivial consequence\nof the neural net's data or task.", "AI": {"tldr": "Proposes criteria for defining when a neural net learns a \"world model,\" focusing on latent state space representation and avoiding trivial solutions.", "motivation": "To operationalize informal terms like \"world model\" for experimental research, providing a common language.", "method": "Uses ideas from linear probing literature to formalize computations factoring through data generation representations, with conditions to ensure non-triviality.", "result": "A precise definition of a \"world model\" in neural nets, emphasizing latent state space and excluding trivial cases.", "conclusion": "Provides a foundation for future experimental work on world models in neural networks, with action effects left for later study."}}
{"id": "2507.21452", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.21452", "abs": "https://arxiv.org/abs/2507.21452", "authors": ["Sodtavilan Odonchimed", "Tatsuya Matsushima", "Simon Holk", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training", "comment": null, "summary": "Diffusion Policies (DPs) have attracted attention for their ability to\nachieve significant accuracy improvements in various imitation learning tasks.\nHowever, DPs depend on Diffusion Models, which require multiple noise removal\nsteps to generate a single action, resulting in long generation times. To solve\nthis problem, knowledge distillation-based methods such as Consistency Policy\n(CP) have been proposed. However, these methods require a significant amount of\ntraining time, especially for difficult tasks. In this study, we propose RAGDP\n(Retrieve-Augmented Generation for Diffusion Policies) as a novel framework\nthat eliminates the need for additional training using a knowledge base to\nexpedite the inference of pre-trained DPs. In concrete, RAGDP encodes\nobservation-action pairs through the DP encoder to construct a vector database\nof expert demonstrations. During inference, the current observation is\nembedded, and the most similar expert action is extracted. This extracted\naction is combined with an intermediate noise removal step to reduce the number\nof steps required compared to the original diffusion step. We show that by\nusing RAGDP with the base model and existing acceleration methods, we improve\nthe accuracy and speed trade-off with no additional training. Even when\naccelerating the models 20 times, RAGDP maintains an advantage in accuracy,\nwith a 7% increase over distillation models such as CP.", "AI": {"tldr": "RAGDP is a novel framework that speeds up Diffusion Policies (DPs) without extra training by using a knowledge base of expert demonstrations, improving accuracy and speed trade-offs.", "motivation": "DPs are slow due to multiple noise removal steps, and existing methods like CP require long training times. RAGDP aims to address these issues.", "method": "RAGDP encodes observation-action pairs into a vector database. During inference, it retrieves the most similar expert action and combines it with intermediate noise removal to reduce steps.", "result": "RAGDP improves accuracy and speed, maintaining a 7% accuracy advantage over CP even when models are accelerated 20 times.", "conclusion": "RAGDP offers a training-free solution to enhance DPs, balancing speed and accuracy effectively."}}
{"id": "2507.21518", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21518", "abs": "https://arxiv.org/abs/2507.21518", "authors": ["Jing Xu", "Weiqiang Wang", "Cunjian Chen", "Jun Liu", "Qiuhong Ke"], "title": "ST-GDance: Long-Term and Collision-Free Group Choreography from Music", "comment": "10 pages, 5 figures. Accepted at BMVC 2025", "summary": "Group dance generation from music has broad applications in film, gaming, and\nanimation production. However, it requires synchronizing multiple dancers while\nmaintaining spatial coordination. As the number of dancers and sequence length\nincrease, this task faces higher computational complexity and a greater risk of\nmotion collisions. Existing methods often struggle to model dense\nspatial-temporal interactions, leading to scalability issues and multi-dancer\ncollisions. To address these challenges, we propose ST-GDance, a novel\nframework that decouples spatial and temporal dependencies to optimize\nlong-term and collision-free group choreography. We employ lightweight graph\nconvolutions for distance-aware spatial modeling and accelerated sparse\nattention for efficient temporal modeling. This design significantly reduces\ncomputational costs while ensuring smooth and collision-free interactions.\nExperiments on the AIOZ-GDance dataset demonstrate that ST-GDance outperforms\nstate-of-the-art baselines, particularly in generating long and coherent group\ndance sequences. Project page: https://yilliajing.github.io/ST-GDance-Website/.", "AI": {"tldr": "ST-GDance is a framework for generating synchronized group dances from music, addressing scalability and collision issues by decoupling spatial and temporal dependencies.", "motivation": "Group dance generation faces challenges in synchronizing multiple dancers and avoiding collisions, especially with longer sequences and more dancers. Existing methods struggle with dense spatial-temporal interactions.", "method": "ST-GDance uses lightweight graph convolutions for spatial modeling and sparse attention for temporal modeling, optimizing long-term choreography and collision avoidance.", "result": "ST-GDance outperforms state-of-the-art methods on the AIOZ-GDance dataset, particularly for long and coherent sequences.", "conclusion": "The proposed framework effectively reduces computational costs while ensuring smooth, collision-free group dance generation."}}
{"id": "2507.21479", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.SY", "eess.SY", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.21479", "abs": "https://arxiv.org/abs/2507.21479", "authors": ["Zheng Wen", "Doina Precup", "Benjamin Van Roy", "Satinder Singh"], "title": "Capacity-Constrained Continual Learning", "comment": null, "summary": "Any agents we can possibly build are subject to capacity constraints, as\nmemory and compute resources are inherently finite. However, comparatively\nlittle attention has been dedicated to understanding how agents with limited\ncapacity should allocate their resources for optimal performance. The goal of\nthis paper is to shed some light on this question by studying a simple yet\nrelevant continual learning problem: the capacity-constrained\nlinear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a\nsolution to this problem under appropriate technical conditions. Moreover, for\nproblems that can be decomposed into a set of sub-problems, we also demonstrate\nhow to optimally allocate capacity across these sub-problems in the steady\nstate. We view the results of this paper as a first step in the systematic\ntheoretical study of learning under capacity constraints.", "AI": {"tldr": "The paper addresses how agents with limited memory and compute resources should allocate capacity for optimal performance, focusing on a continual learning problem called the capacity-constrained LQG sequential prediction problem.", "motivation": "To understand optimal resource allocation for agents with finite capacity, a topic that has received little attention.", "method": "Derives a solution for the capacity-constrained LQG sequential prediction problem under technical conditions and demonstrates optimal capacity allocation for decomposable sub-problems in steady state.", "result": "Provides a theoretical solution for capacity allocation in constrained learning scenarios.", "conclusion": "This work is a foundational step in systematically studying learning under capacity constraints."}}
{"id": "2507.21524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21524", "abs": "https://arxiv.org/abs/2507.21524", "authors": ["Le Liang", "Hao Ye", "Yucheng Sheng", "Ouya Wang", "Jiacheng Wang", "Shi Jin", "Geoffrey Ye Li"], "title": "Large Language Models for Wireless Communications: From Adaptation to Autonomy", "comment": null, "summary": "The emergence of large language models (LLMs) has revolutionized artificial\nintelligence, offering unprecedented capabilities in reasoning, generalization,\nand zero-shot learning. These strengths open new frontiers in wireless\ncommunications, where increasing complexity and dynamics demand intelligent and\nadaptive solutions. This article explores the role of LLMs in transforming\nwireless systems across three key directions: adapting pretrained LLMs for core\ncommunication tasks, developing wireless-specific foundation models to balance\nversatility and efficiency, and enabling agentic LLMs with autonomous reasoning\nand coordination capabilities. We highlight recent advances, practical case\nstudies, and the unique benefits of LLM-based approaches over traditional\nmethods. Finally, we outline open challenges and research opportunities,\nincluding multimodal fusion, collaboration with lightweight models, and\nself-improving capabilities, charting a path toward intelligent, adaptive, and\nautonomous wireless networks of the future.", "AI": {"tldr": "The paper explores how large language models (LLMs) can revolutionize wireless communications by adapting them for core tasks, developing wireless-specific models, and enabling autonomous reasoning. It highlights benefits over traditional methods and outlines future research challenges.", "motivation": "The increasing complexity and dynamics of wireless communications demand intelligent and adaptive solutions, which LLMs can provide due to their reasoning and generalization capabilities.", "method": "The study examines three approaches: adapting pretrained LLMs for communication tasks, creating wireless-specific foundation models, and developing agentic LLMs with autonomous reasoning.", "result": "LLM-based approaches offer unique benefits over traditional methods, as demonstrated by recent advances and case studies.", "conclusion": "The paper identifies open challenges like multimodal fusion and self-improving capabilities, paving the way for intelligent and autonomous wireless networks."}}
{"id": "2507.21494", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21494", "abs": "https://arxiv.org/abs/2507.21494", "authors": ["Wenxuan Bao", "Ruxi Deng", "Ruizhong Qiu", "Tianxin Wei", "Hanghang Tong", "Jingrui He"], "title": "Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning", "comment": "Accepted by ICCV 2025", "summary": "Test-time adaptation with pre-trained vision-language models has gained\nincreasing attention for addressing distribution shifts during testing. Among\nthese approaches, memory-based algorithms stand out due to their training-free\nnature and ability to leverage historical test data. However, existing\ntest-time adaptation methods are typically designed for a single domain with\nabundant data. In decentralized settings such as federated learning, applying\nthese methods individually to each client suffers from limited test data, while\ndirectly sharing a single global memory via the server prevents proper\npersonalization to each client's unique distribution. To address this, we\npropose Latte, a novel framework where each client maintains a local memory to\nstore embeddings from its own historical test data and an external memory to\nstore class prototypes from other relevant clients. During communication, each\nclient retrieves prototypes from similar clients under the server's\ncoordination to expand its memory. For local adaptation, Latte utilizes both\nembedding similarity and uncertainty to enhance model performance. Our\ntheoretical analysis shows that Latte effectively leverages in-distribution\nclients while remaining robust to out-of-distribution clients. Extensive\nexperiments on domain adaptation and corruption benchmarks validate that Latte\nachieves superior performance in decentralized settings, while introducing only\nnegligible communication and computation costs. Our code is available at\nhttps://github.com/baowenxuan/Latte .", "AI": {"tldr": "Latte is a novel framework for test-time adaptation in decentralized settings, using local and external memories to enhance model performance while minimizing communication costs.", "motivation": "Existing test-time adaptation methods struggle with limited data in decentralized settings and lack personalization for individual clients.", "method": "Latte uses local and external memories to store embeddings and class prototypes, leveraging similarity and uncertainty for adaptation.", "result": "Latte outperforms existing methods in decentralized settings with minimal added costs.", "conclusion": "Latte effectively addresses distribution shifts in decentralized environments, offering robust and personalized adaptation."}}
{"id": "2507.21571", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.21571", "abs": "https://arxiv.org/abs/2507.21571", "authors": ["Laura Spillner", "Nima Zargham", "Mihai Pomarlan", "Robert Porzel", "Rainer Malaka"], "title": "Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations", "comment": "Presented at the IJCAI 2023 Workshop on Explainable Artificial\n  Intelligence (XAI)", "summary": "The need for explanations in AI has, by and large, been driven by the desire\nto increase the transparency of black-box machine learning models. However,\nsuch explanations, which focus on the internal mechanisms that lead to a\nspecific output, are often unsuitable for non-experts. To facilitate a\nhuman-centered perspective on AI explanations, agents need to focus on\nindividuals and their preferences as well as the context in which the\nexplanations are given. This paper proposes a personalized approach to\nexplanation, where the agent tailors the information provided to the user based\non what is most likely pertinent to them. We propose a model of the agent's\nworldview that also serves as a personal and dynamic memory of its previous\ninteractions with the same user, based on which the artificial agent can\nestimate what part of its knowledge is most likely new information to the user.", "AI": {"tldr": "The paper proposes a personalized AI explanation approach tailored to user preferences and context, using a dynamic memory model for relevance.", "motivation": "Current AI explanations focus on model internals, often unsuitable for non-experts. A human-centered approach is needed.", "method": "A personalized explanation model with a dynamic memory of user interactions to estimate relevant information.", "result": "The approach aims to improve explanation relevance and usability for non-experts.", "conclusion": "Personalized explanations enhance transparency and user understanding in AI systems."}}
{"id": "2507.21504", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21504", "abs": "https://arxiv.org/abs/2507.21504", "authors": ["Mahmoud Mohammadi", "Yipeng Li", "Jane Lo", "Wendy Yip"], "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "comment": null, "summary": "The rise of LLM-based agents has opened new frontiers in AI applications, yet\nevaluating these agents remains a complex and underdeveloped area. This survey\nprovides an in-depth overview of the emerging field of LLM agent evaluation,\nintroducing a two-dimensional taxonomy that organizes existing work along (1)\nevaluation objectives -- what to evaluate, such as agent behavior,\ncapabilities, reliability, and safety -- and (2) evaluation process -- how to\nevaluate, including interaction modes, datasets and benchmarks, metric\ncomputation methods, and tooling. In addition to taxonomy, we highlight\nenterprise-specific challenges, such as role-based access to data, the need for\nreliability guarantees, dynamic and long-horizon interactions, and compliance,\nwhich are often overlooked in current research. We also identify future\nresearch directions, including holistic, more realistic, and scalable\nevaluation. This work aims to bring clarity to the fragmented landscape of\nagent evaluation and provide a framework for systematic assessment, enabling\nresearchers and practitioners to evaluate LLM agents for real-world deployment.", "AI": {"tldr": "The paper surveys LLM agent evaluation, proposing a taxonomy for objectives and processes, addressing enterprise challenges, and suggesting future research directions.", "motivation": "Evaluating LLM-based agents is complex and underdeveloped, necessitating a structured approach for real-world deployment.", "method": "Introduces a two-dimensional taxonomy (evaluation objectives and process) and discusses enterprise-specific challenges.", "result": "Provides a framework for systematic evaluation, highlighting gaps like reliability and compliance.", "conclusion": "Aims to clarify the fragmented evaluation landscape and guide future research for scalable, realistic assessments."}}
{"id": "2507.21585", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21585", "abs": "https://arxiv.org/abs/2507.21585", "authors": ["Hao Ye", "Mengshi Qi", "Zhaohong Liu", "Liang Liu", "Huadong Ma"], "title": "SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation", "comment": null, "summary": "In this work, we study how vision-language models (VLMs) can be utilized to\nenhance the safety for the autonomous driving system, including perception,\nsituational understanding, and path planning. However, existing research has\nlargely overlooked the evaluation of these models in traffic safety-critical\ndriving scenarios. To bridge this gap, we create the benchmark (SafeDrive228K)\nand propose a new baseline based on VLM with knowledge graph-based\nretrieval-augmented generation (SafeDriveRAG) for visual question answering\n(VQA). Specifically, we introduce SafeDrive228K, the first large-scale\nmultimodal question-answering benchmark comprising 228K examples across 18\nsub-tasks. This benchmark encompasses a diverse range of traffic safety\nqueries, from traffic accidents and corner cases to common safety knowledge,\nenabling a thorough assessment of the comprehension and reasoning abilities of\nthe models. Furthermore, we propose a plug-and-play multimodal knowledge\ngraph-based retrieval-augmented generation approach that employs a novel\nmulti-scale subgraph retrieval algorithm for efficient information retrieval.\nBy incorporating traffic safety guidelines collected from the Internet, this\nframework further enhances the model's capacity to handle safety-critical\nsituations. Finally, we conduct comprehensive evaluations on five mainstream\nVLMs to assess their reliability in safety-sensitive driving tasks.\nExperimental results demonstrate that integrating RAG significantly improves\nperformance, achieving a +4.73% gain in Traffic Accidents tasks, +8.79% in\nCorner Cases tasks and +14.57% in Traffic Safety Commonsense across five\nmainstream VLMs, underscoring the potential of our proposed benchmark and\nmethodology for advancing research in traffic safety. Our source code and data\nare available at https://github.com/Lumos0507/SafeDriveRAG.", "AI": {"tldr": "The paper introduces SafeDrive228K, a large-scale multimodal benchmark for evaluating vision-language models (VLMs) in traffic safety-critical scenarios, and proposes SafeDriveRAG, a retrieval-augmented generation method to enhance VLM performance.", "motivation": "Existing research lacks evaluation of VLMs in safety-critical driving scenarios, prompting the creation of a benchmark and method to address this gap.", "method": "The authors develop SafeDrive228K (228K examples across 18 sub-tasks) and propose SafeDriveRAG, a knowledge graph-based retrieval-augmented generation approach with multi-scale subgraph retrieval.", "result": "Integration of RAG improves VLM performance by +4.73% in Traffic Accidents, +8.79% in Corner Cases, and +14.57% in Traffic Safety Commonsense tasks.", "conclusion": "The benchmark and methodology show promise for advancing traffic safety research, with code and data publicly available."}}
{"id": "2507.21531", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21531", "abs": "https://arxiv.org/abs/2507.21531", "authors": ["Pedram Rajaei", "Maryam Ostadsharif Memar", "Navid Ziaei", "Behzad Nazari", "Ali Yousefi"], "title": "Hierarchical Stochastic Differential Equation Models for Latent Manifold Learning in Neural Time Series", "comment": null, "summary": "The manifold hypothesis suggests that high-dimensional neural time series lie\non a low-dimensional manifold shaped by simpler underlying dynamics. To uncover\nthis structure, latent dynamical variable models such as state-space models,\nrecurrent neural networks, neural ordinary differential equations, and Gaussian\nProcess Latent Variable Models are widely used. We propose a novel hierarchical\nstochastic differential equation (SDE) model that balances computational\nefficiency and interpretability, addressing key limitations of existing\nmethods. Our model assumes the trajectory of a manifold can be reconstructed\nfrom a sparse set of samples from the manifold trajectory. The latent space is\nmodeled using Brownian bridge SDEs, with points - specified in both time and\nvalue - sampled from a multivariate marked point process. These Brownian\nbridges define the drift of a second set of SDEs, which are then mapped to the\nobserved data. This yields a continuous, differentiable latent process capable\nof modeling arbitrarily complex time series as the number of manifold points\nincreases. We derive training and inference procedures and show that the\ncomputational cost of inference scales linearly with the length of the\nobservation data. We then validate our model on both synthetic data and neural\nrecordings to demonstrate that it accurately recovers the underlying manifold\nstructure and scales effectively with data dimensionality.", "AI": {"tldr": "A novel hierarchical SDE model is proposed to efficiently and interpretably uncover low-dimensional manifolds in high-dimensional neural time series, outperforming existing methods.", "motivation": "Existing latent dynamical variable models lack balance between computational efficiency and interpretability for uncovering low-dimensional manifolds in neural time series.", "method": "The model uses hierarchical Brownian bridge SDEs to reconstruct manifold trajectories from sparse samples, mapping these to observed data via continuous, differentiable processes.", "result": "The model accurately recovers manifold structure, scales linearly with data length, and handles high-dimensional data effectively.", "conclusion": "The proposed SDE model offers a scalable, interpretable solution for manifold discovery in neural time series."}}
{"id": "2507.21588", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21588", "abs": "https://arxiv.org/abs/2507.21588", "authors": ["Jiong Yin", "Liang Li", "Jiehua Zhang", "Yuhan Gao", "Chenggang Yan", "Xichun Sheng"], "title": "Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning", "comment": "Accepted by ICCV 2025", "summary": "Audio-visual multi-task incremental learning aims to continuously learn from\nmultiple audio-visual tasks without the need for joint training on all tasks.\nThe challenge of the problem is how to preserve the old task knowledge while\nfacilitating the learning of new task with previous experiences. To address\nthese challenges, we introduce a three-stage Progressive Homeostatic and\nPlastic audio-visual prompt (PHP) method. In the shallow phase, we design the\ntask-shared modality aggregating adapter to foster cross-task and cross-modal\naudio-visual representation learning to enhance shared understanding between\ntasks. In the middle phase, we propose the task-specific modality-shared\ndynamic generating adapter, which constructs prompts that are tailored to\nindividual tasks while remaining general across modalities, which balances the\nmodels ability to retain knowledge against forgetting with its potential for\nversatile multi-task transferability. In the deep phase, we introduce the\ntask-specific modality-independent prompts to further refine the understand\nability by targeting individual information for each task and modality. By\nincorporating these three phases, PHP retains task-specific prompts while\nadapting shared parameters for new tasks to effectively balance knowledge\nsharing and specificity. Our method achieves SOTA performance in different\norders of four tasks (AVE, AVVP, AVS and AVQA). Our code can be available at\nhttps://github.com/ENJOY-Yin-jiong/PHP.", "AI": {"tldr": "The paper introduces PHP, a three-stage method for audio-visual multi-task incremental learning, balancing knowledge retention and new task learning.", "motivation": "To address the challenge of preserving old task knowledge while learning new tasks in audio-visual incremental learning.", "method": "PHP involves three phases: shallow (cross-task/modality adapter), middle (task-specific dynamic adapter), and deep (task/modality-specific prompts).", "result": "PHP achieves state-of-the-art performance on four tasks (AVE, AVVP, AVS, AVQA).", "conclusion": "PHP effectively balances knowledge sharing and specificity, improving incremental learning in audio-visual tasks."}}
{"id": "2507.21616", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21616", "abs": "https://arxiv.org/abs/2507.21616", "authors": ["Kevin Doran", "Tom Baden"], "title": "Categorical Distributions are Effective Neural Network Outputs for Event Prediction", "comment": "32 pages, 26 figures", "summary": "We demonstrate the effectiveness of using a simple neural network output, a\ncategorical probability distribution, for the task of next spike prediction.\nThis case study motivates an investigation into why this simple output\nstructure is not commonly used with neural temporal point process models. We\nfind evidence that many existing datasets for evaluating temporal point process\nmodels do not reveal much information about the underlying event generating\nprocesses, and many existing models perform well due to regularization effects\nof model size and constraints on output structure. We extend existing datasets\nand create new ones in order to explore outside of this information limited\nregime and find that outputting a simple categorical distribution is\ncompetitive across a wide range of datasets.", "AI": {"tldr": "A simple neural network output (categorical probability distribution) is effective for next spike prediction, challenging the underuse of such outputs in neural temporal point process models.", "motivation": "To investigate why simple output structures are uncommon in neural temporal point process models and to explore dataset limitations.", "method": "Extend and create datasets to test the effectiveness of categorical distribution outputs in varied scenarios.", "result": "Simple categorical distribution outputs are competitive across datasets, revealing limitations in existing datasets and models.", "conclusion": "Simple outputs can be effective, and dataset constraints may obscure true model performance."}}
{"id": "2507.21589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21589", "abs": "https://arxiv.org/abs/2507.21589", "authors": ["Bin Liu"], "title": "Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems", "comment": "16 pages", "summary": "Embodied intelligence posits that cognitive capabilities fundamentally emerge\nfrom - and are shaped by - an agent's real-time sensorimotor interactions with\nits environment. Such adaptive behavior inherently requires continuous\ninference under uncertainty. Bayesian statistics offers a principled\nprobabilistic framework to address this challenge by representing knowledge as\nprobability distributions and updating beliefs in response to new evidence. The\ncore computational processes underlying embodied intelligence - including\nperception, action selection, learning, and even higher-level cognition - can\nbe effectively understood and modeled as forms of Bayesian inference. Despite\nthe deep conceptual connection between Bayesian statistics and embodied\nintelligence, Bayesian principles have not been widely or explicitly applied in\ntoday's embodied intelligence systems. In this work, we examine both Bayesian\nand contemporary embodied intelligence approaches through two fundamental\nlenses: search and learning - the two central themes in modern AI, as\nhighlighted in Rich Sutton's influential essay \"The Bitter Lesson\". This\nanalysis sheds light on why Bayesian inference has not played a central role in\nthe development of modern embodied intelligence. At the same time, it reveals\nthat current embodied intelligence systems remain largely confined to\nclosed-physical-world environments, and highlights the potential for Bayesian\nmethods to play a key role in extending these systems toward truly open\nphysical-world embodied intelligence.", "AI": {"tldr": "The paper explores the underutilization of Bayesian methods in embodied intelligence systems, despite their theoretical alignment, and suggests their potential for advancing open-world applications.", "motivation": "To understand why Bayesian principles, which align well with embodied intelligence, are not widely applied in current systems, and to highlight their potential for future advancements.", "method": "Analysis of Bayesian and contemporary embodied intelligence approaches through the lenses of search and learning, as per Rich Sutton's \"The Bitter Lesson.\"", "result": "Bayesian inference is not central in modern embodied intelligence systems, which are limited to closed-world environments, but it holds promise for open-world applications.", "conclusion": "Bayesian methods could significantly enhance embodied intelligence systems, particularly for open-world scenarios, despite their current underuse."}}
{"id": "2507.21648", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21648", "abs": "https://arxiv.org/abs/2507.21648", "authors": ["Raiyan R. Khan", "Philippe Chlenski", "Itsik Pe'er"], "title": "Hyperbolic Genome Embeddings", "comment": "30 pages, 16 figures, 10 tables. Camera-ready version for ICLR 2025", "summary": "Current approaches to genomic sequence modeling often struggle to align the\ninductive biases of machine learning models with the evolutionarily-informed\nstructure of biological systems. To this end, we formulate a novel application\nof hyperbolic CNNs that exploits this structure, enabling more expressive DNA\nsequence representations. Our strategy circumvents the need for explicit\nphylogenetic mapping while discerning key properties of sequences pertaining to\ncore functional and regulatory behavior. Across 37 out of 42 genome\ninterpretation benchmark datasets, our hyperbolic models outperform their\nEuclidean equivalents. Notably, our approach even surpasses state-of-the-art\nperformance on seven GUE benchmark datasets, consistently outperforming many\nDNA language models while using orders of magnitude fewer parameters and\navoiding pretraining. Our results include a novel set of benchmark\ndatasets--the Transposable Elements Benchmark--which explores a major but\nunderstudied component of the genome with deep evolutionary significance. We\nfurther motivate our work by exploring how our hyperbolic models recognize\ngenomic signal under various data-generating conditions and by constructing an\nempirical method for interpreting the hyperbolicity of dataset embeddings.\nThroughout these assessments, we find persistent evidence highlighting the\npotential of our hyperbolic framework as a robust paradigm for genome\nrepresentation learning. Our code and benchmark datasets are available at\nhttps://github.com/rrkhan/HGE.", "AI": {"tldr": "Hyperbolic CNNs outperform Euclidean models in genomic sequence representation, achieving better performance with fewer parameters and no pretraining.", "motivation": "Aligning machine learning inductive biases with biological evolutionary structure for better DNA sequence modeling.", "method": "Novel application of hyperbolic CNNs to exploit evolutionary structure without explicit phylogenetic mapping.", "result": "Outperforms Euclidean models on 37/42 benchmarks and state-of-the-art on 7 GUE datasets, with fewer parameters.", "conclusion": "Hyperbolic framework shows robust potential for genome representation learning, validated by empirical assessments."}}
{"id": "2507.21653", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21653", "abs": "https://arxiv.org/abs/2507.21653", "authors": ["Yuan Li", "Jun Hu", "Bryan Hooi", "Bingsheng He", "Cheng Chen"], "title": "DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs", "comment": null, "summary": "Real-world fraud detection applications benefit from graph learning\ntechniques that jointly exploit node features, often rich in textual data, and\ngraph structural information. Recently, Graph-Enhanced LLMs emerge as a\npromising graph learning approach that converts graph information into prompts,\nexploiting LLMs' ability to reason over both textual and structural\ninformation. Among them, text-only prompting, which converts graph information\nto prompts consisting solely of text tokens, offers a solution that relies only\non LLM tuning without requiring additional graph-specific encoders. However,\ntext-only prompting struggles on heterogeneous fraud-detection graphs:\nmulti-hop relations expand exponentially with each additional hop, leading to\nrapidly growing neighborhoods associated with dense textual information. These\nneighborhoods may overwhelm the model with long, irrelevant content in the\nprompt and suppress key signals from the target node, thereby degrading\nperformance. To address this challenge, we propose Dual Granularity Prompting\n(DGP), which mitigates information overload by preserving fine-grained textual\ndetails for the target node while summarizing neighbor information into\ncoarse-grained text prompts. DGP introduces tailored summarization strategies\nfor different data modalities, bi-level semantic abstraction for textual fields\nand statistical aggregation for numerical features, enabling effective\ncompression of verbose neighbor content into concise, informative prompts.\nExperiments across public and industrial datasets demonstrate that DGP operates\nwithin a manageable token budget while improving fraud detection performance by\nup to 6.8% (AUPRC) over state-of-the-art methods, showing the potential of\nGraph-Enhanced LLMs for fraud detection.", "AI": {"tldr": "Dual Granularity Prompting (DGP) improves fraud detection by summarizing neighbor information into concise prompts, addressing the limitations of text-only prompting in heterogeneous graphs.", "motivation": "Text-only prompting struggles with heterogeneous fraud-detection graphs due to exponential growth of multi-hop relations and dense textual information, which overwhelms models and degrades performance.", "method": "DGP preserves fine-grained textual details for the target node while summarizing neighbor information into coarse-grained prompts, using tailored summarization strategies for different data modalities.", "result": "DGP improves fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods while operating within a manageable token budget.", "conclusion": "DGP demonstrates the potential of Graph-Enhanced LLMs for fraud detection by effectively mitigating information overload and enhancing performance."}}
{"id": "2507.21636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21636", "abs": "https://arxiv.org/abs/2507.21636", "authors": ["Alessio Maritan"], "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "comment": null, "summary": "Large language model (LLM) agents integrate pre-trained LLMs with modular\nalgorithmic components and have shown remarkable reasoning and decision-making\nabilities. In this work, we investigate their use for two tightly intertwined\nchallenges in workforce management: staffing, i.e., the assignment and\nscheduling of tasks to workers, which may require team formation; and\nprofiling, i.e., the continuous estimation of workers' skills, preferences, and\nother latent attributes from unstructured data. We cast these problems in a\nformal mathematical framework that links scheduling decisions to latent feature\nestimation, and we introduce StaffPro, an LLM agent that addresses staffing and\nprofiling jointly. Differently from existing staffing solutions, StaffPro\nallows expressing optimization objectives using natural language, accepts\ntextual task descriptions and provides high flexibility. StaffPro interacts\ndirectly with humans by establishing a continuous human-agent feedback loop,\nensuring natural and intuitive use. By analyzing human feedback, our agent\ncontinuously estimates the latent features of workers, realizing life-long\nworker profiling and ensuring optimal staffing performance over time. A\nconsulting firm simulation example demonstrates that StaffPro successfully\nestimates workers' attributes and generates high quality schedules. With its\ninnovative design, StaffPro offers a robust, interpretable, and human-centric\nsolution for automated personnel management.", "AI": {"tldr": "StaffPro is an LLM agent for workforce management, combining staffing and profiling tasks with natural language flexibility and human feedback.", "motivation": "To address the intertwined challenges of staffing (task assignment/scheduling) and profiling (worker attribute estimation) in workforce management using LLMs.", "method": "Introduces StaffPro, an LLM agent that formalizes staffing and profiling in a mathematical framework, uses natural language for objectives, and employs a human-agent feedback loop for continuous learning.", "result": "StaffPro effectively estimates worker attributes and generates high-quality schedules, demonstrated in a consulting firm simulation.", "conclusion": "StaffPro provides a robust, interpretable, and human-centric solution for automated personnel management."}}
{"id": "2507.21670", "categories": ["cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.21670", "abs": "https://arxiv.org/abs/2507.21670", "authors": ["Paul Patrone", "Anthony Kearsley"], "title": "Probabilistic Consistency in Machine Learning and Its Connection to Uncertainty Quantification", "comment": null, "summary": "Machine learning (ML) is often viewed as a powerful data analysis tool that\nis easy to learn because of its black-box nature. Yet this very nature also\nmakes it difficult to quantify confidence in predictions extracted from ML\nmodels, and more fundamentally, to understand how such models are mathematical\nabstractions of training data. The goal of this paper is to unravel these\nissues and their connections to uncertainty quantification (UQ) by pursuing a\nline of reasoning motivated by diagnostics. In such settings, prevalence - i.e.\nthe fraction of elements in class - is often of inherent interest. Here we\nanalyze the many interpretations of prevalence to derive a level-set theory of\nclassification, which shows that certain types of self-consistent ML models are\nequivalent to class-conditional probability distributions. We begin by studying\nthe properties of binary Bayes optimal classifiers, recognizing that their\nboundary sets can be reinterpreted as level-sets of pairwise density ratios. By\nparameterizing Bayes classifiers in terms of the prevalence, we then show that\nthey satisfy important monotonicity and class-switching properties that can be\nused to deduce the density ratios without direct access to the boundary sets.\nMoreover, this information is sufficient for tasks such as constructing the\nmulticlass Bayes-optimal classifier and estimating inherent uncertainty in the\nclass assignments. In the multiclass case, we use these results to deduce\nnormalization and self-consistency conditions, the latter being equivalent to\nthe law of total probability for classifiers. We also show that these are\nnecessary conditions for arbitrary ML models to have valid probabilistic\ninterpretations. Throughout we demonstrate how this analysis informs the\nbroader task of UQ for ML via an uncertainty propagation framework.", "AI": {"tldr": "The paper explores the connections between machine learning models and uncertainty quantification, focusing on prevalence and deriving a level-set theory of classification to show equivalence between self-consistent ML models and class-conditional probability distributions.", "motivation": "To address the challenges of quantifying confidence in ML predictions and understanding how models abstract training data, particularly in diagnostic settings where prevalence is key.", "method": "Analyzes binary Bayes optimal classifiers, reinterprets their boundary sets as level-sets of density ratios, and parameterizes them by prevalence to deduce properties like monotonicity and class-switching. Extends to multiclass cases with normalization and self-consistency conditions.", "result": "Shows that certain ML models are equivalent to class-conditional probability distributions and derives necessary conditions for valid probabilistic interpretations.", "conclusion": "The analysis provides a framework for uncertainty quantification in ML, linking model properties to probabilistic interpretations and uncertainty propagation."}}
{"id": "2507.21637", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21637", "abs": "https://arxiv.org/abs/2507.21637", "authors": ["Wanying Wang", "Zeyu Ma", "Han Zheng", "Xin Tan", "Mingang Chen"], "title": "Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models", "comment": "Accepted by ACM Multimedia 2025", "summary": "Large vision-language models (LVLMs) are vulnerable to harmful input compared\nto their language-only backbones. We investigated this vulnerability by\nexploring LVLMs internal dynamics, framing their inherent safety understanding\nin terms of three key capabilities. Specifically, we define these capabilities\nas safety perception, semantic understanding, and alignment for linguistic\nexpression, and experimentally pinpointed their primary locations within the\nmodel architecture. The results indicate that safety perception often emerges\nbefore comprehensive semantic understanding, leading to the reduction in\nsafety. Motivated by these findings, we propose \\textbf{Self-Aware Safety\nAugmentation (SASA)}, a technique that projects informative semantic\nrepresentations from intermediate layers onto earlier safety-oriented layers.\nThis approach leverages the model's inherent semantic understanding to enhance\nsafety recognition without fine-tuning. Then, we employ linear probing to\narticulate the model's internal semantic comprehension to detect the risk\nbefore the generation process. Extensive experiments on various datasets and\ntasks demonstrate that SASA significantly improves the safety of LVLMs, with\nminimal impact on the utility.", "AI": {"tldr": "LVLMs are vulnerable to harmful inputs. The paper identifies three safety-related capabilities, proposes SASA to enhance safety without fine-tuning, and shows improved safety with minimal utility impact.", "motivation": "LVLMs are less safe than language-only models, prompting investigation into their internal safety dynamics.", "method": "Defines safety perception, semantic understanding, and alignment. Proposes SASA to project semantic representations onto safety layers and uses linear probing for risk detection.", "result": "SASA improves LVLM safety significantly without compromising utility.", "conclusion": "SASA effectively enhances LVLM safety by leveraging internal dynamics, offering a practical solution."}}
{"id": "2507.21710", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21710", "abs": "https://arxiv.org/abs/2507.21710", "authors": ["Hongwei Ma", "Junbin Gao", "Minh-Ngoc Tran"], "title": "PREIG: Physics-informed and Reinforcement-driven Interpretable GRU for Commodity Demand Forecasting", "comment": null, "summary": "Accurately forecasting commodity demand remains a critical challenge due to\nvolatile market dynamics, nonlinear dependencies, and the need for economically\nconsistent predictions. This paper introduces PREIG, a novel deep learning\nframework tailored for commodity demand forecasting. The model uniquely\nintegrates a Gated Recurrent Unit (GRU) architecture with physics-informed\nneural network (PINN) principles by embedding a domain-specific economic\nconstraint: the negative elasticity between price and demand. This constraint\nis enforced through a customized loss function that penalizes violations of the\nphysical rule, ensuring that model predictions remain interpretable and aligned\nwith economic theory. To further enhance predictive performance and stability,\nPREIG incorporates a hybrid optimization strategy that couples NAdam and L-BFGS\nwith Population-Based Training (POP). Experiments across multiple commodities\ndatasets demonstrate that PREIG significantly outperforms traditional\neconometric models (ARIMA,GARCH) and deep learning baselines (BPNN,RNN) in both\nRMSE and MAPE. When compared with GRU,PREIG maintains good explainability while\nstill performing well in prediction. By bridging domain knowledge, optimization\ntheory and deep learning, PREIG provides a robust, interpretable, and scalable\nsolution for high-dimensional nonlinear time series forecasting in economy.", "AI": {"tldr": "PREIG is a deep learning framework for commodity demand forecasting, combining GRU and PINN with economic constraints, outperforming traditional models.", "motivation": "Addressing the challenge of volatile and nonlinear commodity demand forecasting while ensuring economic consistency.", "method": "Integrates GRU with PINN, enforces economic constraints via a custom loss function, and uses hybrid optimization (NAdam, L-BFGS, POP).", "result": "PREIG outperforms ARIMA, GARCH, BPNN, and RNN in RMSE and MAPE, maintaining explainability.", "conclusion": "PREIG offers a robust, interpretable, and scalable solution for nonlinear time series forecasting in economics."}}
{"id": "2507.21638", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.21638", "abs": "https://arxiv.org/abs/2507.21638", "authors": ["Leonard Hinckeldey", "Elliot Fosong", "Elle Miller", "Rimvydas Rubavicius", "Trevor McInroe", "Patricia Wollstadt", "Christiane B. Wiebel-Herboth", "Subramanian Ramamoorthy", "Stefano V. Albrecht"], "title": "Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics", "comment": "Accepted for the Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025", "summary": "The development of reinforcement learning (RL) algorithms has been largely\ndriven by ambitious challenge tasks and benchmarks. Games have dominated RL\nbenchmarks because they present relevant challenges, are inexpensive to run and\neasy to understand. While games such as Go and Atari have led to many\nbreakthroughs, they often do not directly translate to real-world embodied\napplications. In recognising the need to diversify RL benchmarks and addressing\ncomplexities that arise in embodied interaction scenarios, we introduce\nAssistax: an open-source benchmark designed to address challenges arising in\nassistive robotics tasks. Assistax uses JAX's hardware acceleration for\nsignificant speed-ups for learning in physics-based simulations. In terms of\nopen-loop wall-clock time, Assistax runs up to $370\\times$ faster when\nvectorising training runs compared to CPU-based alternatives. Assistax\nconceptualises the interaction between an assistive robot and an active human\npatient using multi-agent RL to train a population of diverse partner agents\nagainst which an embodied robotic agent's zero-shot coordination capabilities\ncan be tested. Extensive evaluation and hyperparameter tuning for popular\ncontinuous control RL and MARL algorithms provide reliable baselines and\nestablish Assistax as a practical benchmark for advancing RL research for\nassistive robotics. The code is available at:\nhttps://github.com/assistive-autonomy/assistax.", "AI": {"tldr": "Assistax is an open-source benchmark for assistive robotics, leveraging JAX for speed and multi-agent RL for diverse training.", "motivation": "Games dominate RL benchmarks but lack real-world applicability; Assistax addresses embodied interaction complexities.", "method": "Uses JAX for hardware acceleration and multi-agent RL to train diverse partner agents for zero-shot coordination testing.", "result": "Assistax runs 370x faster than CPU-based alternatives and provides reliable baselines for RL in assistive robotics.", "conclusion": "Assistax is a practical benchmark for advancing RL research in assistive robotics, with open-source code available."}}
{"id": "2507.21720", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21720", "abs": "https://arxiv.org/abs/2507.21720", "authors": ["Gang Wang", "Peng Hu"], "title": "Data-Driven Extended Corresponding State Approach for Residual Property Prediction of Hydrofluoroolefins", "comment": null, "summary": "Hydrofluoroolefins are considered the most promising next-generation\nrefrigerants due to their extremely low global warming potential values, which\ncan effectively mitigate the global warming effect. However, the lack of\nreliable thermodynamic data hinders the discovery and application of newer and\nsuperior hydrofluoroolefin refrigerants. In this work, integrating the\nstrengths of theoretical method and data-driven method, we proposed a neural\nnetwork extended corresponding state model to predict the residual\nthermodynamic properties of hydrofluoroolefin refrigerants. The innovation is\nthat the fluids are characterized through their microscopic molecular\nstructures by the inclusion of graph neural network module and the specialized\ndesign of model architecture to enhance its generalization ability. The\nproposed model is trained using the highly accurate data of available known\nfluids, and evaluated via the leave-one-out cross-validation method. Compared\nto conventional extended corresponding state models or cubic equation of state,\nthe proposed model shows significantly improved accuracy for density and energy\nproperties in liquid and supercritical regions, with average absolute deviation\nof 1.49% (liquid) and 2.42% (supercritical) for density, 3.37% and 2.50% for\nresidual entropy, 1.85% and 1.34% for residual enthalpy. These results\ndemonstrate the effectiveness of embedding physics knowledge into the machine\nlearning model. The proposed neural network extended corresponding state model\nis expected to significantly accelerate the discovery of novel\nhydrofluoroolefin refrigerants.", "AI": {"tldr": "A neural network extended corresponding state model is proposed to predict hydrofluoroolefin refrigerant properties, combining theoretical and data-driven methods for improved accuracy.", "motivation": "The lack of reliable thermodynamic data for hydrofluoroolefins hinders their discovery and application as next-generation refrigerants.", "method": "Integrates graph neural networks and specialized model architecture to predict residual thermodynamic properties, trained on accurate data and validated via leave-one-out cross-validation.", "result": "Achieves high accuracy for density and energy properties in liquid and supercritical regions, outperforming conventional models.", "conclusion": "The model effectively embeds physics knowledge into machine learning, accelerating the discovery of superior hydrofluoroolefin refrigerants."}}
{"id": "2507.21664", "categories": ["cs.AI", "cs.HC", "math.HO"], "pdf": "https://arxiv.org/pdf/2507.21664", "abs": "https://arxiv.org/abs/2507.21664", "authors": ["Mariam Alsayyad", "Fayadh Kadhem"], "title": "Can the current trends of AI handle a full course of mathematics?", "comment": "36 pages", "summary": "This paper addresses the question of how able the current trends of\nArtificial Intelligence (AI) are in managing to take the responsibility of a\nfull course of mathematics at a college level. The study evaluates this ability\nin four significant aspects, namely, creating a course syllabus, presenting\nselected material, answering student questions, and creating an assessment. It\nshows that even though the AI is strong in some important parts like\norganization and accuracy, there are still some human aspects that are far away\nfrom the current abilities of AI. There is still a hidden emotional part, even\nin science, that cannot be fulfilled by the AI in its current state. This paper\nsuggests some recommendations to integrate the human and AI potentials to\ncreate better outcomes in terms of reaching the target of creating a full\ncourse of mathematics, at a university level, as best as possible.", "AI": {"tldr": "The paper evaluates AI's ability to manage a full college-level math course, highlighting strengths in organization and accuracy but noting gaps in emotional and human aspects. Recommendations for integrating human and AI efforts are provided.", "motivation": "To assess whether current AI trends can handle the responsibility of teaching a full college-level math course, including syllabus creation, material presentation, answering questions, and assessments.", "method": "The study evaluates AI capabilities in four key areas: syllabus creation, material presentation, answering student questions, and creating assessments.", "result": "AI excels in organization and accuracy but lacks in emotional and human aspects, making it insufficient for fully managing a math course alone.", "conclusion": "The paper recommends combining human and AI strengths to optimize the creation and delivery of a college-level math course."}}
{"id": "2507.21738", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21738", "abs": "https://arxiv.org/abs/2507.21738", "authors": ["Huiqiang Chen", "Tianqing Zhu", "Xin Yu", "Wanlei Zhou"], "title": "Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation", "comment": "Accepted by IJCAI 2025", "summary": "Machine unlearning aims to remove the influence of specific samples from a\ntrained model. A key challenge in this process is over-unlearning, where the\nmodel's performance on the remaining data significantly drops due to the change\nin the model's parameters. Existing unlearning algorithms depend on the\nremaining data to prevent this issue. As such, these methods are inapplicable\nin a more practical scenario, where only the unlearning samples are available\n(i.e., zero-shot unlearning). This paper presents a novel framework, ZS-PAG, to\nfill this gap. Our approach offers three key innovations: (1) we approximate\nthe inaccessible remaining data by generating adversarial samples; (2)\nleveraging the generated samples, we pinpoint a specific subspace to perform\nthe unlearning process, therefore preventing over-unlearning in the challenging\nzero-shot scenario; and (3) we consider the influence of the unlearning process\non the remaining samples and design an influence-based pseudo-labeling\nstrategy. As a result, our method further improves the model's performance\nafter unlearning. The proposed method holds a theoretical guarantee, and\nexperiments on various benchmarks validate the effectiveness and superiority of\nour proposed method over several baselines.", "AI": {"tldr": "ZS-PAG is a novel framework for zero-shot machine unlearning, addressing over-unlearning by generating adversarial samples, pinpointing a subspace for unlearning, and using influence-based pseudo-labeling.", "motivation": "Existing unlearning methods rely on remaining data, making them impractical for zero-shot scenarios where only unlearning samples are available.", "method": "ZS-PAG approximates remaining data with adversarial samples, identifies a subspace for unlearning, and uses influence-based pseudo-labeling to improve performance.", "result": "The method theoretically guarantees performance and outperforms baselines in experiments.", "conclusion": "ZS-PAG effectively addresses zero-shot unlearning challenges, preventing over-unlearning and enhancing model performance."}}
{"id": "2507.21705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21705", "abs": "https://arxiv.org/abs/2507.21705", "authors": ["Sergio Rozada", "Samuel Rey", "Gonzalo Mateos", "Antonio G. Marques"], "title": "Unrolling Dynamic Programming via Graph Filters", "comment": null, "summary": "Dynamic programming (DP) is a fundamental tool used across many engineering\nfields. The main goal of DP is to solve Bellman's optimality equations for a\ngiven Markov decision process (MDP). Standard methods like policy iteration\nexploit the fixed-point nature of these equations to solve them iteratively.\nHowever, these algorithms can be computationally expensive when the\nstate-action space is large or when the problem involves long-term\ndependencies. Here we propose a new approach that unrolls and truncates policy\niterations into a learnable parametric model dubbed BellNet, which we train to\nminimize the so-termed Bellman error from random value function\ninitializations. Viewing the transition probability matrix of the MDP as the\nadjacency of a weighted directed graph, we draw insights from graph signal\nprocessing to interpret (and compactly re-parameterize) BellNet as a cascade of\nnonlinear graph filters. This fresh look facilitates a concise, transferable,\nand unifying representation of policy and value iteration, with an explicit\nhandle on complexity during inference. Preliminary experiments conducted in a\ngrid-like environment demonstrate that BellNet can effectively approximate\noptimal policies in a fraction of the iterations required by classical methods.", "AI": {"tldr": "The paper introduces BellNet, a learnable parametric model that unrolls and truncates policy iterations to efficiently solve Bellman's equations, leveraging graph signal processing for compact representation and reduced computational complexity.", "motivation": "Standard dynamic programming methods like policy iteration are computationally expensive for large state-action spaces or long-term dependencies, prompting the need for a more efficient approach.", "method": "The authors propose BellNet, which re-parameterizes policy iterations as a cascade of nonlinear graph filters, drawing insights from graph signal processing to minimize Bellman error from random initializations.", "result": "Preliminary experiments in a grid-like environment show BellNet approximates optimal policies faster than classical methods.", "conclusion": "BellNet offers a concise, transferable, and computationally efficient alternative to traditional dynamic programming methods."}}
{"id": "2507.21748", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.CE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.21748", "abs": "https://arxiv.org/abs/2507.21748", "authors": ["Simon Daubner", "Alexander E. Cohen", "Benjamin D\u00f6rich", "Samuel J. Cooper"], "title": "evoxels: A differentiable physics framework for voxel-based microstructure simulations", "comment": "9 pages, 3 figures, structure following JOSS style", "summary": "Materials science inherently spans disciplines: experimentalists use advanced\nmicroscopy to uncover micro- and nanoscale structure, while theorists and\ncomputational scientists develop models that link processing, structure, and\nproperties. Bridging these domains is essential for inverse material design\nwhere you start from desired performance and work backwards to optimal\nmicrostructures and manufacturing routes. Integrating high-resolution imaging\nwith predictive simulations and data-driven optimization accelerates discovery\nand deepens understanding of process-structure-property relationships. The\ndifferentiable physics framework evoxels is based on a fully Pythonic, unified\nvoxel-based approach that integrates segmented 3D microscopy data, physical\nsimulations, inverse modeling, and machine learning.", "AI": {"tldr": "The paper introduces evoxels, a Python-based framework integrating microscopy, simulations, and machine learning for inverse material design.", "motivation": "Bridging experimental and computational domains in materials science to enable inverse design by linking processing, structure, and properties.", "method": "Uses a differentiable physics framework (evoxels) combining segmented 3D microscopy data, physical simulations, and machine learning.", "result": "Accelerates discovery and enhances understanding of process-structure-property relationships.", "conclusion": "The evoxels framework effectively integrates diverse tools for advancing inverse material design."}}
{"id": "2507.21727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21727", "abs": "https://arxiv.org/abs/2507.21727", "authors": ["Jianfei Zhu", "Haiqi Zhu", "Shaohui Liu", "Feng Jiang", "Baichun Wei", "Chunzhi Yi"], "title": "GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation", "comment": null, "summary": "Recent deep learning approaches have shown promise in learning such\nindividual brain parcellations from functional magnetic resonance imaging\n(fMRI). However, most existing methods assume consistent data distributions\nacross domains and struggle with domain shifts inherent to real-world\ncross-dataset scenarios. To address this challenge, we proposed Graph Domain\nAdaptation for Individual Parcellation (GDAIP), a novel framework that\nintegrates Graph Attention Networks (GAT) with Minimax Entropy (MME)-based\ndomain adaptation. We construct cross-dataset brain graphs at both the group\nand individual levels. By leveraging semi-supervised training and adversarial\noptimization of the prediction entropy on unlabeled vertices from target brain\ngraph, the reference atlas is adapted from the group-level brain graph to the\nindividual brain graph, enabling individual parcellation under cross-dataset\nsettings. We evaluated our method using parcellation visualization, Dice\ncoefficient, and functional homogeneity. Experimental results demonstrate that\nGDAIP produces individual parcellations with topologically plausible\nboundaries, strong cross-session consistency, and ability of reflecting\nfunctional organization.", "AI": {"tldr": "GDAIP integrates Graph Attention Networks and Minimax Entropy-based domain adaptation to address domain shifts in cross-dataset fMRI brain parcellation, achieving topologically plausible and functionally consistent results.", "motivation": "Existing methods struggle with domain shifts in cross-dataset fMRI scenarios, limiting their effectiveness for individual brain parcellation.", "method": "Proposes GDAIP, combining Graph Attention Networks and Minimax Entropy-based domain adaptation to adapt reference atlases from group-level to individual brain graphs.", "result": "GDAIP produces individual parcellations with plausible boundaries, cross-session consistency, and functional organization reflection.", "conclusion": "GDAIP effectively addresses domain shifts in cross-dataset fMRI, enabling accurate and consistent individual brain parcellation."}}
{"id": "2507.21762", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21762", "abs": "https://arxiv.org/abs/2507.21762", "authors": ["Nguyen Xuan-Vu", "Daniel Armstrong", "Zlatko Joncev", "Philippe Schwaller"], "title": "TempRe: Template generation for single and direct multi-step retrosynthesis", "comment": null, "summary": "Retrosynthesis planning remains a central challenge in molecular discovery\ndue to the vast and complex chemical reaction space. While traditional\ntemplate-based methods offer tractability, they suffer from poor scalability\nand limited generalization, and template-free generative approaches risk\ngenerating invalid reactions. In this work, we propose TempRe, a generative\nframework that reformulates template-based approaches as sequence generation,\nenabling scalable, flexible, and chemically plausible retrosynthesis. We\nevaluated TempRe across single-step and multi-step retrosynthesis tasks,\ndemonstrating its superiority over both template classification and\nSMILES-based generation methods. On the PaRoutes multi-step benchmark, TempRe\nachieves strong top-k route accuracy. Furthermore, we extend TempRe to direct\nmulti-step synthesis route generation, providing a lightweight and efficient\nalternative to conventional single-step and search-based approaches. These\nresults highlight the potential of template generative modeling as a powerful\nparadigm in computer-aided synthesis planning.", "AI": {"tldr": "TempRe is a generative framework for retrosynthesis planning, combining the scalability of template-free methods with the chemical plausibility of template-based approaches, outperforming existing methods.", "motivation": "The challenge in retrosynthesis planning lies in the vast chemical reaction space, with traditional methods being either limited in scalability or prone to invalid reactions.", "method": "TempRe reformulates template-based approaches as sequence generation, enabling scalable and flexible retrosynthesis. It is evaluated on single-step and multi-step tasks.", "result": "TempRe outperforms template classification and SMILES-based methods, achieving strong accuracy on the PaRoutes benchmark and enabling direct multi-step synthesis.", "conclusion": "Template generative modeling, as demonstrated by TempRe, is a promising paradigm for computer-aided synthesis planning."}}
{"id": "2507.21752", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21752", "abs": "https://arxiv.org/abs/2507.21752", "authors": ["Maurice Funk", "Jean Christoph Jung", "Tom Voellmer"], "title": "SAT-Based Bounded Fitting for the Description Logic ALC", "comment": "33 pages, full version of paper accepted at ISWC 2025", "summary": "Bounded fitting is a general paradigm for learning logical formulas from\npositive and negative data examples, that has received considerable interest\nrecently. We investigate bounded fitting for the description logic ALC and its\nsyntactic fragments. We show that the underlying size-restricted fitting\nproblem is NP-complete for all studied fragments, even in the special case of a\nsingle positive and a single negative example. By design, bounded fitting comes\nwith probabilistic guarantees in Valiant's PAC learning framework. In contrast,\nwe show that other classes of algorithms for learning ALC concepts do not\nprovide such guarantees. Finally, we present an implementation of bounded\nfitting in ALC and its fragments based on a SAT solver. We discuss\noptimizations and compare our implementation to other concept learning tools.", "AI": {"tldr": "Bounded fitting for ALC and its fragments is NP-complete, even with minimal examples, and provides PAC learning guarantees, unlike other methods. An implementation using a SAT solver is presented and compared.", "motivation": "To explore bounded fitting in description logic ALC and its fragments, addressing its computational complexity and learning guarantees.", "method": "Investigates NP-completeness of bounded fitting, analyzes PAC learning guarantees, and implements a SAT solver-based approach for ALC.", "result": "Bounded fitting is NP-complete for all studied fragments, even with one positive and negative example, and offers PAC guarantees. Other ALC learning methods lack such guarantees.", "conclusion": "Bounded fitting is computationally hard but provides reliable learning guarantees, with a practical SAT solver implementation outperforming other tools."}}
{"id": "2507.21799", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21799", "abs": "https://arxiv.org/abs/2507.21799", "authors": ["Xie Zhang", "Yina Wang", "Chenshu Wu"], "title": "Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer", "comment": null, "summary": "The empirical success of deep learning has spurred its application to the\nradio-frequency (RF) domain, leading to significant advances in Deep Wireless\nSensing (DWS). However, most existing DWS models function as black boxes with\nlimited interpretability, which hampers their generalizability and raises\nconcerns in security-sensitive physical applications. In this work, inspired by\nthe remarkable advances of white-box transformers, we present RF-CRATE, the\nfirst mathematically interpretable deep network architecture for RF sensing,\ngrounded in the principles of complex sparse rate reduction. To accommodate the\nunique RF signals, we conduct non-trivial theoretical derivations that extend\nthe original real-valued white-box transformer to the complex domain. By\nleveraging the CR-Calculus framework, we successfully construct a fully\ncomplex-valued white-box transformer with theoretically derived self-attention\nand residual multi-layer perceptron modules. Furthermore, to improve the\nmodel's ability to extract discriminative features from limited wireless data,\nwe introduce Subspace Regularization, a novel regularization strategy that\nenhances feature diversity, resulting in an average performance improvement of\n19.98% across multiple sensing tasks. We extensively evaluate RF-CRATE against\nseven baselines with multiple public and self-collected datasets involving\ndifferent RF signals. The results show that RF-CRATE achieves performance on\npar with thoroughly engineered black-box models, while offering full\nmathematical interpretability. More importantly, by extending CRATE to the\ncomplex domain, RF-CRATE yields substantial improvements, achieving an average\nclassification gain of 5.08% and reducing regression error by 10.34% across\ndiverse sensing tasks compared to CRATE. RF-CRATE is fully open-sourced at:\nhttps://github.com/rfcrate/RF_CRATE.", "AI": {"tldr": "RF-CRATE is the first mathematically interpretable deep network for RF sensing, extending white-box transformers to the complex domain with improved performance and interpretability.", "motivation": "Existing deep wireless sensing models lack interpretability, limiting generalizability and raising security concerns in physical applications.", "method": "Extends white-box transformers to the complex domain using CR-Calculus, introduces Subspace Regularization for feature diversity, and evaluates with public and self-collected datasets.", "result": "Achieves performance comparable to black-box models, with 19.98% average improvement, 5.08% classification gain, and 10.34% regression error reduction.", "conclusion": "RF-CRATE offers full mathematical interpretability and superior performance, advancing RF sensing with open-source availability."}}
{"id": "2507.21753", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.21753", "abs": "https://arxiv.org/abs/2507.21753", "authors": ["Gr\u00e9goire Martinon", "Alexandra Lorenzo de Brionne", "J\u00e9r\u00f4me Bohard", "Antoine Lojou", "Damien Hervault", "Nicolas J-B. Brunel"], "title": "Towards a rigorous evaluation of RAG systems: the challenge of due diligence", "comment": "in French language. EvalLLM2025: Workshop on Evaluation Generative\n  Models (LLM) and Challenges, AMIAD, 2025, Marseille, France", "summary": "The rise of generative AI, has driven significant advancements in high-risk\nsectors like healthcare and finance. The Retrieval-Augmented Generation (RAG)\narchitecture, combining language models (LLMs) with search engines, is\nparticularly notable for its ability to generate responses from document\ncorpora. Despite its potential, the reliability of RAG systems in critical\ncontexts remains a concern, with issues such as hallucinations persisting. This\nstudy evaluates a RAG system used in due diligence for an investment fund. We\npropose a robust evaluation protocol combining human annotations and LLM-Judge\nannotations to identify system failures, like hallucinations, off-topic, failed\ncitations, and abstentions. Inspired by the Prediction Powered Inference (PPI)\nmethod, we achieve precise performance measurements with statistical\nguarantees. We provide a comprehensive dataset for further analysis. Our\ncontributions aim to enhance the reliability and scalability of RAG systems\nevaluation protocols in industrial applications.", "AI": {"tldr": "The paper evaluates the reliability of Retrieval-Augmented Generation (RAG) systems in high-risk sectors, proposing a robust evaluation protocol combining human and LLM-Judge annotations to address issues like hallucinations and off-topic responses.", "motivation": "To address concerns about the reliability of RAG systems in critical contexts like healthcare and finance, particularly due to issues such as hallucinations and off-topic responses.", "method": "Proposes a robust evaluation protocol combining human annotations and LLM-Judge annotations, inspired by Prediction Powered Inference (PPI), to measure system performance with statistical guarantees.", "result": "The study provides a comprehensive dataset and precise performance measurements, identifying system failures like hallucinations, off-topic responses, failed citations, and abstentions.", "conclusion": "The contributions aim to enhance the reliability and scalability of RAG system evaluation protocols for industrial applications."}}
{"id": "2507.21803", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21803", "abs": "https://arxiv.org/abs/2507.21803", "authors": ["Sofianos Panagiotis Fotias", "Vassilis Gaganis"], "title": "Bayesian Neural Network Surrogates for Bayesian Optimization of Carbon Capture and Storage Operations", "comment": null, "summary": "Carbon Capture and Storage (CCS) stands as a pivotal technology for fostering\na sustainable future. The process, which involves injecting supercritical\nCO$_2$ into underground formations, a method already widely used for Enhanced\nOil Recovery, serves a dual purpose: it not only curbs CO$_2$ emissions and\naddresses climate change but also extends the operational lifespan and\nsustainability of oil fields and platforms, easing the shift toward greener\npractices. This paper delivers a thorough comparative evaluation of strategies\nfor optimizing decision variables in CCS project development, employing a\nderivative-free technique known as Bayesian Optimization. In addition to\nGaussian Processes, which usually serve as the gold standard in BO, various\nnovel stochastic models were examined and compared within a BO framework. This\nresearch investigates the effectiveness of utilizing more exotic stochastic\nmodels than GPs for BO in environments where GPs have been shown to\nunderperform, such as in cases with a large number of decision variables or\nmultiple objective functions that are not similarly scaled. By incorporating\nNet Present Value (NPV) as a key objective function, the proposed framework\ndemonstrates its potential to improve economic viability while ensuring the\nsustainable deployment of CCS technologies. Ultimately, this study represents\nthe first application in the reservoir engineering industry of the growing body\nof BO research, specifically in the search for more appropriate stochastic\nmodels, highlighting its potential as a preferred method for enhancing\nsustainability in the energy sector.", "AI": {"tldr": "The paper explores Bayesian Optimization (BO) for optimizing Carbon Capture and Storage (CCS) projects, comparing novel stochastic models to Gaussian Processes (GPs) in scenarios where GPs underperform. It highlights BO's potential to improve economic viability and sustainability in CCS.", "motivation": "To enhance CCS project efficiency and sustainability by addressing limitations of traditional BO methods like GPs in complex scenarios (e.g., many decision variables or multiple objectives).", "method": "Uses derivative-free Bayesian Optimization with various stochastic models, including novel ones, and evaluates them against GPs. Incorporates Net Present Value (NPV) as a key objective.", "result": "Demonstrates BO's effectiveness in optimizing CCS projects, especially with exotic stochastic models, improving economic viability and sustainability.", "conclusion": "BO, particularly with alternative stochastic models, is a promising method for optimizing CCS projects, marking its first application in reservoir engineering for sustainability."}}
{"id": "2507.21792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21792", "abs": "https://arxiv.org/abs/2507.21792", "authors": ["Saixiong Liu", "Yuhua Qian", "Jue Li", "Honghong Cheng", "Feijiang Li"], "title": "Hybrid Causal Identification and Causal Mechanism Clustering", "comment": null, "summary": "Bivariate causal direction identification is a fundamental and vital problem\nin the causal inference field. Among binary causal methods, most methods based\non additive noise only use one single causal mechanism to construct a causal\nmodel. In the real world, observations are always collected in different\nenvironments with heterogeneous causal relationships. Therefore, on observation\ndata, this paper proposes a Mixture Conditional Variational Causal Inference\nmodel (MCVCI) to infer heterogeneous causality. Specifically, according to the\nidentifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the\nsuperior fitting capabilities of the Gaussian mixture model and the neural\nnetwork and elegantly uses the likelihoods obtained from the probabilistic\nbounds of the mixture conditional variational auto-encoder as causal decision\ncriteria. Moreover, we model the casual heterogeneity into cluster numbers and\npropose the Mixture Conditional Variational Causal Clustering (MCVCC) method,\nwhich can reveal causal mechanism expression. Compared with state-of-the-art\nmethods, the comprehensive best performance demonstrates the effectiveness of\nthe methods proposed in this paper on several simulated and real data.", "AI": {"tldr": "The paper introduces MCVCI and MCVCC methods for bivariate causal direction identification, leveraging heterogeneous causal relationships and outperforming existing methods.", "motivation": "Existing methods often use a single causal mechanism, but real-world data involves heterogeneous causal relationships across environments.", "method": "Proposes MCVCI, combining Gaussian mixture models and neural networks, and MCVCC for clustering causal mechanisms, using likelihoods from probabilistic bounds.", "result": "The methods outperform state-of-the-art techniques on simulated and real data.", "conclusion": "MCVCI and MCVCC effectively address causal heterogeneity and improve causal inference accuracy."}}
{"id": "2507.21833", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21833", "abs": "https://arxiv.org/abs/2507.21833", "authors": ["Taeyoung Kim"], "title": "Analysis of Fourier Neural Operators via Effective Field Theory", "comment": "37 pages, 10 figures", "summary": "Fourier Neural Operators (FNOs) have emerged as leading surrogates for\nhigh-dimensional partial-differential equations, yet their stability,\ngeneralization and frequency behavior lack a principled explanation. We present\nthe first systematic effective-field-theory analysis of FNOs in an\ninfinite-dimensional function space, deriving closed recursion relations for\nthe layer kernel and four-point vertex and then examining three practically\nimportant settings-analytic activations, scale-invariant cases and\narchitectures with residual connections. The theory shows that nonlinear\nactivations inevitably couple frequency inputs to high-frequency modes that are\notherwise discarded by spectral truncation, and experiments confirm this\nfrequency transfer. For wide networks we obtain explicit criticality conditions\non the weight-initialization ensemble that keep small input perturbations to\nhave uniform scale across depth, and empirical tests validate these\npredictions. Taken together, our results quantify how nonlinearity enables\nneural operators to capture non-trivial features, supply criteria for\nhyper-parameter selection via criticality analysis, and explain why\nscale-invariant activations and residual connections enhance feature learning\nin FNOs.", "AI": {"tldr": "The paper analyzes Fourier Neural Operators (FNOs) using effective-field-theory to explain their stability, generalization, and frequency behavior, revealing how nonlinear activations and architecture choices impact performance.", "motivation": "To provide a principled explanation for the stability, generalization, and frequency behavior of FNOs, which are widely used for high-dimensional PDEs but lack theoretical understanding.", "method": "The study employs effective-field-theory analysis in infinite-dimensional function space, deriving recursion relations for layer kernels and vertices, and examines analytic activations, scale-invariant cases, and residual connections.", "result": "Nonlinear activations couple frequency inputs to high-frequency modes, and criticality conditions for weight initialization are derived. Experiments confirm frequency transfer and validate predictions.", "conclusion": "The work quantifies how nonlinearity aids FNOs in capturing features, offers hyper-parameter selection criteria, and explains the benefits of scale-invariant activations and residual connections."}}
{"id": "2507.21802", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21802", "abs": "https://arxiv.org/abs/2507.21802", "authors": ["Junzhe Li", "Yutao Cui", "Tao Huang", "Yinping Ma", "Chun Fan", "Miles Yang", "Zhao Zhong"], "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE", "comment": null, "summary": "Although GRPO substantially enhances flow matching models in human preference\nalignment of image generation, methods such as FlowGRPO still exhibit\ninefficiency due to the necessity of sampling and optimizing over all denoising\nsteps specified by the Markov Decision Process (MDP). In this paper, we propose\n$\\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed\nsampling strategies through the integration of stochastic differential\nequations (SDE) and ordinary differential equations (ODE). This streamlines the\noptimization process within the MDP to improve efficiency and boost\nperformance. Specifically, MixGRPO introduces a sliding window mechanism, using\nSDE sampling and GRPO-guided optimization only within the window, while\napplying ODE sampling outside. This design confines sampling randomness to the\ntime-steps within the window, thereby reducing the optimization overhead, and\nallowing for more focused gradient updates to accelerate convergence.\nAdditionally, as time-steps beyond the sliding window are not involved in\noptimization, higher-order solvers are supported for sampling. So we present a\nfaster variant, termed $\\textbf{MixGRPO-Flash}$, which further improves\ntraining efficiency while achieving comparable performance. MixGRPO exhibits\nsubstantial gains across multiple dimensions of human preference alignment,\noutperforming DanceGRPO in both effectiveness and efficiency, with nearly 50%\nlower training time. Notably, MixGRPO-Flash further reduces training time by\n71%. Codes and models are available at\n$\\href{https://github.com/Tencent-Hunyuan/MixGRPO}{MixGRPO}$.", "AI": {"tldr": "MixGRPO improves efficiency in human preference alignment for image generation by combining SDE and ODE sampling with a sliding window mechanism, reducing training time by 50% and introducing a faster variant, MixGRPO-Flash, with 71% lower training time.", "motivation": "Existing methods like FlowGRPO are inefficient due to sampling and optimizing over all denoising steps in MDP. MixGRPO aims to streamline this process.", "method": "MixGRPO integrates SDE and ODE sampling, using a sliding window to confine randomness and reduce optimization overhead. A faster variant, MixGRPO-Flash, supports higher-order solvers.", "result": "MixGRPO outperforms DanceGRPO in effectiveness and efficiency, with 50% lower training time. MixGRPO-Flash reduces training time by 71%.", "conclusion": "MixGRPO offers a novel, efficient framework for human preference alignment in image generation, with significant performance and training time improvements."}}
{"id": "2507.21841", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.21841", "abs": "https://arxiv.org/abs/2507.21841", "authors": ["Rahul Golder", "M. M. Faruque Hasan"], "title": "Discovering Interpretable Ordinary Differential Equations from Noisy Data", "comment": "20 pages, 11 figures, 7 tables", "summary": "The data-driven discovery of interpretable models approximating the\nunderlying dynamics of a physical system has gained attraction in the past\ndecade. Current approaches employ pre-specified functional forms or basis\nfunctions and often result in models that lack physical meaning and\ninterpretability, let alone represent the true physics of the system. We\npropose an unsupervised parameter estimation methodology that first finds an\napproximate general solution, followed by a spline transformation to linearly\nestimate the coefficients of the governing ordinary differential equation\n(ODE). The approximate general solution is postulated using the same functional\nform as the analytical solution of a general homogeneous, linear,\nconstant-coefficient ODE. An added advantage is its ability to produce a\nhigh-fidelity, smooth functional form even in the presence of noisy data. The\nspline approximation obtains gradient information from the functional form\nwhich are linearly independent and creates the basis of the gradient matrix.\nThis gradient matrix is used in a linear system to find the coefficients of the\nODEs. From the case studies, we observed that our modeling approach discovers\nODEs with high accuracy and also promotes sparsity in the solution without\nusing any regularization techniques. The methodology is also robust to noisy\ndata and thus allows the integration of data-driven techniques into real\nexperimental setting for data-driven learning of physical phenomena.", "AI": {"tldr": "An unsupervised method for discovering interpretable ODE models from noisy data, using spline transformations and gradient matrices for accurate, sparse solutions.", "motivation": "Current data-driven models often lack physical interpretability and accuracy. The goal is to develop a method that captures true physics while handling noisy data.", "method": "Proposes a two-step approach: 1) Find an approximate general solution using a functional form similar to analytical solutions of ODEs, 2) Use spline transformations to estimate ODE coefficients via gradient matrices.", "result": "The method accurately discovers ODEs, promotes sparsity without regularization, and is robust to noisy data.", "conclusion": "The approach enables high-fidelity, interpretable modeling of physical systems, suitable for real-world experimental data."}}
{"id": "2507.21823", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21823", "abs": "https://arxiv.org/abs/2507.21823", "authors": ["Mohammad Azarijafari", "Luisa Mich", "Michele Missikoff"], "title": "An Agentic AI for a New Paradigm in Business Process Development", "comment": null, "summary": "Artificial Intelligence agents represent the next major revolution in the\ncontinuous technological evolution of industrial automation. In this paper, we\nintroduce a new approach for business process design and development that\nleverages the capabilities of Agentic AI. Departing from the traditional\ntask-based approach to business process design, we propose an agent-based\nmethod, where agents contribute to the achievement of business goals,\nidentified by a set of business objects. When a single agent cannot fulfill a\ngoal, we have a merge goal that can be achieved through the collaboration of\nmultiple agents. The proposed model leads to a more modular and intelligent\nbusiness process development by organizing it around goals, objects, and\nagents. As a result, this approach enables flexible and context-aware\nautomation in dynamic industrial environments.", "AI": {"tldr": "The paper proposes an agent-based method for business process design using Agentic AI, shifting from task-based to goal-oriented automation for flexibility in dynamic environments.", "motivation": "To enhance industrial automation by leveraging Agentic AI for more modular, intelligent, and context-aware business processes.", "method": "Introduces an agent-based approach where agents collaborate to achieve business goals, using business objects and merging goals when necessary.", "result": "Enables flexible, modular, and intelligent business process development suited for dynamic industrial settings.", "conclusion": "The agent-based model improves automation by focusing on goals and collaboration, offering adaptability in industrial environments."}}
{"id": "2507.21898", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21898", "abs": "https://arxiv.org/abs/2507.21898", "authors": ["Risshab Srinivas Ramesh", "Roshani T S Udupa", "Monisha J", "Kushi K K S"], "title": "Cardiovascular Disease Prediction using Machine Learning: A Comparative Analysis", "comment": null, "summary": "Cardiovascular diseases (CVDs) are a main cause of mortality globally,\naccounting for 31% of all deaths. This study involves a cardiovascular disease\n(CVD) dataset comprising 68,119 records to explore the influence of numerical\n(age, height, weight, blood pressure, BMI) and categorical gender, cholesterol,\nglucose, smoking, alcohol, activity) factors on CVD occurrence. We have\nperformed statistical analyses, including t-tests, Chi-square tests, and ANOVA,\nto identify strong associations between CVD and elderly people, hypertension,\nhigher weight, and abnormal cholesterol levels, while physical activity (a\nprotective factor). A logistic regression model highlights age, blood pressure,\nand cholesterol as primary risk factors, with unexpected negative associations\nfor smoking and alcohol, suggesting potential data issues. Model performance\ncomparisons reveal CatBoost as the top performer with an accuracy of 0.734 and\nan ECE of 0.0064 and excels in probabilistic prediction (Brier score = 0.1824).\nData challenges, including outliers and skewed distributions, indicate a need\nfor improved preprocessing to enhance predictive reliability.", "AI": {"tldr": "The study analyzes CVD risk factors using a dataset of 68,119 records, identifying age, blood pressure, and cholesterol as primary risks, with CatBoost as the best-performing model.", "motivation": "Cardiovascular diseases (CVDs) cause 31% of global deaths, necessitating research into risk factors for better prevention.", "method": "Statistical analyses (t-tests, Chi-square, ANOVA) and logistic regression were used to assess CVD associations. Model performance was compared, with CatBoost evaluated for accuracy.", "result": "Key risk factors include age, hypertension, and abnormal cholesterol. CatBoost achieved 0.734 accuracy and excelled in probabilistic prediction. Unexpected negative associations for smoking/alcohol suggest data issues.", "conclusion": "The study highlights significant CVD risk factors but notes data challenges, recommending improved preprocessing for better predictive reliability."}}
{"id": "2507.21830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21830", "abs": "https://arxiv.org/abs/2507.21830", "authors": ["Kuiye Ding", "Fanda Fan", "Yao Wang", "Ruijie jian", "Xiaorui Wang", "Luqi Gong", "Yishan Jiang", "Chunjie Luo an Jianfeng Zhan"], "title": "DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework", "comment": "This paper has been accepted by ACM Multimedia 2025 (ACM MM 2025)", "summary": "Multivariate Time Series Forecasting plays a key role in many applications.\nRecent works have explored using Large Language Models for MTSF to take\nadvantage of their reasoning abilities. However, many methods treat LLMs as\nend-to-end forecasters, which often leads to a loss of numerical precision and\nforces LLMs to handle patterns beyond their intended design. Alternatively,\nmethods that attempt to align textual and time series modalities within latent\nspace frequently encounter alignment difficulty. In this paper, we propose to\ntreat LLMs not as standalone forecasters, but as semantic guidance modules\nwithin a dual-stream framework. We propose DualSG, a dual-stream framework that\nprovides explicit semantic guidance, where LLMs act as Semantic Guides to\nrefine rather than replace traditional predictions. As part of DualSG, we\nintroduce Time Series Caption, an explicit prompt format that summarizes trend\npatterns in natural language and provides interpretable context for LLMs,\nrather than relying on implicit alignment between text and time series in the\nlatent space. We also design a caption-guided fusion module that explicitly\nmodels inter-variable relationships while reducing noise and computation.\nExperiments on real-world datasets from diverse domains show that DualSG\nconsistently outperforms 15 state-of-the-art baselines, demonstrating the value\nof explicitly combining numerical forecasting with semantic guidance.", "AI": {"tldr": "DualSG is a dual-stream framework using LLMs as semantic guides to refine traditional predictions, avoiding loss of numerical precision and alignment issues.", "motivation": "Existing methods either lose numerical precision by treating LLMs as end-to-end forecasters or struggle with aligning textual and time series modalities.", "method": "Proposes DualSG, where LLMs act as semantic guides, introduces Time Series Caption for explicit prompts, and a caption-guided fusion module.", "result": "Outperforms 15 state-of-the-art baselines on real-world datasets.", "conclusion": "Explicitly combining numerical forecasting with semantic guidance improves performance."}}
{"id": "2507.21938", "categories": ["cs.LG", "q-bio.BM", "I.2.6; J.3"], "pdf": "https://arxiv.org/pdf/2507.21938", "abs": "https://arxiv.org/abs/2507.21938", "authors": ["Alex Abrudan", "Sebastian Pujalte Ojeda", "Chaitanya K. Joshi", "Matthew Greenig", "Felipe Engelberger", "Alena Khmelinskaia", "Jens Meiler", "Michele Vendruscolo", "Tuomas P. J. Knowles"], "title": "Multi-state Protein Design with DynamicMPNN", "comment": "ICML 2025 GenBio Workshop", "summary": "Structural biology has long been dominated by the one sequence, one\nstructure, one function paradigm, yet many critical biological processes - from\nenzyme catalysis to membrane transport - depend on proteins that adopt multiple\nconformational states. Existing multi-state design approaches rely on post-hoc\naggregation of single-state predictions, achieving poor experimental success\nrates compared to single-state design. We introduce DynamicMPNN, an inverse\nfolding model explicitly trained to generate sequences compatible with multiple\nconformations through joint learning across conformational ensembles. Trained\non 46,033 conformational pairs covering 75% of CATH superfamilies and evaluated\nusing AlphaFold initial guess, DynamicMPNN outperforms ProteinMPNN by up to 13%\non structure-normalized RMSD across our challenging multi-state protein\nbenchmark.", "AI": {"tldr": "DynamicMPNN, a new inverse folding model, outperforms ProteinMPNN by 13% in multi-state protein design by jointly learning across conformational ensembles.", "motivation": "Overcome limitations of single-state design for proteins that adopt multiple conformations, critical for biological processes like enzyme catalysis and membrane transport.", "method": "Introduces DynamicMPNN, trained on 46,033 conformational pairs covering 75% of CATH superfamilies, using joint learning across ensembles and evaluated with AlphaFold.", "result": "DynamicMPNN achieves up to 13% better structure-normalized RMSD than ProteinMPNN on a multi-state protein benchmark.", "conclusion": "DynamicMPNN advances multi-state protein design by directly addressing conformational diversity, improving experimental success rates."}}
{"id": "2507.21846", "categories": ["cs.AI", "cs.SC"], "pdf": "https://arxiv.org/pdf/2507.21846", "abs": "https://arxiv.org/abs/2507.21846", "authors": ["Chenyuan Zhang", "Cristian Rojas Cardenas", "Hamid Rezatofighi", "Mor Vered", "Buser Say"], "title": "Probabilistic Active Goal Recognition", "comment": "Accepted by KR2025", "summary": "In multi-agent environments, effective interaction hinges on understanding\nthe beliefs and intentions of other agents. While prior work on goal\nrecognition has largely treated the observer as a passive reasoner, Active Goal\nRecognition (AGR) focuses on strategically gathering information to reduce\nuncertainty. We adopt a probabilistic framework for Active Goal Recognition and\npropose an integrated solution that combines a joint belief update mechanism\nwith a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan\nefficiently and infer the actor's hidden goal without requiring domain-specific\nknowledge. Through comprehensive empirical evaluation in a grid-based domain,\nwe show that our joint belief update significantly outperforms passive goal\nrecognition, and that our domain-independent MCTS performs comparably to our\nstrong domain-specific greedy baseline. These results establish our solution as\na practical and robust framework for goal inference, advancing the field toward\nmore interactive and adaptive multi-agent systems.", "AI": {"tldr": "The paper introduces Active Goal Recognition (AGR) using a probabilistic framework with joint belief updates and MCTS, outperforming passive methods and showing domain-independent effectiveness.", "motivation": "To improve multi-agent interactions by actively reducing uncertainty about other agents' goals, moving beyond passive observation.", "method": "Combines joint belief updates with Monte Carlo Tree Search (MCTS) for efficient goal inference without domain-specific knowledge.", "result": "Outperforms passive goal recognition; domain-independent MCTS matches domain-specific baselines.", "conclusion": "Proposes a robust, practical framework for goal inference, enhancing interactive multi-agent systems."}}
{"id": "2507.21963", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21963", "abs": "https://arxiv.org/abs/2507.21963", "authors": ["Siana Rizwan", "Tasnim Ahmed", "Salimur Choudhury"], "title": "SLA-Centric Automated Algorithm Selection Framework for Cloud Environments", "comment": null, "summary": "Cloud computing offers on-demand resource access, regulated by Service-Level\nAgreements (SLAs) between consumers and Cloud Service Providers (CSPs). SLA\nviolations can impact efficiency and CSP profitability. In this work, we\npropose an SLA-aware automated algorithm-selection framework for combinatorial\noptimization problems in resource-constrained cloud environments. The framework\nuses an ensemble of machine learning models to predict performance and rank\nalgorithm-hardware pairs based on SLA constraints. We also apply our framework\nto the 0-1 knapsack problem. We curate a dataset comprising instance specific\nfeatures along with memory usage, runtime, and optimality gap for 6 algorithms.\nAs an empirical benchmark, we evaluate the framework on both classification and\nregression tasks. Our ablation study explores the impact of hyperparameters,\nlearning approaches, and large language models effectiveness in regression, and\nSHAP-based interpretability.", "AI": {"tldr": "An SLA-aware automated algorithm-selection framework for combinatorial optimization in cloud environments, using ML to predict performance and rank algorithms, applied to the 0-1 knapsack problem.", "motivation": "SLA violations in cloud computing impact efficiency and profitability, necessitating automated solutions for optimal algorithm selection under constraints.", "method": "An ensemble of ML models predicts performance and ranks algorithm-hardware pairs based on SLA constraints, tested on the 0-1 knapsack problem with a curated dataset.", "result": "The framework is evaluated on classification and regression tasks, with ablation studies on hyperparameters, learning approaches, LLM effectiveness, and SHAP-based interpretability.", "conclusion": "The proposed framework effectively addresses SLA-aware algorithm selection, demonstrating practical utility in resource-constrained cloud environments."}}
{"id": "2507.21848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21848", "abs": "https://arxiv.org/abs/2507.21848", "authors": ["Xingjian Zhang", "Siwei Wen", "Wenjun Wu", "Lei Huang"], "title": "EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity", "comment": null, "summary": "Large Language Models (LLMs) have made remarkable progress in enhancing\nstep-by-step reasoning through reinforcement learning. However, the Group\nRelative Policy Optimization (GRPO) algorithm, which relies on sparse reward\nrules, often encounters the issue of identical rewards within groups, leading\nto the advantage collapse problem. Existing works typically address this\nchallenge from two perspectives: enforcing model reflection to enhance response\ndiversity, and introducing internal feedback to augment the training signal\n(advantage). In this work, we begin by analyzing the limitations of model\nreflection and investigating the policy entropy of responses at the\nfine-grained sample level. Based on our experimental findings, we propose the\nEDGE-GRPO algorithm, which adopts \\textbf{E}ntropy-\\textbf{D}riven Advantage\nand \\textbf{G}uided \\textbf{E}rror Correction to effectively mitigate the\nproblem of advantage collapse. Extensive experiments on several main reasoning\nbenchmarks demonstrate the effectiveness and superiority of our approach. It is\navailable at https://github.com/ZhangXJ199/EDGE-GRPO.", "AI": {"tldr": "The paper introduces EDGE-GRPO, an algorithm to mitigate advantage collapse in LLMs by leveraging entropy-driven advantage and guided error correction.", "motivation": "Address the issue of identical rewards within groups in GRPO, which causes advantage collapse, by improving response diversity and training signals.", "method": "Analyze model reflection limitations and policy entropy, then propose EDGE-GRPO with entropy-driven advantage and guided error correction.", "result": "EDGE-GRPO outperforms existing methods on reasoning benchmarks, effectively reducing advantage collapse.", "conclusion": "EDGE-GRPO is a superior solution for mitigating advantage collapse in LLMs, validated by extensive experiments."}}
{"id": "2507.21983", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21983", "abs": "https://arxiv.org/abs/2507.21983", "authors": ["Daniel R. Jiang", "Alex Nikulkov", "Yu-Chia Chen", "Yang Bai", "Zheqing Zhu"], "title": "Improving Generative Ad Text on Facebook using Reinforcement Learning", "comment": "D.J. and A.N. contributed equally, 41 pages, 6 figures", "summary": "Generative artificial intelligence (AI), in particular large language models\n(LLMs), is poised to drive transformative economic change. LLMs are pre-trained\non vast text data to learn general language patterns, but a subsequent\npost-training phase is critical to align them for specific real-world tasks.\nReinforcement learning (RL) is the leading post-training technique, yet its\neconomic impact remains largely underexplored and unquantified. We examine this\nquestion through the lens of the first deployment of an RL-trained LLM for\ngenerative advertising on Facebook. Integrated into Meta's Text Generation\nfeature, our model, \"AdLlama,\" powers an AI tool that helps advertisers create\nnew variations of human-written ad text. To train this model, we introduce\nreinforcement learning with performance feedback (RLPF), a post-training method\nthat uses historical ad performance data as a reward signal. In a large-scale\n10-week A/B test on Facebook spanning nearly 35,000 advertisers and 640,000 ad\nvariations, we find that AdLlama improves click-through rates by 6.7%\n(p=0.0296) compared to a supervised imitation model trained on curated ads.\nThis represents a substantial improvement in advertiser return on investment on\nFacebook. We also find that advertisers who used AdLlama generated more ad\nvariations, indicating higher satisfaction with the model's outputs. To our\nknowledge, this is the largest study to date on the use of generative AI in an\necologically valid setting, offering an important data point quantifying the\ntangible impact of RL post-training. Furthermore, the results show that RLPF is\na promising and generalizable approach for metric-driven post-training that\nbridges the gap between highly capable language models and tangible outcomes.", "AI": {"tldr": "The paper explores the economic impact of reinforcement learning (RL) post-training for large language models (LLMs), demonstrating its effectiveness in generative advertising on Facebook through a model called AdLlama.", "motivation": "To quantify the economic impact of RL post-training for LLMs, particularly in real-world applications like generative advertising.", "method": "Introduces reinforcement learning with performance feedback (RLPF), using historical ad performance data as rewards, and tests it in a large-scale A/B experiment on Facebook.", "result": "AdLlama improves click-through rates by 6.7% compared to a supervised imitation model, enhancing advertiser ROI and satisfaction.", "conclusion": "RLPF is a promising, generalizable method for aligning LLMs with tangible outcomes, bridging the gap between model capability and real-world impact."}}
{"id": "2507.21872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21872", "abs": "https://arxiv.org/abs/2507.21872", "authors": ["Shouyi Lu", "Zihan Lin", "Chao Lu", "Huanran Wang", "Guirong Zhuo", "Lianqing Zheng"], "title": "MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors", "comment": null, "summary": "Autonomous driving systems rely heavily on multimodal perception data to\nunderstand complex environments. However, the long-tailed distribution of\nreal-world data hinders generalization, especially for rare but safety-critical\nvehicle categories. To address this challenge, we propose MultiEditor, a\ndual-branch latent diffusion framework designed to edit images and LiDAR point\nclouds in driving scenarios jointly. At the core of our approach is introducing\n3D Gaussian Splatting (3DGS) as a structural and appearance prior for target\nobjects. Leveraging this prior, we design a multi-level appearance control\nmechanism--comprising pixel-level pasting, semantic-level guidance, and\nmulti-branch refinement--to achieve high-fidelity reconstruction across\nmodalities. We further propose a depth-guided deformable cross-modality\ncondition module that adaptively enables mutual guidance between modalities\nusing 3DGS-rendered depth, significantly enhancing cross-modality consistency.\nExtensive experiments demonstrate that MultiEditor achieves superior\nperformance in visual and geometric fidelity, editing controllability, and\ncross-modality consistency. Furthermore, generating rare-category vehicle data\nwith MultiEditor substantially enhances the detection accuracy of perception\nmodels on underrepresented classes.", "AI": {"tldr": "MultiEditor is a dual-branch latent diffusion framework for joint editing of images and LiDAR point clouds in driving scenarios, improving generalization for rare vehicle categories.", "motivation": "Addressing the long-tailed distribution of real-world data in autonomous driving, which hinders generalization for rare but safety-critical vehicle categories.", "method": "Uses 3D Gaussian Splatting (3DGS) as a prior, with multi-level appearance control and depth-guided deformable cross-modality conditioning.", "result": "Achieves high-fidelity reconstruction, editing controllability, and cross-modality consistency, enhancing detection accuracy for rare vehicle categories.", "conclusion": "MultiEditor effectively improves multimodal perception data for autonomous driving, particularly for underrepresented classes."}}
{"id": "2507.21992", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21992", "abs": "https://arxiv.org/abs/2507.21992", "authors": ["Siddhartha Pradhan", "Shikshya Shiwakoti", "Neha Bathuri"], "title": "Teach Me to Trick: Exploring Adversarial Transferability via Knowledge Distillation", "comment": "10 pages, 4 figures", "summary": "We investigate whether knowledge distillation (KD) from multiple\nheterogeneous teacher models can enhance the generation of transferable\nadversarial examples. A lightweight student model is trained using two KD\nstrategies: curriculum-based switching and joint optimization, with ResNet50\nand DenseNet-161 as teachers. The trained student is then used to generate\nadversarial examples using FG, FGS, and PGD attacks, which are evaluated\nagainst a black-box target model (GoogLeNet). Our results show that student\nmodels distilled from multiple teachers achieve attack success rates comparable\nto ensemble-based baselines, while reducing adversarial example generation time\nby up to a factor of six. An ablation study further reveals that lower\ntemperature settings and the inclusion of hard-label supervision significantly\nenhance transferability. These findings suggest that KD can serve not only as a\nmodel compression technique but also as a powerful tool for improving the\nefficiency and effectiveness of black-box adversarial attacks.", "AI": {"tldr": "Knowledge distillation from multiple heterogeneous teachers improves adversarial example generation, achieving comparable attack success to ensembles while being six times faster.", "motivation": "Explore if knowledge distillation (KD) from multiple teachers can enhance adversarial example transferability, aiming for efficiency and effectiveness in black-box attacks.", "method": "Train a lightweight student model using curriculum-based switching and joint optimization KD strategies with ResNet50 and DenseNet-161 teachers. Generate adversarial examples via FG, FGS, and PGD attacks, evaluated against GoogLeNet.", "result": "Student models achieve attack success rates similar to ensemble baselines, with six times faster generation. Lower temperature and hard-label supervision boost transferability.", "conclusion": "KD is not just for model compression but also enhances black-box adversarial attack efficiency and effectiveness."}}
{"id": "2507.21873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21873", "abs": "https://arxiv.org/abs/2507.21873", "authors": ["Raffaele Pojer", "Andrea Passerini", "Kim G. Larsen", "Manfred Jaeger"], "title": "A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data", "comment": "Submitted to the Journal of Artificial Intelligence Research (JAIR);\n  under revision. 29 pages, 6 figures. Code available at\n  https://github.com/raffaelepojer/NeSy-for-graph-data", "summary": "Graph neural networks (GNNs) excel at predictive tasks on graph-structured\ndata but often lack the ability to incorporate symbolic domain knowledge and\nperform general reasoning. Relational Bayesian Networks (RBNs), in contrast,\nenable fully generative probabilistic modeling over graph-like structures and\nsupport rich symbolic knowledge and probabilistic inference. This paper\npresents a neuro-symbolic framework that seamlessly integrates GNNs into RBNs,\ncombining the learning strength of GNNs with the flexible reasoning\ncapabilities of RBNs.\n  We develop two implementations of this integration: one compiles GNNs\ndirectly into the native RBN language, while the other maintains the GNN as an\nexternal component. Both approaches preserve the semantics and computational\nproperties of GNNs while fully aligning with the RBN modeling paradigm. We also\npropose a maximum a-posteriori (MAP) inference method for these neuro-symbolic\nmodels.\n  To demonstrate the framework's versatility, we apply it to two distinct\nproblems. First, we transform a GNN for node classification into a collective\nclassification model that explicitly models homo- and heterophilic label\npatterns, substantially improving accuracy. Second, we introduce a\nmulti-objective network optimization problem in environmental planning, where\nMAP inference supports complex decision-making. Both applications include new\npublicly available benchmark datasets.\n  This work introduces a powerful and coherent neuro-symbolic approach to graph\ndata, bridging learning and reasoning in ways that enable novel applications\nand improved performance across diverse tasks.", "AI": {"tldr": "The paper integrates Graph Neural Networks (GNNs) with Relational Bayesian Networks (RBNs) to combine learning and reasoning, presenting two implementation methods and demonstrating improved performance in node classification and environmental planning.", "motivation": "GNNs lack symbolic reasoning, while RBNs lack learning capabilities. The goal is to merge their strengths for enhanced performance and versatility.", "method": "Two integration approaches: compiling GNNs into RBNs or keeping GNNs external. Includes a MAP inference method for neuro-symbolic models.", "result": "Improved accuracy in node classification and effective decision-making in environmental planning, with new benchmark datasets.", "conclusion": "The framework successfully bridges learning and reasoning, enabling novel applications and better performance in diverse tasks."}}
{"id": "2507.22032", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22032", "abs": "https://arxiv.org/abs/2507.22032", "authors": ["Mokhtar Al-Awadhi", "Ratnadeep Deshmukh"], "title": "Classification of Honey Botanical and Geographical Sources using Mineral Profiles and Machine Learning", "comment": "13 pages, 7 figures, conference paper", "summary": "This paper proposes a machine learning-based approach for identifying honey\nfloral and geographical sources using mineral element profiles. The proposed\nmethod comprises two steps: preprocessing and classification. The preprocessing\nphase involves missing-value treatment and data normalization. In the\nclassification phase, we employ various supervised classification models for\ndiscriminating between six botanical sources and 13 geographical origins of\nhoney. We test the classifiers' performance on a publicly available honey\nmineral element dataset. The dataset contains mineral element profiles of\nhoneys from various floral and geographical origins. Results show that mineral\nelement content in honey provides discriminative information useful for\nclassifying honey botanical and geographical sources. Results also show that\nthe Random Forests (RF) classifier obtains the best performance on this\ndataset, achieving a cross-validation accuracy of 99.30% for classifying honey\nbotanical origins and 98.01% for classifying honey geographical origins.", "AI": {"tldr": "A machine learning approach using mineral element profiles effectively classifies honey's floral and geographical sources, with Random Forests achieving high accuracy.", "motivation": "To identify honey's botanical and geographical origins using mineral element profiles for quality control and authenticity verification.", "method": "Two-step process: preprocessing (missing-value treatment, normalization) and classification (supervised models tested on a honey mineral dataset).", "result": "Mineral elements are discriminative; Random Forests achieve 99.30% accuracy for botanical and 98.01% for geographical classification.", "conclusion": "Mineral element profiles combined with machine learning, especially Random Forests, are highly effective for honey origin classification."}}
{"id": "2507.21875", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21875", "abs": "https://arxiv.org/abs/2507.21875", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis", "comment": null, "summary": "Pain is a complex and pervasive condition that affects a significant portion\nof the population. Accurate and consistent assessment is essential for\nindividuals suffering from pain, as well as for developing effective management\nstrategies in a healthcare system. Automatic pain assessment systems enable\ncontinuous monitoring, support clinical decision-making, and help minimize\npatient distress while mitigating the risk of functional deterioration.\nLeveraging physiological signals offers objective and precise insights into a\nperson's state, and their integration in a multimodal framework can further\nenhance system performance. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed approach introduces \\textit{Tiny-BioMoE}, a lightweight pretrained\nembedding model for biosignal analysis. Trained on $4.4$ million biosignal\nimage representations and consisting of only $7.3$ million parameters, it\nserves as an effective tool for extracting high-quality embeddings for\ndownstream tasks. Extensive experiments involving electrodermal activity, blood\nvolume pulse, respiratory signals, peripheral oxygen saturation, and their\ncombinations highlight the model's effectiveness across diverse modalities in\nautomatic pain recognition tasks. \\textit{\\textcolor{blue}{The model's\narchitecture (code) and weights are available at\nhttps://github.com/GkikasStefanos/Tiny-BioMoE.", "AI": {"tldr": "The paper introduces Tiny-BioMoE, a lightweight pretrained model for biosignal analysis, aimed at improving automatic pain assessment through multimodal physiological signals.", "motivation": "Accurate pain assessment is crucial for patient care and management, and leveraging physiological signals can provide objective insights.", "method": "The study proposes Tiny-BioMoE, a pretrained embedding model trained on 4.4 million biosignal image representations with 7.3 million parameters, tested on diverse physiological signals.", "result": "The model demonstrates effectiveness in automatic pain recognition across various biosignal modalities.", "conclusion": "Tiny-BioMoE offers a lightweight, high-quality solution for biosignal embedding extraction, enhancing pain assessment systems."}}
{"id": "2507.22040", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.22040", "abs": "https://arxiv.org/abs/2507.22040", "authors": ["Alvaro Maggiar", "Sohrab Andaz", "Akhil Bagaria", "Carson Eisenach", "Dean Foster", "Omer Gottesman", "Dominique Perrault-Joncas"], "title": "Structure-Informed Deep Reinforcement Learning for Inventory Management", "comment": null, "summary": "This paper investigates the application of Deep Reinforcement Learning (DRL)\nto classical inventory management problems, with a focus on practical\nimplementation considerations. We apply a DRL algorithm based on DirectBackprop\nto several fundamental inventory management scenarios including multi-period\nsystems with lost sales (with and without lead times), perishable inventory\nmanagement, dual sourcing, and joint inventory procurement and removal. The DRL\napproach learns policies across products using only historical information that\nwould be available in practice, avoiding unrealistic assumptions about demand\ndistributions or access to distribution parameters. We demonstrate that our\ngeneric DRL implementation performs competitively against or outperforms\nestablished benchmarks and heuristics across these diverse settings, while\nrequiring minimal parameter tuning. Through examination of the learned\npolicies, we show that the DRL approach naturally captures many known\nstructural properties of optimal policies derived from traditional operations\nresearch methods. To further improve policy performance and interpretability,\nwe propose a Structure-Informed Policy Network technique that explicitly\nincorporates analytically-derived characteristics of optimal policies into the\nlearning process. This approach can help interpretability and add robustness to\nthe policy in out-of-sample performance, as we demonstrate in an example with\nrealistic demand data. Finally, we provide an illustrative application of DRL\nin a non-stationary setting. Our work bridges the gap between data-driven\nlearning and analytical insights in inventory management while maintaining\npractical applicability.", "AI": {"tldr": "The paper explores using Deep Reinforcement Learning (DRL) for inventory management, showing it outperforms benchmarks and heuristics while requiring minimal tuning. It introduces a Structure-Informed Policy Network to enhance interpretability and robustness.", "motivation": "To bridge the gap between data-driven learning and analytical insights in inventory management, avoiding unrealistic assumptions about demand distributions.", "method": "Applies a DRL algorithm (DirectBackprop) to various inventory scenarios, using historical data. Introduces a Structure-Informed Policy Network to incorporate optimal policy characteristics.", "result": "DRL performs competitively or better than benchmarks, captures structural properties of optimal policies, and improves interpretability with the proposed technique.", "conclusion": "DRL effectively combines data-driven learning with analytical insights, offering practical and robust solutions for inventory management."}}
{"id": "2507.21881", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21881", "abs": "https://arxiv.org/abs/2507.21881", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image", "comment": null, "summary": "Pain is a multifaceted phenomenon that affects a substantial portion of the\npopulation. Reliable and consistent evaluation benefits those experiencing pain\nand underpins the development of effective and advanced management strategies.\nAutomatic pain-assessment systems deliver continuous monitoring, inform\nclinical decision-making, and aim to reduce distress while preventing\nfunctional decline. By incorporating physiological signals, these systems\nprovide objective, accurate insights into an individual's condition. This study\nhas been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for\nNext-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline\nthat leverages electrodermal activity signals as input modality. Multiple\nrepresentations of the signal are created and visualized as waveforms, and they\nare jointly visualized within a single multi-representation diagram. Extensive\nexperiments incorporating various processing and filtering techniques, along\nwith multiple representation combinations, demonstrate the effectiveness of the\nproposed approach. It consistently yields comparable, and in several cases\nsuperior, results to traditional fusion methods, establishing it as a robust\nalternative for integrating different signal representations or modalities.", "AI": {"tldr": "The paper proposes a pipeline using electrodermal activity signals for automatic pain assessment, demonstrating its effectiveness through experiments and comparing it favorably to traditional methods.", "motivation": "Pain affects many people, and reliable assessment is crucial for effective management. Automated systems can provide continuous, objective monitoring to improve clinical decisions and reduce distress.", "method": "The method uses electrodermal activity signals, creating and visualizing multiple signal representations in a single diagram. Various processing and filtering techniques are tested.", "result": "The approach performs comparably or better than traditional fusion methods, proving robust for integrating signal representations or modalities.", "conclusion": "The proposed pipeline is a viable alternative for pain assessment, offering accuracy and reliability in monitoring physiological signals."}}
{"id": "2507.22045", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.22045", "abs": "https://arxiv.org/abs/2507.22045", "authors": ["Haley Rosso", "Lars Ruthotto", "Khachik Sargsyan"], "title": "Weight-Parameterization in Continuous Time Deep Neural Networks for Surrogate Modeling", "comment": "34 pages, 6 figures, submitted to the MoRE24 special issue of\n  Computational Science and Engineering", "summary": "Continuous-time deep learning models, such as neural ordinary differential\nequations (ODEs), offer a promising framework for surrogate modeling of complex\nphysical systems. A central challenge in training these models lies in learning\nexpressive yet stable time-varying weights, particularly under computational\nconstraints. This work investigates weight parameterization strategies that\nconstrain the temporal evolution of weights to a low-dimensional subspace\nspanned by polynomial basis functions. We evaluate both monomial and Legendre\npolynomial bases within neural ODE and residual network (ResNet) architectures\nunder discretize-then-optimize and optimize-then-discretize training paradigms.\nExperimental results across three high-dimensional benchmark problems show that\nLegendre parameterizations yield more stable training dynamics, reduce\ncomputational cost, and achieve accuracy comparable to or better than both\nmonomial parameterizations and unconstrained weight models. These findings\nelucidate the role of basis choice in time-dependent weight parameterization\nand demonstrate that using orthogonal polynomial bases offers a favorable\ntradeoff between model expressivity and training efficiency.", "AI": {"tldr": "The paper explores polynomial basis functions (monomial and Legendre) for parameterizing time-varying weights in neural ODEs and ResNets, finding Legendre bases improve stability, efficiency, and accuracy.", "motivation": "Training continuous-time deep learning models like neural ODEs requires expressive yet stable time-varying weights under computational constraints.", "method": "Evaluated monomial and Legendre polynomial bases in neural ODEs and ResNets using discretize-then-optimize and optimize-then-discretize paradigms.", "result": "Legendre bases provided more stable training, lower computational cost, and comparable or better accuracy than monomial or unconstrained weights.", "conclusion": "Orthogonal polynomial bases (e.g., Legendre) offer a favorable balance between expressivity and training efficiency for time-dependent weight parameterization."}}
{"id": "2507.21882", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21882", "abs": "https://arxiv.org/abs/2507.21882", "authors": ["Elmira Onagh", "Alireza Davoodi", "Maleknaz Nayebi"], "title": "The Impact of Foundational Models on Patient-Centric e-Health Systems", "comment": "Paper published in COMPSAC 2025", "summary": "As Artificial Intelligence (AI) becomes increasingly embedded in healthcare\ntechnologies, understanding the maturity of AI in patient-centric applications\nis critical for evaluating its trustworthiness, transparency, and real-world\nimpact. In this study, we investigate the integration and maturity of AI\nfeature integration in 116 patient-centric healthcare applications. Using Large\nLanguage Models (LLMs), we extracted key functional features, which are then\ncategorized into different stages of the Gartner AI maturity model. Our results\nshow that over 86.21\\% of applications remain at the early stages of AI\nintegration, while only 13.79% demonstrate advanced AI integration.", "AI": {"tldr": "The study evaluates AI maturity in 116 patient-centric healthcare apps, finding most (86.21%) at early stages and few (13.79%) with advanced AI.", "motivation": "Assess AI maturity in healthcare apps to gauge trustworthiness, transparency, and impact.", "method": "Used LLMs to extract and categorize features into Gartner AI maturity stages.", "result": "86.21% of apps are in early AI stages; 13.79% show advanced integration.", "conclusion": "AI in healthcare apps is mostly immature, highlighting a need for further development."}}
{"id": "2507.22053", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22053", "abs": "https://arxiv.org/abs/2507.22053", "authors": ["Wei Yang", "Defu Cao", "Yan Liu"], "title": "Foundation Models for Demand Forecasting via Dual-Strategy Ensembling", "comment": null, "summary": "Accurate demand forecasting is critical for supply chain optimization, yet\nremains difficult in practice due to hierarchical complexity, domain shifts,\nand evolving external factors. While recent foundation models offer strong\npotential for time series forecasting, they often suffer from architectural\nrigidity and limited robustness under distributional change. In this paper, we\npropose a unified ensemble framework that enhances the performance of\nfoundation models for sales forecasting in real-world supply chains. Our method\ncombines two complementary strategies: (1) Hierarchical Ensemble (HE), which\npartitions training and inference by semantic levels (e.g., store, category,\ndepartment) to capture localized patterns; and (2) Architectural Ensemble (AE),\nwhich integrates predictions from diverse model backbones to mitigate bias and\nimprove stability. We conduct extensive experiments on the M5 benchmark and\nthree external sales datasets, covering both in-domain and zero-shot\nforecasting. Results show that our approach consistently outperforms strong\nbaselines, improves accuracy across hierarchical levels, and provides a simple\nyet effective mechanism for boosting generalization in complex forecasting\nenvironments.", "AI": {"tldr": "A unified ensemble framework improves sales forecasting by combining hierarchical and architectural strategies, outperforming baselines in accuracy and generalization.", "motivation": "Demand forecasting is challenging due to hierarchical complexity, domain shifts, and external factors. Foundation models lack robustness under distributional change.", "method": "Proposes Hierarchical Ensemble (HE) for localized patterns and Architectural Ensemble (AE) for diverse model integration.", "result": "Outperforms baselines on M5 benchmark and external datasets, improving accuracy and generalization.", "conclusion": "The framework effectively enhances forecasting performance in complex supply chain environments."}}
{"id": "2507.21886", "categories": ["cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21886", "abs": "https://arxiv.org/abs/2507.21886", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "comment": null, "summary": "Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity.", "AI": {"tldr": "A study proposes a respiration-based pain assessment method using a cross-attention transformer and multi-windowing strategy, showing strong performance with compact models.", "motivation": "Accurate pain evaluation is crucial for effective management, and automated systems can aid continuous monitoring and clinical decisions.", "method": "The method uses respiration signals, a cross-attention transformer, and a multi-windowing strategy to capture short-term, long-term, and global features.", "result": "Respiration proves valuable for pain assessment, and optimized compact models outperform larger ones. The multi-window approach enhances feature representation.", "conclusion": "The proposed pipeline is effective for pain assessment, highlighting the potential of compact models and respiration signals."}}
{"id": "2507.21899", "categories": ["cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21899", "abs": "https://arxiv.org/abs/2507.21899", "authors": ["Malik Uzair Mehmood", "Shahid Hussain", "Wen Li Wang", "Muhammad Usama Malik"], "title": "LLM-based Content Classification Approach for GitHub Repositories by the README Files", "comment": "8 pages, 4 Figures", "summary": "GitHub is the world's most popular platform for storing, sharing, and\nmanaging code. Every GitHub repository has a README file associated with it.\nThe README files should contain project-related information as per the\nrecommendations of GitHub to support the usage and improvement of repositories.\nHowever, GitHub repository owners sometimes neglected these recommendations.\nThis prevents a GitHub repository from reaching its full potential. This\nresearch posits that the comprehensiveness of a GitHub repository's README file\nsignificantly influences its adoption and utilization, with a lack of detail\npotentially hindering its full potential for widespread engagement and impact\nwithin the research community. Large Language Models (LLMs) have shown great\nperformance in many text-based tasks including text classification, text\ngeneration, text summarization and text translation. In this study, an approach\nis developed to fine-tune LLMs for automatically classifying different sections\nof GitHub README files. Three encoder-only LLMs are utilized, including BERT,\nDistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a\ngold-standard dataset consisting of 4226 README file sections. This approach\noutperforms current state-of-the-art methods and has achieved an overall F1\nscore of 0.98. Moreover, we have also investigated the use of\nParameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation\n(LoRA) and shown an economical alternative to full fine-tuning without\ncompromising much performance. The results demonstrate the potential of using\nLLMs in designing an automatic classifier for categorizing the content of\nGitHub README files. Consequently, this study contributes to the development of\nautomated tools for GitHub repositories to improve their identifications and\npotential usages.", "AI": {"tldr": "The study fine-tunes LLMs (BERT, DistilBERT, RoBERTa) to classify GitHub README sections, achieving high accuracy (F1=0.98) and exploring cost-effective PEFT techniques like LoRA.", "motivation": "GitHub README files often lack detail, hindering repository adoption. Automating classification can improve repository usability and impact.", "method": "Fine-tuned three encoder-only LLMs (BERT, DistilBERT, RoBERTa) on 4226 README sections, tested PEFT techniques like LoRA.", "result": "Achieved an F1 score of 0.98, outperforming state-of-the-art methods. PEFT techniques like LoRA offered economical alternatives.", "conclusion": "LLMs can effectively automate README classification, enhancing GitHub repository usability and adoption."}}
{"id": "2507.21929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21929", "abs": "https://arxiv.org/abs/2507.21929", "authors": ["Ziyang Chen", "Huimu Yu", "Xing Wu", "Dongqin Liu", "Songlin Hu"], "title": "Libra: Large Chinese-based Safeguard for AI Content", "comment": null, "summary": "Large language models (LLMs) excel in text understanding and generation but\nraise significant safety and ethical concerns in high-stakes applications. To\nmitigate these risks, we present Libra-Guard, a cutting-edge safeguard system\ndesigned to enhance the safety of Chinese-based LLMs. Leveraging a two-stage\ncurriculum training pipeline, Libra-Guard enhances data efficiency by employing\nguard pretraining on synthetic samples, followed by fine-tuning on\nhigh-quality, real-world data, thereby significantly reducing reliance on\nmanual annotations. To enable rigorous safety evaluations, we also introduce\nLibra-Test, the first benchmark specifically designed to evaluate the\neffectiveness of safeguard systems for Chinese content. It covers seven\ncritical harm scenarios and includes over 5,700 samples annotated by domain\nexperts. Experiments show that Libra-Guard achieves 86.79% accuracy,\noutperforming Qwen2.5-14B-Instruct (74.33%) and ShieldLM-Qwen-14B-Chat\n(65.69%), and nearing closed-source models like Claude-3.5-Sonnet and GPT-4o.\nThese contributions establish a robust framework for advancing the safety\ngovernance of Chinese LLMs and represent a tentative step toward developing\nsafer, more reliable Chinese AI systems.", "AI": {"tldr": "Libra-Guard is a safeguard system for Chinese LLMs, using a two-stage training pipeline and introducing Libra-Test for safety evaluation, achieving high accuracy.", "motivation": "To address safety and ethical concerns in high-stakes applications of Chinese LLMs.", "method": "Two-stage curriculum training: guard pretraining on synthetic samples, followed by fine-tuning on real-world data. Introduces Libra-Test benchmark for evaluation.", "result": "Libra-Guard achieves 86.79% accuracy, outperforming other models.", "conclusion": "Establishes a framework for safer Chinese LLMs and advances AI safety governance."}}
{"id": "2507.21964", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21964", "abs": "https://arxiv.org/abs/2507.21964", "authors": ["Sourish Gunesh Dhekane", "Thomas Ploetz"], "title": "Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities", "comment": null, "summary": "Developing zero-shot human activity recognition (HAR) methods is a critical\ndirection in smart home research -- considering its impact on making HAR\nsystems work across smart homes having diverse sensing modalities, layouts, and\nactivities of interest. The state-of-the-art solutions along this direction are\nbased on generating natural language descriptions of the sensor data and\nfeeding it via a carefully crafted prompt to the LLM to perform classification.\nDespite their performance guarantees, such ``prompt-the-LLM'' approaches carry\nseveral risks, including privacy invasion, reliance on an external service, and\ninconsistent predictions due to version changes, making a case for alternative\nzero-shot HAR methods that do not require prompting the LLMs. In this paper, we\npropose one such solution that models sensor data and activities using natural\nlanguage, leveraging its embeddings to perform zero-shot classification and\nthereby bypassing the need to prompt the LLMs for activity predictions. The\nimpact of our work lies in presenting a detailed case study on six datasets,\nhighlighting how language modeling can bolster HAR systems in zero-shot\nrecognition.", "AI": {"tldr": "The paper proposes a zero-shot HAR method using natural language embeddings to avoid LLM prompting, addressing privacy, reliability, and consistency issues.", "motivation": "Current LLM-based HAR methods pose risks like privacy invasion and inconsistency, necessitating alternative approaches.", "method": "The method models sensor data and activities with natural language embeddings for zero-shot classification, bypassing LLM prompting.", "result": "The solution is validated on six datasets, demonstrating the effectiveness of language modeling in zero-shot HAR.", "conclusion": "The work presents a viable alternative to LLM-based HAR, enhancing privacy and reliability without sacrificing performance."}}
{"id": "2507.21974", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.21974", "abs": "https://arxiv.org/abs/2507.21974", "authors": ["Mohamed Sana", "Nicola Piovesan", "Antonio De Domenico", "Yibin Kang", "Haozhe Zhang", "Merouane Debbah", "Fadhel Ayed"], "title": "Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks", "comment": null, "summary": "Root Cause Analysis (RCA) in mobile networks remains a challenging task due\nto the need for interpretability, domain expertise, and causal reasoning. In\nthis work, we propose a lightweight framework that leverages Large Language\nModels (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of\nannotated troubleshooting problems designed to benchmark RCA capabilities. Our\nevaluation reveals that existing open-source reasoning LLMs struggle with these\nproblems, underscoring the need for domain-specific adaptation. To address this\nissue, we propose a two-stage training methodology that combines supervised\nfine-tuning with reinforcement learning to improve the accuracy and reasoning\nquality of LLMs. The proposed approach fine-tunes a series of RCA models to\nintegrate domain knowledge and generate structured, multi-step diagnostic\nexplanations, improving both interpretability and effectiveness. Extensive\nexperiments across multiple LLM sizes show significant performance gains over\nstate-of-the-art reasoning and non-reasoning models, including strong\ngeneralization to randomized test variants. These results demonstrate the\npromise of domain-adapted, reasoning-enhanced LLMs for practical and\nexplainable RCA in network operation and management.", "AI": {"tldr": "A lightweight framework using LLMs for RCA in mobile networks is proposed, with a two-stage training method improving accuracy and reasoning.", "motivation": "RCA in mobile networks is challenging due to interpretability and domain expertise needs.", "method": "Two-stage training (supervised fine-tuning + reinforcement learning) on TeleLogs dataset to adapt LLMs for RCA.", "result": "Significant performance gains over state-of-the-art models, with strong generalization.", "conclusion": "Domain-adapted, reasoning-enhanced LLMs show promise for practical and explainable RCA."}}
{"id": "2507.21976", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21976", "abs": "https://arxiv.org/abs/2507.21976", "authors": ["Tanvir Ahmed Khan", "Aranya Saha", "Ismam Nur Swapnil", "Mohammad Ariful Haque"], "title": "The Effect of Compression Techniques on Large Multimodal Language Models in the Medical Domain", "comment": "12 pages, 5 figures. tcolorbox dependencies were removed for arXiv\n  compatibility. All references are included via a precompiled .bbl file", "summary": "Multimodal Large Language Models (MLLMs) hold huge potential for usage in the\nmedical domain, but their computational costs necessitate efficient compression\ntechniques. This paper evaluates the impact of structural pruning and\nactivation-aware quantization on a fine-tuned LLAVA model for medical\napplications. We propose a novel layer selection method for pruning, analyze\ndifferent quantization techniques, and assess the performance trade-offs in a\nprune-SFT-quantize pipeline. Our proposed method enables MLLMs with 7B\nparameters to run within 4 GB of VRAM, reducing memory usage by 70% while\nachieving 4% higher model performance compared to traditional pruning and\nquantization techniques in the same compression ratio.", "AI": {"tldr": "The paper evaluates pruning and quantization for compressing MLLMs in medical applications, proposing a novel layer selection method. It achieves 70% memory reduction and 4% higher performance.", "motivation": "MLLMs are computationally expensive, requiring efficient compression for medical use.", "method": "Proposes a layer selection method for pruning, analyzes quantization techniques, and tests a prune-SFT-quantize pipeline.", "result": "Enables 7B-parameter MLLMs to run in 4GB VRAM, reducing memory by 70% with 4% higher performance.", "conclusion": "The method effectively compresses MLLMs for medical applications, balancing performance and efficiency."}}
{"id": "2507.22009", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22009", "abs": "https://arxiv.org/abs/2507.22009", "authors": ["Bahar \u0130lgen", "Akshat Dubey", "Georges Hattab"], "title": "PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences", "comment": "Preprint. Under review", "summary": "Ensuring transparency and trust in AI-driven public health and biomedical\nsciences systems requires more than accurate predictions-it demands\nexplanations that are clear, contextual, and socially accountable. While\nexplainable AI (XAI) has advanced in areas like feature attribution and model\ninterpretability, most methods still lack the structure and adaptability needed\nfor diverse health stakeholders, including clinicians, policymakers, and the\ngeneral public. We introduce PHAX-a Public Health Argumentation and\neXplainability framework-that leverages structured argumentation to generate\nhuman-centered explanations for AI outputs. PHAX is a multi-layer architecture\ncombining defeasible reasoning, adaptive natural language techniques, and user\nmodeling to produce context-aware, audience-specific justifications. More\nspecifically, we show how argumentation enhances explainability by supporting\nAI-driven decision-making, justifying recommendations, and enabling interactive\ndialogues across user types. We demonstrate the applicability of PHAX through\nuse cases such as medical term simplification, patient-clinician communication,\nand policy justification. In particular, we show how simplification decisions\ncan be modeled as argument chains and personalized based on user\nexpertise-enhancing both interpretability and trust. By aligning formal\nreasoning methods with communicative demands, PHAX contributes to a broader\nvision of transparent, human-centered AI in public health.", "AI": {"tldr": "PHAX is a framework for generating human-centered AI explanations in public health, using structured argumentation to enhance transparency and trust.", "motivation": "Current XAI methods lack adaptability for diverse health stakeholders, requiring clearer, context-aware explanations.", "method": "PHAX combines defeasible reasoning, natural language techniques, and user modeling to create audience-specific justifications.", "result": "PHAX improves interpretability and trust in AI outputs, demonstrated through medical term simplification and policy justification use cases.", "conclusion": "PHAX advances transparent, human-centered AI in public health by aligning formal reasoning with communicative needs."}}
{"id": "2507.22025", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.22025", "abs": "https://arxiv.org/abs/2507.22025", "authors": ["Shuquan Lian", "Yuhang Wu", "Jia Ma", "Zihan Song", "Bingqi Chen", "Xiawu Zheng", "Hui Li"], "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding", "comment": null, "summary": "The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.", "AI": {"tldr": "UI-AGILE enhances GUI agents with improved training (Continuous Reward, Simple Thinking reward, Cropping-based Resampling) and inference (Decomposed Grounding with Selection), achieving state-of-the-art performance.", "motivation": "Addressing issues in GUI agent training (ineffective reward, visual noise) and inference (reasoning designs).", "method": "Proposes Continuous Reward, Simple Thinking reward, Cropping-based Resampling for training; Decomposed Grounding with Selection for inference.", "result": "23% grounding accuracy improvement over best baseline on ScreenSpot-Pro.", "conclusion": "UI-AGILE significantly advances GUI agent capabilities with its comprehensive framework."}}
{"id": "2507.22034", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22034", "abs": "https://arxiv.org/abs/2507.22034", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Zhiwei Liu", "Jianguo Zhang", "Haolin Chen", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "UserBench: An Interactive Gym Environment for User-Centric Agents", "comment": "25 Pages, 17 Figures, 6 Tables", "summary": "Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.", "AI": {"tldr": "UserBench is a benchmark for evaluating LLM agents in multi-turn, preference-driven interactions, revealing gaps in proactive collaboration with users.", "motivation": "Current LLM agents excel in reasoning and tool use but struggle with proactive collaboration when user goals are vague or evolving.", "method": "Introduces UserBench, a user-centric benchmark with simulated users and incremental preference revelation, testing agents' ability to clarify intent and use tools.", "result": "Evaluation shows low alignment (20%) with user intents and preference discovery (<30%), highlighting the challenge of true collaboration.", "conclusion": "UserBench provides a framework to measure and improve LLM agents' collaborative capabilities."}}
{"id": "2507.22047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22047", "abs": "https://arxiv.org/abs/2507.22047", "authors": ["Xiuwen Zheng", "Bornali Phukon", "Jonghwan Na", "Ed Cutrell", "Kyu Han", "Mark Hasegawa-Johnson", "Pan-Pan Jiang", "Aadhrik Kuila", "Colin Lea", "Bob MacDonald", "Gautam Mantena", "Venkatesh Ravichandran", "Leda Sari", "Katrin Tomanek", "Chang D. Yoo", "Chris Zwilling"], "title": "The Interspeech 2025 Speech Accessibility Project Challenge", "comment": "To appear in Proceedings of Interspeech, 2025", "summary": "While the last decade has witnessed significant advancements in Automatic\nSpeech Recognition (ASR) systems, performance of these systems for individuals\nwith speech disabilities remains inadequate, partly due to limited public\ntraining data. To bridge this gap, the 2025 Interspeech Speech Accessibility\nProject (SAP) Challenge was launched, utilizing over 400 hours of SAP data\ncollected and transcribed from more than 500 individuals with diverse speech\ndisabilities. Hosted on EvalAI and leveraging the remote evaluation pipeline,\nthe SAP Challenge evaluates submissions based on Word Error Rate and Semantic\nScore. Consequently, 12 out of 22 valid teams outperformed the whisper-large-v2\nbaseline in terms of WER, while 17 teams surpassed the baseline on SemScore.\nNotably, the top team achieved the lowest WER of 8.11\\%, and the highest\nSemScore of 88.44\\% at the same time, setting new benchmarks for future ASR\nsystems in recognizing impaired speech.", "AI": {"tldr": "The 2025 Interspeech SAP Challenge improved ASR for speech disabilities using 400+ hours of data, with 12/22 teams beating the baseline WER and 17/22 surpassing SemScore. Top team achieved 8.11% WER and 88.44% SemScore.", "motivation": "Address inadequate ASR performance for individuals with speech disabilities due to limited training data.", "method": "Utilized 400+ hours of SAP data from 500+ individuals, evaluated submissions via EvalAI using Word Error Rate and Semantic Score.", "result": "12 teams outperformed whisper-large-v2 on WER; 17 on SemScore. Top team achieved 8.11% WER and 88.44% SemScore.", "conclusion": "The SAP Challenge set new benchmarks for ASR in recognizing impaired speech, demonstrating significant progress."}}
{"id": "2507.17307", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.17307", "abs": "https://arxiv.org/abs/2507.17307", "authors": ["Zhuokun Chen", "Zeren Chen", "Jiahao He", "Mingkui Tan", "Jianfei Cai", "Bohan Zhuang"], "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "comment": null, "summary": "Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of\nlarge language models by encouraging step-by-step intermediate reasoning during\ninference. While effective, CoT introduces substantial computational overhead\ndue to its reliance on autoregressive decoding over long token sequences.\nExisting acceleration strategies either reduce sequence length through early\nstopping or compressive reward designs, or improve decoding speed via\nspeculative decoding with smaller models. However, speculative decoding suffers\nfrom limited speedup when the agreement between small and large models is low,\nand fails to exploit the potential advantages of small models in producing\nconcise intermediate reasoning. In this paper, we present R-Stitch, a\ntoken-level, confidence-based hybrid decoding framework that accelerates CoT\ninference by switching between a small language model (SLM) and a large\nlanguage model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to\ngenerate tokens by default and delegates to the LLM only when the SLM's\nconfidence falls below a threshold. This design avoids full-sequence rollback\nand selectively invokes the LLM on uncertain steps, preserving both efficiency\nand answer quality. R-Stitch is model-agnostic, training-free, and compatible\nwith standard decoding pipelines. Experiments on math reasoning benchmarks\ndemonstrate that R-Stitch achieves up to 85\\% reduction in inference latency\nwith negligible accuracy drop, highlighting its practical effectiveness in\naccelerating CoT reasoning.", "AI": {"tldr": "R-Stitch accelerates CoT reasoning by hybrid decoding between small and large language models, reducing latency by 85% with minimal accuracy loss.", "motivation": "Current CoT acceleration methods like speculative decoding have limitations in speedup and fail to leverage small models' concise reasoning.", "method": "R-Stitch uses token-level confidence-based switching between SLM and LLM, invoking LLM only when SLM confidence is low.", "result": "Achieves up to 85% reduction in inference latency with negligible accuracy drop on math reasoning benchmarks.", "conclusion": "R-Stitch is a practical, model-agnostic solution for efficient CoT reasoning without compromising quality."}}
{"id": "2507.20894", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20894", "abs": "https://arxiv.org/abs/2507.20894", "authors": ["Lara Neves", "Afonso Louren\u00e7o", "Alberto Cano", "Goreti Marreiros"], "title": "Online hierarchical partitioning of the output space in extreme multi-label data stream", "comment": "Accepted at 28th European Conference on Artificial Intelligence (ECAI\n  2025)", "summary": "Mining data streams with multi-label outputs poses significant challenges due\nto evolving distributions, high-dimensional label spaces, sparse label\noccurrences, and complex label dependencies. Moreover, concept drift affects\nnot only input distributions but also label correlations and imbalance ratios\nover time, complicating model adaptation. To address these challenges,\nstructured learners are categorized into local and global methods. Local\nmethods break down the task into simpler components, while global methods adapt\nthe algorithm to the full output space, potentially yielding better predictions\nby exploiting label correlations. This work introduces iHOMER (Incremental\nHierarchy Of Multi-label Classifiers), an online multi-label learning framework\nthat incrementally partitions the label space into disjoint, correlated\nclusters without relying on predefined hierarchies. iHOMER leverages online\ndivisive-agglomerative clustering based on \\textit{Jaccard} similarity and a\nglobal tree-based learner driven by a multivariate \\textit{Bernoulli} process\nto guide instance partitioning. To address non-stationarity, it integrates\ndrift detection mechanisms at both global and local levels, enabling dynamic\nrestructuring of label partitions and subtrees. Experiments across 23\nreal-world datasets show iHOMER outperforms 5 state-of-the-art global\nbaselines, such as MLHAT, MLHT of Pruned Sets and iSOUPT, by 23\\%, and 12 local\nbaselines, such as binary relevance transformations of kNN, EFDT, ARF, and\nADWIN bagging/boosting ensembles, by 32\\%, establishing its robustness for\nonline multi-label classification.", "AI": {"tldr": "iHOMER is an online multi-label learning framework that dynamically clusters labels and detects drift, outperforming state-of-the-art methods.", "motivation": "Challenges in multi-label data streams include evolving distributions, high-dimensional labels, and concept drift affecting label correlations.", "method": "iHOMER uses incremental clustering (Jaccard similarity) and a tree-based learner with drift detection at global/local levels.", "result": "iHOMER outperforms 5 global baselines by 23% and 12 local baselines by 32% in experiments.", "conclusion": "iHOMER is robust for online multi-label classification, effectively handling dynamic label spaces and concept drift."}}
