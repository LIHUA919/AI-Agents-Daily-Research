{"id": "2601.10774", "categories": ["cs.LG", "hep-lat"], "pdf": "https://arxiv.org/pdf/2601.10774", "abs": "https://arxiv.org/abs/2601.10774", "authors": ["Mathis Gerdes", "Miranda C. N. Cheng"], "title": "Analytic Bijections for Smooth and Interpretable Normalizing Flows", "comment": "33 + 5 pages, 17 + 1 figures, 3 tables", "summary": "A key challenge in designing normalizing flows is finding expressive scalar bijections that remain invertible with tractable Jacobians. Existing approaches face trade-offs: affine transformations are smooth and analytically invertible but lack expressivity; monotonic splines offer local control but are only piecewise smooth and act on bounded domains; residual flows achieve smoothness but need numerical inversion. We introduce three families of analytic bijections -- cubic rational, sinh, and cubic polynomial -- that are globally smooth ($C^\\infty$), defined on all of $\\mathbb{R}$, and analytically invertible in closed form, combining the favorable properties of all prior approaches. These bijections serve as drop-in replacements in coupling flows, matching or exceeding spline performance. Beyond coupling layers, we develop radial flows: a novel architecture using direct parametrization that transforms the radial coordinate while preserving angular direction. Radial flows exhibit exceptional training stability, produce geometrically interpretable transformations, and on targets with radial structure can achieve comparable quality to coupling flows with $1000\\times$ fewer parameters. We provide comprehensive evaluation on 1D and 2D benchmarks, and demonstrate applicability to higher-dimensional physics problems through experiments on $\u03c6^4$ lattice field theory, where our bijections outperform affine baselines and enable problem-specific designs that address mode collapse.", "AI": {"tldr": "New analytic bijections and radial flow architecture for normalizing flows offer smooth, invertible transformations with better expressivity, stability, and efficiency than existing methods.", "motivation": "Existing normalizing flow approaches face trade-offs: affine transformations lack expressivity, monotonic splines are only piecewise smooth and bounded, and residual flows require numerical inversion. There's a need for expressive scalar bijections that are globally smooth, defined on all real numbers, and analytically invertible.", "method": "Introduces three families of analytic bijections (cubic rational, sinh, and cubic polynomial) for use in coupling flows, plus a novel radial flow architecture that transforms radial coordinates while preserving angular direction.", "result": "The analytic bijections match or exceed spline performance as drop-in replacements in coupling flows. Radial flows show exceptional training stability and interpretability, achieving comparable quality to coupling flows with 1000\u00d7 fewer parameters for radially structured targets. The methods outperform affine baselines on 1D/2D benchmarks and enable better performance on \u03c6\u2074 lattice field theory while addressing mode collapse.", "conclusion": "The proposed analytic bijections and radial flow architecture offer significant improvements over existing normalizing flow methods, combining the favorable properties of prior approaches while enabling more efficient, stable, and interpretable models with better performance across various domains."}}
{"id": "2601.10779", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10779", "abs": "https://arxiv.org/abs/2601.10779", "authors": ["Qingyue Zhang", "Chang Chu", "Haohao Fu", "Tianren Peng", "Yanru Wu", "Guanbo Huang", "Yang Li", "Shao-Lun Huang"], "title": "Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework", "comment": null, "summary": "Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.", "AI": {"tldr": "UOWQ framework jointly optimizes source weights and transfer quantities for multi-source transfer learning, preventing negative transfer and outperforming baselines.", "motivation": "Current transfer learning methods show that naive uniform transfer from multiple source tasks causes negative transfer, and existing methods either optimize source weights or transfer quantities but not both jointly.", "method": "Developed Unified Optimization of Weights and Quantities (UOWQ), a theoretical framework formulating multi-source transfer learning as parameter estimation using asymptotic analysis of KL divergence-based generalization error, with closed-form solutions for single-source and convex optimization for multi-source.", "result": "Proved that using all available source samples is optimal with properly adjusted weights, provided practical algorithms for multi-source transfer and multi-task learning, and showed consistent outperformance of baselines on benchmarks like DomainNet and Office-Home.", "conclusion": "UOWQ effectively addresses negative transfer by jointly optimizing weights and quantities, providing both theoretical guarantees and practical effectiveness in multi-source transfer learning."}}
{"id": "2601.10801", "categories": ["cs.LG", "hep-ex", "physics.ins-det", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10801", "abs": "https://arxiv.org/abs/2601.10801", "authors": ["Alberto Coppi", "Ema Puljak", "Lorenzo Borella", "Daniel Jaschke", "Enrique Rico", "Maurizio Pierini", "Jacopo Pazzini", "Andrea Triossi", "Simone Montangero"], "title": "Towards Tensor Network Models for Low-Latency Jet Tagging on FPGAs", "comment": "10 pages, 8 figures", "summary": "We present a systematic study of Tensor Network (TN) models $\\unicode{x2013}$ Matrix Product States (MPS) and Tree Tensor Networks (TTN) $\\unicode{x2013}$ for real-time jet tagging in high-energy physics, with a focus on low-latency deployment on Field Programmable Gate Arrays (FPGAs). Motivated by the strict requirements of the HL-LHC Level-1 trigger system, we explore TNs as compact and interpretable alternatives to deep neural networks. Using low-level jet constituent features, our models achieve competitive performance compared to state-of-the-art deep learning classifiers. We investigate post-training quantization to enable hardware-efficient implementations without degrading classification performance or latency. The best-performing models are synthesized to estimate FPGA resource usage, latency, and memory occupancy, demonstrating sub-microsecond latency and supporting the feasibility of online deployment in real-time trigger systems. Overall, this study highlights the potential of TN-based models for fast and resource-efficient inference in low-latency environments.", "AI": {"tldr": "A study of Tensor Network models (MPS and TTN) for real-time jet tagging in high-energy physics, focusing on low-latency FPGA deployment, showing competitive performance to deep learning, hardware efficiency, and feasibility for online triggers.", "motivation": "Motivated by the strict latency requirements of the HL-LHC Level-1 trigger system, exploring TN models as compact and interpretable alternatives to deep neural networks to meet real-time constraints in high-energy physics applications.", "method": "Systematic study of Tensor Network models, including Matrix Product States (MPS) and Tree Tensor Networks (TTN), using low-level jet constituent features. Investigates post-training quantization for hardware-efficient implementations without degrading performance or latency, with synthesis to estimate FPGA resource usage.", "result": "TN models achieve competitive performance compared to state-of-the-art deep learning classifiers. Best-performing models demonstrate sub-microsecond latency, low FPGA resource usage, and memory occupancy, supporting feasibility for online deployment in real-time trigger systems.", "conclusion": "The study highlights the potential of TN-based models for fast and resource-efficient inference in low-latency environments, such as HL-LHC trigger systems, offering a viable alternative to deep neural networks."}}
{"id": "2601.10810", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10810", "abs": "https://arxiv.org/abs/2601.10810", "authors": ["Mengmeng Peng", "Zhenyu Fang", "He Sun"], "title": "Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning -- Towards a Pure Neural Logic Core", "comment": null, "summary": "Large language models (LLMs) currently suffer from parameter entanglement, where general reasoning capabilities (logic) and specific factual knowledge (facts) exist in a superposition state within shared weights. This coupling leads to the \"memory wall,\" where computational capacity is squandered on simulating retrieval, often resulting in hallucinations. In this paper, we propose \"digital metabolism,\" a thermodynamic hypothesis suggesting that targeted forgetting is necessary for distilling a pure neural logic core. To validate this hypothesis, we introduce the Regenerative Logic-Core Protocol (RLCP), a dual-stream training framework that renders specific factual dependencies linearly undecodable via deep-layer gradient reversal. Applying RLCP to Qwen2.5-0.5B, we observe a distinct phase transition: the model achieves near-zero retention of targeted factual associations (Accuracy < 7%) while exhibiting changes consistent with an emergent \"structural crystallization\" effect. Empirical analysis on GSM8K reveals that the \"metabolized\" model spontaneously adopts chain-of-thought (CoT) scaffolding, which we interpret as compensating for the loss of direct associative recall (shifting from $O(1)$ recall to $O(N)$ reasoning). While the causal mechanism underlying this behavioral shift requires further investigation, our findings provide a dynamic weight-level counterpart to architectural innovations like DeepSeek's Engram, paving the way for modular \"Neural CPU + Symbolic RAM\" architectures.", "AI": {"tldr": "Researchers propose \"digital metabolism\" - a thermodynamic hypothesis that targeted forgetting of factual knowledge is needed to distill a pure neural logic core. They introduce RLCP training framework that makes factual dependencies undecodable, resulting in models that lose specific factual recall but gain enhanced reasoning capabilities.", "motivation": "Current LLMs suffer from parameter entanglement where general reasoning capabilities and specific factual knowledge exist in superposition within shared weights. This coupling creates a \"memory wall\" where computational capacity is wasted on simulating retrieval, leading to hallucinations.", "method": "Introduce Regenerative Logic-Core Protocol (RLCP), a dual-stream training framework that makes specific factual dependencies linearly undecodable via deep-layer gradient reversal. Applied to Qwen2.5-0.5B model to test the digital metabolism hypothesis.", "result": "The model achieved near-zero retention of targeted factual associations (Accuracy < 7%) while exhibiting \"structural crystallization\" effects. On GSM8K, the metabolized model spontaneously adopted chain-of-thought scaffolding, shifting from O(1) recall to O(N) reasoning.", "conclusion": "Targeted forgetting enables distillation of pure neural logic cores, providing a dynamic weight-level counterpart to architectural innovations. This paves the way for modular \"Neural CPU + Symbolic RAM\" architectures where reasoning and memory are separated."}}
{"id": "2601.10849", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10849", "abs": "https://arxiv.org/abs/2601.10849", "authors": ["Cuong Le", "Symeon Chatzinotas", "Thang X. Vu"], "title": "Cooperative UAVs for Remote Data Collection under Limited Communications: An Asynchronous Multiagent Learning Framework", "comment": "Accepted to IEEE Transactions on Wireless Communications", "summary": "This paper addresses the joint optimization of trajectories and bandwidth allocation for multiple Unmanned Aerial Vehicles (UAVs) to enhance energy efficiency in the cooperative data collection problem. We focus on an important yet underestimated aspect of the system, where action synchronization across all UAVs is impossible. Since most existing learning-based solutions are not designed to learn in this asynchronous environment, we formulate the trajectory planning problem as a Decentralized Partially Observable Semi-Markov Decision Process and introduce an asynchronous multi-agent learning algorithm to learn UAVs' cooperative policies. Once the UAVs' trajectory policies are learned, the bandwidth allocation can be optimally solved based on local observations at each collection point. Comprehensive empirical results demonstrate the superiority of the proposed method over other learning-based and heuristic baselines in terms of both energy efficiency and mission completion time. Additionally, the learned policies exhibit robustness under varying environmental conditions.", "AI": {"tldr": "Joint optimization of UAV trajectories and bandwidth allocation using an asynchronous multi-agent learning algorithm, formulated as a Dec-POSMDP, improves energy efficiency and mission completion time while being robust to environmental changes.", "motivation": "To address the joint optimization of trajectories and bandwidth allocation for multiple UAVs in cooperative data collection, focusing on the underestimated aspect where action synchronization across UAVs is impossible. Most existing learning-based solutions are not designed for such asynchronous environments.", "method": "The trajectory planning problem is formulated as a Decentralized Partially Observable Semi-Markov Decision Process (Dec-POSMDP). An asynchronous multi-agent learning algorithm is introduced to learn UAVs' cooperative policies. After learning trajectory policies, bandwidth allocation is optimally solved based on local observations at each collection point.", "result": "Comprehensive empirical results show the proposed method outperforms other learning-based and heuristic baselines in terms of energy efficiency and mission completion time. The learned policies also demonstrate robustness under varying environmental conditions.", "conclusion": "The proposed asynchronous multi-agent learning algorithm effectively handles the asynchronous environment of UAVs, enabling them to learn cooperative policies that optimize both energy efficiency and mission completion time. The method's robustness under varying environmental conditions further validates its practical applicability."}}
{"id": "2601.10718", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10718", "abs": "https://arxiv.org/abs/2601.10718", "authors": ["Junyu Liu", "Siwen Yang", "Dexiu Ma", "Qian Niu", "Zequn Zhang", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design", "comment": null, "summary": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.", "AI": {"tldr": "Developed a dual-purpose AI system that provides verified HPV vaccine information via chatbot while generating analytical reports for health institutions, achieving high performance scores and demonstrating feasibility for addressing vaccine hesitancy.", "motivation": "To address HPV vaccine hesitancy in Japan, where proactive vaccination recommendations were suspended (2013-2021), creating an information gap exacerbated by social media misinformation, and the lack of systems that can simultaneously handle individual queries while monitoring population-level discourse.", "method": "Implemented a system comprising: a vector database integrating diverse sources; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, sentiment analysis, and user interaction pattern identification.", "result": "The chatbot achieved high performance scores (0-5 scale): in single-turn evaluation, mean scores were relevance 4.83, routing 4.89, reference quality 4.50, correctness 4.90, professional identity 4.88 (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, helpfulness 3.67-5.00, with reference validity 5.00 across all periods.", "conclusion": "This study demonstrates the feasibility and effectiveness of a dual-purpose AI agent system for addressing HPV vaccine hesitancy, providing both verified information to individuals and analytical insights to health institutions, with a framework transferable to other public health topics."}}
{"id": "2601.10820", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10820", "abs": "https://arxiv.org/abs/2601.10820", "authors": ["Himanshu Thakur", "Anusha Kamath", "Anurag Muthyala", "Dhwani Sanmukhani", "Smruthi Mukund", "Jay Katukuri"], "title": "Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents", "comment": null, "summary": "Recent advances in code generation models have unlocked unprecedented opportunities for automating feature engineering, yet their adoption in real-world ML teams remains constrained by critical challenges: (i) the scarcity of datasets capturing the iterative and complex coding processes of production-level feature engineering, (ii) limited integration and personalization of widely used coding agents, such as CoPilot and Devin, with a team's unique tools, codebases, workflows, and practices, and (iii) suboptimal human-AI collaboration due to poorly timed or insufficient feedback. We address these challenges with a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. The LLM-powered planner leverages a team's environment, represented as a graph, to orchestrate calls to available agents, generate context-aware prompts, and use downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps, ensuring generated code is reliable, maintainable, and aligned with team expectations. On a novel in-house dataset, our approach achieves 38% and 150% improvement in the evaluation metric over manually crafted and unplanned workflows respectively. In practice, when building features for recommendation models serving over 120 million users, our approach has delivered real-world impact by reducing feature engineering cycles from three weeks to a single day.", "AI": {"tldr": "A planner-guided multi-agent framework for automating feature engineering in ML teams, improving code generation by 38-150% and reducing feature development cycles from weeks to days.", "motivation": "Current code generation models face three main challenges in real-world ML feature engineering: lack of datasets capturing iterative coding processes, limited integration/personalization with team-specific tools and workflows, and poor human-AI collaboration timing.", "method": "A planner-guided, constrained-topology multi-agent framework where an LLM-powered planner orchestrates calls to available agents using a graph representation of the team's environment. It generates context-aware prompts, uses downstream failures to correct upstream artifacts, and can request human intervention at critical steps.", "result": "On a novel in-house dataset, the approach achieved 38% improvement over manually crafted workflows and 150% improvement over unplanned workflows. In production for recommendation models serving 120M+ users, it reduced feature engineering cycles from three weeks to a single day.", "conclusion": "The planner-guided multi-agent framework successfully addresses critical challenges in automating feature engineering, enabling reliable, maintainable code generation that aligns with team expectations and delivers significant real-world productivity gains."}}
{"id": "2601.11327", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11327", "abs": "https://arxiv.org/abs/2601.11327", "authors": ["Agata \u017bywot", "Xinyi Chen", "Maarten de Rijke"], "title": "Can Small Agent Collaboration Beat a Single Big LLM?", "comment": null, "summary": "This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift.", "AI": {"tldr": "Small models with tools beat large models without tools; explicit thinking is tricky, sometimes helps, often hurts\u2014tools are key.", "motivation": "To determine if smaller, tool-augmented agents can match or surpass larger monolithic models in reasoning tasks, and to assess the efficacy of explicit thinking and tool use.", "method": "The study evaluates scaled Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework varying thinking modes (no thinking, planner-only, full) and tool access (search, code, mind-map) on the GAIA benchmark.", "result": "Tool augmentation consistently improved performance, enabling 4B models to outperform 32B models without tool access on the GAIA benchmark; planner-only thinking improved decomposition and constraint tracking, while full thinking degraded performance due to tool misuse and format issues.", "conclusion": "Small tool-augmented models can outperform larger models without tools on GAIA, with tools providing consistent benefits while explicit thinking can be beneficial in structured forms but harmful if fully unrestricted."}}
{"id": "2601.10719", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.", "AI": {"tldr": "LLMs implicitly encode psychologically coherent trust signals from pretraining, with strongest associations to fairness, certainty, and accountability dimensions, providing foundations for trustworthy AI systems.", "motivation": "To understand whether large language models (LLMs) embedded in search, recommendation, and conversational systems represent perceived trustworthiness in psychologically coherent ways, given its crucial role in how users navigate online information.", "method": "Analyzed instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encoding perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Conducted layer- and head-level activation analysis, probing analyses for linearly decodable trust signals, and fine-tuning experiments.", "result": "Systematic layer- and head-level activation differences distinguish high- from low-trust texts across models. Trust cues are implicitly encoded during pretraining, with linearly decodable trust signals. Fine-tuning refines rather than restructures these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self - dimensions central to human trust formation online.", "conclusion": "Modern LLMs internalize psychologically grounded trust signals without explicit supervision, providing a representational foundation for designing credible, transparent, and trustworthy AI systems in the web ecosystem."}}
{"id": "2601.10823", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.10823", "abs": "https://arxiv.org/abs/2601.10823", "authors": ["Daniel Price", "Prabhu Vellaisamy", "John Shen", "Di Wu"], "title": "Mugi: Value Level Parallelism For Efficient LLMs", "comment": "2026 International Conference on Architectural Support for Programming Languages and Operating Systems", "summary": "Value level parallelism (VLP) has been proposed to improve the efficiency of large-batch, low-precision general matrix multiply (GEMM) between symmetric activations and weights. In transformer based large language models (LLMs), there exist more sophisticated operations beyond activation-weight GEMM. In this paper, we explore how VLP benefits LLMs. First, we generalize VLP for nonlinear approximations, outperforming existing nonlinear approximations in end-to-end LLM accuracy, performance, and efficiency. Our VLP approximation follows a value-centric approach, where important values are assigned with greater accuracy. Second, we optimize VLP for small-batch GEMMs with asymmetric inputs efficiently, which leverages timely LLM optimizations, including weight-only quantization, key-value (KV) cache quantization, and group query attention. Finally, we design a new VLP architecture, Mugi, to encapsulate the innovations above and support full LLM workloads, while providing better performance, efficiency and sustainability. Our experimental results show that Mugi can offer significant improvements on throughput and energy efficiency, up to $45\\times$ and $668\\times$ for nonlinear softmax operations, and $2.07\\times$ and $3.11\\times$ for LLMs, and also decrease operational carbon for LLM operation by $1.45\\times$ and embodied carbon by $1.48\\times$.", "AI": {"tldr": "This paper extends VLP for LLMs through generalized nonlinear approximations, optimized small-batch GEMMs, and new Mugi architecture, achieving major performance and efficiency gains.", "motivation": "While VLP has been used for large-batch GEMM operations, transformers have complex operations beyond basic GEMM. The paper aims to explore how VLP can benefit LLMs with their sophisticated computational patterns.", "method": "The paper generalizes VLP for nonlinear approximations, optimizes VLP for small-batch GEMMs with asymmetric inputs, and designs a new VLP architecture called Mugi that supports full LLM workloads.", "result": "Mugi achieves up to 45\u00d7 throughput and 668\u00d7 energy efficiency improvements for nonlinear softmax operations, and 2.07\u00d7 throughput and 3.11\u00d7 energy efficiency for LLMs, while reducing operational carbon by 1.45\u00d7 and embodied carbon by 1.48\u00d7.", "conclusion": "Mugi provides significant performance, efficiency, and sustainability improvements for LLMs through VLP innovations, demonstrating practical benefits for real-world LLM deployment."}}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "AI agents help job seekers write better referral requests using an improver agent to rewrite requests and an evaluator agent to assess quality, with RAG-enhanced LLM revisions increasing predicted success rates for weaker requests by 14% without harming stronger ones.", "motivation": "To help job seekers write more effective requests for job referrals in professional online communities, since well-written referral requests are more likely to receive positive responses.", "method": "Developed a two-agent system: 1) an improver agent that rewrites referral requests using LLM, 2) an evaluator agent that measures revision quality using a model trained to predict referral probability. Enhanced the LLM with Retrieval-Augmented Generation (RAG) to improve performance.", "result": "LLM revisions increased predicted success rates for weaker requests but reduced them for stronger requests. RAG enhancement prevented edits that worsened stronger requests while amplifying improvements for weaker requests. Overall, RAG-enhanced LLM revisions increased predicted success rate for weaker requests by 14% without degrading performance on stronger requests.", "conclusion": "While model-predicted improvements don't guarantee real-world success, they provide low-cost signals for promising features before conducting higher-stakes experiments with real users, demonstrating the potential of AI agents to assist with professional communication tasks."}}
{"id": "2601.10859", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10859", "abs": "https://arxiv.org/abs/2601.10859", "authors": ["Dat Quoc Ha", "Md Ferdous Alam", "Markus J. Buehler", "Faez Ahmed", "Josephine V. Carstensen"], "title": "AI-Guided Human-In-the-Loop Inverse Design of High Performance Engineering Structures", "comment": "21 pages, 10 figures", "summary": "Inverse design tools such as Topology Optimization (TO) can achieve new levels of improvement for high-performance engineered structures. However, widespread use is hindered by high computational times and a black-box nature that inhibits user interaction. Human-in-the-loop TO approaches are emerging that integrate human intuition into the design generation process. However, these rely on the time-consuming bottleneck of iterative region selection for design modifications. To reduce the number of iterative trials, this contribution presents an AI co-pilot that uses machine learning to predict the user's preferred regions. The prediction model is configured as an image segmentation task with a U-Net architecture. It is trained on synthetic datasets where human preferences either identify the longest topological member or the most complex structural connection. The model successfully predicts plausible regions for modification and presents them to the user as AI recommendations. The human preference model demonstrates generalization across diverse and non-standard TO problems and exhibits emergent behavior outside the single-region selection training data. Demonstration examples show that the new human-in-the-loop TO approach that integrates the AI co-pilot can improve manufacturability or improve the linear buckling load by 39% while only increasing the total design time by 15 sec compared to conventional simplistic TO.", "AI": {"tldr": "AI co-pilot for topology optimization predicts user-preferred modification regions using U-Net image segmentation, reducing iterative trials and improving manufacturability/performance with minimal time increase.", "motivation": "Topology optimization faces barriers due to high computational times and black-box nature; human-in-the-loop approaches exist but suffer from time-consuming iterative region selection bottlenecks.", "method": "Developed AI co-pilot using U-Net architecture for image segmentation trained on synthetic datasets of human preferences (longest topological member or most complex structural connection).", "result": "Model successfully predicts plausible modification regions, generalizes across diverse TO problems, and shows emergent behavior beyond single-region training. Integration improves manufacturability and boosts linear buckling load by 39% with only 15-second time increase.", "conclusion": "AI co-pilot effectively reduces iterative trials in human-in-the-loop topology optimization, making TO more accessible and efficient while maintaining user control."}}
{"id": "2601.10729", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10729", "abs": "https://arxiv.org/abs/2601.10729", "authors": ["Xinyue Ma", "Heelim Hong", "Taegeon Um", "Jongseop Lee", "Seoyeong Choy", "Woo-Yeon Lee", "Myeongjae Jeon"], "title": "ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration", "comment": "Accepted at the 52nd International Conference on Very Large Data Bases (VLDB 2026). Xinyue Ma and Heelim Hong contributed equally (co-first authors)", "summary": "Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods.", "AI": {"tldr": "ORBITFLOW is an adaptive KV cache management system for long-context LLM serving that uses a lightweight ILP solver and runtime feedback to optimize GPU memory usage, improving SLO attainment and throughput while reducing latency.", "motivation": "Serving long-context LLMs faces challenges due to fluctuating memory demands during token generation, with existing static offloading strategies causing excessive CPU-to-GPU KV transfers, latency spikes, and SLO violations.", "method": "ORBITFLOW employs a lightweight ILP solver to decide which KV caches to keep on the GPU per request under memory constraints, refines placements based on runtime feedback, and uses a fallback mechanism to defer memory-heavy requests under heavy load.", "result": "Experiments show ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, reduces 95th percentile latency by 38%, and achieves up to 3.3x higher throughput compared to existing methods.", "conclusion": "ORBITFLOW provides an effective solution for dynamic KV cache management in long-context LLM serving, enhancing performance and reliability under variable workloads."}}
{"id": "2601.10863", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10863", "abs": "https://arxiv.org/abs/2601.10863", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Beyond Accuracy: A Stability-Aware Metric for Multi-Horizon Forecasting", "comment": null, "summary": "Traditional time series forecasting methods optimize for accuracy alone. This objective neglects temporal consistency, in other words, how consistently a model predicts the same future event as the forecast origin changes. We introduce the forecast accuracy and coherence score (forecast AC score for short) for measuring the quality of probabilistic multi-horizon forecasts in a way that accounts for both multi-horizon accuracy and stability. Our score additionally provides for user-specified weights to balance accuracy and consistency requirements. As an example application, we implement the score as a differentiable objective function for training seasonal ARIMA models and evaluate it on the M4 Hourly benchmark dataset. Results demonstrate substantial improvements over traditional maximum likelihood estimation. Our AC-optimized models achieve a 75\\% reduction in forecast volatility for the same target timestamps while maintaining comparable or improved point forecast accuracy.", "AI": {"tldr": "A method is proposed to measure probabilistic multi-horizon forecasts with a combined metric for accuracy and temporal consistency, applied to seasonal ARIMA models.", "motivation": "Traditional forecasting methods optimize only for accuracy, neglecting temporal consistency, which can lead to unstable predictions over time.", "method": "The paper introduces the forecast AC score to account for both multi-horizon accuracy and stability, with user-specified weights. It is applied as a differentiable objective function for training seasonal ARIMA models.", "result": "Evaluation on the M4 Hourly dataset shows significant improvements over maximum likelihood estimation, with a 75% reduction in forecast volatility while maintaining or improving accuracy.", "conclusion": "The forecast AC score effectively balances accuracy and consistency, enhancing model reliability and performance in practical time series forecasting."}}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "Constrained Temporal Hierarchical Architecture (CTHA) is introduced to stabilize multi-time-scale agent systems by structuring inter-layer communication, reducing coordination conflicts, and enhancing performance.", "motivation": "Multi-time-scale agent architectures improve performance but disrupt coordination stability across layers, leading to conflicts, error propagation, and scalability issues.", "method": "CTHA projects inter-layer communication onto structured manifolds and uses three constraints: Message Contract Constraints (formalized information flow), Authority Manifold Constraints (bounded decision spaces by temporal scope), and Arbiter Resolution Constraints (conflict-free multi-layer decisions).", "result": "Empirical experiments show CTHA reduces failure cascades by 47%, improves sample efficiency by 2.3x, and achieves superior scalability compared to unconstrained hierarchical baselines.", "conclusion": "CTHA is a principled framework that addresses coordination instability in multi-time-scale agents, offering a path toward robust autonomous systems and deeper understanding of multi-agent interactions."}}
{"id": "2601.10873", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10873", "abs": "https://arxiv.org/abs/2601.10873", "authors": ["Jeffrey Uhlmann"], "title": "Unit-Consistent (UC) Adjoint for GSD and Backprop in Deep Learning Applications", "comment": null, "summary": "Deep neural networks constructed from linear maps and positively homogeneous nonlinearities (e.g., ReLU) possess a fundamental gauge symmetry: the network function is invariant to node-wise diagonal rescalings. However, standard gradient descent is not equivariant to this symmetry, causing optimization trajectories to depend heavily on arbitrary parameterizations. Prior work has proposed rescaling-invariant optimization schemes for positively homogeneous networks (e.g., path-based or path-space updates). Our contribution is complementary: we formulate the invariance requirement at the level of the backward adjoint/optimization geometry, which provides a simple, operator-level recipe that can be applied uniformly across network components and optimizer state. By replacing the Euclidean transpose with a Unit-Consistent (UC) adjoint, we derive UC gauge-consistent steepest descent and backprogation.", "AI": {"tldr": "The paper proposes Unit-Consistent (UC) adjoint optimization for positively homogeneous neural networks to achieve gauge invariance, replacing Euclidean transpose with UC adjoint for consistent steepest descent and backpropagation.", "motivation": "Deep neural networks with positively homogeneous nonlinearities (like ReLU) have gauge symmetry where node-wise diagonal rescalings don't change network function, but standard gradient descent isn't equivariant to this symmetry, making optimization trajectories depend heavily on arbitrary parameterizations.", "method": "Formulate invariance requirement at the level of backward adjoint/optimization geometry, replacing Euclidean transpose with Unit-Consistent (UC) adjoint to derive UC gauge-consistent steepest descent and backpropagation.", "result": "Develops a simple, operator-level recipe that can be applied uniformly across network components and optimizer state to achieve gauge-invariant optimization.", "conclusion": "The UC adjoint approach provides a principled way to achieve gauge-consistent optimization for positively homogeneous networks, addressing the parameterization dependence problem in standard gradient descent."}}
