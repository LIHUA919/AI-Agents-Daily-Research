<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [AI-Augmented Density-Driven Optimal Control (D2OC) for Decentralized Environmental Mapping](https://arxiv.org/abs/2601.21126)
*Kooktae Lee,Julian Martinez*

Main category: cs.MA

TL;DR: AI-augmented decentralized framework for multi-agent environmental mapping under limited sensing/communication, using adaptive optimal transport to refine density estimates and enhance mapping accuracy.


<details>
  <summary>Details</summary>
Motivation: Conventional multi-agent mapping methods degrade under uncertain or biased prior maps, limiting performance in real-world scenarios with imperfect information.

Method: Proposes an adaptive self-correcting mechanism within an optimal transport framework, with a dual MLP module to infer local statistics and regulate uncertainty for unvisited regions.

Result: Theoretical convergence proven under Wasserstein metric; simulations show robust alignment with ground-truth density and higher-fidelity reconstruction of complex distributions than baselines.

Conclusion: The AI-augmented density-driven optimal control framework achieves scalable, consistent, and precise multi-agent environmental mapping, outperforming conventional decentralized approaches.

Abstract: This paper presents an AI-augmented decentralized framework for multi-agent (multi-robot) environmental mapping under limited sensing and communication. While conventional coverage formulations achieve effective spatial allocation when an accurate reference map is available, their performance deteriorates under uncertain or biased priors. The proposed method introduces an adaptive and self-correcting mechanism that enables agents to iteratively refine local density estimates within an optimal transport-based framework, ensuring theoretical consistency and scalability. A dual multilayer perceptron (MLP) module enhances adaptivity by inferring local mean-variance statistics and regulating virtual uncertainty for long-unvisited regions, mitigating stagnation around local minima. Theoretical analysis rigorously proves convergence under the Wasserstein metric, while simulation results demonstrate that the proposed AI-augmented Density-Driven Optimal Control consistently achieves robust and precise alignment with the ground-truth density, yielding substantially higher-fidelity reconstruction of complex multi-modal spatial distributions compared with conventional decentralized baselines.

</details>


### [2] [Mean-Field Control on Sparse Graphs: From Local Limits to GNNs via Neighborhood Distributions](https://arxiv.org/abs/2601.21477)
*Tobias Schmidt,Kai Cui*

Main category: cs.MA

TL;DR: A framework for mean-field control on large sparse graphs, enabling scalable reinforcement learning via local neighborhoods and Graph Neural Networks.


<details>
  <summary>Details</summary>
Motivation: Traditional mean-field control assumes dense, all-to-all interactions, which is restrictive and does not align with real-world sparse network structures.

Method: Redefine system state as a probability measure over decorated rooted neighborhoods, prove horizon-dependent locality for optimal policies, and derive a Dynamic Programming Principle on neighborhood distributions.

Result: Horizon-dependent locality is proven: for finite-horizon problems, an agent's optimal policy at time t depends on its (T-t)-hop neighborhood, making the control problem tractable and supporting GNN-based actor-critic algorithms.

Conclusion: The framework bridges the gap to real-world networks, recovers classical mean-field control as a degenerate case, and enables efficient, theoretically grounded control on complex sparse topologies.

Abstract: Mean-field control (MFC) offers a scalable solution to the curse of dimensionality in multi-agent systems but traditionally hinges on the restrictive assumption of exchangeability via dense, all-to-all interactions. In this work, we bridge the gap to real-world network structures by proposing a rigorous framework for MFC on large sparse graphs. We redefine the system state as a probability measure over decorated rooted neighborhoods, effectively capturing local heterogeneity. Our central contribution is a theoretical foundation for scalable reinforcement learning in this setting. We prove horizon-dependent locality: for finite-horizon problems, an agent's optimal policy at time t depends strictly on its (T-t)-hop neighborhood. This result renders the infinite-dimensional control problem tractable and underpins a novel Dynamic Programming Principle (DPP) on the lifted space of neighborhood distributions. Furthermore, we formally and experimentally justify the use of Graph Neural Networks (GNNs) for actor-critic algorithms in this context. Our framework naturally recovers classical MFC as a degenerate case while enabling efficient, theoretically grounded control on complex sparse topologies.

</details>


### [3] [Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems](https://arxiv.org/abs/2601.22041)
*Naomi Pitzer,Daniela Mihai*

Main category: cs.MA

TL;DR: Emergent communication in heterogeneous agents shows convergence to class-consistent messages, with unimodal systems being more efficient, meaning encoded distributionally, and cross-modality communication requiring fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Most research on emergent communication assumes homogeneous modalities or aligned representational spaces, ignoring real-world perceptual heterogeneity, so this paper aims to study how agents develop shared representations in a heterogeneous multi-step binary communication game with perceptual misalignment.

Method: The study uses a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding, analyzing multimodal and unimodal systems through convergence, bit perturbation experiments, and interoperability analyses with fine-tuning.

Result: Multimodal systems converge to class-consistent messages grounded in perceptual input; unimodal systems communicate more efficiently with fewer bits and lower entropy; meaning is encoded distributionally, as each bit's role depends on context; cross-system communication fails directly but succeeds with limited fine-tuning.

Conclusion: This work positions emergent communication as a framework for studying representation adaptation and transfer across heterogeneous modalities, offering new directions for theory and experimentation in how agents adapt to perceptual diversity.

Abstract: Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignment, multimodal systems converge to class-consistent messages grounded in perceptual input. Unimodal systems communicate more efficiently, using fewer bits and achieving lower classification entropy, while multimodal agents require greater information exchange and exhibit higher uncertainty. Bit perturbation experiments provide strong evidence that meaning is encoded in a distributional rather than compositional manner, as each bit's contribution depends on its surrounding pattern. Finally, interoperability analyses show that systems trained in different perceptual worlds fail to directly communicate, but limited fine-tuning enables successful cross-system communication. This work positions emergent communication as a framework for studying how agents adapt and transfer representations across heterogeneous modalities, opening new directions for both theory and experimentation.

</details>
