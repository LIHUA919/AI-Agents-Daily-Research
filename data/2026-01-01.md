<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]
- [cs.LG](#cs.LG) [Total: 14]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP (Science Context Protocol) is an open-source standard for autonomous scientific agents, enabling global resource integration and orchestrated experiment lifecycle management to accelerate discovery.


<details>
  <summary>Details</summary>
Motivation: To address the need for seamless collaboration between AI systems and human researchers across platforms and institutions, reducing integration overhead and enhancing reproducibility in scientific workflows.

Method: Built on two pillars: (1) Unified Resource Integration—a universal specification for describing/invoking scientific resources (tools, models, datasets, instruments); (2) Orchestrated Experiment Lifecycle Management—a secure service architecture with SCP Hub and Servers to manage registration, planning, execution, monitoring, and archival, with authentication and workflow orchestration.

Result: A scientific discovery platform based on SCP offers over 1,600 tool resources, facilitating secure, large-scale collaboration across use cases, significantly reducing integration overhead and enhancing reproducibility.

Conclusion: By standardizing scientific context and tool orchestration at the protocol level, SCP provides essential infrastructure for scalable, multi-institution, agent-driven science, accelerating discovery through a global network of autonomous agents.

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [2] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: Introduces DDFT to measure epistemic robustness in LLMs, showing robustness is independent of model size/architecture and highlighting error detection as the critical bottleneck.


<details>
  <summary>Details</summary>
Motivation: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses.

Method: Introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness by evaluating models under progressive semantic compression and adversarial fabrication. Propose a two-system cognitive model comprising a Semantic System and an Epistemic Verifier. Evaluate 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations).

Result: Epistemic robustness is orthogonal to conventional design paradigms: neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007). Flagship models exhibit brittleness despite scale, while smaller models can achieve robust performance.

Conclusion: The study introduces DDFT as a protocol to measure epistemic robustness, revealing that robustness is orthogonal to conventional design paradigms and challenging assumptions about the relationship between model size and reliability. It provides theoretical foundation and practical tools for assessing epistemic robustness before deployment.

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [3] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE is a self-evolving LLM agent framework that enables AI agents to learn external tools and codify knowledge via continuous learning and self-reflection, achieving high success rates in scientific tasks.


<details>
  <summary>Details</summary>
Motivation: Current LLM agents rely on predefined tools or fragile tool generation, limiting their capability and adaptability to complex scientific research tasks.

Method: The framework uses two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration. It is evaluated on SciSkillBench, a benchmark of 116 materials science and chemistry tasks.

Result: CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms, and demonstrates real-world applications in computational analysis, autonomous lab experiments, and paper reproduction.

Conclusion: CASCADE accumulates executable skills that can be shared across agents and scientists, advancing scalable AI-assisted scientific research and marking a transition from tool use to skill acquisition.

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [4] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy combines LLMs and ASP to automate disease diagnosis from medical literature and patient data.


<details>
  <summary>Details</summary>
Motivation: Symbolic AI's adoption in healthcare is limited due to the manual effort of constructing knowledge bases. This paper aims to overcome this by integrating LLMs and ASP for automated prediction.

Method: The McCoy framework uses an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to generate diagnoses.

Result: Preliminary results show strong performance on small-scale disease diagnosis tasks.

Conclusion: McCoy provides a robust, interpretable framework that leverages both LLMs and ASP, enabling more efficient disease prediction and reducing barriers in healthcare adoption.

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [5] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK is a multi-agent LLM framework for personalized search using specialized persona agents with memory, coordination, and collaboration mechanisms.


<details>
  <summary>Details</summary>
Motivation: Traditional search systems use static profiles or monolithic pipelines that cannot model users' evolving, multi-dimensional information needs.

Method: Defines persona space (role, expertise, task context, domain), uses Persona Coordinator to activate relevant agents, each agent runs retrieval-augmented generation with long/short-term memory, and facilitates inter-agent collaboration through communication protocols.

Result: Framework yields testable predictions about coordination efficiency, personalization quality, and cognitive load distribution, with adaptive learning for persona refinement.

Conclusion: SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [6] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD is a novel framework for automatic prompt optimization in LLMs that bypasses the need for curated datasets by using a multi-agent debugging approach, achieving significant performance gains with high sample efficiency.


<details>
  <summary>Details</summary>
Motivation: In real-world software engineering, curated datasets for prompt optimization are often unavailable during cold starts, with engineers facing messy production logs instead. Current APO methods rely on labeled gold-standard sets, limiting applicability.

Method: ROAD uses a multi-agent architecture (Analyzer, Optimizer, Coach) to treat optimization as dynamic debugging, converting unstructured failure logs into structured Decision Tree Protocols, replacing stochastic search or evolutionary methods.

Result: ROAD improved success rates by 5.6% (73.6% to 79.2%) and search accuracy by 3.8% in three automated iterations on a benchmark, and boosted agent performance by ~19% on complex reasoning tasks in retail, showing high sample efficiency.

Conclusion: Mimicking human failure analysis loops offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents, as demonstrated by ROAD's effectiveness in integrating debugging with automated optimization.

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [7] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow is a self-evolving agent framework using a cognitive 'Plan-Execute-Summarize' paradigm and hybrid evolutionary memory to enhance reasoning and efficiency in high-dimensional code spaces, outperforming baselines by up to 60%.


<details>
  <summary>Details</summary>
Motivation: Traditional evolutionary methods for transitioning static LLMs to self-improving agents lack structured reasoning, leading to premature convergence and inefficient exploration in high-dimensional code spaces.

Method: LoongFlow integrates LLMs into a 'Plan-Execute-Summarize' paradigm and employs a hybrid evolutionary memory system with Multi-Island models, MAP-Elites, and adaptive Boltzmann selection to balance exploration-exploitation and maintain architectural coherence.

Result: Evaluations on AlphaEvolve benchmark and Kaggle competitions show LoongFlow outperforms leading baselines like OpenEvolve and ShinkaEvolve by up to 60% in evolutionary efficiency while discovering superior solutions.

Conclusion: LoongFlow advances autonomous scientific discovery by enabling expert-level solutions with reduced computational overhead, marking a significant step forward in self-evolving agent frameworks.

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [8] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: The paper proposes CogRec, a cognitive recommender agent that combines the strengths of LLMs for knowledge initialization and the Soar cognitive architecture for symbolic reasoning and online learning to improve recommendation accuracy and explainability.


<details>
  <summary>Details</summary>
Motivation: LLMs are effective in understanding user preferences but face issues like lack of interpretability ('Black-Box' nature), susceptibility to hallucinations and limited online learning, while traditional cognitive architectures like Soar offer structured and interpretable reasoning but require manual knowledge acquisition.

Method: To address these complementary challenges, the author proposes CogRec, which uses Soar as a symbolic reasoning engine and an LLM for initializing knowledge by populating its working memory with production rules. The agent operates on a Perception-Cognition-Action cycle and dynamically queries the LLM when an impasse is encountered, generating a solution that is transformed into a new symbolic production rule via Soar's chunking mechanism to enable robust online learning.

Result: CogRec demonstrates significant advantages in recommendation accuracy, explainability and addressing the long-tail problem in evaluations on three public datasets.

Conclusion: The agent continuously evolves its knowledge base and provides highly interpretable rationales for recommendations, offering a solution that bridges the interpretability and online learning gaps of LLMs with scalable knowledge acquisition.

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [9] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: A training-free graph-based approach for interactive reasoning in ARC-AGI-3 uses graph-structured exploration to solve tasks where state-of-the-art LLMs fail.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with ARC-AGI-3 tasks requiring inference of mechanics through interactions, so a method leveraging systematic exploration is needed.

Method: Combines vision-based frame processing with graph-structured state-space exploration, segmenting components and prioritizing actions via shortest paths to untested pairs.

Result: Solves median 30/52 levels, ranks 3rd on leaderboard, outperforming LLM-based agents.

Conclusion: Explicit graph-structured exploration serves as a strong baseline, highlighting systematic tracking in environments where LLMs fail.

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [10] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: TL;DR: A deep reinforcement learning method (FRIPN) efficiently solves the Fleet Size and Mix Vehicle Routing Problem by integrating fleet composition and routing decisions, achieving near-optimal solutions fast, with strengths in computational efficiency and scalability.


<details>
  <summary>Details</summary>
Motivation: FSMVRP is complex due to simultaneous fleet composition and routing decisions, especially in large-scale and time-constrained real-world scenarios, requiring efficient solutions.

Method: Formulate FSMVRP as a Markov Decision Process (MDP) and develop FRIPN, a policy network with specialized input embeddings like remaining graph embedding, to integrate fleet composition and routing decisions.

Result: Experiments on random instances and benchmark datasets show the method generates near-optimal solutions within seconds, excelling in computational efficiency and scalability in large-scale, time-constrained scenarios.

Conclusion: The approach demonstrates strong potential for practical applications in FSMVRP and provides inspiration for extending deep reinforcement learning to other VRP variants.

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [11] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: Proposes RSA, a risk-aware alignment method using nested risk measures for token-level policy optimization, achieving better safety and reduced catastrophic risks than risk-neutral approaches.


<details>
  <summary>Details</summary>
Motivation: Existing safety alignment methods like Safe RLHF and SACPO operate under risk-neutral paradigms that inadequately address risks from policy deviations and catastrophic harmful behaviors, lacking robustness.

Method: RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem using nested risk measures, solved through stepwise alignment with token-level policy updates.

Result: RSA achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks (low-probability yet high-impact unsafe responses).

Conclusion: The proposed Risk-aware Stepwise Alignment (RSA) method effectively balances helpfulness and safety in language model alignment, demonstrating strong performance in reducing tail risks and catastrophic behaviors.

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [12] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: An adaptive LLM agent refines beliefs via posterior-guided inference at test time, using an external structured belief model and maximizing information gain for action selection, outperforming baselines in alignment with world states with low overhead.


<details>
  <summary>Details</summary>
Motivation: LLM agents often struggle with partial observability, requiring costly gradient updates or additional training for effective inference, which limits real-time adaptability and efficiency.

Method: Maintain an external structured belief over environment state, update iteratively via action-conditioned observations, select actions by maximizing predicted information gain estimated with a lightweight LLM-based surrogate, and assess alignment via a reward quantifying consistency between posterior belief and ground truth.

Result: The method outperforms inference-time scaling baselines like prompt-augmented or retrieval-enhanced LLMs in aligning with latent world states, with significantly lower integration overhead.

Conclusion: Posterior-guided belief refinement enables effective test-time adaptation for LLM agents under partial observability, enhancing alignment without gradient-based updates or extra training, demonstrating feasibility for low-overhead applications.

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [13] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: This paper investigates JEPA-WMs as a class of world models for AI agents, aiming to optimize planning in learned representation spaces, and proposes an improved model that outperforms baselines in navigation and manipulation tasks.


<details>
  <summary>Details</summary>
Motivation: There is a need for AI agents capable of generalizing across diverse physical tasks, with current methods using world models for planning; JEPA-WMs offer potential for efficient planning by abstracting irrelevant details, but their optimal technical components require comprehensive study.

Method: The authors propose a systematic study of key components in JEPA-WMs, including model architecture, training objective, and planning algorithm, using experiments in simulated environments and real-world robotic data to evaluate planning success.

Result: The study identifies optimal approaches within the JEPA-WM family, leading to a proposed model that outperforms baselines DINO-WM and V-JEPA-2-AC in both navigation and manipulation tasks.

Conclusion: Optimizing JEPA-WMs through careful component selection enhances planning efficiency and generalizability, providing a robust foundation for developing advanced AI agents for physical tasks, with open-sourced resources for further research.

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [14] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: This paper proposes an interactive evaluation framework for analyzing how foundation model (FM) agents understand and act in symbolic map environments, focusing on exploration, memory, and reasoning to assess spatial tasks.


<details>
  <summary>Details</summary>
Motivation: Most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding, which is critical for reliable map-based reasoning and applications.

Method: An interactive evaluation framework is introduced where agents incrementally explore partially observable grid-based maps (with roads, intersections, and POIs), using only local observations per step. Spatial understanding is evaluated through six spatial tasks, systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models.

Result: Exploration primarily affects experience acquisition with limited impact on reasoning accuracy; memory representation, especially structured (sequential and graph-based), significantly improves performance on structure-intensive tasks like path planning; reasoning schemes shape knowledge use, with advanced prompts aiding multi-step inference; spatial reasoning performance saturates beyond a capability threshold.

Conclusion: Improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning, not just scaling, as performance saturates across model versions and scales.

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [15] [Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems](https://arxiv.org/abs/2512.23809)
*Samaresh Kumar Singh,Joyjit Roy,Martin So*

Main category: cs.LG

TL;DR: A Zero-Trust Agentic Federated Learning framework enhances IIoT security with cryptographic attestation, explainable Byzantine detection, and privacy-preserving adversarial training, achieving high accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: Address urgent security gaps in IIoT deployments exposed by recent attacks on critical infrastructure, overcoming vulnerabilities in existing Federated Learning frameworks to Byzantine poisoning attacks and lack of robust agent authentication.

Method: The paper introduces a defense in depth framework with three key components: TPM-based cryptographic attestation, a SHAP-weighted aggregation algorithm for explainable Byzantine detection under non-IID conditions, and privacy-preserving on-device adversarial training.

Result: Comprehensive experiments show ZTA-FL achieves 97.8% detection accuracy, 93.2% accuracy under 30% Byzantine attacks (outperforming FLAME by 3.1%, p < 0.01), 89.3% adversarial robustness, and reduces communication overhead by 34%.

Conclusion: Zero-Trust Agentic Federated Learning (ZTA-FL) effectively addresses security challenges in IIoT environments by combining provable cryptographic trust, explainable Byzantine detection, and on-device adversarial training.

Abstract: Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.

</details>


### [16] [Network Traffic Analysis with Process Mining: The UPSIDE Case Study](https://arxiv.org/abs/2512.23718)
*Francesco Vitale,Paolo Palmiero,Massimiliano Rak,Nicola Mazzocca*

Main category: cs.LG

TL;DR: A process mining method analyzes gaming network traffic to model states as interpretable Petri nets for classification of video games, showing high coherence and specificity in results.


<details>
  <summary>Details</summary>
Motivation: Online gaming generates significant market revenue and requires modeling network device behavior for bandwidth evaluation, load prediction, and malicious activity detection, where process mining offers data-driven and model-based insights.

Method: Proposes a process mining-based method that analyzes gaming network traffic to characterize states unsupervised, encode them into interpretable Petri nets, and classify traffic to identify different video games.

Result: Applied to the UPSIDE case study with data from Clash Royale and Rocket League, the method effectively models network behavior with 94.02% inter-device similarity and 174.99% inter-state separation, achieving 73.84% AUC classification accuracy.

Conclusion: The approach demonstrates that process mining can effectively and interpretably model gaming network traffic through Petri nets, enabling accurate video game classification with promising coherence and specificity metrics.

Abstract: Online gaming is a popular activity involving the adoption of complex systems and network infrastructures. The relevance of gaming, which generates large amounts of market revenue, drove research in modeling network devices' behavior to evaluate bandwidth consumption, predict and sustain high loads, and detect malicious activity. In this context, process mining appears promising due to its ability to combine data-driven analyses with model-based insights. In this paper, we propose a process mining-based method that analyzes gaming network traffic, allowing: unsupervised characterization of different states from gaming network data; encoding such states through process mining into interpretable Petri nets; and classification of gaming network traffic data to identify different video games being played. We apply the method to the UPSIDE case study, involving gaming network data of several devices interacting with two video games: Clash Royale and Rocket League. Results demonstrate that the gaming network behavior can be effectively and interpretably modeled through states represented as Petri nets with sufficient coherence (94.02% inter-device similarity) and specificity (174.99% inter-state separation) while maintaining a good classification accuracy of the two different video games (73.84% AUC).

</details>


### [17] [A Comprehensive Study of Deep Learning Model Fixing Approaches](https://arxiv.org/abs/2512.23745)
*Hanmo You,Zan Wang,Zishuo Dong,Luanqi Mo,Jianjun Zhao,Junjie Chen*

Main category: cs.LG

TL;DR: This paper evaluates 16 DL model fixing approaches across effectiveness, robustness, fairness, and compatibility, finding model-level methods best for fixing but with side effects, suggesting future research focus.


<details>
  <summary>Details</summary>
Motivation: DL systems are prone to faults like traditional software, posing risks; to address this, many fixing approaches exist, but a comprehensive evaluation of their performance and side effects was lacking.

Method: A large-scale empirical study of 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, using diverse datasets, model architectures, and domains in a uniform experimental setup.

Result: Model-level approaches show superior fixing effectiveness; no single approach best fixes performance while also improving accuracy and maintaining all other properties like robustness and fairness.

Conclusion: Industry and academia should note key findings: model-level methods are most effective for fixing, but side effects exist, necessitating future research to mitigate impacts on properties like fairness and robustness.

Abstract: Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.

</details>


### [18] [A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios](https://arxiv.org/abs/2512.23748)
*Haley Rosso,Talea Mayo*

Main category: cs.LG

TL;DR: This review article surveys diffusion models as a simulation-based inference (SBI) method for likelihood-free posterior estimation, covering mathematical foundations, advantages over normalizing flows, robustness in non-ideal scientific conditions, and open challenges.


<details>
  <summary>Details</summary>
Motivation: Classical likelihood-based inference is often infeasible for complex simulation problems due to intractable likelihoods. Diffusion models offer a flexible, generative approach to SBI that can handle challenging scientific data scenarios.

Method: The review explains diffusion modeling principles (forward noising, reverse SDE/ODE, score matching) and how conditional scores enable posterior sampling. It compares diffusion models to normalizing flows in SBI, discusses robustness to data issues like misspecification and missingness, and synthesizes methods like sequential samplers and amortized architectures.

Result: Diffusion-based SBI provides a robust framework for posterior inference under non-ideal conditions, addressing limitations of other methods but introducing trade-offs such as iterative sampling costs.

Conclusion: The article concludes with open problems in diffusion-based SBI, highlighting potential applications in uncertainty quantification for geophysical models and future research directions.

Abstract: For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters $\mathbfθ$ given observed data $\mathbf{x}_{\text{o}}$. Recent work has brought attention to diffusion models -- a type of generative model rooted in score matching and reverse-time stochastic dynamics -- as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.

</details>


### [19] [Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents](https://arxiv.org/abs/2512.23749)
*Amin Sadri,M Maruf Hossain*

Main category: cs.LG

TL;DR: CM² is a Green AI model achieving human-level one-shot learning for document classification by focusing on structural features, offering advantages over data-intensive and compute-heavy methods.


<details>
  <summary>Details</summary>
Motivation: Humans learn concepts from single examples, while traditional machine learning requires many samples; CM² aims to mimic human learning efficiency by identifying key structural features for classification.

Method: Introduces the Coordinate Matrix Machine (CM²), a small model that learns document structures to classify documents, designed as a Green AI solution avoiding massive pre-training and GPU reliance.

Result: CM² outperforms traditional vectorizers and deep learning models, achieving high accuracy with minimal data (one sample per class) and offering benefits like explainability, speed, and CPU optimization.

Conclusion: CM² demonstrates that human-level concept learning can be achieved in AI through structural intelligence, providing a sustainable, efficient, and effective alternative to resource-intensive models.

Abstract: Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \vspace*{6pt}
  Contribution: In this paper, we present the Coordinate Matrix Machine (CM$^2$). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern "Red AI" trends rely on massive pre-training and energy-intensive GPU infrastructure, CM$^2$ is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural "important features" a human would consider, allowing it to classify very similar documents using only one sample per class.
  Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM$^2$ offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable

</details>


### [20] [Geometric Scaling of Bayesian Inference in LLMs](https://arxiv.org/abs/2512.23752)
*Naman Aggarwal,Siddhartha R. Dalal,Vishal Misra*

Main category: cs.LG

TL;DR: This paper investigates whether the geometric signatures enabling Bayesian inference in small transformers persist in production-grade language models, finding they do and organize updates along this substrate.


<details>
  <summary>Details</summary>
Motivation: To determine if geometric substrates (value manifolds, orthogonal keys) observed in synthetic transformer settings for Bayesian inference extend to real large language models.

Method: Analyze value representations in models like Pythia, Phi-2, Llama-3, and Mistral; perform targeted interventions on entropy-aligned axes during in-context learning to probe geometry.

Result: Last-layer values organize along an entropy-correlated axis, with prompts collapsing into low-dimensional manifolds; interventions disrupt uncertainty geometry but not proportionally degrade Bayesian-like behavior.

Conclusion: Modern language models preserve the geometric substrate for Bayesian inference, using it as a privileged readout of uncertainty rather than a singular bottleneck.

Abstract: Recent work has shown that small transformers trained in controlled "wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.
  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.

</details>


### [21] [Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation](https://arxiv.org/abs/2512.23753)
*Deep Shankar Pandey,Hyomin Choi,Qi Yu*

Main category: cs.LG

TL;DR: EDL models use Subjective Logic for uncertainty awareness but face learning-freeze issues due to activation constraints, addressed by novel activations and regularizers validated on diverse benchmarks.


<details>
  <summary>Details</summary>
Motivation: EDL models efficiently quantify uncertainty but are constrained by non-negative evidence, leading to activation-dependent learning-freeze behavior where gradients diminish in low-evidence regions.

Method: Theoretically characterize learning-freeze behavior, analyze evidential activations' influence on dynamics, and design a family of activation functions with corresponding regularizers for consistent evidence updates.

Result: Extensive experiments on benchmark classification (MNIST, CIFAR-10, CIFAR-100, Tiny-ImageNet), few-shot classification, and face restoration validate theory and show effectiveness of generalized regularized models.

Conclusion: Proposed generalized activation functions and regularizers mitigate learning-freeze issues, improving EDL model performance and consistency across applications, enhancing uncertainty quantification.

Abstract: Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models.

</details>


### [22] [HINTS: Extraction of Human Insights from Time-Series Without External Sources](https://arxiv.org/abs/2512.23755)
*Sheo Yon Jhin,Noseong Park*

Main category: cs.LG

TL;DR: HINTS is a self-supervised framework that extracts human factors from time series residuals using opinion dynamics, boosting forecast accuracy without external data.


<details>
  <summary>Details</summary>
Motivation: Human decision-making and collective psychology significantly influence financial time series. Existing models rely on external data (e.g., news, social media) which incurs high data dependency costs. The goal is to extract human factors endogenously.

Method: The HINTS framework uses self-supervised learning to extract latent human factors from time series residuals, leveraging the Friedkin-Johnsen opinion dynamics model as an inductive bias. These factors are integrated as an attention map into a state-of-the-art backbone model.

Result: HINTS consistently improves forecasting accuracy across nine real-world and benchmark datasets. Case studies and ablation studies confirm its interpretability, showing alignment between extracted factors and real-world events.

Conclusion: HINTS provides a cost-effective and interpretable approach to incorporate human factors in time series forecasting without external data, enhancing accuracy and practical utility.

Abstract: Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.

</details>


### [23] [Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data](https://arxiv.org/abs/2512.23761)
*Esha Saha,Hao Wang*

Main category: cs.LG

TL;DR: MUSIC integrates partial physics with data-driven learning for coupled systems with incomplete knowledge, using sparsity and multitasking to improve efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: There is a mismatch between known physics and observed data in complex coupled systems, where governing equations are available for only one variable while others are only accessible through data.

Method: MUSIC employs a sparsity-induced multitask neural network framework with mesh-free (random) sampling and sparsity regularization.

Result: MUSIC accurately learns solutions to complex coupled systems (shock wave, discontinuous, pattern formation solutions) under data-scarce and noisy conditions, outperforming non-sparse formulations.

Conclusion: MUSIC presents a novel and effective approach for modeling complex coupled systems with partial physical knowledge and sparse data.

Abstract: Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable can be accessed only through data. This mismatch between known physics and observed data poses a fundamental challenge for existing physics-informed machine learning approaches, which generally assume either complete knowledge of the governing equations or full data availability across all variables. In this paper, we introduce MUSIC (Multitask Learning Under Sparse and Incomplete Constraints), a sparsity induced multitask neural network framework that integrates partial physical constraints with data-driven learning to recover full-dimensional solutions of coupled systems when physics-constrained and data-informed variables are mutually exclusive. MUSIC employs mesh-free (random) sampling of training data and sparsity regularization, yielding highly compressed models with improved training and evaluation efficiency. We demonstrate that MUSIC accurately learns solutions (shock wave solutions, discontinuous solutions, pattern formation solutions) to complex coupled systems under data-scarce and noisy conditions, consistently outperforming non-sparse formulations. These results highlight MUSIC as a flexible and effective approach for modeling partially observed systems with incomplete physical knowledge.

</details>


### [24] [Drift-Based Dataset Stability Benchmark](https://arxiv.org/abs/2512.23762)
*Dominik Soukup,Richard Plný,Daniel Vašata,Tomáš Čejka*

Main category: cs.LG

TL;DR: A novel framework to evaluate dataset stability and benchmark datasets in network traffic classification, using concept drift detection enhanced by ML feature weights.


<details>
  <summary>Details</summary>
Motivation: Network traffic classification models often degrade soon after deployment due to outdated datasets and concept drift, leading to large performance drops. Typically, the solution is complete retraining without investigating root causes, assuming good dataset quality, which is not always true.

Method: The framework combines concept drift detection with machine learning feature weights to boost detection performance, then analyzes the CESNET-TLS-Year22 dataset using the proposed stability evaluation and benchmarking workflow.

Result: The approach is demonstrated on the CESNET-TLS-Year22 dataset, providing an initial dataset stability benchmark, revealing dataset weak points, and showing optimization impact on dataset variants via the proposed benchmarking methodology.

Conclusion: The work successfully introduces a way to benchmark dataset stability and identify areas needing optimization, offering significant benefits for making network traffic classification models more robust against drift.

Abstract: Machine learning (ML) represents an efficient and popular approach for network traffic classification. However, network traffic classification is a challenging domain, and trained models may degrade soon after deployment due to the obsolete datasets and quick evolution of computer networks as new or updated protocols appear. Moreover, significant change in the behavior of a traffic type (and, therefore, the underlying features representing the traffic) can produce a large and sudden performance drop of the deployed model, known as a data or concept drift. In most cases, complete retraining is performed, often without further investigation of root causes, as good dataset quality is assumed. However, this is not always the case and further investigation must be performed. This paper proposes a novel methodology to evaluate the stability of datasets and a benchmark workflow that can be used to compare datasets.
  The proposed framework is based on a concept drift detection method that also uses ML feature weights to boost the detection performance. The benefits of this work are demonstrated on CESNET-TLS-Year22 dataset. We provide the initial dataset stability benchmark that is used to describe dataset stability and weak points to identify the next steps for optimization. Lastly, using the proposed benchmarking methodology, we show the optimization impact on the created dataset variants.

</details>


### [25] [Neural Optimal Design of Experiment for Inverse Problems](https://arxiv.org/abs/2512.23763)
*John E. Darges,Babak Maboudi Afkham,Matthias Chung*

Main category: cs.LG

TL;DR: Neural Optimal Design of Experiments (NODE) trains a neural reconstruction model with continuous design variables to optimize sensor locations directly, outperforming baselines in inverse problems.


<details>
  <summary>Details</summary>
Motivation: Classical optimal experimental design uses bilevel optimization and indirect sparsity regularization, which is computationally complex and requires tuning. NODE aims to avoid these issues by enabling sparsity by design in a single optimization loop.

Method: Jointly train a neural reconstruction model and fixed-budget continuous design variables (e.g., sensor locations, sampling times) in one optimization loop, directly optimizing measurements rather than weighting dense candidate grids.

Result: Validated on an exponential growth benchmark, MNIST image sampling, and a sparse-view X-ray CT example, NODE outperforms baselines with improved reconstruction accuracy and task-specific performance.

Conclusion: NODE provides a learning-based method for optimal experimental design that enforces sparsity directly, reduces computational complexity, eliminates l1 tuning, and demonstrates effectiveness across various applications.

Abstract: We introduce Neural Optimal Design of Experiments, a learning-based framework for optimal experimental design in inverse problems that avoids classical bilevel optimization and indirect sparsity regularization. NODE jointly trains a neural reconstruction model and a fixed-budget set of continuous design variables representing sensor locations, sampling times, or measurement angles, within a single optimization loop. By optimizing measurement locations directly rather than weighting a dense grid of candidates, the proposed approach enforces sparsity by design, eliminates the need for l1 tuning, and substantially reduces computational complexity. We validate NODE on an analytically tractable exponential growth benchmark, on MNIST image sampling, and illustrate its effectiveness on a real world sparse view X ray CT example. In all cases, NODE outperforms baseline approaches, demonstrating improved reconstruction accuracy and task-specific performance.

</details>


### [26] [Exploring Cumulative Effects in Survival Data Using Deep Learning Networks](https://arxiv.org/abs/2512.23764)
*Kang-Chung Yang,Shinsheng Yuan*

Main category: cs.LG

TL;DR: CENNSurv is a deep learning method for survival analysis that models cumulative effects of time-dependent exposures with both accuracy and interpretability, addressing scalability issues of conventional methods.


<details>
  <summary>Details</summary>
Motivation: To address challenges in modeling cumulative effects of time-dependent exposures on survival outcomes, where conventional spline-based methods require data transformation and are less scalable, and existing neural network methods often lack interpretability.

Method: CENNSurv, a neural network-based approach, is designed to capture dynamic risk relationships from time-dependent data without requiring repeated data transformation for spline parameter tuning.

Result: Evaluations on real-world datasets show CENNSurv successfully captures multi-year lagged associations between chronic environmental exposure and survival outcomes, and identifies short-term behavioral shifts prior to subscription lapse.

Conclusion: CENNSurv is introduced as a practical tool for researchers studying cumulative effects of time-dependent exposures, providing interpretable insights into complex temporal patterns.

Abstract: In epidemiological research, modeling the cumulative effects of time-dependent exposures on survival outcomes presents a challenge due to their intricate temporal dynamics. Conventional spline-based statistical methods, though effective, require repeated data transformation for each spline parameter tuning, with survival analysis computations relying on the entire dataset, posing difficulties for large datasets. Meanwhile, existing neural network-based survival analysis methods focus on accuracy but often overlook the interpretability of cumulative exposure patterns. To bridge this gap, we introduce CENNSurv, a novel deep learning approach that captures dynamic risk relationships from time-dependent data. Evaluated on two diverse real-world datasets, CENNSurv revealed a multi-year lagged association between chronic environmental exposure and a critical survival outcome, as well as a critical short-term behavioral shift prior to subscription lapse. This demonstrates CENNSurv's ability to model complex temporal patterns with improved scalability. CENNSurv provides researchers studying cumulative effects a practical tool with interpretable insights.

</details>


### [27] [A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit](https://arxiv.org/abs/2512.23766)
*Karim Salta,Michael Kirby,Chris Peterson*

Main category: cs.LG

TL;DR: A subspace clustering algorithm using trainable Schubert Variety of Best Fit prototypes, integrated into Linde-Buzo-Grey pipeline, improves cluster purity on various datasets.


<details>
  <summary>Details</summary>
Motivation: In classification and clustering, geometric representatives like means or medians on Grassmann or flag manifolds are useful but can be limited; we propose a more effective prototype for subspace clustering to enhance performance.

Method: We introduce a subspace clustering algorithm that uses a trainable prototype called a Schubert Variety of Best Fit (SVBF), defined as a subspace intersecting cluster members in at least one fixed direction, and integrate it into the Linde-Buzo-Grey (LBG) pipeline.

Result: The SVBF-LBG scheme demonstrates improved cluster purity on synthetic, image, spectral, and video action data compared to traditional methods.

Conclusion: Integrating SVBF prototypes into clustering pipelines enhances cluster purity while preserving mathematical structure for downstream analysis, offering a robust alternative to subspace means.

Abstract: In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.

</details>


### [28] [Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics](https://arxiv.org/abs/2512.23767)
*Bin Xu,Ayan Banerjee,Sandeep Gupta*

Main category: cs.LG

TL;DR: MERINDA is an FPGA-accelerated framework for efficient model recovery on edge devices, outperforming GPU methods in energy, memory, and speed while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art model recovery methods like EMILY and PINN+SR use Neural ODEs with iterative solvers, making them inefficient for edge hardware with latency, compute, and power constraints.

Method: MERINDA replaces Neural ODEs with a hardware-friendly formulation combining GRU-based discretized dynamics, dense inverse-ODE layers, sparsity-driven dropout, and lightweight ODE solvers for streaming parallelism on FPGAs.

Result: On four benchmark nonlinear dynamical systems, MERINDA achieves 114× lower energy, 28× smaller memory footprint, and 1.68× faster training than GPU implementations while matching accuracy.

Conclusion: MERINDA enables accurate, explainable model recovery for real-time monitoring of autonomous systems at the edge, making physical AI practical on resource-constrained devices.

Abstract: Physical AI at the edge -- enabling autonomous systems to understand and predict real-world dynamics in real time -- requires hardware-efficient learning and inference. Model recovery (MR), which identifies governing equations from sensor data, is a key primitive for safe and explainable monitoring in mission-critical autonomous systems operating under strict latency, compute, and power constraints. However, state-of-the-art MR methods (e.g., EMILY and PINN+SR) rely on Neural ODE formulations that require iterative solvers and are difficult to accelerate efficiently on edge hardware. We present \textbf{MERINDA} (Model Recovery in Reconfigurable Dynamic Architecture), an FPGA-accelerated MR framework designed to make physical AI practical on resource-constrained devices. MERINDA replaces expensive Neural ODE components with a hardware-friendly formulation that combines (i) GRU-based discretized dynamics, (ii) dense inverse-ODE layers, (iii) sparsity-driven dropout, and (iv) lightweight ODE solvers. The resulting computation is structured for streaming parallelism, enabling critical kernels to be fully parallelized on the FPGA. Across four benchmark nonlinear dynamical systems, MERINDA delivers substantial gains over GPU implementations: \textbf{114$\times$ lower energy} (434~J vs.\ 49{,}375~J), \textbf{28$\times$ smaller memory footprint} (214~MB vs.\ 6{,}118~MB), and \textbf{1.68$\times$ faster training}, while matching state-of-the-art model-recovery accuracy. These results demonstrate that MERINDA can bring accurate, explainable MR to the edge for real-time monitoring of autonomous systems.

</details>
