{"id": "2601.16237", "categories": ["cs.MA", "cs.AI", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.16237", "abs": "https://arxiv.org/abs/2601.16237", "authors": ["Vik Pant", "Eric Yu"], "title": "Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty", "comment": "68 pages, 22 figures. Third technical report in research program; should be read with companion arXiv:2510.18802 and arXiv:2510.24909. Adapts and extends complex actor material from Pant (2021) doctoral dissertation, University of Toronto", "summary": "Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmstr\u00f6m established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p<0.001, Cohen's d=0.71.", "AI": {"tldr": "A computational framework for analyzing collective action problems in mixed-motive multi-agent systems using loyalty-moderated utility functions to overcome free-riding.", "motivation": "Mixed-motive settings suffer from persistent free-riding where individual effort benefits all but costs are borne individually, leading to universal shirking in Nash equilibrium. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings.", "method": "Develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). Integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams and multi-agent systems.", "result": "Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using Apache HTTP Server case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases with statistical significance (p<0.001, Cohen's d=0.71).", "conclusion": "The framework successfully extends computational foundations for strategic coopetition to team-level dynamics, providing scalable mechanisms to analyze how collective action problems emerge and resolve in mixed-motive settings through loyalty-moderation, validated both experimentally and empirically."}}
{"id": "2601.16292", "categories": ["cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16292", "abs": "https://arxiv.org/abs/2601.16292", "authors": ["Anh-Duy Pham"], "title": "AMBER: A Columnar Architecture for High-Performance Agent-Based Modeling in Python", "comment": null, "summary": "Agent-based modeling (ABM) has emerged as an indispensable methodology for studying complex adaptive systems across the natural and social sciences. However, Python-based ABM frameworks face a fundamental tension between the accessibility that has made Python dominant in scientific computing and the performance requirements of large-scale simulations. This paper introduces AMBER, a framework that resolves this tension through a novel architectural approach: replacing the conventional object-per-agent representation with columnar state management using the Polars DataFrame library. We analyze the computational characteristics of both paradigms, present the architectural design of AMBER including its core abstractions, spatial environments, experiment management, and optimization capabilities. Empirical evaluation on three canonical benchmarks demonstrates that AMBER achieves speedups of 1.2x to 93x depending on workload characteristics, with the greatest advantages for models dominated by population-wide attribute operations. Memory profiling reveals 30-50% reduction in peak usage compared to object-oriented frameworks. Our results establish columnar state management as a viable architectural foundation for high-performance ABM in interpreted languages.", "AI": {"tldr": "AMBER is a Python-based agent-based modeling framework that uses columnar state management with Polars DataFrames instead of object-per-agent representation, achieving significant performance improvements for large-scale simulations.", "motivation": "There's a fundamental tension in Python-based ABM frameworks between accessibility (Python's strength) and performance requirements for large-scale simulations. Conventional object-per-agent representations struggle with performance as model complexity grows.", "method": "AMBER introduces a novel architectural approach replacing object-per-agent representation with columnar state management using Polars DataFrame library. This includes core abstractions, spatial environments, experiment management, and optimization capabilities.", "result": "Empirical evaluation on three canonical benchmarks shows speedups of 1.2x to 93x depending on workload characteristics, with greatest advantages for models dominated by population-wide attribute operations. Memory profiling reveals 30-50% reduction in peak usage compared to object-oriented frameworks.", "conclusion": "Columnar state management is established as a viable architectural foundation for high-performance agent-based modeling in interpreted languages like Python, resolving the accessibility-performance tension through efficient data representation."}}
{"id": "2601.16286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.16286", "abs": "https://arxiv.org/abs/2601.16286", "authors": ["Varun Chillara", "Dylan Kline", "Christopher Alvares", "Evan Wooten", "Huan Yang", "Shlok Khetan", "Cade Bauer", "Tr\u00e9 Guillory", "Tanishka Shah", "Yashodhara Dhariwal", "Volodymyr Pavlov", "George Popstefanov"], "title": "SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems", "comment": null, "summary": "Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.\n  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.\n  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.", "AI": {"tldr": "SemanticALLI introduces a pipeline-aware caching architecture in the Alli platform to detect and reuse structured intermediate representations, boosting cache hit rates and reducing redundant LLM calls and token usage.", "motivation": "Agentic AI pipelines inefficiently rebuild identical intermediate logic (e.g., metric normalization) even with novel user inputs, as conventional monolithic caching fails due to linguistic variance, highlighting a need for smarter caching.", "method": "Decompose generation into Analytic Intent Resolution and Visualization Synthesis stages, elevating structured intermediate representations to cacheable artifacts within the SemanticALLI architecture in the Alli platform.", "result": "Baseline caching hits 38.7% hit rate; SemanticALLI's structured approach achieves 83.10% hit rate in Visualization Synthesis, bypassing 4,023 LLM calls with median latency of 2.66 ms and reducing total token consumption.", "conclusion": "SemanticALLI demonstrates that caching at structured checkpoints efficiently reuses pipeline logic, offering a practical design lesson for AI systems to reduce redundancy even with unique user inputs."}}
{"id": "2601.16863", "categories": ["cs.AI", "cs.LG", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16863", "abs": "https://arxiv.org/abs/2601.16863", "authors": ["Tims Pecerskis", "Aivars Smirnovs"], "title": "Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation", "comment": null, "summary": "This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.", "AI": {"tldr": "NSED protocol is a Runtime MoM architecture enabling small models to match or exceed large models through dynamic expert selection and iterative refinement.", "motivation": "To overcome static limitations of traditional MoE and leverage hardware arbitrage by using small consumer-grade models effectively.", "method": "Uses Dynamic Expertise Broker for live model selection, formalizes deliberation as a Macro-Scale RNN with semantic forget gate, and includes orchestration fabric, Quadratic Voting, and feedback-driven updates.", "result": "On benchmarks (AIME 2025, LiveCodeBench), small models (<20B) match or exceed 100B+ model performance, with DarkBench showing reduced sycophancy.", "conclusion": "NSED establishes a new efficiency frontier for AI systems by enabling high-performance with smaller models and enhancing safety via peer review."}}
{"id": "2601.16249", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16249", "abs": "https://arxiv.org/abs/2601.16249", "authors": ["Vy Vo", "He Zhao", "Trung Le", "Edwin V. Bonilla", "Dinh Phung"], "title": "Ordering-based Causal Discovery via Generalized Score Matching", "comment": null, "summary": "Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.", "AI": {"tldr": "The paper presents a causal discovery method using score matching for discrete data, introducing a leaf discriminant criterion to identify topological orders and improve graph recovery accuracy.", "motivation": "To address the challenge of learning directed acyclic graph (DAG) structures from purely observational discrete data, which remains difficult in scientific domains, by extending continuous data methods to handle discrete data through novel leaf detection.", "method": "Extends the score matching framework for causal discovery, originally for continuous data, by introducing a leaf discriminant criterion based on the discrete score function to identify topological orders via leaf node detection and edge pruning.", "result": "Through simulated and real-world experiments, the method accurately infers true causal orders from observed discrete data and significantly boosts the accuracy of existing causal discovery baselines in almost all settings.", "conclusion": "The introduced leaf discriminant criterion effectively enables causal discovery from discrete observational data, enhancing baseline methods and offering practical improvements for DAG structure learning."}}
{"id": "2601.16280", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16280", "abs": "https://arxiv.org/abs/2601.16280", "authors": ["Donghao Huang", "Gauri Malwe", "Zhaoxia Wang"], "title": "When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems", "comment": "Accepted for publication in 2026 The 9th International Conference on Artificial Intelligence and Big Data (ICAIBD 2026)", "summary": "Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.", "AI": {"tldr": "A diagnostic framework using big data analytics is introduced to evaluate procedural reliability in LLM-powered multi-agent systems, identifying reliability thresholds and trade-offs for deployment in SMEs and privacy-sensitive environments.", "motivation": "Multi-agent systems using LLMs advance enterprise automation, but systematic evaluation tools for tool-use reliability are lacking, especially for SMEs in privacy-sensitive settings.", "method": "The framework uses a 12-category error taxonomy covering tool initialization, parameter handling, execution, and result interpretation, evaluated on 1,980 deterministic test instances across open-weight (Qwen2.5 series, Functionary) and proprietary models (GPT-4, Claude 3.5/3.7) on edge hardware.", "result": "Procedural reliability, especially tool initialization failures, limits smaller models; qwen2.5:32b matches GPT-4 with flawless performance, while mid-sized models like qwen2.5:14b achieve 96.6% success rate with 7.3s latency on commodity hardware, offering efficiency-accuracy trade-offs.", "conclusion": "This work provides a foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems, enabling cost-effective deployment for resource-constrained organizations."}}
