{"id": "2507.22951", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "AI": {"tldr": "The paper proposes a unified framework for post-hoc explainability in Knowledge Graph Completion (KGC), balancing effectiveness and conciseness, and suggests improved evaluation protocols.", "motivation": "Lack of formalization and consistent evaluations in post-hoc explainability for KGC hinders reproducibility and cross-study comparisons.", "method": "A general framework for post-hoc explanations via multi-objective optimization, unifying existing algorithms, and improved evaluation protocols using metrics like Mean Reciprocal Rank and Hits@k.", "result": "The framework unifies existing methods and refines evaluation standards, making KGC explainability research more reproducible and impactful.", "conclusion": "By unifying methods and refining evaluations, the work aims to enhance the reproducibility and impact of KGC explainability research."}}
{"id": "2507.23018", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "AI": {"tldr": "The paper explores Data Readiness for AI (DRAI) in leadership-scale scientific datasets, proposing a two-dimensional framework (Data Readiness Levels and Data Processing Stages) for HPC environments.", "motivation": "To address challenges in preparing scientific data for AI training, especially for transformer-based generative models, across domains like climate, fusion, bio/health, and materials.", "method": "Analyzes workflows in four domains, introduces a readiness framework with tailored Data Readiness Levels and Processing Stages for HPC.", "result": "A conceptual maturity matrix to guide standardized, cross-domain AI-ready data infrastructure.", "conclusion": "The framework aids in scalable, reproducible AI for science by addressing data transformation challenges."}}
{"id": "2507.23067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "AI": {"tldr": "The study explores balancing reasoning ability and bias mitigation in Multimodal Large Language Models (MLLMs), identifying a 1:4 mix of debias and reasoning samples with reinforcement learning as optimal.", "motivation": "To address the trade-off between improving reasoning and reducing social biases in MLLMs, which remains an unresolved issue.", "method": "Benchmarked three bias-mitigation strategies (SFT, KD, RL) and varied sample proportions to analyze the reasoning-bias trade-off.", "result": "A 1:4 mix trained with RL reduced biases by 10% while retaining 88% of reasoning accuracy.", "conclusion": "The findings provide practical guidance for balancing fairness and capability in MLLMs."}}
{"id": "2507.23091", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "AI": {"tldr": "AI systems perform poorly on auditory tasks humans handle easily, with a 93% failure rate in tests. The study highlights gaps in selective attention and noise robustness.", "motivation": "Inspired by Moravec's paradox, the study aims to quantify the gap between human and machine auditory capabilities and identify AI shortcomings.", "method": "An auditory Turing test with 917 challenges across seven categories was used to evaluate state-of-the-art audio models like GPT-4 and Whisper.", "result": "AI models failed 93% of tasks, with the best achieving only 6.9% accuracy vs. humans' 52%. Key issues include selective attention and noise robustness.", "conclusion": "The study underscores the need for new AI approaches integrating selective attention and context-aware perception to bridge the human-machine auditory gap."}}
{"id": "2507.23080", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23080", "abs": "https://arxiv.org/abs/2507.23080", "authors": ["Jing Wang", "Yan Jin", "Fei Ding", "Chongfeng Wei"], "title": "Causal-Inspired Multi-Agent Decision-Making via Graph Reinforcement Learning", "comment": null, "summary": "Since the advent of autonomous driving technology, it has experienced\nremarkable progress over the last decade. However, most existing research still\nstruggles to address the challenges posed by environments where multiple\nvehicles have to interact seamlessly. This study aims to integrate causal\nlearning with reinforcement learning-based methods by leveraging causal\ndisentanglement representation learning (CDRL) to identify and extract causal\nfeatures that influence optimal decision-making in autonomous vehicles. These\nfeatures are then incorporated into graph neural network-based reinforcement\nlearning algorithms to enhance decision-making in complex traffic scenarios. By\nusing causal features as inputs, the proposed approach enables the optimization\nof vehicle behavior at an unsignalized intersection. Experimental results\ndemonstrate that our proposed method achieves the highest average reward during\ntraining and our approach significantly outperforms other learning-based\nmethods in several key metrics such as collision rate and average cumulative\nreward during testing. This study provides a promising direction for advancing\nmulti-agent autonomous driving systems and make autonomous vehicles' navigation\nsafer and more efficient in complex traffic environments.", "AI": {"tldr": "The paper integrates causal learning with reinforcement learning to improve autonomous vehicle decision-making in complex traffic scenarios.", "motivation": "Existing research struggles with seamless interaction in multi-vehicle environments, prompting the need for better decision-making methods.", "method": "Combines causal disentanglement representation learning (CDRL) with graph neural network-based reinforcement learning to extract and use causal features.", "result": "The method achieves the highest average reward during training and outperforms others in metrics like collision rate and cumulative reward.", "conclusion": "The approach advances multi-agent autonomous driving, making navigation safer and more efficient in complex environments."}}
{"id": "2507.22954", "categories": ["cs.LG", "eess.IV", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.22954", "abs": "https://arxiv.org/abs/2507.22954", "authors": ["Ridvan Yesiloglu", "Wei Peng", "Md Tauhidul Islam", "Ehsan Adeli"], "title": "Neural Autoregressive Modeling of Brain Aging", "comment": "Accepted at Deep Generative Models Workshop @ MICCAI 2025", "summary": "Brain aging synthesis is a critical task with broad applications in clinical\nand computational neuroscience. The ability to predict the future structural\nevolution of a subject's brain from an earlier MRI scan provides valuable\ninsights into aging trajectories. Yet, the high-dimensionality of data, subtle\nchanges of structure across ages, and subject-specific patterns constitute\nchallenges in the synthesis of the aging brain. To overcome these challenges,\nwe propose NeuroAR, a novel brain aging simulation model based on generative\nautoregressive transformers. NeuroAR synthesizes the aging brain by\nautoregressively estimating the discrete token maps of a future scan from a\nconvenient space of concatenated token embeddings of a previous and future\nscan. To guide the generation, it concatenates into each scale the subject's\nprevious scan, and uses its acquisition age and the target age at each block\nvia cross-attention. We evaluate our approach on both the elderly population\nand adolescent subjects, demonstrating superior performance over\nstate-of-the-art generative models, including latent diffusion models (LDM) and\ngenerative adversarial networks, in terms of image fidelity. Furthermore, we\nemploy a pre-trained age predictor to further validate the consistency and\nrealism of the synthesized images with respect to expected aging patterns.\nNeuroAR significantly outperforms key models, including LDM, demonstrating its\nability to model subject-specific brain aging trajectories with high fidelity.", "AI": {"tldr": "NeuroAR, a generative autoregressive transformer model, predicts brain aging trajectories from MRI scans, outperforming state-of-the-art methods like LDM and GANs in fidelity and realism.", "motivation": "Brain aging synthesis is crucial for clinical and computational neuroscience, but challenges like high-dimensional data and subtle structural changes hinder accurate predictions.", "method": "NeuroAR uses autoregressive transformers to synthesize aging brains by estimating future scan token maps from past and future scan embeddings, guided by subject-specific data and age information via cross-attention.", "result": "NeuroAR outperforms LDM and GANs in image fidelity and realism, validated by a pre-trained age predictor, demonstrating superior modeling of subject-specific aging trajectories.", "conclusion": "NeuroAR is a highly effective model for synthesizing brain aging, offering significant improvements over existing generative methods."}}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "The paper introduces 'argumentative coherence' in judgmental forecasting, showing its practical value in improving accuracy for both humans and LLMs, while noting users often don't align with it.", "motivation": "To study the role of argumentative coherence in judgmental forecasting and its impact on accuracy.", "method": "Formally define coherence, evaluate its impact on human and LLM forecasters, and conduct user experiments.", "result": "Filtering incoherent predictions improves accuracy; users don't naturally align with coherence.", "conclusion": "Mechanisms to filter incoherent opinions are needed in argumentation-based forecasting."}}
{"id": "2507.23644", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23644", "abs": "https://arxiv.org/abs/2507.23644", "authors": ["Alba Aguilera", "Georgina Curto", "Nardine Osman"], "title": "Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity", "comment": null, "summary": "Agent-based simulations have an enormous potential as tools to evaluate\nsocial policies in a non-invasive way, before these are implemented to\nreal-world populations. However, the recommendations that these computational\napproaches may offer to tackle urgent human development challenges can vary\nsubstantially depending on how we model agents' (people) behaviour and the\ncriteria that we use to measure inequity. In this paper, we integrate the\nconceptual framework of the capability approach (CA), which is explicitly\ndesigned to promote and assess human well-being, to guide the simulation and\nevaluate the effectiveness of policies. We define a reinforcement learning\nenvironment where agents behave to restore their capabilities under the\nconstraints of a specific policy. Working in collaboration with local\nstakeholders, non-profits and domain experts, we apply our model in a case\nstudy to mitigate health inequity among the population experiencing\nhomelessness (PEH) in Barcelona. By doing so, we present the first proof of\nconcept simulation, aligned with the CA for human development, to assess the\nimpact of policies under parliamentary discussion.", "AI": {"tldr": "Agent-based simulations using the capability approach (CA) assess policy impacts on human well-being, demonstrated in a case study on health inequity among Barcelona's homeless population.", "motivation": "To evaluate social policies non-invasively and address human development challenges by modeling agent behavior and measuring inequity.", "method": "Integrates CA into a reinforcement learning environment where agents restore capabilities under policy constraints, validated via stakeholder collaboration.", "result": "First proof-of-concept simulation aligning with CA to assess policy impacts, applied to health inequity in Barcelona's homeless population.", "conclusion": "Demonstrates potential of CA-aligned simulations for policy evaluation, offering actionable insights for human development."}}
{"id": "2507.22956", "categories": ["cs.LG", "cs.HC", "K.3.1"], "pdf": "https://arxiv.org/pdf/2507.22956", "abs": "https://arxiv.org/abs/2507.22956", "authors": ["Dong Hyun Roh", "Rajesh Kumar", "An Ngo"], "title": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes", "comment": "This paper has 11 pages, 6 figures, 2 tables, and has been accepted\n  for publication at IEEE-IJCB 2025", "summary": "This paper presents a keystroke-based framework for detecting LLM-assisted\ncheating in Korean, addressing key gaps in prior research regarding language\ncoverage, cognitive context, and the granularity of LLM involvement. Our\nproposed dataset includes 69 participants who completed writing tasks under\nthree conditions: Bona fide writing, paraphrasing ChatGPT responses, and\ntranscribing ChatGPT responses. Each task spans six cognitive processes defined\nin Bloom's Taxonomy (remember, understand, apply, analyze, evaluate, and\ncreate). We extract interpretable temporal and rhythmic features and evaluate\nmultiple classifiers under both Cognition-Aware and Cognition-Unaware settings.\nTemporal features perform well under Cognition-Aware evaluation scenarios,\nwhile rhythmic features generalize better under cross-cognition scenarios.\nMoreover, detecting bona fide and transcribed responses was easier than\nparaphrased ones for both the proposed models and human evaluators, with the\nmodels significantly outperforming the humans. Our findings affirm that\nkeystroke dynamics facilitate reliable detection of LLM-assisted writing across\nvarying cognitive demands and writing strategies, including paraphrasing and\ntranscribing LLM-generated responses.", "AI": {"tldr": "A keystroke-based framework detects LLM-assisted cheating in Korean, using temporal and rhythmic features to distinguish between bona fide writing, paraphrasing, and transcribing ChatGPT responses. Models outperform humans in detection, especially for paraphrased content.", "motivation": "Address gaps in prior research on language coverage, cognitive context, and granularity of LLM involvement in detecting cheating.", "method": "Dataset of 69 participants completing writing tasks under three conditions (bona fide, paraphrasing, transcribing) across six cognitive processes. Temporal and rhythmic features are extracted and evaluated under Cognition-Aware and Cognition-Unaware settings.", "result": "Temporal features excel in Cognition-Aware scenarios, while rhythmic features generalize better. Models outperform humans, especially in detecting paraphrased responses.", "conclusion": "Keystroke dynamics reliably detect LLM-assisted writing across cognitive demands and strategies, including paraphrasing and transcribing."}}
{"id": "2507.23191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23191", "abs": "https://arxiv.org/abs/2507.23191", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "AI": {"tldr": "The paper analyzes the complexity of computing Shapley-value-based responsibility scores (WSMS) in ontology-mediated query answering, showing polynomial data complexity for first-order-rewritable queries but intractability for certain ontology languages. It identifies tractable cases for DL-Lite dialects.", "motivation": "To quantify the contributions of facts to query answers using responsibility measures, particularly in ontology-mediated query answering, and understand the computational complexity of these measures.", "method": "Exploits database results to analyze WSMS complexity, focusing on first-order-rewritable queries and ontology languages. Studies combined complexity for atomic and conjunctive queries.", "result": "Polynomial data complexity for first-order-rewritable queries; intractability for languages encoding reachability. Tractable cases identified for DL-Lite dialects.", "conclusion": "The study delineates the tractability frontier for WSMS computation, providing insights into feasible and intractable scenarios in ontology-mediated query answering."}}
{"id": "2507.23694", "categories": ["cs.MA", "cs.AI", "68T42", "I.2.11"], "pdf": "https://arxiv.org/pdf/2507.23694", "abs": "https://arxiv.org/abs/2507.23694", "authors": ["Virginia Padilla", "Jacinto D\u00e1vila"], "title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM", "comment": "20 pages, 1 table", "summary": "We provide a comprehensive examination of agent-based approaches that codify\nthe principles and linkages underlying multi-agent systems, simulations, and\ninformation systems. Based on two decades of study, this paper confirms a\nframework intended as a formal specification for geosimulation platforms. Our\nfindings show that large language models (LLMs) can be effectively incorporated\nas agent components if they follow a structured architecture specific to\nfundamental agent activities such as perception, memory, planning, and action.\nThis integration is precisely consistent with the architecture that we\nformalize, providing a solid platform for next-generation geosimulation\nsystems.", "AI": {"tldr": "The paper examines agent-based approaches for multi-agent systems and confirms a framework for geosimulation platforms, showing LLMs can be integrated as agents following a structured architecture.", "motivation": "To formalize a framework for geosimulation platforms by examining agent-based approaches and integrating LLMs as agent components.", "method": "Comprehensive examination of agent-based approaches over two decades, focusing on principles and linkages in multi-agent systems, simulations, and information systems.", "result": "LLMs can be effectively incorporated as agent components if they follow a structured architecture for fundamental agent activities.", "conclusion": "The formalized architecture provides a solid platform for next-generation geosimulation systems."}}
{"id": "2507.22959", "categories": ["cs.LG", "cs.CE", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.22959", "abs": "https://arxiv.org/abs/2507.22959", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran", "Amin Hamed Mashhadzadeh", "Shirko Faroughi"], "title": "Scientific Machine Learning with Kolmogorov-Arnold Networks", "comment": null, "summary": "The field of scientific machine learning, which originally utilized\nmultilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold\nNetworks (KANs) for data encoding. This shift is driven by the limitations of\nMLPs, including poor interpretability, fixed activation functions, and\ndifficulty capturing localized or high-frequency features. KANs address these\nissues with enhanced interpretability and flexibility, enabling more efficient\nmodeling of complex nonlinear interactions and effectively overcoming the\nconstraints associated with conventional MLP architectures. This review\ncategorizes recent progress in KAN-based models across three distinct\nperspectives: (i) data-driven learning, (ii) physics-informed modeling, and\n(iii) deep operator learning. Each perspective is examined through the lens of\narchitectural design, training strategies, application efficacy, and\ncomparative evaluation against MLP-based counterparts. By benchmarking KANs\nagainst MLPs, we highlight consistent improvements in accuracy, convergence,\nand spectral representation, clarifying KANs' advantages in capturing complex\ndynamics while learning more effectively. Finally, this review identifies\ncritical challenges and open research questions in KAN development,\nparticularly regarding computational efficiency, theoretical guarantees,\nhyperparameter tuning, and algorithm complexity. We also outline future\nresearch directions aimed at improving the robustness, scalability, and\nphysical consistency of KAN-based frameworks.", "AI": {"tldr": "The paper reviews the shift from MLPs to KANs in scientific machine learning, highlighting KANs' advantages in interpretability, flexibility, and performance. It categorizes progress into data-driven learning, physics-informed modeling, and deep operator learning, benchmarking KANs against MLPs. Challenges and future directions are also discussed.", "motivation": "The limitations of MLPs (poor interpretability, fixed activation functions, difficulty capturing localized/high-frequency features) motivate the adoption of KANs, which offer enhanced interpretability and flexibility.", "method": "The review categorizes KAN-based models into three perspectives: data-driven learning, physics-informed modeling, and deep operator learning. It examines architectural design, training strategies, application efficacy, and comparative evaluation against MLPs.", "result": "KANs consistently outperform MLPs in accuracy, convergence, and spectral representation, demonstrating better capability in capturing complex dynamics.", "conclusion": "The paper identifies challenges (computational efficiency, theoretical guarantees, hyperparameter tuning) and outlines future research directions to improve KAN robustness, scalability, and physical consistency."}}
{"id": "2507.23197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23197", "abs": "https://arxiv.org/abs/2507.23197", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "comment": null, "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "AI": {"tldr": "The paper proposes a divide-and-conquer approach using partial MILP calls and introduces a solution-aware ReLU scoring (SAS) method to efficiently select critical ReLU variables, reducing binary variables by 6x while maintaining accuracy.", "motivation": "To address the inefficiency of previous methods in handling complex verification instances by optimizing the selection of ReLU variables.", "method": "Uses a hybrid approach: first applies \u03b1,\u03b2-CROWN with a short timeout, then partial MILP. Introduces SAS for ReLU scoring and adapts BaB-SR and BaB-FSB as global scoring functions.", "result": "SAS reduces binary variables by 6x, maintains accuracy, and reduces undecided instances by 40% (to 8-15%). Runtime remains reasonable (46s-417s per instance).", "conclusion": "The proposed Hybrid MILP with SAS is an efficient and accurate verifier, even for large CNNs with 2 million parameters."}}
{"id": "2507.23261", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23261", "abs": "https://arxiv.org/abs/2507.23261", "authors": ["Hui Yi Leong", "Yuqing Wu"], "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "comment": null, "summary": "Current multi-agent systems (MAS) frameworks often rely on manually designed\nand static collaboration graph structures, limiting adaptability and\nperformance. To address these limitations, we propose DynaSwarm, a dynamic\nframework that enhances LLM-based MAS through two key innovations: (1) an\nactor-critic reinforcement learning (A2C) mechanism to optimize graph\nstructures with improved stability over prior RL methods, and (2) a dynamic\ngraph selector that adaptively chooses the optimal graph structure for each\ninput sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the\nneed for rigid, one-fits-all graph architectures, instead leveraging\nsample-specific idiosyncrasies to dynamically route queries through specialized\nagent networks. (c) We propose to fine-tune the demonstration retriever to\nfully exploit the power of in-context learning (ICL). Extensive experiments on\nquestion answering, mathematical reasoning, and coding tasks demonstrate that\nDynaSwarm consistently outperforms state-of-the-art single-agent and MAS\nbaselines across multiple LLM backbones. Our findings highlight the importance\nof sample-aware structural flexibility in LLM MAS designs.", "AI": {"tldr": "DynaSwarm is a dynamic multi-agent system (MAS) framework that improves adaptability and performance by optimizing graph structures with A2C reinforcement learning and a dynamic graph selector, outperforming static MAS and single-agent baselines.", "motivation": "Current MAS frameworks use static collaboration graphs, limiting adaptability and performance. DynaSwarm aims to overcome this by dynamically optimizing graph structures.", "method": "DynaSwarm uses (1) an A2C reinforcement learning mechanism for stable graph optimization and (2) a dynamic graph selector for sample-specific routing. It also fine-tunes the demonstration retriever for in-context learning.", "result": "Experiments on question answering, math reasoning, and coding tasks show DynaSwarm outperforms state-of-the-art single-agent and MAS baselines.", "conclusion": "Sample-aware structural flexibility is crucial for LLM-based MAS, as demonstrated by DynaSwarm's superior performance."}}
{"id": "2507.22962", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22962", "abs": "https://arxiv.org/abs/2507.22962", "authors": ["Boyuan Zheng", "Victor W. Chu"], "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "comment": "Pre-print v0.8 2025-07-30", "summary": "Climate extremes present escalating risks to agriculture intensifying the\nneed for reliable multi-hazard early warning systems (EWS). The situation is\nevolving due to climate change and hence such systems should have the\nintelligent to continue to learn from recent climate behaviours. However,\ntraditional single-hazard forecasting methods fall short in capturing complex\ninteractions among concurrent climatic events. To address this deficiency, in\nthis paper, we combine sequential deep learning models and advanced Explainable\nArtificial Intelligence (XAI) techniques to introduce a multi-hazard\nforecasting framework for agriculture. In our experiments, we utilize\nmeteorological data from four prominent agricultural regions in the United\nStates (between 2010 and 2023) to validate the predictive accuracy of our\nframework on multiple severe event types, which are extreme cold, floods,\nfrost, hail, heatwaves, and heavy rainfall, with tailored models for each area.\nThe framework uniquely integrates attention mechanisms with TimeSHAP (a\nrecurrent XAI explainer for time series) to provide comprehensive temporal\nexplanations revealing not only which climatic features are influential but\nprecisely when their impacts occur. Our results demonstrate strong predictive\naccuracy, particularly with the BiLSTM architecture, and highlight the system's\ncapacity to inform nuanced, proactive risk management strategies. This research\nsignificantly advances the explainability and applicability of multi-hazard\nEWS, fostering interdisciplinary trust and effective decision-making process\nfor climate risk management in the agricultural industry.", "AI": {"tldr": "The paper introduces a multi-hazard forecasting framework for agriculture using deep learning and XAI, validated with US meteorological data, achieving strong predictive accuracy and explainability.", "motivation": "Climate extremes are increasing risks to agriculture, requiring adaptive EWS. Traditional methods fail to capture complex interactions among concurrent events.", "method": "Combines sequential deep learning (e.g., BiLSTM) and XAI (TimeSHAP) to create a multi-hazard forecasting framework, tested on US agricultural data (2010-2023).", "result": "Demonstrates strong predictive accuracy, especially with BiLSTM, and provides temporal explanations for climatic feature impacts.", "conclusion": "Advances explainable multi-hazard EWS, aiding proactive risk management and interdisciplinary trust in agriculture."}}
{"id": "2507.23276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23276", "abs": "https://arxiv.org/abs/2507.23276", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "title": "How Far Are AI Scientists from Changing the World?", "comment": null, "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "AI": {"tldr": "The paper surveys the progress of AI Scientist systems, assessing their potential to revolutionize scientific research and identifying key challenges for achieving groundbreaking discoveries.", "motivation": "To evaluate how close AI Scientist systems are to transforming scientific research and uncovering unknown phenomena.", "method": "A prospect-driven review analyzing current achievements, bottlenecks, and essential components for AI Scientists.", "result": "Identifies limitations and gaps in current AI Scientist systems, outlining goals for future advancements.", "conclusion": "The survey aims to clarify the current state, missing elements, and ultimate objectives for AI in scientific research."}}
{"id": "2507.23336", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23336", "abs": "https://arxiv.org/abs/2507.23336", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "title": "DSBC : Data Science task Benchmarking with Context engineering", "comment": "32 pages", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "AI": {"tldr": "A benchmark evaluates LLM-based data science agents, comparing three models and methods, revealing performance disparities and practical deployment factors.", "motivation": "Despite rapid adoption of LLM-based data science agents, systematic benchmarks assessing their efficacy and limitations are lacking.", "method": "Evaluates three LLMs (Claude-4.0-Sonnet, Gemini-2.5-Flash, OpenAI-o4-Mini) across three approaches (zero-shot, multi-step, SmolAgent) on eight task categories, testing sensitivity to prompting issues and temperature parameters.", "result": "Reveals distinct performance disparities among models and methodologies, highlighting critical deployment factors.", "conclusion": "The benchmark provides a foundation for future research on robust and effective data science agents."}}
{"id": "2507.22963", "categories": ["cs.LG", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2507.22963", "abs": "https://arxiv.org/abs/2507.22963", "authors": ["Abdelrhman Gaber", "Hassan Abd-Eltawab", "John Elgallab", "Youssif Abuzied", "Dineo Mpanya", "Turgay Celik", "Swarun Kumar", "Tamer ElBatt"], "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization", "comment": null, "summary": "Cardiovascular diseases (CVD) cause over 17 million deaths annually\nworldwide, highlighting the urgent need for privacy-preserving predictive\nsystems. We introduce FedCVD++, an enhanced federated learning (FL) framework\nthat integrates both parametric models (logistic regression, SVM, neural\nnetworks) and non-parametric models (Random Forest, XGBoost) for coronary heart\ndisease risk prediction. To address key FL challenges, we propose: (1)\ntree-subset sampling that reduces Random Forest communication overhead by 70%,\n(2) XGBoost-based feature extraction enabling lightweight federated ensembles,\nand (3) federated SMOTE synchronization for resolving cross-institutional class\nimbalance.\n  Evaluated on the Framingham dataset (4,238 records), FedCVD++ achieves\nstate-of-the-art results: federated XGBoost (F1 = 0.80) surpasses its\ncentralized counterpart (F1 = 0.78), and federated Random Forest (F1 = 0.81)\nmatches non-federated performance. Additionally, our communication-efficient\nstrategies reduce bandwidth consumption by 3.2X while preserving 95% accuracy.\n  Compared to existing FL frameworks, FedCVD++ delivers up to 15% higher\nF1-scores and superior scalability for multi-institutional deployment. This\nwork represents the first practical integration of non-parametric models into\nfederated healthcare systems, providing a privacy-preserving solution validated\nunder real-world clinical constraints.", "AI": {"tldr": "FedCVD++ is an enhanced federated learning framework for CVD risk prediction, integrating parametric and non-parametric models while addressing FL challenges like communication overhead and class imbalance.", "motivation": "The urgent need for privacy-preserving predictive systems in healthcare due to the high mortality rate of CVDs (17M deaths annually).", "method": "Combines parametric (logistic regression, SVM, neural networks) and non-parametric models (Random Forest, XGBoost). Proposes tree-subset sampling, XGBoost-based feature extraction, and federated SMOTE synchronization.", "result": "Achieves state-of-the-art results: federated XGBoost (F1=0.80) outperforms centralized (F1=0.78), and federated Random Forest (F1=0.81) matches non-federated performance. Reduces bandwidth by 3.2X with 95% accuracy preserved.", "conclusion": "FedCVD++ is the first practical integration of non-parametric models into federated healthcare, offering privacy-preserving, scalable, and high-performance solutions for CVD risk prediction."}}
{"id": "2507.23330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23330", "abs": "https://arxiv.org/abs/2507.23330", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl L\u00f6wenmark"], "title": "AI Must not be Fully Autonomous", "comment": "11 pages, 1 figure", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "AI": {"tldr": "The paper argues against fully autonomous AI (level 3) due to risks, advocating for human oversight, supported by theories, arguments, and evidence.", "motivation": "To highlight the risks of fully autonomous AI and emphasize the need for human oversight, especially with the potential rise of artificial superintelligence (ASI).", "method": "Discusses theories of autonomy, AI, and agents; presents 12 arguments, 6 counterarguments with rebuttals, and 15 pieces of evidence on AI risks.", "result": "Identifies 3 levels of autonomous AI, stressing the dangers of level 3 (fully autonomous) without human oversight.", "conclusion": "Fully autonomous AI is too risky; responsible human oversight is essential to mitigate potential harms."}}
{"id": "2507.23344", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23344", "abs": "https://arxiv.org/abs/2507.23344", "authors": ["Tatsuya Mitomi", "Fumiyasu Makinoshima", "Fumiya Makihara", "Eigo Segawa"], "title": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "comment": null, "summary": "Bike-sharing systems are emerging in various cities as a new ecofriendly\ntransportation system. In these systems, spatiotemporally varying user demands\nlead to imbalanced inventory at bicycle stations, resulting in additional\nrelocation costs. Therefore, it is essential to manage user demand through\noptimal dynamic pricing for the system. However, optimal pricing design for\nsuch a system is challenging because the system involves users with diverse\nbackgrounds and their probabilistic choices. To address this problem, we\ndevelop a differentiable agent-based simulation to rapidly design dynamic\npricing in bike-sharing systems, achieving balanced bicycle inventory despite\nspatiotemporally heterogeneous trips and probabilistic user decisions. We first\nvalidate our approach against conventional methods through numerical\nexperiments involving 25 bicycle stations and five time slots, yielding 100\nparameters. Compared to the conventional methods, our approach obtains a more\naccurate solution with a 73% to 78% reduction in loss while achieving more than\na 100-fold increase in convergence speed. We further validate our approach on a\nlarge-scale urban bike-sharing system scenario involving 289 bicycle stations,\nresulting in a total of 1156 parameters. Through simulations using the obtained\npricing policies, we confirm that these policies can naturally induce balanced\ninventory without any manual relocation. Additionally, we find that the cost of\ndiscounts to induce the balanced inventory can be minimized by setting\nappropriate initial conditions.", "AI": {"tldr": "The paper proposes a differentiable agent-based simulation for dynamic pricing in bike-sharing systems to balance inventory, outperforming conventional methods in accuracy and speed.", "motivation": "Bike-sharing systems face imbalanced inventory due to spatiotemporal demand variations, requiring dynamic pricing to manage user demand efficiently.", "method": "Develops a differentiable agent-based simulation to design dynamic pricing, validated through numerical experiments and large-scale urban scenarios.", "result": "Achieves 73-78% loss reduction, 100x faster convergence, and balanced inventory without manual relocation.", "conclusion": "Optimal dynamic pricing can balance bike inventory efficiently, with minimized discount costs through proper initial conditions."}}
{"id": "2507.23000", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23000", "abs": "https://arxiv.org/abs/2507.23000", "authors": ["Shengao Yi", "Xiaojiang Li", "Wei Tu", "Tianhong Zhao"], "title": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "comment": null, "summary": "As extreme heat events intensify due to climate change and urbanization,\ncities face increasing challenges in mitigating outdoor heat stress. While\ntraditional physical models such as SOLWEIG and ENVI-met provide detailed\nassessments of human-perceived heat exposure, their computational demands limit\nscalability for city-wide planning. In this study, we propose GSM-UTCI, a\nmultimodal deep learning framework designed to predict daytime average\nUniversal Thermal Climate Index (UTCI) at 1-meter hyperlocal resolution. The\nmodel fuses surface morphology (nDSM), high-resolution land cover data, and\nhourly meteorological conditions using a feature-wise linear modulation (FiLM)\narchitecture that dynamically conditions spatial features on atmospheric\ncontext. Trained on SOLWEIG-derived UTCI maps, GSM-UTCI achieves near-physical\naccuracy, with an R2 of 0.9151 and a mean absolute error (MAE) of 0.41{\\deg}C,\nwhile reducing inference time from hours to under five minutes for an entire\ncity. To demonstrate its planning relevance, we apply GSM-UTCI to simulate\nsystematic landscape transformation scenarios in Philadelphia, replacing bare\nearth, grass, and impervious surfaces with tree canopy. Results show spatially\nheterogeneous but consistently strong cooling effects, with impervious-to-tree\nconversion producing the highest aggregated benefit (-4.18{\\deg}C average\nchange in UTCI across 270.7 km2). Tract-level bivariate analysis further\nreveals strong alignment between thermal reduction potential and land cover\nproportions. These findings underscore the utility of GSM-UTCI as a scalable,\nfine-grained decision support tool for urban climate adaptation, enabling\nscenario-based evaluation of greening strategies across diverse urban\nenvironments.", "AI": {"tldr": "GSM-UTCI, a deep learning model, predicts hyperlocal UTCI with high accuracy and speed, aiding urban heat mitigation planning.", "motivation": "Cities need scalable tools to assess and mitigate outdoor heat stress due to climate change and urbanization, as traditional models are computationally intensive.", "method": "GSM-UTCI uses multimodal data (nDSM, land cover, meteorology) with a FiLM architecture to predict UTCI, trained on SOLWEIG-derived maps.", "result": "Achieves R2 of 0.9151 and MAE of 0.41\u00b0C, reducing inference time to under five minutes. Applied to Philadelphia, tree canopy scenarios show significant cooling.", "conclusion": "GSM-UTCI is a scalable, precise tool for urban climate adaptation, enabling efficient evaluation of greening strategies."}}
{"id": "2507.23429", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "pdf": "https://arxiv.org/pdf/2507.23429", "abs": "https://arxiv.org/abs/2507.23429", "authors": ["Jorge Ruiz G\u00f3mez", "Lidia Andr\u00e9s Susinos", "Jorge Alamo Oliv\u00e9", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hern\u00e1ndez"], "title": "Chatting with your ERP: A Recipe", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "AI": {"tldr": "A dual-agent LLM architecture for translating natural language to SQL in ERP systems, improving reliability.", "motivation": "To enhance interaction with ERP systems by enabling natural language queries.", "method": "Dual-agent architecture with reasoning and critique stages, using open-weight LLMs.", "result": "Improved reliability in generating executable SQL from natural language queries.", "conclusion": "The proposed architecture effectively bridges natural language and ERP system interactions."}}
{"id": "2507.23009", "categories": ["cs.LG", "cs.AI", "91E45", "I.2"], "pdf": "https://arxiv.org/pdf/2507.23009", "abs": "https://arxiv.org/abs/2507.23009", "authors": ["Tom S\u00fchr", "Florian E. Dorner", "Olawale Salaudeen", "Augustin Kelava", "Samira Samadi"], "title": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead", "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable results on a range of\nstandardized tests originally designed to assess human cognitive and\npsychological traits, such as intelligence and personality. While these results\nare often interpreted as strong evidence of human-like characteristics in LLMs,\nthis paper argues that such interpretations constitute an ontological error.\nHuman psychological and educational tests are theory-driven measurement\ninstruments, calibrated to a specific human population. Applying these tests to\nnon-human subjects without empirical validation, risks mischaracterizing what\nis being measured. Furthermore, a growing trend frames AI performance on\nbenchmarks as measurements of traits such as ``intelligence'', despite known\nissues with validity, data contamination, cultural bias and sensitivity to\nsuperficial prompt changes. We argue that interpreting benchmark performance as\nmeasurements of human-like traits, lacks sufficient theoretical and empirical\njustification. This leads to our position: Stop Evaluating AI with Human Tests,\nDevelop Principled, AI-specific Tests instead. We call for the development of\nprincipled, AI-specific evaluation frameworks tailored to AI systems. Such\nframeworks might build on existing frameworks for constructing and validating\npsychometrics tests, or could be created entirely from scratch to fit the\nunique context of AI.", "AI": {"tldr": "The paper argues against using human psychological tests to evaluate LLMs, calling for AI-specific evaluation frameworks instead.", "motivation": "Human tests are theory-driven and calibrated for humans, making them unsuitable for evaluating AI traits like intelligence.", "method": "The paper critiques current practices and highlights issues like validity, data contamination, and cultural bias in using human tests for AI.", "result": "Mischaracterization of AI traits occurs when human tests are applied without empirical validation.", "conclusion": "The paper advocates for developing principled, AI-specific tests to accurately evaluate AI systems."}}
{"id": "2507.23377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23377", "abs": "https://arxiv.org/abs/2507.23377", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "comment": null, "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "AI": {"tldr": "LLM4Rail is a railway service platform using LLMs for personalized services like ticketing, food recommendations, and chitchat, employing the QTAO framework and a zero-shot recommender for onboard dining.", "motivation": "To meet the demand for individualized railway services by leveraging LLMs for accurate and personalized responses.", "method": "Developed the QTAO prompting framework for reasoning-guided actions and introduced a zero-shot conversational recommender with post-processing for railway food recommendations.", "result": "Created the CRFD-25 dataset for railway catering and demonstrated effective personalized service delivery.", "conclusion": "LLM4Rail successfully integrates LLMs for tailored railway services, showcasing the potential of LLMs in specialized domains."}}
{"id": "2507.23010", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23010", "abs": "https://arxiv.org/abs/2507.23010", "authors": ["Siwoo Park"], "title": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "comment": null, "summary": "This paper investigates the inverse capabilities and broader utility of\nmultimodal latent spaces within task-specific AI (Artificial Intelligence)\nmodels. While these models excel at their designed forward tasks (e.g.,\ntext-to-image generation, audio-to-text transcription), their potential for\ninverse mappings remains largely unexplored. We propose an optimization-based\nframework to infer input characteristics from desired outputs, applying it\nbidirectionally across Text-Image (BLIP, Flux.1-dev) and Text-Audio\n(Whisper-Large-V3, Chatterbox-TTS) modalities.\n  Our central hypothesis posits that while optimization can guide models\ntowards inverse tasks, their multimodal latent spaces will not consistently\nsupport semantically meaningful and perceptually coherent inverse mappings.\nExperimental results consistently validate this hypothesis. We demonstrate that\nwhile optimization can force models to produce outputs that align textually\nwith targets (e.g., a text-to-image model generating an image that an image\ncaptioning model describes correctly, or an ASR model transcribing optimized\naudio accurately), the perceptual quality of these inversions is chaotic and\nincoherent. Furthermore, when attempting to infer the original semantic input\nfrom generative models, the reconstructed latent space embeddings frequently\nlack semantic interpretability, aligning with nonsensical vocabulary tokens.\n  These findings highlight a critical limitation. multimodal latent spaces,\nprimarily optimized for specific forward tasks, do not inherently possess the\nstructure required for robust and interpretable inverse mappings. Our work\nunderscores the need for further research into developing truly semantically\nrich and invertible multimodal latent spaces.", "AI": {"tldr": "The paper explores inverse capabilities of multimodal latent spaces in AI models, finding them chaotic and semantically incoherent despite optimization efforts.", "motivation": "To investigate whether multimodal latent spaces, optimized for forward tasks, can support meaningful inverse mappings.", "method": "An optimization-based framework is applied bidirectionally across Text-Image and Text-Audio modalities to infer input characteristics from outputs.", "result": "Inverse mappings are textually aligned but perceptually chaotic and semantically incoherent, lacking interpretability.", "conclusion": "Multimodal latent spaces lack inherent structure for robust inverse mappings, highlighting the need for further research into invertible spaces."}}
{"id": "2507.23035", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.23035", "abs": "https://arxiv.org/abs/2507.23035", "authors": ["Xueying Wu", "Baijun Zhou", "Zhihui Gao", "Yuzhe Fu", "Qilin Zheng", "Yintao He", "Hai Li"], "title": "KLLM: Fast LLM Inference with K-Means Quantization", "comment": null, "summary": "Large language model (LLM) inference poses significant challenges due to its\nintensive memory and computation demands. Weight and activation quantization\n(WAQ) offers a promising solution by reducing both memory footprint and\narithmetic complexity. However, two key challenges remain in the existing WAQ\ndesigns. (1) Traditional WAQ designs rely on uniform integer-based quantization\nfor hardware efficiency, but this often results in significant accuracy\ndegradation at low precision. K-Means-based quantization, a non-uniform\nquantization technique, achieves higher accuracy by matching the Gaussian-like\ndistributions of weights and activations in LLMs. However, its non-uniform\nnature prevents direct execution on low-precision compute units, requiring\ndequantization and floating-point matrix multiplications (MatMuls) during\ninference. (2) Activation outliers further hinder effective low-precision WAQ.\nOffline thresholding methods for outlier detection can lead to significant\nmodel performance degradation, while existing online detection techniques\nintroduce substantial runtime overhead.\n  To address the aforementioned challenges and fully unleash the potential of\nWAQ with K-Means quantization for LLM inference, in this paper, we propose\nKLLM, a hardware-software co-design framework. KLLM features an index-based\ncomputation scheme for efficient execution of MatMuls and nonlinear operations\non K-Means-quantized data, which avoids most of the dequantization and\nfull-precision computations. Moreover, KLLM incorporates a novel outlier\ndetection engine, Orizuru, that efficiently identifies the top-$k$ largest and\nsmallest elements in the activation data stream during online inference.\n  Extensive experiments show that, on average, KLLM achieves speedups of 9.67x,\n7.03x and energy efficiency improvements of 229.50x, 150.21x compared to the\nA100 GPU and Atom, respectively.", "AI": {"tldr": "KLLM is a hardware-software co-design framework addressing challenges in weight and activation quantization for LLM inference, improving efficiency and accuracy.", "motivation": "Existing WAQ designs face accuracy degradation and inefficiency due to uniform quantization and activation outliers.", "method": "KLLM uses index-based computation for K-Means-quantized data and an outlier detection engine (Orizuru) for efficient online inference.", "result": "KLLM achieves significant speedups (9.67x, 7.03x) and energy efficiency improvements (229.50x, 150.21x) over A100 GPU and Atom.", "conclusion": "KLLM effectively enhances LLM inference efficiency and accuracy through innovative quantization and outlier handling."}}
{"id": "2507.23440", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23440", "abs": "https://arxiv.org/abs/2507.23440", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "comment": "Accepted by Findings of ACL 2025", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "AI": {"tldr": "Self-Foveate is an LLM-driven method for synthesizing diverse and challenging instructions from unsupervised text, using a multi-level foveation approach.", "motivation": "Existing methods for instruction synthesis lack diversity and difficulty, relying heavily on human effort or limited automation.", "method": "Proposes 'Micro-Scatter-Macro' multi-level foveation to guide LLMs in extracting fine-grained information from text.", "result": "Validated across multiple corpora and architectures, showing effectiveness and superiority.", "conclusion": "Self-Foveate enhances instruction synthesis, with data and code publicly released."}}
{"id": "2507.23037", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23037", "abs": "https://arxiv.org/abs/2507.23037", "authors": ["Aur\u00e9lie Leribaux", "Rafael Oyamada", "Johannes De Smedt", "Zahra Dasht Bozorgi", "Artem Polyvyanyy", "Jochen De Weerdt"], "title": "Linking Actor Behavior to Process Performance Over Time", "comment": "Accepted for presentation at the 5th Workshop on Change, Drift, and\n  Dynamics of Organizational Processes (ProDy), BPM 2025", "summary": "Understanding how actor behavior influences process outcomes is a critical\naspect of process mining. Traditional approaches often use aggregate and static\nprocess data, overlooking the temporal and causal dynamics that arise from\nindividual actor behavior. This limits the ability to accurately capture the\ncomplexity of real-world processes, where individual actor behavior and\ninteractions between actors significantly shape performance. In this work, we\naddress this gap by integrating actor behavior analysis with Granger causality\nto identify correlating links in time series data. We apply this approach to\nrealworld event logs, constructing time series for actor interactions, i.e.\ncontinuation, interruption, and handovers, and process outcomes. Using Group\nLasso for lag selection, we identify a small but consistently influential set\nof lags that capture the majority of causal influence, revealing that actor\nbehavior has direct and measurable impacts on process performance, particularly\nthroughput time. These findings demonstrate the potential of actor-centric,\ntime series-based methods for uncovering the temporal dependencies that drive\nprocess outcomes, offering a more nuanced understanding of how individual\nbehaviors impact overall process efficiency.", "AI": {"tldr": "The paper integrates actor behavior analysis with Granger causality to study temporal and causal dynamics in process mining, revealing direct impacts of actor behavior on process performance.", "motivation": "Traditional process mining overlooks temporal and causal dynamics from individual actor behavior, limiting understanding of real-world process complexity.", "method": "Uses Granger causality and Group Lasso for lag selection on time series data of actor interactions and process outcomes.", "result": "Identifies influential lags showing actor behavior directly impacts process performance, especially throughput time.", "conclusion": "Actor-centric, time series methods offer nuanced insights into how individual behaviors drive process efficiency."}}
{"id": "2507.23488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23488", "abs": "https://arxiv.org/abs/2507.23488", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "comment": null, "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "AI": {"tldr": "Advanced reasoning models like OpenAI's o-series and DeepSeek-R show significant improvements in causal discovery, especially with structured in-context pipelines, outperforming conventional methods by nearly three-fold.", "motivation": "The challenge of causal inference in large language models and the potential of reasoning-first architectures to address overfitting and poor performance under data perturbations.", "method": "Study causal discovery on the Corr2Cause benchmark using reasoning models, introduce a modular in-context pipeline inspired by Tree-of-Thoughts and Chain-of-Thoughts, and analyze reasoning chain length and complexity.", "result": "Reasoning models achieve significantly better performance than prior approaches, with the in-context pipeline yielding nearly three-fold improvements over baselines.", "conclusion": "Advanced reasoning models are a leap forward, but structured in-context frameworks are crucial to maximize their potential, providing a generalizable approach for causal discovery."}}
{"id": "2507.23043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23043", "abs": "https://arxiv.org/abs/2507.23043", "authors": ["Junyi Fan", "Li Sun", "Shuheng Chen", "Yong Si", "Minoo Ahmadi", "Greg Placencia", "Elham Pishgar", "Kamiar Alaei", "Maryam Pishgar"], "title": "Prediction of Significant Creatinine Elevation in First ICU Stays with Vancomycin Use: A retrospective study through Catboost", "comment": null, "summary": "Background: Vancomycin, a key antibiotic for severe Gram-positive infections\nin ICUs, poses a high nephrotoxicity risk. Early prediction of kidney injury in\ncritically ill patients is challenging. This study aimed to develop a machine\nlearning model to predict vancomycin-related creatinine elevation using routine\nICU data.\n  Methods: We analyzed 10,288 ICU patients (aged 18-80) from the MIMIC-IV\ndatabase who received vancomycin. Kidney injury was defined by KDIGO criteria\n(creatinine rise >=0.3 mg/dL within 48h or >=50% within 7d). Features were\nselected via SelectKBest (top 30) and Random Forest ranking (final 15). Six\nalgorithms were tested with 5-fold cross-validation. Interpretability was\nevaluated using SHAP, Accumulated Local Effects (ALE), and Bayesian posterior\nsampling.\n  Results: Of 10,288 patients, 2,903 (28.2%) developed creatinine elevation.\nCatBoost performed best (AUROC 0.818 [95% CI: 0.801-0.834], sensitivity 0.800,\nspecificity 0.681, negative predictive value 0.900). Key predictors were\nphosphate, total bilirubin, magnesium, Charlson index, and APSIII. SHAP\nconfirmed phosphate as a major risk factor. ALE showed dose-response patterns.\nBayesian analysis estimated mean risk 60.5% (95% credible interval: 16.8-89.4%)\nin high-risk cases.\n  Conclusions: This machine learning model predicts vancomycin-associated\ncreatinine elevation from routine ICU data with strong accuracy and\ninterpretability, enabling early risk detection and supporting timely\ninterventions in critical care.", "AI": {"tldr": "A machine learning model was developed to predict vancomycin-related kidney injury in ICU patients using routine data, achieving strong accuracy and interpretability.", "motivation": "Early prediction of vancomycin-induced nephrotoxicity is challenging but crucial for timely interventions in critically ill patients.", "method": "Analyzed 10,288 ICU patients from MIMIC-IV, selected features via SelectKBest and Random Forest, and tested six algorithms with cross-validation. Interpretability was assessed using SHAP, ALE, and Bayesian methods.", "result": "CatBoost performed best (AUROC 0.818), with phosphate, bilirubin, and Charlson index as key predictors. SHAP and ALE provided insights into risk factors and dose-response patterns.", "conclusion": "The model offers accurate, interpretable predictions for vancomycin-associated kidney injury, aiding early risk detection and intervention in critical care."}}
{"id": "2507.23497", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23497", "abs": "https://arxiv.org/abs/2507.23497", "authors": ["David A Kelly", "Hana Chockler"], "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "comment": "13 pages, 13 figures, appendix included", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "AI": {"tldr": "The paper introduces causal explanations for image classifiers, combining formal rigor with practical computability, and proposes contrastive and complete causal explanations with confidence awareness.", "motivation": "Existing explanation methods for image classifiers lack formal rigor or rely on impractical assumptions. Causal explanations offer a rigorous yet computable alternative.", "method": "The authors define causal explanations, prove their formal properties, and introduce contrastive and complete causal explanations. They implement these definitions in a black-box algorithm.", "result": "Experiments show varying patterns of sufficiency, contrastiveness, and completeness across models. The algorithm is efficient (6s per image on ResNet50) and fully black-box.", "conclusion": "Causal explanations provide a rigorous, computable, and practical solution for explaining image classifier outputs, with efficient and black-box implementation."}}
{"id": "2507.23073", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23073", "abs": "https://arxiv.org/abs/2507.23073", "authors": ["Annalisa Barbara", "Joseph Lazzaro", "Ciara Pike-Burke"], "title": "Locally Differentially Private Thresholding Bandits", "comment": "18th European Workshop on Reinforcement Learning (EWRL 2025)", "summary": "This work investigates the impact of ensuring local differential privacy in\nthe thresholding bandit problem. We consider both the fixed budget and fixed\nconfidence settings. We propose methods that utilize private responses,\nobtained through a Bernoulli-based differentially private mechanism, to\nidentify arms with expected rewards exceeding a predefined threshold. We show\nthat this procedure provides strong privacy guarantees and derive theoretical\nperformance bounds on the proposed algorithms. Additionally, we present general\nlower bounds that characterize the additional loss incurred by any\ndifferentially private mechanism, and show that the presented algorithms match\nthese lower bounds up to poly-logarithmic factors. Our results provide valuable\ninsights into privacy-preserving decision-making frameworks in bandit problems.", "AI": {"tldr": "The paper explores local differential privacy in the thresholding bandit problem, proposing methods with strong privacy guarantees and theoretical performance bounds.", "motivation": "To address privacy concerns in bandit problems by ensuring local differential privacy while identifying high-reward arms.", "method": "Uses a Bernoulli-based differentially private mechanism for private responses in fixed budget and fixed confidence settings.", "result": "The algorithms provide strong privacy guarantees and match lower bounds up to poly-logarithmic factors.", "conclusion": "The work offers insights into privacy-preserving decision-making in bandit problems."}}
{"id": "2507.23554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23554", "abs": "https://arxiv.org/abs/2507.23554", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "comment": null, "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "AI": {"tldr": "DICE introduces a dynamic, theoretically grounded method for selecting in-context demonstrations to improve LLM agent performance by decomposing knowledge into transferable and non-transferable components.", "motivation": "Existing in-context learning (ICL) methods for LLM agents are sensitive to demonstration choices, lacking a general, principled approach for effective selection across reasoning steps.", "method": "DICE decomposes demonstration knowledge into transferable and non-transferable components using a causal lens, proposing a stepwise selection criterion with performance guarantees.", "result": "Extensive experiments show DICE's effectiveness and generality, improving agent performance without additional training costs.", "conclusion": "Principled, context-aware demonstration selection is crucial for robust and efficient LLM agents, as demonstrated by DICE."}}
{"id": "2507.23077", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2507.23077", "abs": "https://arxiv.org/abs/2507.23077", "authors": ["Agnese Marcato", "Aleksandra Pachalieva", "Ryley G. Hill", "Kai Gao", "Xiaoyu Wang", "Esteban Rougier", "Zhou Lei", "Vinamra Agrawal", "Janel Chua", "Qinjun Kang", "Jeffrey D. Hyman", "Abigail Hunter", "Nathan DeBardeleben", "Earl Lawrence", "Hari Viswanathan", "Daniel O'Malley", "Javier E. Santos"], "title": "A Foundation Model for Material Fracture Prediction", "comment": null, "summary": "Accurately predicting when and how materials fail is critical to designing\nsafe, reliable structures, mechanical systems, and engineered components that\noperate under stress. Yet, fracture behavior remains difficult to model across\nthe diversity of materials, geometries, and loading conditions in real-world\napplications. While machine learning (ML) methods show promise, most models are\ntrained on narrow datasets, lack robustness, and struggle to generalize.\nMeanwhile, physics-based simulators offer high-fidelity predictions but are\nfragmented across specialized methods and require substantial high-performance\ncomputing resources to explore the input space. To address these limitations,\nwe present a data-driven foundation model for fracture prediction, a\ntransformer-based architecture that operates across simulators, a wide range of\nmaterials (including plastic-bonded explosives, steel, aluminum, shale, and\ntungsten), and diverse loading conditions. The model supports both structured\nand unstructured meshes, combining them with large language model embeddings of\ntextual input decks specifying material properties, boundary conditions, and\nsolver settings. This multimodal input design enables flexible adaptation\nacross simulation scenarios without changes to the model architecture. The\ntrained model can be fine-tuned with minimal data on diverse downstream tasks,\nincluding time-to-failure estimation, modeling fracture evolution, and adapting\nto combined finite-discrete element method simulations. It also generalizes to\nunseen materials such as titanium and concrete, requiring as few as a single\nsample, dramatically reducing data needs compared to standard ML. Our results\nshow that fracture prediction can be unified under a single model architecture,\noffering a scalable, extensible alternative to simulator-specific workflows.", "AI": {"tldr": "A transformer-based foundation model for fracture prediction unifies diverse materials and loading conditions, reducing data needs and improving generalization.", "motivation": "Accurate fracture prediction is crucial for safe design but is challenging due to diverse materials and conditions. Existing ML models lack robustness, and physics-based simulators are resource-intensive.", "method": "A transformer-based architecture combines multimodal inputs (structured/unstructured meshes and text embeddings) to adapt flexibly across simulations without architectural changes.", "result": "The model generalizes to unseen materials with minimal data, excels in tasks like time-to-failure estimation, and reduces data needs compared to standard ML.", "conclusion": "The model offers a scalable, extensible solution for fracture prediction, unifying diverse scenarios under one architecture."}}
{"id": "2507.23565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23565", "abs": "https://arxiv.org/abs/2507.23565", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "comment": null, "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "AI": {"tldr": "Proposes an autonomous trust orchestration method using agentic AI and hypergraph for efficient trust evaluation in collaborative systems.", "motivation": "Addresses the complexity and resource consumption of trust evaluations in distributed collaboration due to task complexity, dynamic device resources, and assessment overhead.", "method": "Uses agentic AI and hypergraph to autonomously perceive device states, perform trust evaluations during idle periods, and analyze task-specific resource alignment. Maintains a trust hypergraph for hierarchical management and multi-hop collaboration.", "result": "Achieves resource-efficient trust evaluation, balancing overhead and accuracy.", "conclusion": "The method enables efficient utilization of distributed resources and supports large-scale collaboration."}}
{"id": "2507.23093", "categories": ["cs.LG", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.23093", "abs": "https://arxiv.org/abs/2507.23093", "authors": ["Ghazal Sobhani", "Md. Monzurul Amin Ifath", "Tushar Sharma", "Israat Haque"], "title": "On the Sustainability of AI Inferences in the Edge", "comment": "14 pages, 8 figures, 6 tables, in preparation for journal submission", "summary": "The proliferation of the Internet of Things (IoT) and its cutting-edge\nAI-enabled applications (e.g., autonomous vehicles and smart industries)\ncombine two paradigms: data-driven systems and their deployment on the edge.\nUsually, edge devices perform inferences to support latency-critical\napplications. In addition to the performance of these resource-constrained edge\ndevices, their energy usage is a critical factor in adopting and deploying edge\napplications. Examples of such devices include Raspberry Pi (RPi), Intel Neural\nCompute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU).\nDespite their adoption in edge deployment for AI inferences, there is no study\non their performance and energy usage for informed decision-making on the\ndevice and model selection to meet the demands of applications. This study\nfills the gap by rigorously characterizing the performance of traditional,\nneural networks, and large language models on the above-edge devices.\nSpecifically, we analyze trade-offs among model F1 score, inference time,\ninference power, and memory usage. Hardware and framework optimization, along\nwith external parameter tuning of AI models, can balance between model\nperformance and resource usage to realize practical edge AI deployments.", "AI": {"tldr": "This study evaluates the performance and energy usage of edge devices (e.g., Raspberry Pi, NVIDIA Jetson nano) for AI inferences, focusing on trade-offs between model accuracy, inference time, power, and memory.", "motivation": "The lack of comprehensive studies on edge device performance and energy usage for AI applications motivates this research to aid informed device and model selection.", "method": "The study rigorously characterizes traditional, neural network, and large language model performance on edge devices, analyzing trade-offs in F1 score, inference time, power, and memory.", "result": "Findings highlight how hardware/framework optimizations and model parameter tuning can balance performance and resource usage for practical edge AI deployments.", "conclusion": "The research provides insights for optimizing edge AI deployments by addressing performance-energy trade-offs in device and model selection."}}
{"id": "2507.23633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23633", "abs": "https://arxiv.org/abs/2507.23633", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "comment": null, "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.", "AI": {"tldr": "The paper introduces a strategy-guided agent-assisted memory recall method, MemoCue, which uses a Recall Router framework to enhance memory recall by transforming queries into cue-rich ones. It outperforms LLM-based methods by 17.74%.", "motivation": "Conventional memory recall methods are limited by memory module size, hindering complete memory acquisition. Memory theories suggest proactive activation of memories through cues, inspiring the proposed method.", "method": "A Recall Router framework is introduced, featuring a 5W Recall Map for query classification and fifteen recall strategy patterns. A hierarchical recall tree with Monte Carlo Tree Search optimizes strategy selection and response generation. MemoCue, an LLM-based agent, is fine-tuned for memory-inspired responses.", "result": "Experiments show MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Human evaluation confirms its effectiveness in memory-recall applications.", "conclusion": "The proposed method effectively addresses challenges in agent-assisted memory recall, demonstrating superior performance and practical utility."}}
{"id": "2507.23111", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23111", "abs": "https://arxiv.org/abs/2507.23111", "authors": ["Richard Williams", "Eric Nalisnick", "Andrew Holbrook"], "title": "Scalable Generative Modeling of Weighted Graphs", "comment": "25 pages, 5 figures, included appendix. code at\n  https://github.com/rlwilliams34/BiGG-E", "summary": "Weighted graphs are ubiquitous throughout biology, chemistry, and the social\nsciences, motivating the development of generative models for abstract weighted\ngraph data using deep neural networks. However, most current deep generative\nmodels are either designed for unweighted graphs and are not easily extended to\nweighted topologies or incorporate edge weights without consideration of a\njoint distribution with topology. Furthermore, learning a distribution over\nweighted graphs must account for complex nonlocal dependencies between both the\nedges of the graph and corresponding weights of each edge. We develop an\nautoregressive model BiGG-E, a nontrivial extension of the BiGG model, that\nlearns a joint distribution over weighted graphs while still exploiting\nsparsity to generate a weighted graph with $n$ nodes and $m$ edges in $O((n +\nm)\\log n)$ time. Simulation studies and experiments on a variety of benchmark\ndatasets demonstrate that BiGG-E best captures distributions over weighted\ngraphs while remaining scalable and computationally efficient.", "AI": {"tldr": "BiGG-E is an autoregressive model extending BiGG to learn joint distributions over weighted graphs, addressing dependencies between edges and weights efficiently.", "motivation": "Current deep generative models for weighted graphs either ignore joint distributions with topology or fail to handle nonlocal dependencies between edges and weights.", "method": "BiGG-E extends BiGG, leveraging sparsity to generate weighted graphs in O((n + m)log n) time, learning joint distributions over edges and weights.", "result": "BiGG-E outperforms benchmarks in capturing weighted graph distributions, remaining scalable and efficient.", "conclusion": "BiGG-E effectively models weighted graphs, addressing prior limitations and demonstrating superior performance."}}
{"id": "2507.23664", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23664", "abs": "https://arxiv.org/abs/2507.23664", "authors": ["Haipeng Liu", "Yuxuan Liu", "Ting Long"], "title": "Personalized Education with Ranking Alignment Recommendation", "comment": null, "summary": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.", "AI": {"tldr": "RAR improves personalized question recommendation by integrating collaborative ideas into exploration, outperforming traditional RL methods.", "motivation": "Existing RL-based methods struggle with efficient exploration, limiting their ability to recommend optimal questions for students.", "method": "Proposes Ranking Alignment Recommendation (RAR), incorporating collaborative ideas into the exploration mechanism for better efficiency.", "result": "RAR enhances recommendation performance and is adaptable to any RL-based recommender.", "conclusion": "RAR offers a scalable and effective solution for personalized question recommendation."}}
{"id": "2507.23115", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23115", "abs": "https://arxiv.org/abs/2507.23115", "authors": ["David J Goetze", "Dahlia J Felten", "Jeannie R Albrecht", "Rohit Bhattacharya"], "title": "FLOSS: Federated Learning with Opt-Out and Straggler Support", "comment": "5 pages", "summary": "Previous work on data privacy in federated learning systems focuses on\nprivacy-preserving operations for data from users who have agreed to share\ntheir data for training. However, modern data privacy agreements also empower\nusers to use the system while opting out of sharing their data as desired. When\ncombined with stragglers that arise from heterogeneous device capabilities, the\nresult is missing data from a variety of sources that introduces bias and\ndegrades model performance. In this paper, we present FLOSS, a system that\nmitigates the impacts of such missing data on federated learning in the\npresence of stragglers and user opt-out, and empirically demonstrate its\nperformance in simulations.", "AI": {"tldr": "FLOSS mitigates bias and performance degradation in federated learning caused by missing data from stragglers and user opt-out.", "motivation": "Modern data privacy agreements allow users to opt out of sharing data, and heterogeneous device capabilities cause stragglers, leading to biased and degraded model performance.", "method": "The paper presents FLOSS, a system designed to address missing data issues in federated learning due to stragglers and user opt-out.", "result": "FLOSS is empirically demonstrated to improve performance in simulations.", "conclusion": "FLOSS effectively reduces the negative impacts of missing data in federated learning systems."}}
{"id": "2507.23701", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23701", "abs": "https://arxiv.org/abs/2507.23701", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "comment": null, "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.", "AI": {"tldr": "TextQuests is a new benchmark based on interactive fiction games to evaluate AI agents' intrinsic long-context reasoning and autonomous problem-solving in exploratory environments.", "motivation": "Existing benchmarks lack the ability to assess AI agents' autonomous reasoning in long-horizon, exploratory tasks.", "method": "TextQuests uses Infocom's interactive fiction games, requiring precise actions and long sessions, to test agents without external tools.", "result": "The benchmark evaluates agents' self-contained problem-solving and trial-and-error learning in long-context scenarios.", "conclusion": "TextQuests aims to advance AI agents' intrinsic reasoning capabilities in complex, exploratory environments."}}
{"id": "2507.23128", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23128", "abs": "https://arxiv.org/abs/2507.23128", "authors": ["Ana\u00efs Baranger", "Lucas Maison"], "title": "Evaluating and Improving the Robustness of Speech Command Recognition Models to Noise and Distribution Shifts", "comment": "Submitted to ICASSP 2026", "summary": "Although prior work in computer vision has shown strong correlations between\nin-distribution (ID) and out-of-distribution (OOD) accuracies, such\nrelationships remain underexplored in audio-based models. In this study, we\ninvestigate how training conditions and input features affect the robustness\nand generalization abilities of spoken keyword classifiers under OOD\nconditions. We benchmark several neural architectures across a variety of\nevaluation sets. To quantify the impact of noise on generalization, we make use\nof two metrics: Fairness (F), which measures overall accuracy gains compared to\na baseline model, and Robustness (R), which assesses the convergence between ID\nand OOD performance. Our results suggest that noise-aware training improves\nrobustness in some configurations. These findings shed new light on the\nbenefits and limitations of noise-based augmentation for generalization in\nspeech models.", "AI": {"tldr": "The paper explores how training conditions and input features impact the robustness and generalization of spoken keyword classifiers under OOD conditions, finding noise-aware training beneficial in some cases.", "motivation": "Prior work in computer vision shows correlations between ID and OOD accuracies, but this relationship is underexplored in audio-based models.", "method": "Benchmarking neural architectures across evaluation sets, using Fairness (F) and Robustness (R) metrics to quantify noise impact.", "result": "Noise-aware training improves robustness in some configurations.", "conclusion": "The study highlights the benefits and limitations of noise-based augmentation for generalization in speech models."}}
{"id": "2507.23726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23726", "abs": "https://arxiv.org/abs/2507.23726", "authors": ["Luoxin Chen", "Jinming Gu", "Liankai Huang", "Wenhao Huang", "Zhicheng Jiang", "Allan Jie", "Xiaoran Jin", "Xing Jin", "Chenggang Li", "Kaijing Ma", "Cheng Ren", "Jiawei Shen", "Wenlei Shi", "Tong Sun", "He Sun", "Jiahui Wang", "Siran Wang", "Zhihong Wang", "Chenrui Wei", "Shufa Wei", "Yonghui Wu", "Yuchen Wu", "Yihang Xia", "Huajian Xin", "Fan Yang", "Huaiyuan Ying", "Hongyi Yuan", "Zheng Yuan", "Tianyang Zhan", "Chi Zhang", "Yue Zhang", "Ge Zhang", "Tianyun Zhao", "Jianqiu Zhao", "Yichi Zhou", "Thomas Hanwen Zhu"], "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "comment": null, "summary": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "AI": {"tldr": "Seed-Prover, a lemma-style whole-proof reasoning model, leverages Lean feedback and self-summarization to refine proofs, achieving high success rates on IMO and Putnam problems. Seed-Geometry addresses Lean's geometry limitations, contributing to automated theorem proving.", "motivation": "LLMs struggle with theorem proving due to unclear supervision signals in natural language. Formal verification via Lean provides clear supervision, enabling effective training.", "method": "Seed-Prover iteratively refines proofs using Lean feedback, proved lemmas, and self-summarization. Three test-time inference strategies are designed for deep and broad reasoning. Seed-Geometry is introduced for geometry support.", "result": "Seed-Prover proves 78.1% of formalized IMO problems, saturates MiniF2F, and achieves >50% on PutnamBench. Seed-Geometry outperforms previous formal geometry engines.", "conclusion": "The work advances automated mathematical reasoning by combining formal verification with long chain-of-thought reasoning, demonstrated by high success rates in IMO 2025."}}
{"id": "2507.23136", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23136", "abs": "https://arxiv.org/abs/2507.23136", "authors": ["Erin George", "Deanna Needell", "Berk Ustun"], "title": "Observational Multiplicity", "comment": null, "summary": "Many prediction tasks can admit multiple models that can perform almost\nequally well. This phenomenon can can undermine interpretability and safety\nwhen competing models assign conflicting predictions to individuals. In this\nwork, we study how arbitrariness can arise in probabilistic classification\ntasks as a result of an effect that we call \\emph{observational multiplicity}.\nWe discuss how this effect arises in a broad class of practical applications\nwhere we learn a classifier to predict probabilities $p_i \\in [0,1]$ but are\ngiven a dataset of observations $y_i \\in \\{0,1\\}$. We propose to evaluate the\narbitrariness of individual probability predictions through the lens of\n\\emph{regret}. We introduce a measure of regret for probabilistic\nclassification tasks, which measures how the predictions of a model could\nchange as a result of different training labels change. We present a\ngeneral-purpose method to estimate the regret in a probabilistic classification\ntask. We use our measure to show that regret is higher for certain groups in\nthe dataset and discuss potential applications of regret. We demonstrate how\nestimating regret promote safety in real-world applications by abstention and\ndata collection.", "AI": {"tldr": "The paper explores arbitrariness in probabilistic classification due to observational multiplicity, introduces a regret-based measure to evaluate it, and demonstrates its application for safety.", "motivation": "Addressing the issue of multiple models performing equally well but yielding conflicting predictions, undermining interpretability and safety.", "method": "Proposes a regret measure for probabilistic classification, with a general-purpose method to estimate it.", "result": "Shows higher regret for certain groups and discusses applications like abstention and data collection for safety.", "conclusion": "Estimating regret can enhance safety and interpretability in probabilistic classification tasks."}}
{"id": "2507.23751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23751", "abs": "https://arxiv.org/abs/2507.23751", "authors": ["Ping Yu", "Jack Lanchantin", "Tianlu Wang", "Weizhe Yuan", "Olga Golovneva", "Ilia Kulikov", "Sainbayar Sukhbaatar", "Jason Weston", "Jing Xu"], "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "comment": null, "summary": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.", "AI": {"tldr": "CoT-Self-Instruct is a synthetic data generation method using Chain-of-Thought reasoning to create high-quality prompts for LLM training, outperforming existing datasets in reasoning and instruction-following tasks.", "motivation": "To improve LLM training by generating high-quality synthetic data that enhances reasoning and instruction-following capabilities.", "method": "Uses Chain-of-Thought reasoning to generate and filter synthetic prompts from seed tasks, ensuring quality and complexity.", "result": "Outperforms existing datasets (e.g., s1k, OpenMathReasoning) in verifiable reasoning tasks and human/standard prompts in instruction-following tasks.", "conclusion": "CoT-Self-Instruct effectively enhances LLM performance by generating superior synthetic training data."}}
{"id": "2507.23141", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.23141", "abs": "https://arxiv.org/abs/2507.23141", "authors": ["Xiangshu Gong", "Zhiqiang Xie", "Xiaowei Jin", "Chen Wang", "Yanling Qu", "Wangmeng Zuo", "Hui Li"], "title": "AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver", "comment": null, "summary": "Many problems are governed by differential equations (DEs). Artificial\nintelligence (AI) is a new path for solving DEs. However, data is very scarce\nand existing AI solvers struggle with approximation of high frequency\ncomponents (AHFC). We propose an AI paradigm for solving diverse DEs, including\nDE-ruled first-principles data generation methodology and scale-dilation\noperator (SDO) AI solver. Using either prior knowledge or random fields, we\ngenerate solutions and then substitute them into the DEs to derive the sources\nand initial/boundary conditions through balancing DEs, thus producing\narbitrarily vast amount of, first-principles-consistent training datasets at\nextremely low computational cost. We introduce a reversible SDO that leverages\nthe Fourier transform of the multiscale solutions to fix AHFC, and design a\nspatiotemporally coupled, attention-based Transformer AI solver of DEs with\nSDO. An upper bound on the Hessian condition number of the loss function is\nproven to be proportional to the squared 2-norm of the solution gradient,\nrevealing that SDO yields a smoother loss landscape, consequently fixing AHFC\nwith efficient training. Extensive tests on diverse DEs demonstrate that our AI\nparadigm achieves consistently superior accuracy over state-of-the-art methods.\nThis work makes AI solver of DEs to be truly usable in broad nature and\nengineering fields.", "AI": {"tldr": "The paper proposes an AI paradigm for solving differential equations (DEs) with a focus on addressing high-frequency component approximation challenges. It introduces a first-principles data generation method and a scale-dilation operator (SDO) AI solver, achieving superior accuracy over existing methods.", "motivation": "Existing AI solvers struggle with high-frequency component approximation and data scarcity. The paper aims to develop a more efficient and accurate AI-based solution for diverse DEs.", "method": "The method involves generating first-principles-consistent training datasets using prior knowledge or random fields, and introducing a reversible SDO to address high-frequency issues. A Transformer-based AI solver with SDO is designed for spatiotemporally coupled DEs.", "result": "Extensive tests show the proposed AI paradigm consistently outperforms state-of-the-art methods in accuracy. The SDO also smooths the loss landscape, improving training efficiency.", "conclusion": "The work advances AI solvers for DEs, making them practical for broad applications in nature and engineering."}}
{"id": "2507.23773", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.23773", "abs": "https://arxiv.org/abs/2507.23773", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "comment": null, "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.", "AI": {"tldr": "SimuRA introduces a goal-oriented architecture for generalized agentic reasoning, overcoming autoregressive LLM limitations with world-model-based planning, achieving significant success in web browsing tasks.", "motivation": "Current AI agents are limited by one-task-one-agent approaches and autoregressive LLMs, lacking scalability and generality. Humans, however, reason by simulating outcomes, inspiring a more general AI agent.", "method": "SimuRA uses a world model for planning via simulation, implemented with LLMs, enabling flexible planning in diverse environments using natural language's latent space.", "result": "SimuRA improved flight search success from 0% to 32.2%, with world-model-based planning showing up to 124% advantage over autoregressive methods.", "conclusion": "SimuRA demonstrates the potential for a single, general LLM-based agent capable of superintelligent action across environments, with a web-browsing agent available for public testing."}}
{"id": "2507.23154", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23154", "abs": "https://arxiv.org/abs/2507.23154", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Raphael Canals", "Rachid Nedjai"], "title": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "comment": "Accepted in the 2025 International Conference on Machine Intelligence\n  for GeoAnalytics and Remote Sensing (MIGARS)", "summary": "Urban heatwaves, droughts, and land degradation are pressing and growing\nchallenges in the context of climate change. A valuable approach to studying\nthem requires accurate spatio-temporal information on land surface conditions.\nOne of the most important variables for assessing and understanding these\nphenomena is Land Surface Temperature (LST), which is derived from satellites\nand provides essential information about the thermal state of the Earth's\nsurface. However, satellite platforms inherently face a trade-off between\nspatial and temporal resolutions. To bridge this gap, we propose FuseTen, a\nnovel generative framework that produces daily LST observations at a fine 10 m\nspatial resolution by fusing spatio-temporal observations derived from\nSentinel-2, Landsat 8, and Terra MODIS. FuseTen employs a generative\narchitecture trained using an averaging-based supervision strategy grounded in\nphysical principles. It incorporates attention and normalization modules within\nthe fusion process and uses a PatchGAN discriminator to enforce realism.\nExperiments across multiple dates show that FuseTen outperforms linear\nbaselines, with an average 32.06% improvement in quantitative metrics and\n31.42% in visual fidelity. To the best of our knowledge, this is the first\nnon-linear method to generate daily LST estimates at such fine spatial\nresolution.", "AI": {"tldr": "FuseTen is a generative framework that fuses satellite data to produce daily Land Surface Temperature (LST) at 10m resolution, outperforming linear methods by 32.06% in metrics and 31.42% visually.", "motivation": "Urban heatwaves, droughts, and land degradation require accurate LST data, but satellite trade-offs between spatial and temporal resolution limit availability.", "method": "FuseTen combines Sentinel-2, Landsat 8, and Terra MODIS data using a generative architecture with attention, normalization, and PatchGAN for realism.", "result": "FuseTen improves quantitative metrics by 32.06% and visual fidelity by 31.42% over linear baselines.", "conclusion": "FuseTen is the first non-linear method to achieve daily LST at 10m resolution, addressing critical gaps in land surface monitoring."}}
{"id": "2507.23170", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23170", "abs": "https://arxiv.org/abs/2507.23170", "authors": ["Jinan Zhou", "Rajat Ghosh", "Vaishnavi Bhargava", "Debojyoti Dutta", "Aryan Singhal"], "title": "BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning", "comment": null, "summary": "When designing LLM services, practitioners care about three key properties:\ninference-time budget, factual authenticity, and reasoning capacity. However,\nour analysis shows that no model can simultaneously optimize for all three. We\nformally prove this trade-off and propose a principled framework named The BAR\nTheorem for LLM-application design.", "AI": {"tldr": "The BAR Theorem framework addresses the trade-off between inference-time budget, factual authenticity, and reasoning capacity in LLM services.", "motivation": "Practitioners need to balance inference-time budget, factual authenticity, and reasoning capacity in LLM services, but no model optimizes all three.", "method": "Formal proof of the trade-off and proposal of the BAR Theorem framework.", "result": "Demonstrates the inherent trade-off and provides a principled design framework.", "conclusion": "The BAR Theorem offers a structured approach to LLM-application design despite the trade-offs."}}
{"id": "2507.23186", "categories": ["cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.23186", "abs": "https://arxiv.org/abs/2507.23186", "authors": ["Peter Sharpe"], "title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "comment": null, "summary": "Sparsity detection in black-box functions enables significant computational\nspeedups in gradient-based optimization through Jacobian compression, but\nexisting finite-difference methods suffer from false negatives due to\ncoincidental zero gradients. These false negatives can silently corrupt\ngradient calculations, leading to difficult-to-diagnose errors. We introduce\nNaN-propagation, which exploits the universal contamination property of IEEE\n754 Not-a-Number floating-point values to trace input-output dependencies\nthrough floating-point numerical computations. By systematically contaminating\ninputs with NaN and observing which outputs become NaN, the method reconstructs\nconservative sparsity patterns that eliminate false negatives. We demonstrate\nthe approach on an aerospace wing weight model, achieving a 1.52x speedup while\ndetecting dozens of dependencies missed by conventional methods -- a\nsignificant improvement since gradient computation is the bottleneck in many\noptimization workflows. The technique leverages IEEE 754 compliance to work\nacross programming languages and math libraries without modifying existing\nblack-box codes. Advanced strategies including NaN payload encoding enable\nfaster-than-linear time complexity, improving upon existing black-box sparsity\ndetection methods. Practical algorithms are also proposed to mitigate\nchallenges from branching code execution common in engineering applications.", "AI": {"tldr": "NaN-propagation detects sparsity in black-box functions by exploiting IEEE 754 NaN values, eliminating false negatives and improving gradient optimization speed.", "motivation": "Existing finite-difference methods for sparsity detection produce false negatives due to coincidental zero gradients, leading to corrupted gradient calculations.", "method": "Systematically contaminates inputs with NaN to trace dependencies, reconstructing conservative sparsity patterns without modifying black-box codes.", "result": "Achieves a 1.52x speedup on an aerospace model, detecting dependencies missed by conventional methods.", "conclusion": "NaN-propagation is a robust, language-agnostic method for accurate sparsity detection, enhancing gradient-based optimization workflows."}}
{"id": "2507.23217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23217", "abs": "https://arxiv.org/abs/2507.23217", "authors": ["Hyeon Seong Jeong", "Sangwoo Jo", "Byeong Hyun Yoon", "Yoonseok Heo", "Haedong Jeong", "Taehoon Kim"], "title": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "comment": null, "summary": "Understanding complex multimodal documents remains challenging due to their\nstructural inconsistencies and limited training data availability. We introduce\n\\textit{DocsRay}, a training-free document understanding system that integrates\npseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented\nGeneration (RAG). Our approach leverages multimodal Large Language Models'\n(LLMs) native capabilities to seamlessly process documents containing diverse\nelements such as text, images, charts, and tables without requiring specialized\nmodels or additional training. DocsRay's framework synergistically combines\nthree key techniques: (1) a semantic structuring module using prompt-based LLM\ninteractions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal\nanalysis that converts diverse document elements into unified, text-centric\nrepresentations using the inherent capabilities of multimodal LLMs, and (3) an\nefficient two-stage hierarchical retrieval system that reduces retrieval\ncomplexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents\naveraging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency\nfrom 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the\nMMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,\nsubstantially surpassing previous state-of-the-art results.", "AI": {"tldr": "DocsRay is a training-free system for understanding multimodal documents using pseudo-TOC generation and hierarchical RAG, improving efficiency and accuracy.", "motivation": "Addressing challenges in understanding complex multimodal documents due to structural inconsistencies and limited training data.", "method": "Combines pseudo-TOC generation, zero-shot multimodal analysis, and hierarchical retrieval to process diverse document elements without training.", "result": "Reduced query latency by 45% and achieved 64.7% accuracy on MMLongBench-Doc, surpassing previous benchmarks.", "conclusion": "DocsRay effectively processes multimodal documents without training, offering significant efficiency and accuracy improvements."}}
{"id": "2507.23221", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23221", "abs": "https://arxiv.org/abs/2507.23221", "authors": ["Charles O'Neill", "Slava Chalnev", "Chi Chi Zhao", "Max Kirkby", "Mudith Jayasekara"], "title": "A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations", "comment": null, "summary": "Contextual hallucinations -- statements unsupported by given context --\nremain a significant challenge in AI. We demonstrate a practical\ninterpretability insight: a generator-agnostic observer model detects\nhallucinations via a single forward pass and a linear probe on its residual\nstream. This probe isolates a single, transferable linear direction separating\nhallucinated from faithful text, outperforming baselines by 5-27 points and\nshowing robust mid-layer performance across Gemma-2 models (2B to 27B).\nGradient-times-activation localises this signal to sparse, late-layer MLP\nactivity. Critically, manipulating this direction causally steers generator\nhallucination rates, proving its actionability. Our results offer novel\nevidence of internal, low-dimensional hallucination tracking linked to specific\nMLP sub-circuits, exploitable for detection and mitigation. We release the\n2000-example ContraTales benchmark for realistic assessment of such solutions.", "AI": {"tldr": "A method using a generator-agnostic observer model detects AI hallucinations via a linear probe on residual streams, outperforming baselines and showing robust performance across model sizes.", "motivation": "Addressing the challenge of contextual hallucinations in AI by identifying and mitigating unsupported statements.", "method": "Uses a linear probe on the residual stream of an observer model to isolate a transferable direction separating hallucinated from faithful text, with localization via gradient-times-activation.", "result": "Outperforms baselines by 5-27 points, shows robust mid-layer performance, and causally steers hallucination rates.", "conclusion": "Demonstrates low-dimensional hallucination tracking linked to MLP sub-circuits, offering actionable insights for detection and mitigation."}}
{"id": "2507.23257", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23257", "abs": "https://arxiv.org/abs/2507.23257", "authors": ["Jiawei Liu", "Chenwang Wu", "Defu Lian", "Enhong Chen"], "title": "Efficient Machine Unlearning via Influence Approximation", "comment": "12 pages, 4 figures", "summary": "Due to growing privacy concerns, machine unlearning, which aims at enabling\nmachine learning models to ``forget\" specific training data, has received\nincreasing attention. Among existing methods, influence-based unlearning has\nemerged as a prominent approach due to its ability to estimate the impact of\nindividual training samples on model parameters without retraining. However,\nthis approach suffers from prohibitive computational overhead arising from the\nnecessity to compute the Hessian matrix and its inverse across all training\nsamples and parameters, rendering it impractical for large-scale models and\nscenarios involving frequent data deletion requests. This highlights the\ndifficulty of forgetting. Inspired by cognitive science, which suggests that\nmemorizing is easier than forgetting, this paper establishes a theoretical link\nbetween memorizing (incremental learning) and forgetting (unlearning). This\nconnection allows machine unlearning to be addressed from the perspective of\nincremental learning. Unlike the time-consuming Hessian computations in\nunlearning (forgetting), incremental learning (memorizing) typically relies on\nmore efficient gradient optimization, which supports the aforementioned\ncognitive theory. Based on this connection, we introduce the Influence\nApproximation Unlearning (IAU) algorithm for efficient machine unlearning from\nthe incremental perspective. Extensive empirical evaluations demonstrate that\nIAU achieves a superior balance among removal guarantee, unlearning efficiency,\nand comparable model utility, while outperforming state-of-the-art methods\nacross diverse datasets and model architectures. Our code is available at\nhttps://github.com/Lolo1222/IAU.", "AI": {"tldr": "The paper introduces Influence Approximation Unlearning (IAU), an efficient machine unlearning method inspired by cognitive science, linking memorizing (incremental learning) to forgetting (unlearning).", "motivation": "Growing privacy concerns necessitate machine unlearning, but existing methods like influence-based unlearning are computationally expensive due to Hessian matrix calculations.", "method": "The paper proposes IAU, leveraging the connection between incremental learning and unlearning for efficiency, avoiding costly Hessian computations.", "result": "IAU achieves a superior balance of removal guarantee, efficiency, and model utility, outperforming state-of-the-art methods.", "conclusion": "IAU offers a practical solution for efficient machine unlearning, validated across diverse datasets and models."}}
{"id": "2507.23291", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23291", "abs": "https://arxiv.org/abs/2507.23291", "authors": ["Yuetian Chen", "Zhiqi Wang", "Nathalie Baracaldo", "Swanand Ravindra Kadhe", "Lei Yu"], "title": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "comment": null, "summary": "Membership inference attacks (MIAs) pose a critical threat to the privacy of\ntraining data in deep learning. Despite significant progress in attack\nmethodologies, our understanding of when and how models encode membership\ninformation during training remains limited. This paper presents a dynamic\nanalytical framework for dissecting and quantifying privacy leakage dynamics at\nthe individual sample level. By tracking per-sample vulnerabilities on an\nFPR-TPR plane throughout training, our framework systematically measures how\nfactors such as dataset complexity, model architecture, and optimizer choice\ninfluence the rate and severity at which samples become vulnerable. Crucially,\nwe discover a robust correlation between a sample's intrinsic learning\ndifficulty, and find that the privacy risk of samples highly vulnerable in the\nfinal trained model is largely determined early during training. Our results\nthus provide a deeper understanding of how privacy risks dynamically emerge\nduring training, laying the groundwork for proactive, privacy-aware model\ntraining strategies.", "AI": {"tldr": "The paper introduces a dynamic framework to analyze privacy leakage in deep learning, focusing on how training factors influence sample-level vulnerabilities and revealing early-stage determination of privacy risks.", "motivation": "To understand when and how deep learning models encode membership information during training, addressing gaps in current knowledge about privacy leakage dynamics.", "method": "A dynamic analytical framework tracks per-sample vulnerabilities on an FPR-TPR plane during training, examining factors like dataset complexity, model architecture, and optimizer choice.", "result": "Findings show a strong correlation between a sample's learning difficulty and its privacy risk, with highly vulnerable samples' risks determined early in training.", "conclusion": "The study enhances understanding of dynamic privacy risk emergence, supporting proactive, privacy-aware training strategies."}}
{"id": "2507.23292", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23292", "abs": "https://arxiv.org/abs/2507.23292", "authors": ["RJ Skerry-Ryan", "Julian Salazar", "Soroosh Mariooryad", "David Kao", "Daisy Stanton", "Eric Battenberg", "Matt Shannon", "Ron J. Weiss", "Robin Scheibler", "Jonas Rothfuss", "Tom Bagby"], "title": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "comment": null, "summary": "We introduce a neural network layer API and library for sequence modeling,\ndesigned for easy creation of sequence models that can be executed both\nlayer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,\nautoregressive sampling). To achieve this, layers define an explicit\nrepresentation of their state over time (e.g., a Transformer KV cache, a\nconvolution buffer, an RNN hidden state), and a step method that evolves that\nstate, tested to give identical results to a stateless layer-wise invocation.\nThis and other aspects of the SequenceLayers contract enables complex models to\nbe immediately streamable, mitigates a wide range of common bugs arising in\nboth streaming and parallel sequence processing, and can be implemented in any\ndeep learning library. A composable and declarative API, along with a\ncomprehensive suite of layers and combinators, streamlines the construction of\nproduction-scale models from simple streamable components while preserving\nstrong correctness guarantees. Our current implementations of SequenceLayers\n(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.", "AI": {"tldr": "A neural network layer API for sequence modeling, enabling both layer-by-layer and step-by-step execution, with explicit state representation and strong correctness guarantees.", "motivation": "To simplify the creation of streamable and correct sequence models, addressing bugs in streaming and parallel processing.", "method": "Layers define explicit state over time and a step method for state evolution, ensuring identical results to stateless layer-wise invocation.", "result": "Enables immediate streaming, bug mitigation, and composable model construction with correctness guarantees.", "conclusion": "SequenceLayers provides a practical solution for building production-scale sequence models with ease and reliability."}}
{"id": "2507.23303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23303", "abs": "https://arxiv.org/abs/2507.23303", "authors": ["Luca Corbucci", "Javier Alejandro Borges Legrottaglie", "Francesco Spinnato", "Anna Monreale", "Riccardo Guidotti"], "title": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "comment": null, "summary": "Accurately identifying items forgotten during a supermarket visit and\nproviding clear, interpretable explanations for recommending them remains an\nunderexplored problem within the Next Basket Prediction (NBP) domain. Existing\nNBP approaches typically only focus on forecasting future purchases, without\nexplicitly addressing the detection of unintentionally omitted items. This gap\nis partly due to the scarcity of real-world datasets that allow for the\nreliable estimation of forgotten items. Furthermore, most current NBP methods\nrely on black-box models, which lack transparency and limit the ability to\njustify recommendations to end users. In this paper, we formally introduce the\nforgotten item prediction task and propose two novel interpretable-by-design\nalgorithms. These methods are tailored to identify forgotten items while\noffering intuitive, human-understandable explanations. Experiments on a\nreal-world retail dataset show our algorithms outperform state-of-the-art NBP\nbaselines by 10-15% across multiple evaluation metrics.", "AI": {"tldr": "The paper introduces a novel task of predicting forgotten items in supermarket visits, proposing two interpretable algorithms that outperform existing methods by 10-15%.", "motivation": "Existing NBP approaches lack focus on detecting unintentionally omitted items and rely on opaque models, limiting transparency and user trust.", "method": "Two interpretable-by-design algorithms are proposed to identify forgotten items with clear explanations.", "result": "The algorithms outperform state-of-the-art NBP baselines by 10-15% on a real-world retail dataset.", "conclusion": "The study successfully addresses the gap in forgotten item prediction, offering transparent and effective solutions."}}
{"id": "2507.23535", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.23535", "abs": "https://arxiv.org/abs/2507.23535", "authors": ["Dhanesh Ramachandram", "Himanshu Joshi", "Judy Zhu", "Dhari Gandhi", "Lucas Hartman", "Ananya Raval"], "title": "Transparent AI: The Case for Interpretability and Explainability", "comment": null, "summary": "As artificial intelligence systems increasingly inform high-stakes decisions\nacross sectors, transparency has become foundational to responsible and\ntrustworthy AI implementation. Leveraging our role as a leading institute in\nadvancing AI research and enabling industry adoption, we present key insights\nand lessons learned from practical interpretability applications across diverse\ndomains. This paper offers actionable strategies and implementation guidance\ntailored to organizations at varying stages of AI maturity, emphasizing the\nintegration of interpretability as a core design principle rather than a\nretrospective add-on.", "AI": {"tldr": "The paper highlights the importance of transparency in AI for high-stakes decisions and provides practical insights and strategies for integrating interpretability into AI systems.", "motivation": "Transparency is crucial for responsible and trustworthy AI, especially in high-stakes applications.", "method": "The paper draws on practical interpretability applications across diverse domains and offers tailored strategies for organizations.", "result": "Actionable guidance is provided to integrate interpretability as a core design principle in AI systems.", "conclusion": "Interpretability should be a foundational element of AI design, not an afterthought, to ensure responsible implementation."}}
{"id": "2507.23317", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23317", "abs": "https://arxiv.org/abs/2507.23317", "authors": ["Tao He", "Rongchuan Mu", "Lizi Liao", "Yixin Cao", "Ming Liu", "Bing Qin"], "title": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "comment": "33 pages, 3 figures, 19 tables", "summary": "Large reasoning models (LRMs) have recently shown promise in solving complex\nmath problems when optimized with Reinforcement Learning (RL). But conventional\napproaches rely on outcome-only rewards that provide sparse feedback, resulting\nin inefficient optimization process. In this work, we investigate the function\nof process reward models (PRMs) to accelerate the RL training for LRMs. We\npropose a novel intrinsic signal-driven generative process evaluation mechanism\noperating at the thought level to address major bottlenecks in RL-based\ntraining. Specifically, instead of requiring PRMs to know how to solve\nproblems, our method uses intrinsic signals in solutions to judge stepwise\ncorrectness and aggregate contiguous correct/incorrect steps into coherent\n'thought' units. This structured, thought-level rewards enable more reliable\ncredit assignment by reducing ambiguity in step segmentation and alleviating\nreward hacking. We further introduce a capability-adaptive reward mechanism\nthat dynamically balances exploration and exploitation based on the LRM's\ncurrent proficiency, guiding learning without stifling creative\ntrial-and-error. These innovations are integrated into a new off-policy RL\nalgorithm, TP-GRPO, which extends grouped proximal optimization with\nprocess-based rewards and improves training efficiency. Experiments on 1.5B and\n7B parameter LRMs demonstrate that our method achieves higher problem-solving\naccuracy with significantly fewer training samples than outcome-only reward\nbaselines. The results validate that well-structured process rewards can\nsubstantially accelerate LRM optimization in math reasoning tasks. Code is\navailable at https://github.com/cs-holder/tp_grpo.", "AI": {"tldr": "The paper introduces process reward models (PRMs) and TP-GRPO, a novel RL algorithm, to improve training efficiency for large reasoning models (LRMs) in math tasks by providing structured, thought-level rewards.", "motivation": "Conventional RL approaches for LRMs rely on sparse outcome-only rewards, leading to inefficient optimization. The study aims to address this by leveraging intrinsic signals for stepwise correctness and dynamic reward balancing.", "method": "The proposed method uses intrinsic signals to evaluate stepwise correctness, aggregates steps into coherent 'thought' units, and dynamically balances exploration-exploitation. This is integrated into TP-GRPO, an off-policy RL algorithm.", "result": "Experiments on 1.5B and 7B parameter LRMs show higher accuracy with fewer training samples compared to outcome-only reward baselines.", "conclusion": "Structured process rewards significantly accelerate LRM optimization in math reasoning, validated by improved efficiency and accuracy."}}
{"id": "2507.23536", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23536", "abs": "https://arxiv.org/abs/2507.23536", "authors": ["Georg Slamanig", "Francesco Corti", "Olga Saukh"], "title": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs\nof updating deep learning models by minimizing the number of additional\nparameters used to adapt a model to a down- stream task. While extensively\nresearched in large language models (LLMs), their application to smaller models\nused on edge devices, such as convolutional neural networks, remains\nunderexplored. This paper benchmarks and analyzes popular PEFT methods on\nconvolutional architectures typically deployed in resource-constrained edge\nenvironments. We evaluate LoRA, DoRA, and GaLore for updating standard and\ndepthwise convolutional architectures to handle distribution shifts and\naccommodate unseen classes. We utilize recently proposed PyTorch profilers to\ncompare the updated model performance and computational costs of these PEFT\nmethods with traditional fine-tuning approaches. With resource efficiency in\nmind, we investigate their update behavior across different rank dimensions. We\nfind that the evaluated PEFT methods are only half as memory-efficient when\napplied to depthwise-separable convolution architectures, compared to their\nefficiency with LLMs. Conversely, when targeting convolu- tional architectures\noptimized for edge deployment, adapter-based PEFT methods can reduce floating\npoint operations (FLOPs) during model updates by up to 95%. These insights\noffer valuable guidance for selecting PEFT methods based on hardware\nconstraints, performance requirements, and application needs. Our code is\nonline.", "AI": {"tldr": "PEFT methods are benchmarked on convolutional architectures for edge devices, showing varied efficiency compared to LLMs and traditional fine-tuning.", "motivation": "To explore and evaluate PEFT methods for smaller models on edge devices, where computational efficiency is critical.", "method": "Benchmarked LoRA, DoRA, and GaLore on convolutional architectures using PyTorch profilers to compare performance and computational costs.", "result": "PEFT methods are less memory-efficient for depthwise-separable convolutions but can reduce FLOPs by up to 95% for edge-optimized architectures.", "conclusion": "PEFT methods' efficiency varies by architecture, providing guidance for selecting methods based on hardware and performance needs."}}
{"id": "2507.23335", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23335", "abs": "https://arxiv.org/abs/2507.23335", "authors": ["Qilin Zhou", "Haipeng Wang", "Zhengyuan Wei", "W. K. Chan"], "title": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "comment": "accepted by QRS 2025", "summary": "Patch robustness certification is an emerging verification approach for\ndefending against adversarial patch attacks with provable guarantees for deep\nlearning systems. Certified recovery techniques guarantee the prediction of the\nsole true label of a certified sample. However, existing techniques, if\napplicable to top-k predictions, commonly conduct pairwise comparisons on those\nvotes between labels, failing to certify the sole true label within the top k\nprediction labels precisely due to the inflation on the number of votes\ncontrolled by the attacker (i.e., attack budget); yet enumerating all\ncombinations of vote allocation suffers from the combinatorial explosion\nproblem. We propose CostCert, a novel, scalable, and precise voting-based\ncertified recovery defender. CostCert verifies the true label of a sample\nwithin the top k predictions without pairwise comparisons and combinatorial\nexplosion through a novel design: whether the attack budget on the sample is\ninfeasible to cover the smallest total additional votes on top of the votes\nuncontrollable by the attacker to exclude the true labels from the top k\nprediction labels. Experiments show that CostCert significantly outperforms the\ncurrent state-of-the-art defender PatchGuard, such as retaining up to 57.3% in\ncertified accuracy when the patch size is 96, whereas PatchGuard has already\ndropped to zero.", "AI": {"tldr": "CostCert is a scalable and precise certified recovery defender for deep learning systems, outperforming PatchGuard by avoiding pairwise comparisons and combinatorial explosion.", "motivation": "Existing techniques for patch robustness certification fail to precisely certify the true label within top-k predictions due to vote inflation and combinatorial issues.", "method": "CostCert verifies the true label by checking if the attack budget is insufficient to exclude it from top-k predictions, avoiding pairwise comparisons.", "result": "CostCert retains up to 57.3% certified accuracy for large patch sizes, while PatchGuard drops to zero.", "conclusion": "CostCert offers a more effective and scalable solution for certified recovery in adversarial patch defense."}}
{"id": "2507.23607", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23607", "abs": "https://arxiv.org/abs/2507.23607", "authors": ["Tien Huu Do", "Antoine Masquelier", "Nae Eoun Lee", "Jonathan Crowther"], "title": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "comment": null, "summary": "Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.", "AI": {"tldr": "A deep learning-based method using pre-trained language models and attention mechanisms predicts clinical trial patient enrollment more accurately than baseline models.", "motivation": "Accurate patient enrollment prediction is critical for clinical trial success but challenging due to complexities in clinical documents and uncertainties.", "method": "Proposes a neural network model combining PLMs for document representation, tabular features via attention, and a Gamma-based probabilistic layer for uncertainty.", "result": "Outperforms baseline models in predicting patient enrollment across sites, validated on real-world clinical trial data.", "conclusion": "The method effectively addresses enrollment prediction challenges, enhancing clinical trial planning."}}
{"id": "2507.23615", "categories": ["cs.LG", "cs.AI", "68T01", "I.5.1; G.3; H.2.8; I.2.1"], "pdf": "https://arxiv.org/pdf/2507.23615", "abs": "https://arxiv.org/abs/2507.23615", "authors": ["Luis Roque", "Carlos Soares", "Vitor Cerqueira", "Luis Torgo"], "title": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "comment": null, "summary": "Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods.", "AI": {"tldr": "L-GTA is a transformer-based generative model for time series augmentation, improving data reliability and predictive accuracy.", "motivation": "Data augmentation is crucial for time series tasks, but existing methods lack control and reliability.", "method": "Uses a transformer-based variational recurrent autoencoder to apply controlled latent-space transformations.", "result": "Produces more reliable and controllable augmented data, enhancing predictive accuracy.", "conclusion": "L-GTA outperforms direct transformation methods in generating high-quality synthetic time series."}}
{"id": "2507.23389", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23389", "abs": "https://arxiv.org/abs/2507.23389", "authors": ["David Komnick", "Kathrin Lammers", "Barbara Hammer", "Valerie Vaquet", "Fabian Hinder"], "title": "Causal Explanation of Concept Drift -- A Truly Actionable Approach", "comment": "This manuscript is accepted to be presented at the TempXAI workshop\n  at the European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECMLPKDD 2025)", "summary": "In a world that constantly changes, it is crucial to understand how those\nchanges impact different systems, such as industrial manufacturing or critical\ninfrastructure. Explaining critical changes, referred to as concept drift in\nthe field of machine learning, is the first step towards enabling targeted\ninterventions to avoid or correct model failures, as well as malfunctions and\nerrors in the physical world. Therefore, in this work, we extend model-based\ndrift explanations towards causal explanations, which increases the\nactionability of the provided explanations. We evaluate our explanation\nstrategy on a number of use cases, demonstrating the practical usefulness of\nour framework, which isolates the causally relevant features impacted by\nconcept drift and, thus, allows for targeted intervention.", "AI": {"tldr": "The paper extends model-based drift explanations to causal explanations to improve actionability in addressing concept drift in systems like manufacturing and infrastructure.", "motivation": "Understanding and explaining concept drift is essential to prevent model failures and physical system malfunctions.", "method": "The work extends model-based drift explanations to causal explanations and evaluates the framework on practical use cases.", "result": "The framework successfully isolates causally relevant features affected by concept drift, enabling targeted interventions.", "conclusion": "Causal explanations enhance the actionability of drift explanations, making them more practical for real-world applications."}}
{"id": "2507.23638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23638", "abs": "https://arxiv.org/abs/2507.23638", "authors": ["Mohammad Karami", "Fatemeh Ghassemi", "Hamed Kebriaei", "Hamid Azadegan"], "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach.", "AI": {"tldr": "OptiGradTrust is a defense framework for Federated Learning (FL) that uses a six-dimensional fingerprint to evaluate gradients and a hybrid RL-attention module for trust scoring. FedBN-Prox addresses data heterogeneity, improving accuracy and convergence. Evaluations show superior performance against Byzantine attacks and non-IID data.", "motivation": "FL is vulnerable to Byzantine attacks and statistical heterogeneity, compromising model integrity and privacy. A robust defense mechanism is needed to ensure secure and efficient collaborative training.", "method": "OptiGradTrust employs a six-dimensional fingerprint (VAE reconstruction error, cosine similarity, $L_2$ norm, sign-consistency ratio, Monte Carlo Shapley value) and a hybrid RL-attention module. FedBN-Prox combines Federated Batch Normalization with proximal regularization.", "result": "The framework outperforms state-of-the-art defenses, achieving up to +1.6 percentage points over FLGuard under non-IID conditions and robust performance against diverse attacks.", "conclusion": "OptiGradTrust and FedBN-Prox provide a secure and efficient solution for FL, addressing both Byzantine attacks and data heterogeneity, with validated improvements in real-world datasets."}}
{"id": "2507.23391", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.23391", "abs": "https://arxiv.org/abs/2507.23391", "authors": ["Tung M. Luu", "Donghoon Lee", "Younghwan Lee", "Chang D. Yoo"], "title": "Policy Learning from Large Vision-Language Model Feedback without Reward Modeling", "comment": "Accepted to IROS 2025", "summary": "Offline reinforcement learning (RL) provides a powerful framework for\ntraining robotic agents using pre-collected, suboptimal datasets, eliminating\nthe need for costly, time-consuming, and potentially hazardous online\ninteractions. This is particularly useful in safety-critical real-world\napplications, where online data collection is expensive and impractical.\nHowever, existing offline RL algorithms typically require reward labeled data,\nwhich introduces an additional bottleneck: reward function design is itself\ncostly, labor-intensive, and requires significant domain expertise. In this\npaper, we introduce PLARE, a novel approach that leverages large\nvision-language models (VLMs) to provide guidance signals for agent training.\nInstead of relying on manually designed reward functions, PLARE queries a VLM\nfor preference labels on pairs of visual trajectory segments based on a\nlanguage task description. The policy is then trained directly from these\npreference labels using a supervised contrastive preference learning objective,\nbypassing the need to learn explicit reward models. Through extensive\nexperiments on robotic manipulation tasks from the MetaWorld, PLARE achieves\nperformance on par with or surpassing existing state-of-the-art VLM-based\nreward generation methods. Furthermore, we demonstrate the effectiveness of\nPLARE in real-world manipulation tasks with a physical robot, further\nvalidating its practical applicability.", "AI": {"tldr": "PLARE introduces a novel offline RL method using vision-language models (VLMs) to bypass manual reward design, achieving competitive performance in robotic tasks.", "motivation": "Offline RL avoids costly online data collection, but existing methods rely on manually designed rewards, which are labor-intensive. PLARE addresses this by using VLMs for preference-based guidance.", "method": "PLARE queries VLMs for preference labels on visual trajectory segments based on task descriptions, training policies directly with a contrastive learning objective, avoiding explicit reward models.", "result": "PLARE matches or surpasses state-of-the-art VLM-based reward methods in MetaWorld tasks and shows effectiveness in real-world robotic manipulation.", "conclusion": "PLARE offers a practical, scalable solution for offline RL by eliminating manual reward design, validated in both simulated and real-world settings."}}
{"id": "2507.23412", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23412", "abs": "https://arxiv.org/abs/2507.23412", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "title": "A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles", "comment": null, "summary": "This paper aims to develop a Machine Learning (ML)-based system for detecting\nhoney adulteration utilizing honey mineral element profiles. The proposed\nsystem comprises two phases: preprocessing and classification. The\npreprocessing phase involves the treatment of missing-value attributes and\nnormalization. In the classifica-tion phase, we use three supervised ML models:\nlogistic regression, decision tree, and random forest, to dis-criminate between\nauthentic and adulterated honey. To evaluate the performance of the ML models,\nwe use a public dataset comprising measurements of mineral element content of\nauthentic honey, sugar syrups, and adul-terated honey. Experimental findings\nshow that mineral element content in honey provides robust discriminative\ninformation for detecting honey adulteration. Results also demonstrate that the\nrandom forest-based classifier outperforms other classifiers on this dataset,\nachieving the highest cross-validation accuracy of 98.37%.", "AI": {"tldr": "ML-based system detects honey adulteration using mineral profiles, with random forest achieving 98.37% accuracy.", "motivation": "To address honey adulteration by leveraging ML and mineral element profiles for detection.", "method": "Two-phase system: preprocessing (missing-value treatment, normalization) and classification (logistic regression, decision tree, random forest).", "result": "Random forest outperforms others with 98.37% accuracy; mineral content is discriminative.", "conclusion": "ML, especially random forest, effectively detects honey adulteration using mineral profiles."}}
{"id": "2507.23771", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23771", "abs": "https://arxiv.org/abs/2507.23771", "authors": ["Justin Kay", "Grant Van Horn", "Subhransu Maji", "Daniel Sheldon", "Sara Beery"], "title": "Consensus-Driven Active Model Selection", "comment": "ICCV 2025 Highlight. 16 pages, 8 figures", "summary": "The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda.", "AI": {"tldr": "CODA is a method for active model selection that reduces annotation effort by prioritizing data points that differentiate the best candidate model, outperforming existing methods by up to 70%.", "motivation": "Traditional model selection requires costly validation datasets; CODA aims to minimize annotation effort by leveraging predictions from candidate models.", "method": "CODA uses a probabilistic framework to model relationships between classifiers, categories, and data points, guiding label acquisition via consensus and disagreement between models.", "result": "CODA reduces annotation effort by over 70% compared to prior methods, validated on 26 benchmark tasks.", "conclusion": "CODA efficiently identifies the best model with minimal labeling, offering a scalable solution for model selection."}}
{"id": "2507.23418", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23418", "abs": "https://arxiv.org/abs/2507.23418", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "title": "Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning", "comment": null, "summary": "In this paper, we propose a system for detecting adulteration in coconut\nmilk, utilizing infrared spectroscopy. The machine learning-based proposed\nsystem comprises three phases: preprocessing, feature extraction, and\nclassification. The first phase involves removing irrelevant data from coconut\nmilk spectral signals. In the second phase, we employ the Linear Discriminant\nAnalysis (LDA) algorithm for extracting the most discriminating features. In\nthe third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut\nmilk samples into authentic or adulterated. We evaluate the performance of the\nproposed system using a public dataset comprising Fourier Transform Infrared\n(FTIR) spectral information of pure and contaminated coconut milk samples.\nFindings show that the proposed method successfully detects adulteration with a\ncross-validation accuracy of 93.33%.", "AI": {"tldr": "A machine learning system using infrared spectroscopy detects coconut milk adulteration with 93.33% accuracy.", "motivation": "To address the issue of adulteration in coconut milk, ensuring product authenticity and safety.", "method": "Three-phase system: preprocessing (data cleaning), feature extraction (LDA), and classification (KNN).", "result": "Achieved 93.33% cross-validation accuracy in detecting adulteration.", "conclusion": "The proposed system is effective for identifying adulterated coconut milk using infrared spectroscopy and machine learning."}}
{"id": "2507.23428", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23428", "abs": "https://arxiv.org/abs/2507.23428", "authors": ["Nodens F. Koren", "Samuel Lanthaler"], "title": "Merging Memory and Space: A Spatiotemporal State Space Neural Operator", "comment": null, "summary": "We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact\narchitecture for learning solution operators of time-dependent partial\ndifferential equations (PDEs). ST-SSM introduces a novel factorization of the\nspatial and temporal dimensions, using structured state-space models to\nindependently model temporal evolution and spatial interactions. This design\nenables parameter efficiency and flexible modeling of long-range spatiotemporal\ndynamics. A theoretical connection is established between SSMs and neural\noperators, and a unified universality theorem is proved for the resulting class\nof architectures. Empirically, we demonstrate that our factorized formulation\noutperforms alternative schemes such as zigzag scanning and parallel\nindependent processing on several PDE benchmarks, including 1D Burgers'\nequation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations\nunder varying physical conditions. Our model performs competitively with\nexisting baselines while using significantly fewer parameters. In addition, our\nresults reinforce previous findings on the benefits of temporal memory by\nshowing improved performance under partial observability. Our results highlight\nthe advantages of dimensionally factorized operator learning for efficient and\ngeneralizable PDE modeling, and put this approach on a firm theoretical\nfooting.", "AI": {"tldr": "ST-SSM is a compact neural operator for time-dependent PDEs, using spatiotemporal factorization for efficiency and performance.", "motivation": "To address the challenge of learning solution operators for time-dependent PDEs efficiently and effectively.", "method": "Introduces a factorization of spatial and temporal dimensions using structured state-space models, enabling parameter efficiency and long-range dynamics modeling.", "result": "Outperforms alternatives on PDE benchmarks, uses fewer parameters, and shows improved performance under partial observability.", "conclusion": "ST-SSM offers efficient, generalizable PDE modeling with strong theoretical and empirical support."}}
{"id": "2507.23437", "categories": ["cs.LG", "I.2.6; C.1.3; C.3"], "pdf": "https://arxiv.org/pdf/2507.23437", "abs": "https://arxiv.org/abs/2507.23437", "authors": ["Yinhui Ma", "Tomomasa Yamasaki", "Zhehui Wang", "Tao Luo", "Bo Wang"], "title": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "comment": "Accepted to ICCAD 2025 (camera-ready); 9 pages, 5 figures", "summary": "Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach\nto automatically co-optimizing neural network performance and hardware energy\nefficiency, making it particularly useful for the development of Deep Neural\nNetwork accelerators on the edge. However, the extensive search space and high\ncomputational cost pose significant challenges to its practical adoption. To\naddress these limitations, we propose Coflex, a novel HW-NAS framework that\nintegrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian\noptimization. By leveraging sparse inducing points, Coflex reduces the GP\nkernel complexity from cubic to near-linear with respect to the number of\ntraining samples, without compromising optimization performance. This enables\nscalable approximation of large-scale search space, substantially decreasing\ncomputational overhead while preserving high predictive accuracy. We evaluate\nthe efficacy of Coflex across various benchmarks, focusing on\naccelerator-specific architecture. Our experi- mental results show that Coflex\noutperforms state-of-the-art methods in terms of network accuracy and\nEnergy-Delay-Product, while achieving a computational speed-up ranging from\n1.9x to 9.5x.", "AI": {"tldr": "Coflex, a novel HW-NAS framework, uses Sparse Gaussian Process and multi-objective Bayesian optimization to efficiently co-optimize neural network performance and hardware energy efficiency, reducing computational costs significantly.", "motivation": "The extensive search space and high computational cost of HW-NAS limit its practical adoption, necessitating a more efficient solution.", "method": "Coflex integrates Sparse Gaussian Process with multi-objective Bayesian optimization, reducing kernel complexity from cubic to near-linear using sparse inducing points.", "result": "Coflex outperforms state-of-the-art methods in accuracy and Energy-Delay-Product, achieving computational speed-ups of 1.9x to 9.5x.", "conclusion": "Coflex offers a scalable and efficient solution for HW-NAS, balancing performance and computational overhead."}}
{"id": "2507.23449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23449", "abs": "https://arxiv.org/abs/2507.23449", "authors": ["Shervin Rahimzadeh Arashloo"], "title": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "comment": null, "summary": "We generalise the recently introduced large-margin $\\ell_p$-SVDD approach to\nexploit the geometry of data distribution via manifold regularising and a\nsignature kernel representation for time series anomaly detection.\nSpecifically, we formulate a manifold-regularised variant of the $\\ell_p$-SVDD\nmethod to encourage label smoothness on the underlying manifold to capture\nstructural information for improved detection performance. Drawing on an\nexisting Representer theorem, we then provide an effective optimisation\ntechnique for the proposed method and show that it can benefit from the\nsignature kernel to capture time series complexities for anomaly detection.\n  We theoretically study the proposed approach using Rademacher complexities to\nanalyse its generalisation performance and also provide an experimental\nassessment of the proposed method across various data sets to compare its\nperformance against other methods.", "AI": {"tldr": "The paper generalizes the large-margin \u2113p-SVDD method with manifold regularization and signature kernels for time series anomaly detection, improving performance by capturing data geometry and complexities.", "motivation": "To enhance anomaly detection in time series by leveraging data distribution geometry and structural information through manifold regularization and signature kernels.", "method": "A manifold-regularized \u2113p-SVDD variant is formulated, optimized using a Representer theorem, and employs signature kernels to handle time series complexities.", "result": "Theoretical analysis via Rademacher complexities and experimental validation show improved detection performance compared to other methods.", "conclusion": "The proposed method effectively combines manifold regularization and signature kernels for superior time series anomaly detection."}}
{"id": "2507.23491", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23491", "abs": "https://arxiv.org/abs/2507.23491", "authors": ["Olga Vershinina", "Jacopo Sabbatinelli", "Anna Rita Bonfigli", "Dalila Colombaretti", "Angelica Giuliani", "Mikhail Krivonosov", "Arseniy Trukhanov", "Claudio Franceschi", "Mikhail Ivanchenko", "Fabiola Olivieri"], "title": "Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus", "comment": null, "summary": "Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent\nnon-communicable chronic disease that substantially reduces life expectancy.\nAccurate estimation of all-cause mortality risk in T2DM patients is crucial for\npersonalizing and optimizing treatment strategies. Research Design and Methods.\nThis study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed\nT2DM over a maximum follow-up period of 16.8 years, during which 202 patients\n(36%) died. Key survival-associated features were identified, and multiple\nmachine learning (ML) models were trained and validated to predict all-cause\nmortality risk. To improve model interpretability, Shapley additive\nexplanations (SHAP) was applied to the best-performing model. Results. The\nextra survival trees (EST) model, incorporating ten key features, demonstrated\nthe best predictive performance. The model achieved a C-statistic of 0.776,\nwith the area under the receiver operating characteristic curve (AUC) values of\n0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause\nmortality predictions, respectively. The SHAP approach was employed to\ninterpret the model's individual decision-making processes. Conclusions. The\ndeveloped model exhibited strong predictive performance for mortality risk\nassessment. Its clinically interpretable outputs enable potential bedside\napplication, improving the identification of high-risk patients and supporting\ntimely treatment optimization.", "AI": {"tldr": "A machine learning model (EST) was developed to predict all-cause mortality in T2DM patients, achieving strong performance and interpretability using SHAP.", "motivation": "Accurate mortality risk estimation in T2DM patients is essential for personalized treatment.", "method": "Analyzed 554 T2DM patients over 16.8 years, identified key features, and trained ML models, with SHAP for interpretability.", "result": "The EST model achieved a C-statistic of 0.776 and high AUC values (0.86-0.826) for mortality prediction.", "conclusion": "The model is clinically interpretable and effective for identifying high-risk T2DM patients, aiding treatment optimization."}}
{"id": "2507.23495", "categories": ["cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23495", "abs": "https://arxiv.org/abs/2507.23495", "authors": ["Maurits Kaptein"], "title": "Incorporating structural uncertainty in causal decision making", "comment": "This work is under review at the Journal of Causal Inference", "summary": "Practitioners making decisions based on causal effects typically ignore\nstructural uncertainty. We analyze when this uncertainty is consequential\nenough to warrant methodological solutions (Bayesian model averaging over\ncompeting causal structures). Focusing on bivariate relationships ($X\n\\rightarrow Y$ vs. $X \\leftarrow Y$), we establish that model averaging is\nbeneficial when: (1) structural uncertainty is moderate to high, (2) causal\neffects differ substantially between structures, and (3) loss functions are\nsufficiently sensitive to the size of the causal effect. We prove optimality\nresults of our suggested methodological solution under regularity conditions\nand demonstrate through simulations that modern causal discovery methods can\nprovide, within limits, the necessary quantification. Our framework complements\nexisting robust causal inference approaches by addressing a distinct source of\nuncertainty typically overlooked in practice.", "AI": {"tldr": "The paper examines when structural uncertainty in causal inference is significant enough to require Bayesian model averaging, identifying key conditions for its benefit.", "motivation": "Practitioners often ignore structural uncertainty in causal inference, potentially leading to flawed decisions. This paper addresses when such uncertainty matters.", "method": "The study focuses on bivariate relationships, using Bayesian model averaging over competing causal structures. It identifies conditions under which this method is beneficial.", "result": "Model averaging is beneficial when structural uncertainty is moderate to high, causal effects vary between structures, and loss functions are sensitive to effect size. Optimality results are proven under regularity conditions.", "conclusion": "The framework addresses a typically overlooked source of uncertainty, complementing robust causal inference methods."}}
{"id": "2507.23501", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.23501", "abs": "https://arxiv.org/abs/2507.23501", "authors": ["Nicklas Werge", "Yi-Shan Wu", "Bahareh Tasdighi", "Melih Kandemir"], "title": "Directional Ensemble Aggregation for Actor-Critics", "comment": null, "summary": "Off-policy reinforcement learning in continuous control tasks depends\ncritically on accurate $Q$-value estimates. Conservative aggregation over\nensembles, such as taking the minimum, is commonly used to mitigate\noverestimation bias. However, these static rules are coarse, discard valuable\ninformation from the ensemble, and cannot adapt to task-specific needs or\ndifferent learning regimes. We propose Directional Ensemble Aggregation (DEA),\nan aggregation method that adaptively combines $Q$-value estimates in\nactor-critic frameworks. DEA introduces two fully learnable directional\nparameters: one that modulates critic-side conservatism and another that guides\nactor-side policy exploration. Both parameters are learned using ensemble\ndisagreement-weighted Bellman errors, which weight each sample solely by the\ndirection of its Bellman error. This directional learning mechanism allows DEA\nto adjust conservatism and exploration in a data-driven way, adapting\naggregation to both uncertainty levels and the phase of training. We evaluate\nDEA across continuous control benchmarks and learning regimes - from\ninteractive to sample-efficient - and demonstrate its effectiveness over static\nensemble strategies.", "AI": {"tldr": "DEA is a dynamic ensemble aggregation method for Q-value estimates in actor-critic frameworks, adapting conservatism and exploration based on data-driven directional parameters.", "motivation": "Static ensemble aggregation rules in off-policy RL are inflexible and discard useful information, limiting adaptability to task needs or training phases.", "method": "DEA introduces learnable directional parameters for critic-side conservatism and actor-side exploration, trained using ensemble disagreement-weighted Bellman errors.", "result": "DEA outperforms static ensemble strategies across continuous control benchmarks and various learning regimes.", "conclusion": "DEA provides a flexible, adaptive solution for Q-value aggregation, improving performance in continuous control tasks."}}
{"id": "2507.23504", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23504", "abs": "https://arxiv.org/abs/2507.23504", "authors": ["Maurits Kaptein"], "title": "A Verifier Hierarchy", "comment": "This paper is primarily relevant to cs.CC, but submitted under cs.ML\n  due to lack of endorsement. The paper is under review at \"Information and\n  Communication\"", "summary": "We investigate the trade-off between certificate length and verifier runtime.\nWe prove a Verifier Trade-off Theorem showing that reducing the inherent\nverification time of a language from \\(f(n)\\) to \\(g(n)\\), where \\(f(n) \\ge\ng(n)\\), requires certificates of length at least \\(\\Omega(\\log(f(n) / g(n)))\\).\nThis theorem induces a natural hierarchy based on certificate complexity. We\ndemonstrate its applicability to analyzing conjectured separations between\ncomplexity classes (e.g., \\(\\np\\) and \\(\\exptime\\)) and to studying natural\nproblems such as string periodicity and rotation detection. Additionally, we\nprovide perspectives on the \\(\\p\\) vs. \\(\\np\\) problem by relating it to the\nexistence of sub-linear certificates.", "AI": {"tldr": "The paper explores the trade-off between certificate length and verifier runtime, proving a theorem that links reduced verification time to longer certificates. It applies this to complexity class separations and problems like string periodicity, offering insights into P vs. NP.", "motivation": "To understand the relationship between certificate length and verifier runtime, and how this impacts complexity theory and problem-solving.", "method": "Proves a Verifier Trade-off Theorem, showing the minimum certificate length required for reduced verification time, and applies it to complexity classes and natural problems.", "result": "Establishes a hierarchy based on certificate complexity and provides insights into conjectured separations between complexity classes and problems like string periodicity.", "conclusion": "The theorem offers a framework for analyzing complexity trade-offs and sheds light on the P vs. NP problem through sub-linear certificates."}}
{"id": "2507.23512", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.23512", "abs": "https://arxiv.org/abs/2507.23512", "authors": ["Saleh Vatan Khah", "Savelii Chezhegov", "Shahrokh Farahmand", "Samuel Horv\u00e1th", "Eduard Gorbunov"], "title": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "comment": "60 pages", "summary": "Gradient clipping is a fundamental tool in Deep Learning, improving the\nhigh-probability convergence of stochastic first-order methods like SGD,\nAdaGrad, and Adam under heavy-tailed noise, which is common in training large\nlanguage models. It is also a crucial component of Differential Privacy (DP)\nmechanisms. However, existing high-probability convergence analyses typically\nrequire the clipping threshold to increase with the number of optimization\nsteps, which is incompatible with standard DP mechanisms like the Gaussian\nmechanism. In this work, we close this gap by providing the first\nhigh-probability convergence analysis for DP-Clipped-SGD with a fixed clipping\nlevel, applicable to both convex and non-convex smooth optimization under\nheavy-tailed noise, characterized by a bounded central $\\alpha$-th moment\nassumption, $\\alpha \\in (1,2]$. Our results show that, with a fixed clipping\nlevel, the method converges to a neighborhood of the optimal solution with a\nfaster rate than the existing ones. The neighborhood can be balanced against\nthe noise introduced by DP, providing a refined trade-off between convergence\nspeed and privacy guarantees.", "AI": {"tldr": "The paper provides the first high-probability convergence analysis for DP-Clipped-SGD with a fixed clipping level, showing improved convergence rates under heavy-tailed noise.", "motivation": "Existing analyses require increasing clipping thresholds, conflicting with standard DP mechanisms like the Gaussian mechanism. This work bridges the gap by analyzing fixed clipping levels.", "method": "The study analyzes DP-Clipped-SGD with a fixed clipping level for convex and non-convex smooth optimization under heavy-tailed noise (bounded central \u03b1-th moment).", "result": "The method converges to a neighborhood of the optimal solution faster than prior work, balancing convergence speed and privacy guarantees.", "conclusion": "Fixed clipping levels in DP-Clipped-SGD offer a refined trade-off between convergence and privacy, advancing practical DP implementations."}}
{"id": "2507.23534", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23534", "abs": "https://arxiv.org/abs/2507.23534", "authors": ["Chih-Fan Hsu", "Ming-Ching Chang", "Wei-Chao Chen"], "title": "Continual Learning with Synthetic Boundary Experience Blending", "comment": null, "summary": "Continual learning (CL) aims to address catastrophic forgetting in models\ntrained sequentially on multiple tasks. While experience replay has shown\npromise, its effectiveness is often limited by the sparse distribution of\nstored key samples, leading to overly simplified decision boundaries. We\nhypothesize that introducing synthetic data near the decision boundary\n(Synthetic Boundary Data, or SBD) during training serves as an implicit\nregularizer, improving boundary stability and mitigating forgetting. To\nvalidate this hypothesis, we propose a novel training framework, {\\bf\nExperience Blending}, which integrates knowledge from both stored key samples\nand synthetic, boundary-adjacent data. Experience blending consists of two core\ncomponents: (1) a multivariate Differential Privacy (DP) noise mechanism that\ninjects batch-wise noise into low-dimensional feature representations,\ngenerating SBD; and (2) an end-to-end training strategy that jointly leverages\nboth stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100,\nand Tiny ImageNet demonstrate that our method outperforms nine CL baselines,\nachieving accuracy improvements of 10%, 6%, and 13%, respectively.", "AI": {"tldr": "A novel continual learning method, Experience Blending, uses synthetic boundary data (SBD) and stored key samples to mitigate catastrophic forgetting, outperforming baselines by 10-13% in accuracy.", "motivation": "Address catastrophic forgetting in continual learning by improving decision boundary stability with synthetic data.", "method": "Proposes Experience Blending: (1) DP noise for SBD generation, (2) joint training with stored samples and SBD.", "result": "Outperforms 9 baselines on CIFAR-10, CIFAR-100, and Tiny ImageNet with accuracy gains of 10%, 6%, and 13%.", "conclusion": "Experience Blending effectively mitigates forgetting by leveraging synthetic boundary data and stored samples."}}
{"id": "2507.23539", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.23539", "abs": "https://arxiv.org/abs/2507.23539", "authors": ["Piotr Indyk", "Michael Kapralov", "Kshiteej Sheth", "Tal Wagner"], "title": "Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions", "comment": "Published in ICLR 2025", "summary": "Motivated by the problem of fast processing of attention matrices, we study\nfast algorithms for computing matrix-vector products for asymmetric Gaussian\nKernel matrices $K\\in \\mathbb{R}^{n\\times n}$. $K$'s columns are indexed by a\nset of $n$ keys $k_1,k_2\\ldots, k_n\\in \\mathbb{R}^d$, rows by a set of $n$\nqueries $q_1,q_2,\\ldots,q_n\\in \\mathbb{R}^d $, and its $i,j$ entry is $K_{ij} =\ne^{-\\|q_i-k_j\\|_2^2/2\\sigma^2}$ for some bandwidth parameter $\\sigma>0$. Given\na vector $x\\in \\mathbb{R}^n$ and error parameter $\\epsilon>0$, our task is to\noutput a $y\\in \\mathbb{R}^n$ such that $\\|Kx-y\\|_2\\leq \\epsilon \\|x\\|_2$ in\ntime subquadratic in $n$ and linear in $d$. Our algorithms rely on the\nfollowing modelling assumption about the matrices $K$: the sum of the entries\nof $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We\nvalidate this assumption experimentally, for Gaussian kernel matrices\nencountered in various settings such as fast attention computation in LLMs. We\nobtain the first subquadratic-time algorithm that works under this assumption,\nfor unrestricted vectors.", "AI": {"tldr": "The paper introduces a subquadratic-time algorithm for computing matrix-vector products with asymmetric Gaussian Kernel matrices, validated by experimental results.", "motivation": "The need for fast processing of attention matrices, particularly in applications like LLMs, drives the study of efficient algorithms for matrix-vector products with Gaussian Kernel matrices.", "method": "The algorithm leverages a modelling assumption that the sum of matrix entries scales linearly in n, enabling subquadratic-time computation for unrestricted vectors.", "result": "The proposed algorithm achieves the first subquadratic-time solution under the given assumption, with experimental validation.", "conclusion": "The work provides a practical and efficient solution for fast attention computation, validated in real-world settings."}}
{"id": "2507.23562", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.23562", "abs": "https://arxiv.org/abs/2507.23562", "authors": ["Sirine Arfa", "Bernhard Vogginger", "Christian Mayr"], "title": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "comment": "8 pages, 5 figures, 3 tables", "summary": "Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning.", "AI": {"tldr": "The paper presents an energy-efficient SNN-based RL implementation for control tasks, achieving 32x lower energy consumption on SpiNNaker2 compared to GPUs, with competitive latency.", "motivation": "To leverage SNNs for low-power, low-latency RL on neuromorphic hardware, addressing energy efficiency in robotic tasks.", "method": "Quantized SNNs trained via Q-learning, fine-tuned for 8-bit precision, and deployed on SpiNNaker2. Performance compared to a GTX 1650 GPU.", "result": "SpiNNaker2 reduces energy consumption by 32x, maintains competitive latency, and shows potential for real-time neuromorphic control.", "conclusion": "SpiNNaker2 is viable for efficient deep Q-learning, offering scalable, low-energy neuromorphic computing."}}
{"id": "2507.23568", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.23568", "abs": "https://arxiv.org/abs/2507.23568", "authors": ["Fernando Mart\u00ednez-Garc\u00eda", "\u00c1lvaro Rubio-Garc\u00eda", "Samuel Fern\u00e1ndez-Lorenzo", "Juan Jos\u00e9 Garc\u00eda-Ripoll", "Diego Porras"], "title": "Optimised Feature Subset Selection via Simulated Annealing", "comment": "12 pages, 2 figures", "summary": "We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.23581", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23581", "abs": "https://arxiv.org/abs/2507.23581", "authors": ["Chuanyue Yu", "Kuo Zhao", "Yuhan Li", "Heng Chang", "Mingjian Feng", "Xiangzhe Jiang", "Yufei Sun", "Jia Li", "Yuzhi Zhang", "Jianxin Li", "Ziwei Zhang"], "title": "GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning", "comment": null, "summary": "Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness\nin enhancing the reasoning abilities of LLMs by leveraging graph structures for\nknowledge representation and modeling complex real-world relationships.\nHowever, existing GraphRAG methods still face significant bottlenecks when\nhandling complex problems that require multi-hop reasoning, as their query and\nretrieval phases are largely based on pre-defined heuristics and do not fully\nutilize the reasoning potentials of LLMs. To address this problem, we propose\nGraphRAG-R1, an adaptive GraphRAG framework by training LLMs with\nprocess-constrained outcome-based reinforcement learning (RL) to enhance the\nmulti-hop reasoning ability. Our method can decompose complex problems,\nautonomously invoke retrieval tools to acquire necessary information, and\nperform effective reasoning. Specifically, we utilize a modified version of\nGroup Relative Policy Optimization (GRPO) that supports rollout-with-thinking\ncapability. Next, we design two process-constrained reward functions. To handle\nthe shallow retrieval problem, we design a Progressive Retrieval Attenuation\n(PRA) reward to encourage essential retrievals. Then, to handle the\nover-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the\nmodel performance with computational costs. We further design a phase-dependent\ntraining strategy, containing three training stages corresponding to cold start\nand these two rewards. Lastly, our method adopts a hybrid graph-textual\nretrieval to improve the reasoning capacity. Extensive experimental results\ndemonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex\nreasoning problems compared to state-of-the-art GraphRAG methods on both\nin-domain and out-of-domain datasets. Furthermore, our framework can be\nflexibly integrated with various existing retrieval methods, consistently\ndelivering performance improvements.", "AI": {"tldr": "GraphRAG-R1 enhances multi-hop reasoning in LLMs using adaptive reinforcement learning, addressing retrieval and over-thinking issues with novel rewards and hybrid retrieval.", "motivation": "Existing GraphRAG methods struggle with multi-hop reasoning due to heuristic-based retrieval and underutilized LLM reasoning potential.", "method": "Proposes GraphRAG-R1 with process-constrained RL (modified GRPO), PRA and CAF rewards, phase-dependent training, and hybrid graph-textual retrieval.", "result": "Outperforms state-of-the-art GraphRAG methods on in-domain and out-of-domain datasets, with flexible integration into existing retrieval methods.", "conclusion": "GraphRAG-R1 effectively boosts LLM reasoning for complex problems, offering adaptable and scalable improvements."}}
{"id": "2507.23600", "categories": ["cs.LG", "cs.CE", "G.1.6; G.3; G.4; I.6.5"], "pdf": "https://arxiv.org/pdf/2507.23600", "abs": "https://arxiv.org/abs/2507.23600", "authors": ["Yu-Tang Chang", "Shih-Fang Chen"], "title": "EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution", "comment": null, "summary": "Signal unmixing analysis decomposes data into basic patterns and is widely\napplied in chemical and biological research. Multivariate curve resolution\n(MCR), a branch of signal unmixing, separates mixed chemical signals into base\npatterns (components) and their concentrations, playing a key role in\nunderstanding composition. Classical MCR is typically framed as matrix\nfactorization (MF) and requires a user-specified component count, usually\nunknown in real data. As dataset size or component count increases, the\nscalability and reliability of MF-based MCR face significant challenges. This\nstudy reformulates MCR as a generative process (gMCR), and introduces an\nenergy-based deep learning solver, EB-gMCR, that automatically discovers the\nsmallest component set able to reconstruct the data faithfully. EB-gMCR starts\nfrom a large candidate pool (e.g., 1024 spectra) and employs a differentiable\ngating network to retain only active components while estimating their\nconcentrations. On noisy synthetic datasets containing up to 256 latent\nsources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count\nwithin 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near\nexact component estimation. Additional chemical priors, such as non-negativity\nor nonlinear mixing, enter as simple plug-in functions, enabling adaptation to\nother instruments or domains without altering the core learning process. By\nuniting high-capacity generative modeling and hard component selection, EB-gMCR\noffers a practical route to large-scale signal unmixing analysis, including\nchemical library-driven scenarios. The source code is available at\nhttps://github.com/b05611038/ebgmcr_solver.", "AI": {"tldr": "The paper introduces EB-gMCR, a deep learning-based method for signal unmixing, automating component discovery and improving scalability and reliability over traditional matrix factorization approaches.", "motivation": "Classical MCR methods require manual component count specification and struggle with scalability and reliability for large datasets or high component counts.", "method": "The study reformulates MCR as a generative process (gMCR) and uses an energy-based deep learning solver (EB-gMCR) to automatically find the smallest component set for faithful data reconstruction.", "result": "EB-gMCR achieved high accuracy (R^2 >= 0.98) on noisy synthetic datasets with up to 256 sources, recovering component counts within 5% of ground truth.", "conclusion": "EB-gMCR combines generative modeling and component selection, offering a scalable and adaptable solution for large-scale signal unmixing."}}
{"id": "2507.23604", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23604", "abs": "https://arxiv.org/abs/2507.23604", "authors": ["Tommaso Marzi", "Cesare Alippi", "Andrea Cini"], "title": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning", "comment": null, "summary": "Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art.", "AI": {"tldr": "Proposes a novel method combining hierarchical reinforcement learning (HRL) and message-passing for decentralized MARL to address partial observability and non-stationarity.", "motivation": "Address challenges in decentralized MARL like partial observability and non-stationarity by integrating coordination and temporal abstraction.", "method": "Uses feudal HRL and hierarchical graph structure for planning. Lower-level agents follow upper-level goals and exchange messages. Novel reward-assignment method trains lower-level policies.", "result": "Outperforms state-of-the-art methods on benchmarks.", "conclusion": "The combination of HRL and message-passing is effective for scalable multi-agent policies."}}
{"id": "2507.23632", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23632", "abs": "https://arxiv.org/abs/2507.23632", "authors": ["Gabriel Mongaras", "Eric C. Larson"], "title": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective", "comment": null, "summary": "Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts.", "AI": {"tldr": "The paper explains why softmax attention outperforms linear attention by analyzing it as an RNN, revealing the importance of its components.", "motivation": "To understand why softmax attention, despite its quadratic complexity, is more expressive than linear attention methods.", "method": "Derives softmax attention's recurrent form, treating it as an RNN to analyze its components and their interactions.", "result": "Identifies the expressive power of softmax attention by dissecting its RNN-like structure.", "conclusion": "Softmax attention's components, when analyzed as an RNN, explain its superior performance over linear attention."}}
{"id": "2507.23665", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23665", "abs": "https://arxiv.org/abs/2507.23665", "authors": ["Amal Saadallah"], "title": "SHAP-Guided Regularization in Machine Learning Models", "comment": null, "summary": "Feature attribution methods such as SHapley Additive exPlanations (SHAP) have\nbecome instrumental in understanding machine learning models, but their role in\nguiding model optimization remains underexplored. In this paper, we propose a\nSHAP-guided regularization framework that incorporates feature importance\nconstraints into model training to enhance both predictive performance and\ninterpretability. Our approach applies entropy-based penalties to encourage\nsparse, concentrated feature attributions while promoting stability across\nsamples. The framework is applicable to both regression and classification\ntasks. Our first exploration started with investigating a tree-based model\nregularization using TreeSHAP. Through extensive experiments on benchmark\nregression and classification datasets, we demonstrate that our method improves\ngeneralization performance while ensuring robust and interpretable feature\nattributions. The proposed technique offers a novel, explainability-driven\nregularization approach, making machine learning models both more accurate and\nmore reliable.", "AI": {"tldr": "A SHAP-guided regularization framework is proposed to improve model performance and interpretability by incorporating feature importance constraints during training.", "motivation": "To enhance predictive performance and interpretability of machine learning models by leveraging SHAP feature attributions for optimization.", "method": "Introduces entropy-based penalties to encourage sparse, stable feature attributions, applicable to regression and classification tasks, starting with TreeSHAP for tree-based models.", "result": "Improves generalization performance and ensures robust, interpretable feature attributions in benchmark datasets.", "conclusion": "The framework provides an explainability-driven regularization approach, making models more accurate and reliable."}}
{"id": "2507.23674", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23674", "abs": "https://arxiv.org/abs/2507.23674", "authors": ["Muhammad Taha Cheema", "Abeer Aamir", "Khawaja Gul Muhammad", "Naveed Anwar Bhatti", "Ihsan Ayyub Qazi", "Zafar Ayyub Qazi"], "title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "comment": "13 pages, 9 figures", "summary": "Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.", "AI": {"tldr": "TweakLLM introduces a lightweight LLM to dynamically adapt cached responses, improving cache effectiveness without compromising response quality.", "motivation": "Efficient response caching in LLMs is challenging due to personalized interactions and limited semantic similarity accuracy.", "method": "TweakLLM uses a lightweight LLM to dynamically tweak cached responses for incoming prompts.", "result": "TweakLLM maintains response quality comparable to frontier models while significantly improving cache effectiveness.", "conclusion": "TweakLLM is a scalable, resource-efficient caching solution for high-volume LLM deployments."}}
{"id": "2507.23675", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23675", "abs": "https://arxiv.org/abs/2507.23675", "authors": ["Tianyi Chen", "Haitong Ma", "Na Li", "Kai Wang", "Bo Dai"], "title": "One-Step Flow Policy Mirror Descent", "comment": null, "summary": "Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference.", "AI": {"tldr": "FPMD enables 1-step sampling in RL, improving responsiveness without extra training, matching diffusion policy performance with fewer evaluations.", "motivation": "Diffusion policies in RL are expressive but slow due to iterative sampling. FPMD aims to address this limitation.", "method": "FPMD leverages flow matching models for 1-step sampling, using flow policy and MeanFlow policy variants.", "result": "FPMD matches diffusion policy performance on MuJoCo benchmarks with significantly fewer function evaluations.", "conclusion": "FPMD offers a faster, efficient alternative to diffusion policies in online RL without compromising performance."}}
{"id": "2507.23676", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23676", "abs": "https://arxiv.org/abs/2507.23676", "authors": ["Rabeya Tus Sadia", "Qiang Cheng"], "title": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "comment": null, "summary": "Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation.", "AI": {"tldr": "DepMicroDiff, a diffusion-based framework with Dependency-Aware Transformer, outperforms existing methods in microbiome data imputation by leveraging metadata and capturing microbial dependencies.", "motivation": "Microbiome data's sparsity and noise hinder accurate imputation, limiting downstream tasks like biomarker discovery. Existing methods miss microbial interdependencies and contextual metadata.", "method": "Combines diffusion-based generative modeling with a Dependency-Aware Transformer (DAT), enhanced by VAE pretraining and metadata conditioning via an LLM.", "result": "Achieves higher Pearson correlation (0.712), cosine similarity (0.812), and lower RMSE/MAE on TCGA datasets, showing robustness across cancer types.", "conclusion": "DepMicroDiff is a robust, generalizable solution for microbiome imputation, outperforming state-of-the-art methods."}}
{"id": "2507.23712", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23712", "abs": "https://arxiv.org/abs/2507.23712", "authors": ["Aymane Abdali", "Bartosz Boguslawski", "Lucas Drumetz", "Vincent Gripon"], "title": "Anomalous Samples for Few-Shot Anomaly Detection", "comment": null, "summary": "Several anomaly detection and classification methods rely on large amounts of\nnon-anomalous or \"normal\" samples under the assump- tion that anomalous data is\ntypically harder to acquire. This hypothesis becomes questionable in Few-Shot\nsettings, where as little as one anno- tated sample can make a significant\ndifference. In this paper, we tackle the question of utilizing anomalous\nsamples in training a model for bi- nary anomaly classification. We propose a\nmethodology that incorporates anomalous samples in a multi-score anomaly\ndetection score leveraging recent Zero-Shot and memory-based techniques. We\ncompare the utility of anomalous samples to that of regular samples and study\nthe benefits and limitations of each. In addition, we propose an\naugmentation-based validation technique to optimize the aggregation of the\ndifferent anomaly scores and demonstrate its effectiveness on popular\nindustrial anomaly detection datasets.", "AI": {"tldr": "The paper explores using anomalous samples in few-shot settings for binary anomaly classification, proposing a multi-score method and augmentation-based validation.", "motivation": "Anomalous data is often scarce, but even a few samples can be valuable. The study questions the reliance on normal samples and investigates leveraging anomalies for better classification.", "method": "Proposes a multi-score anomaly detection method combining Zero-Shot and memory-based techniques, with augmentation-based validation for score optimization.", "result": "Demonstrates the effectiveness of anomalous samples in training and validates the proposed method on industrial datasets.", "conclusion": "Anomalous samples can significantly improve anomaly classification, especially in few-shot settings, with the proposed method showing promise."}}
{"id": "2507.23756", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.23756", "abs": "https://arxiv.org/abs/2507.23756", "authors": ["Diana Mortagua"], "title": "Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System", "comment": "Master's thesis", "summary": "This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL.", "AI": {"tldr": "The paper proposes a Knowledge-Based Recommendation System (RS) for Active Learning (AL) that selects annotators based on past accuracy, mood, and fatigue levels to reduce annotation errors and improve model performance.", "motivation": "The study aims to address the gap in AL strategies by considering internal human factors (mood, fatigue) that influence annotator performance, which are often overlooked in existing methods.", "method": "The paper introduces an RS that ranks annotators using past accuracy, mood, and fatigue levels, along with query instance information, to optimize query-annotator pairs.", "result": "The proposed approach reduces annotation errors and model uncertainty, with improved accuracy and F1-scores compared to methods ignoring internal factors.", "conclusion": "The study highlights the importance of human cognitive factors in AL and demonstrates the effectiveness of integrating them into annotator selection strategies."}}
