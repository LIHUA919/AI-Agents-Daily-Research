<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2511.11788)
*Antonio Sabbatella*

Main category: cs.MA

TL;DR: MALBO is a Bayesian optimization framework that automates efficient LLM team composition, finding Pareto-optimal configurations balancing performance and cost, achieving up to 65.8% cost reduction while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Current optimization methods focus on single-agent settings and lack a principled framework for the multi-agent, multi-objective problem of assigning LLMs to specialized roles, which involves vast combinatorial search space and expensive evaluations.

Method: Formalizes assignment as multi-objective optimization problem, uses multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models, searches over continuous feature-space representation of LLMs guided by expected hypervolume improvement.

Result: Bayesian optimization maintained comparable average performance while reducing average configuration cost by over 45% compared to random search. Identified heterogeneous teams achieving up to 65.8% cost reduction compared to homogeneous baselines while maintaining maximum performance.

Conclusion: MALBO provides a principled, automated methodology that yields Pareto-optimal team configurations, offering a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.

Abstract: The optimal assignment of Large Language Models (LLMs) to specialized roles in multi-agent systems is a significant challenge, defined by a vast combinatorial search space, expensive black-box evaluations, and an inherent trade-off between performance and cost. Current optimization methods focus on single-agent settings and lack a principled framework for this multi-agent, multi-objective problem.
  This thesis introduces MALBO (Multi-Agent LLM Bayesian Optimization), a systematic framework designed to automate the efficient composition of LLM-based agent teams. We formalize the assignment challenge as a multi-objective optimization problem, aiming to identify the Pareto front of configurations between task accuracy and inference cost. The methodology employs multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models. By searching over a continuous feature-space representation of the LLMs, this approach performs a sample-efficient exploration guided by the expected hypervolume improvement.
  The primary contribution is a principled and automated methodology that yields a Pareto front of optimal team configurations. Our results demonstrate that the Bayesian optimization phase, compared to an initial random search, maintained a comparable average performance while reducing the average configuration cost by over 45%. Furthermore, MALBO identified specialized, heterogeneous teams that achieve cost reductions of up to 65.8% compared to homogeneous baselines, all while maintaining maximum performance. The framework thus provides a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.

</details>


### [2] [From Single to Societal: Analyzing Persona-Induced Bias in Multi-Agent Interactions](https://arxiv.org/abs/2511.11789)
*Jiayi Li,Xiao Liu,Yansong Feng*

Main category: cs.MA

TL;DR: Personas in LLM-based multi-agent systems introduce biases in trustworthiness and insistence, with historically advantaged groups perceived as less trustworthy and showing less insistence, plus significant in-group favoritism.


<details>
  <summary>Details</summary>
Motivation: To investigate whether assigning personas to LLM-based agents introduces biases in multi-agent interactions, particularly regarding social traits like trustworthiness and insistence.

Method: Conducted controlled experiments in collaborative problem-solving and persuasion tasks across various LLMs, group sizes, and interaction rounds.

Result: Found that personas from historically advantaged groups (men, White individuals) are perceived as less trustworthy and demonstrate less insistence, and agents show significant in-group favoritism by conforming more to same-persona agents.

Conclusion: Persona-induced biases persist across different conditions, highlighting an urgent need for awareness and mitigation to ensure fairness and reliability in multi-agent systems.

Abstract: Large Language Model (LLM)-based multi-agent systems are increasingly used to simulate human interactions and solve collaborative tasks. A common practice is to assign agents with personas to encourage behavioral diversity. However, this raises a critical yet underexplored question: do personas introduce biases into multi-agent interactions? This paper presents a systematic investigation into persona-induced biases in multi-agent interactions, with a focus on social traits like trustworthiness (how an agent's opinion is received by others) and insistence (how strongly an agent advocates for its opinion). Through a series of controlled experiments in collaborative problem-solving and persuasion tasks, we reveal that (1) LLM-based agents exhibit biases in both trustworthiness and insistence, with personas from historically advantaged groups (e.g., men and White individuals) perceived as less trustworthy and demonstrating less insistence; and (2) agents exhibit significant in-group favoritism, showing a higher tendency to conform to others who share the same persona. These biases persist across various LLMs, group sizes, and numbers of interaction rounds, highlighting an urgent need for awareness and mitigation to ensure the fairness and reliability of multi-agent systems.

</details>


### [3] [Conflict-Free Flight Scheduling Using Strategic Demand Capacity Balancing for Urban Air Mobility Operations](https://arxiv.org/abs/2511.11854)
*Vahid Hemmati,Yonas Ayalew,Ahmad Mohammadi,Reza Ahmari,Parham Kebria,Abdollah Homaifar,Mehrdad Saif*

Main category: cs.MA

TL;DR: Proposes a conflict-free multi-agent flight scheduling method using delayed departures and kinematic principles to ensure safe separation in constrained airspace for Urban Air Mobility operations.


<details>
  <summary>Details</summary>
Motivation: To address the need for robust separation in constrained airspace for Urban Air Mobility (UAM) operations, particularly as traffic densities increase in emerging urban air mobility systems.

Method: Introduces Pairwise Conflict Avoidance (PCA) based on delayed departures using kinematic principles, then expands to multi-agent scenarios with an optimization approach that systematically determines departure times under increasing traffic densities.

Result: Numerical simulations across diverse multi-agent environments and real-world UAM use cases demonstrate significant reduction in total delay while ensuring collision-free operations.

Conclusion: The approach provides a scalable framework for emerging urban air mobility systems, effectively reducing delays while maintaining safety through systematic departure time optimization.

Abstract: In this paper, we propose a conflict-free multi- agent flight scheduling that ensures robust separation in con- strained airspace for Urban Air Mobility (UAM) operations application. First, we introduce Pairwise Conflict Avoidance (PCA) based on delayed departures, leveraging kinematic principles to maintain safe distances. Next, we expand PCA to multi-agent scenarios, formulating an optimization approach that systematically determines departure times under increasing traffic densities. Performance metrics, such as average delay, assess the effectiveness of our solution. Through numerical simulations across diverse multi-agent environments and real- world UAM use cases, our method demonstrates a significant reduction in total delay while ensuring collision-free operations. This approach provides a scalable framework for emerging urban air mobility systems.

</details>
