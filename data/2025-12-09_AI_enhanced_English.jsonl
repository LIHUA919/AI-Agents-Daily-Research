{"id": "2512.05983", "categories": ["cs.MA", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.05983", "abs": "https://arxiv.org/abs/2512.05983", "authors": ["Eyal Briman", "Ehud Shapiro", "Nimrod Talmon"], "title": "AI-Generated Compromises for Coalition Formation: Modeling, Simulation, and a Textual Case Study", "comment": "In Proceedings TARK 2025, arXiv:2511.20540. arXiv admin note: substantial text overlap with arXiv:2506.06837", "summary": "The challenge of finding compromises between agent proposals is fundamental to AI sub-fields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. The crucial step in this iterative process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals, however, remains an open question. We address this gap by formalizing a holistic model that encompasses agent bounded rationality and uncertainty and developing AI models to generate such compromise proposals. We focus on the domain of collaboratively writing text documents -- e.g., to enable the democratic creation of a community constitution. We apply NLP (Natural Language Processing) techniques and utilize LLMs (Large Language Models) to create a semantic metric space for text and develop algorithms to suggest suitable compromise points. To evaluate the effectiveness of our algorithms, we simulate various coalition formation processes and demonstrate the potential of AI to facilitate large-scale democratic text editing, such as collaboratively drafting a constitution, an area where traditional tools are limited.", "AI": {"tldr": "AI-driven approach for finding compromise proposals in multi-agent coalition formation, specifically applied to collaborative text document editing using NLP and LLMs", "motivation": "The challenge of finding compromises between agent proposals is fundamental in AI fields like argumentation and negotiation, but effectively identifying compromise proposals remains an open question", "method": "Formalize holistic model encompassing agent bounded rationality and uncertainty, develop AI models using NLP techniques and LLMs to create semantic metric space for text, design algorithms for compromise proposal generation", "result": "Algorithms successfully simulate coalition formation processes and demonstrate AI's potential for large-scale democratic text editing tasks like constitution drafting", "conclusion": "AI models can effectively facilitate compromise finding in collaborative text editing, overcoming limitations of traditional tools in democratic document creation"}}
{"id": "2512.06432", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.06432", "abs": "https://arxiv.org/abs/2512.06432", "authors": ["Yihan Xia", "Taotao Wang", "Shengli Zhang", "Zhangyuhua Weng", "Bin Cao", "Soung Chang Liew"], "title": "HiveMind: Contribution-Guided Online Prompt Optimization of LLM Multi-Agent Systems", "comment": "This paper was accepted to AAAI2026", "summary": "Recent advances in LLM-based multi-agent systems have demonstrated remarkable capabilities in complex decision-making scenarios such as financial trading and software engineering. However, evaluating each individual agent's effectiveness and online optimization of underperforming agents remain open challenges. To address these issues, we present HiveMind, a self-adaptive framework designed to optimize LLM multi-agent collaboration through contribution analysis. At its core, HiveMind introduces Contribution-Guided Online Prompt Optimization (CG-OPO), which autonomously refines agent prompts based on their quantified contributions. We first propose the Shapley value as a grounded metric to quantify each agent's contribution, thereby identifying underperforming agents in a principled manner for automated prompt refinement. To overcome the computational complexity of the classical Shapley value, we present DAG-Shapley, a novel and efficient attribution algorithm that leverages the inherent Directed Acyclic Graph structure of the agent workflow to axiomatically prune non-viable coalitions. By hierarchically reusing intermediate outputs of agents in the DAG, our method further reduces redundant computations, and achieving substantial cost savings without compromising the theoretical guarantees of Shapley values. Evaluated in a multi-agent stock-trading scenario, HiveMind achieves superior performance compared to static baselines. Notably, DAG-Shapley reduces LLM calls by over 80\\% while maintaining attribution accuracy comparable to full Shapley values, establishing a new standard for efficient credit assignment and enabling scalable, real-world optimization of multi-agent collaboration.", "AI": {"tldr": "HiveMind framework optimizes LLM multi-agent collaboration using novel DAG-Shapley method for efficient contribution analysis and prompt optimization.", "motivation": "Existing LLM-based multi-agent systems lack effective methods to evaluate individual agent effectiveness and optimize underperforming agents online.", "method": "Proposes Contribution-Guided Online Prompt Optimization (CG-OPO) using Shapley values and introduces DAG-Shapley - an efficient algorithm that leverages Directed Acyclic Graph structure of agent workflows to reduce computational complexity.", "result": "HiveMind achieves superior performance in multi-agent stock-trading scenarios, with DAG-Shapley reducing LLM calls by over 80% while maintaining attribution accuracy comparable to full Shapley values.", "conclusion": "The framework establishes a new standard for efficient credit assignment, enabling scalable, real-world optimization of multi-agent collaboration through automated prompt refinement based on quantified contributions."}}
{"id": "2512.06595", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06595", "abs": "https://arxiv.org/abs/2512.06595", "authors": ["Joe Shymanski"], "title": "ChargingBoul: A Competitive Negotiating Agent with Novel Opponent Modeling", "comment": "10 pages, 3 figures. Describes the ChargingBoul negotiating agent submitted to ANAC 2022. Preprint", "summary": "Automated negotiation has emerged as a critical area of research in multiagent systems, with applications spanning e-commerce, resource allocation, and autonomous decision-making. This paper presents ChargingBoul, a negotiating agent that competed in the 2022 Automated Negotiating Agents Competition (ANAC) and placed second in individual utility by an exceptionally narrow margin. ChargingBoul employs a lightweight yet effective strategy that balances concession and opponent modeling to achieve high negotiation outcomes. The agent classifies opponents based on bid patterns, dynamically adjusts its bidding strategy, and applies a concession policy in later negotiation stages to maximize utility while fostering agreements. We evaluate ChargingBoul's performance using competition results and subsequent studies that have utilized the agent in negotiation research. Our analysis highlights ChargingBoul's effectiveness across diverse opponent strategies and its contributions to advancing automated negotiation techniques. We also discuss potential enhancements, including more sophisticated opponent modeling and adaptive bidding heuristics, to improve its performance further.", "AI": {"tldr": "ChargingBoul negotiating agent placed 2nd in ANAC 2022 using lightweight strategy balancing concession and opponent modeling", "motivation": "Advance automated negotiation in multiagent systems for e-commerce, resource allocation, and autonomous decision-making", "method": "Classifies opponents based on bid patterns, dynamically adjusts bidding strategy, applies concession policy in later stages", "result": "Achieved high negotiation outcomes and second place in competition by narrow margin", "conclusion": "Agent demonstrates effectiveness across diverse strategies, with potential enhancements through improved opponent modeling and adaptive heuristics"}}
{"id": "2512.06645", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.06645", "abs": "https://arxiv.org/abs/2512.06645", "authors": ["Muyang Fan"], "title": "Analyzing Collision Rates in Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Vehicle collisions remain a major challenge in large-scale mixed traffic systems, especially when human-driven vehicles (HVs) and robotic vehicles (RVs) interact under dynamic and uncertain conditions. Although Multi-Agent Reinforcement Learning (MARL) offers promising capabilities for traffic signal control, ensuring safety in such environments remains difficult. As a direct indicator of traffic risk, the collision rate must be well understood and incorporated into traffic control design. This study investigates the primary factors influencing collision rates in a MARL-governed Mixed Traffic Control (MTC) network. We examine three dimensions: total vehicle count, signalized versus unsignalized intersection configurations, and turning-movement strategies. Through controlled simulation experiments, we evaluate how each factor affects collision likelihood. The results show that collision rates are sensitive to traffic density, the level of signal coordination, and turning-control design. These findings provide practical insights for improving the safety and robustness of MARL-based mixed traffic control systems, supporting the development of intelligent transportation systems in which both efficiency and safety are jointly optimized.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.05989", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.05989", "abs": "https://arxiv.org/abs/2512.05989", "authors": ["Selma Dahms", "Luca Torresi", "Shahbaz Tareq Bandesha", "Jan Hansmann", "Holger R\u00f6hm", "Alexander Colsmann", "Marco Schott", "Pascal Friederich"], "title": "A self-driving lab for solution-processed electrochromic thin films", "comment": null, "summary": "Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.", "AI": {"tldr": "Self-driving laboratories accelerate electrochromic coating development using automation and machine learning", "motivation": "Traditional optimization of electrochromic thin films is slow and complex, hindering rapid development of energy-efficient smart windows and displays", "method": "Combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to efficiently explore processing parameters", "result": "Developed system that increases throughput and enables targeted search for optimal electrochromic coating parameters", "conclusion": "Self-driving labs show great potential for accelerating materials discovery and process optimization across various solution-processed materials"}}
{"id": "2512.05998", "categories": ["cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05998", "abs": "https://arxiv.org/abs/2512.05998", "authors": ["Michael Todasco"], "title": "Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals", "comment": "25 pages, 8 tables, 2 figures. Pilot study. Data, prompts, and code available at https://osf.io/dc24t/", "summary": "Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. \"Whale\" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.", "AI": {"tldr": "This paper proposes a betting game framework using fictional currency (LLMCoin) to improve LLM evaluation accuracy and surface calibrated confidence signals through wagering behavior.", "motivation": "Current LLM evaluation methods lack representation of confidence in their judgments, making it difficult to assess model reliability.", "method": "Researchers generated 100 math/logic questions with verifiable answers. Six baseline models answered questions, while three predictor models forecasted baseline performance under two conditions: Control (binary predictions) and Incentive (predictions plus wagers).", "result": "Incentive condition showed modestly higher accuracy (81.5% vs 79.1%) and significantly faster learning. Bet sizes correlated with confidence - large bets (40k+ coins) were 99% accurate while small bets (<1k coins) were 74% accurate.", "conclusion": "Betting mechanics create legible confidence signals, suggesting financial framing can help transform LLMs into risk-aware forecasters with visible internal beliefs."}}
{"id": "2512.07219", "categories": ["cs.MA", "cs.GT", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.07219", "abs": "https://arxiv.org/abs/2512.07219", "authors": ["Sungyong Chung", "Alireza Talebpour", "Samer H. Hamdar"], "title": "Characterizing Lane-Changing Behavior in Mixed Traffic", "comment": null, "summary": "Characterizing and understanding lane-changing behavior in the presence of automated vehicles (AVs) is crucial to ensuring safety and efficiency in mixed traffic. Accordingly, this study aims to characterize the interactions between the lane-changing vehicle (active vehicle) and the vehicle directly impacted by the maneuver in the target lane (passive vehicle). Utilizing real-world trajectory data from the Waymo Open Motion Dataset (WOMD), this study explores patterns in lane-changing behavior and provides insight into how these behaviors evolve under different AV market penetration rates (MPRs). In particular, we propose a game-theoretic framework to analyze cooperative and defective behaviors in mixed traffic, applied to the 7,636 observed lane-changing events in the WOMD. First, we utilize k-means clustering to classify vehicles as cooperative or defective, revealing that the proportions of cooperative AVs are higher than those of HDVs in both active and passive roles. Next, we jointly estimate the utilities of active and passive vehicles to model their behaviors using the quantal response equilibrium framework. Empirical payoff tables are then constructed based on these utilities. Using these payoffs, we analyze the presence of social dilemmas and examine the evolution of cooperative behaviors using evolutionary game theory. Our results reveal the presence of social dilemmas in approximately 4% and 11% of lane-changing events for active and passive vehicles, respectively, with most classified as Stag Hunt or Prisoner's Dilemma (Chicken Game rarely observed). Moreover, the Monte Carlo simulation results show that repeated lane-changing interactions consistently lead to increased cooperative behavior over time, regardless of the AV penetration rate.", "AI": {"tldr": "This study analyzes lane-changing interactions in mixed traffic using real-world data and game theory, revealing AVs are more cooperative than human drivers and showing how cooperation evolves over time.", "motivation": "Understanding lane-changing behavior in mixed traffic with automated vehicles is crucial for safety and efficiency, particularly characterizing interactions between active lane-changing vehicles and passive affected vehicles.", "method": "Used Waymo Open Motion Dataset with 7,636 lane-changing events; applied k-means clustering to classify cooperative/defective behaviors, quantal response equilibrium to model utilities, and evolutionary game theory with Monte Carlo simulations.", "result": "AVs showed higher cooperation rates than human drivers; social dilemmas found in 4% (active) and 11% (passive) of events, mostly Stag Hunt or Prisoner's Dilemma; repeated interactions increased cooperation over time regardless of AV penetration.", "conclusion": "The game-theoretic framework effectively characterizes lane-changing interactions, demonstrating AVs' cooperative advantage and the evolutionary trend toward increased cooperation in mixed traffic environments."}}
{"id": "2512.05990", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.05990", "abs": "https://arxiv.org/abs/2512.05990", "authors": ["Xin Li"], "title": "Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure", "comment": null, "summary": "Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \\textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \\textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \\textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \\textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \\textbf{Search $\\to$ Closure $\\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \\textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \\textit{Dynamic Programming} in P) via the mechanism of \\textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.", "AI": {"tldr": "MAI is a theoretical framework using algebraic topology to unify learning and memory as phase transitions, explaining how biological cognition achieves efficiency through topological transformations.", "motivation": "Current ML systems lack the sample efficiency and thermodynamic frugality of biological cognition due to separating static parameters from dynamic inference.", "method": "Proposes Memory-Amortized Inference (MAI) based on Homological Parity Principle: even homology (H_even) for stable Content structures, odd homology (H_odd) for dynamic Context flows. Uses topological trinity transformation (Search \u2192 Closure \u2192 Structure) to transition from high-complexity search (NPSPACE) to low-complexity lookup (P) via Topological Cycle Closure.", "result": "Demonstrates that cognition converts recursive search into efficient lookup through topological consolidation, governed by a topological Wake-Sleep algorithm alternating between optimizing H_odd flows and condensing cycles into H_even scaffolds.", "conclusion": "MAI rigorously explains emergence of fast-thinking intuition from slow-thinking reasoning and provides a blueprint for post-Turing architectures computing via topological resonance."}}
{"id": "2512.06161", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06161", "abs": "https://arxiv.org/abs/2512.06161", "authors": ["Gondy Leroy", "Prakash Bisht", "Sai Madhuri Kandula", "Nell Maltman", "Sydney Rice"], "title": "Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach", "comment": "9 pages", "summary": "Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.", "AI": {"tldr": "BioBERT-based transparent ML model for ASD diagnosis using clinical text, outperforming black-box approaches with 97% sensitivity and 98% specificity.", "motivation": "Automate ASD diagnosis with interpretable models that generalize better than single-dataset black-box approaches.", "method": "Leverage BioBERT to analyze clinical text, map behaviors to diagnostic criteria, and evaluate transfer learning across datasets.", "result": "Mixed-data training yielded best performance (97% sensitivity, 98% specificity), superior to sequential training and black-box models.", "conclusion": "Transparent ML approach enables trustworthy, generalizable AI tools for neurodevelopmental diagnostics."}}
{"id": "2512.07462", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.07462", "abs": "https://arxiv.org/abs/2512.07462", "authors": ["Trung-Kiet Huynh", "Duy-Minh Dao-Sy", "Thanh-Bang Cao", "Phong-Hao Le", "Hong-Dan Nguyen", "Phu-Quy Nguyen-Lam", "Minh-Luan Nguyen-Vo", "Hong-Phat Pham", "Phu-Hoa Pham", "Thien-Kim Than", "Chi-Nguyen Tran", "Huy Tran", "Gia-Thoai Tran-Le", "Alessio Buscemi", "Le Hong Trang", "The Anh Han"], "title": "Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics", "comment": null, "summary": "As Large Language Models (LLMs) increasingly operate as autonomous decision-makers in interactive and multi-agent systems and human societies, understanding their strategic behaviour has profound implications for safety, coordination, and the design of AI-driven social and economic infrastructures. Assessing such behaviour requires methods that capture not only what LLMs output, but the underlying intentions that guide their decisions. In this work, we extend the FAIRGAME framework to systematically evaluate LLM behaviour in repeated social dilemmas through two complementary advances: a payoff-scaled Prisoners Dilemma isolating sensitivity to incentive magnitude, and an integrated multi-agent Public Goods Game with dynamic payoffs and multi-agent histories. These environments reveal consistent behavioural signatures across models and languages, including incentive-sensitive cooperation, cross-linguistic divergence and end-game alignment toward defection. To interpret these patterns, we train traditional supervised classification models on canonical repeated-game strategies and apply them to FAIRGAME trajectories, showing that LLMs exhibit systematic, model- and language-dependent behavioural intentions, with linguistic framing at times exerting effects as strong as architectural differences. Together, these findings provide a unified methodological foundation for auditing LLMs as strategic agents and reveal systematic cooperation biases with direct implications for AI governance, collective decision-making, and the design of safe multi-agent systems.", "AI": {"tldr": "Extends FAIRGAME framework to evaluate LLM behavior in social dilemmas using Prisoner's Dilemma and Public Goods Game, revealing consistent behavioral patterns and strategic intentions.", "motivation": "Understand LLM strategic behavior in autonomous decision-making for safety, coordination, and AI-driven social/economic infrastructure design.", "method": "Uses payoff-scaled Prisoner's Dilemma and multi-agent Public Goods Game with dynamic payoffs to assess LLM behavioral signatures.", "result": "LLMs show incentive-sensitive cooperation, cross-linguistic divergence, and systematic behavioral intentions influenced by model/language.", "conclusion": "Provides unified method for auditing LLMs as strategic agents, revealing cooperation biases crucial for AI governance and safe multi-agent systems."}}
{"id": "2512.06059", "categories": ["cs.LG", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.06059", "abs": "https://arxiv.org/abs/2512.06059", "authors": ["Andrea Della Valle", "Annalisa D'Arco", "Tiziana Mancini", "Rosanna Mosetti", "Maria Chiara Paolozzi", "Stefano Lupi", "Sebastiano Pilati", "Andrea Perali"], "title": "Deep learning recognition and analysis of Volatile Organic Compounds based on experimental and synthetic infrared absorption spectra", "comment": null, "summary": "Volatile Organic Compounds (VOCs) are organic molecules that have low boiling points and therefore easily evaporate into the air. They pose significant risks to human health, making their accurate detection the crux of efforts to monitor and minimize exposure. Infrared (IR) spectroscopy enables the ultrasensitive detection at low-concentrations of VOCs in the atmosphere by measuring their IR absorption spectra. However, the complexity of the IR spectra limits the possibility to implement VOC recognition and quantification in real-time. While deep neural networks (NNs) are increasingly used for the recognition of complex data structures, they typically require massive datasets for the training phase. Here, we create an experimental VOC dataset for nine different classes of compounds at various concentrations, using their IR absorption spectra. To further increase the amount of spectra and their diversity in term of VOC concentration, we augment the experimental dataset with synthetic spectra created via conditional generative NNs. This allows us to train robust discriminative NNs, able to reliably identify the nine VOCs, as well as to precisely predict their concentrations. The trained NN is suitable to be incorporated into sensing devices for VOCs recognition and analysis.", "AI": {"tldr": "This paper presents a method using deep neural networks combined with experimental and synthetic IR spectroscopy data to recognize and quantify nine different volatile organic compounds (VOCs) effectively.", "motivation": "VOCs are hazardous to health but current IR spectroscopy detection methods struggle with real-time recognition due to complex spectra and the need for large training datasets.", "method": "Created an experimental VOC dataset with IR absorption spectra for nine compounds at various concentrations, augmented with synthetic spectra generated by conditional generative neural networks to enhance data diversity and volume.", "result": "Successfully trained robust discriminative neural networks that reliably identify the nine VOCs and accurately predict their concentrations.", "conclusion": "The trained neural network is suitable for integration into sensing devices, enabling efficient VOC recognition and analysis."}}
{"id": "2512.06196", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06196", "abs": "https://arxiv.org/abs/2512.06196", "authors": ["Charlie Masters", "Marta Grze\u015bkiewicz", "Stefano V. Albrecht"], "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "comment": "Accepted to the AAAI 2026 LLAMAS Workshop (Large Language Model Agents for Multi-Agent Systems)", "summary": "As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.", "AI": {"tldr": "ARCANE framework uses natural-language rubrics for interpretable, dynamic alignment of AI agents with stakeholder preferences without retraining.", "motivation": "Maintaining alignment of AI agents with stakeholder preferences in long-horizon tasks requires interpretable and adjustable reward models.", "method": "Formulates alignment as multi-agent collaboration, learns rubrics via regularized Group-Sequence Policy Optimization (GSPO) balancing interpretability and faithfulness.", "result": "Learned rubrics produce compact evaluations, enable configurable trade-offs, and show effectiveness on tasks requiring multi-step reasoning.", "conclusion": "Rubric-based reward models offer a promising approach for interpretable, adaptive alignment in complex AI systems."}}
{"id": "2512.07588", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.07588", "abs": "https://arxiv.org/abs/2512.07588", "authors": ["James Rudd-Jones", "Mar\u00eda P\u00e9rez-Ortiz", "Mirco Musolesi"], "title": "Understanding Individual Decision-Making in Multi-Agent Reinforcement Learning: A Dynamical Systems Approach", "comment": null, "summary": "Analysing learning behaviour in Multi-Agent Reinforcement Learning (MARL) environments is challenging, in particular with respect to \\textit{individual} decision-making. Practitioners frequently tend to study or compare MARL algorithms from a qualitative perspective largely due to the inherent stochasticity in practical algorithms arising from random dithering exploration strategies, environment transition noise, and stochastic gradient updates to name a few. Traditional analytical approaches, such as replicator dynamics, often rely on mean-field approximations to remove stochastic effects, but this simplification, whilst able to provide general overall trends, might lead to dissonance between analytical predictions and actual realisations of individual trajectories. In this paper, we propose a novel perspective on MARL systems by modelling them as \\textit{coupled stochastic dynamical systems}, capturing both agent interactions and environmental characteristics. Leveraging tools from dynamical systems theory, we analyse the stability and sensitivity of agent behaviour at individual level, which are key dimensions for their practical deployments, for example, in presence of strict safety requirements. This framework allows us, for the first time, to rigorously study MARL dynamics taking into consideration their inherent stochasticity, providing a deeper understanding of system behaviour and practical insights for the design and control of multi-agent learning processes.", "AI": {"tldr": "A novel framework for analyzing MARL systems as coupled stochastic dynamical systems to study individual agent behavior stability and sensitivity.", "motivation": "Existing analytical approaches like replicator dynamics rely on mean-field approximations that remove stochastic effects, leading to dissonance between predictions and actual individual trajectories.", "method": "Model MARL systems as coupled stochastic dynamical systems and leverage tools from dynamical systems theory to analyze stability and sensitivity at individual level.", "result": "A framework that rigorously studies MARL dynamics considering inherent stochasticity, providing deeper understanding of system behavior.", "conclusion": "This approach offers practical insights for the design and control of multi-agent learning processes, especially important for deployments with strict safety requirements."}}
{"id": "2512.06062", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06062", "abs": "https://arxiv.org/abs/2512.06062", "authors": ["S. M. Mustaqim", "Anantaa Kotal", "Paul H. Yi"], "title": "When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models", "comment": null, "summary": "Generative models are increasingly used to produce privacy-preserving synthetic data as a safe alternative to sharing sensitive training datasets. However, we demonstrate that such synthetic releases can still leak information about the underlying training samples through structural overlap in the data manifold. We propose a black-box membership inference attack that exploits this vulnerability without requiring access to model internals or real data. The attacker repeatedly queries the generative model to obtain large numbers of synthetic samples, performs unsupervised clustering to identify dense regions of the synthetic distribution, and then analyzes cluster medoids and neighborhoods that correspond to high-density regions in the original training data. These neighborhoods act as proxies for training samples, enabling the adversary to infer membership or reconstruct approximate records. Our experiments across healthcare, finance, and other sensitive domains show that cluster overlap between real and synthetic data leads to measurable membership leakage-even when the generator is trained with differential privacy or other noise mechanisms. The results highlight an under-explored attack surface in synthetic data generation pipelines and call for stronger privacy guarantees that account for distributional neighborhood inference rather than sample-level memorization alone, underscoring its role in privacy-preserving data publishing. Implementation and evaluation code are publicly available at:github.com/Cluster-Medoid-Leakage-Attack.", "AI": {"tldr": "A membership inference attack exploiting structural overlap in synthetic data manifold to infer training data membership, even with privacy mechanisms like differential privacy.", "motivation": "Synthetic data generation is used for privacy preservation but may still leak information through structural patterns matching original training data.", "method": "Black-box attack using repeated generative model queries, unsupervised clustering to identify dense synthetic regions, and analysis of cluster medoids/neighborhoods as proxies for training samples.", "result": "Demonstrated measurable membership leakage across healthcare, finance, and other domains, even with differential privacy, highlighting distributional neighborhood inference as a new attack surface.", "conclusion": "Need stronger privacy guarantees addressing distributional neighborhood inference beyond sample-level memorization in synthetic data pipelines."}}
{"id": "2512.06205", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06205", "abs": "https://arxiv.org/abs/2512.06205", "authors": ["Daniel Quigley", "Eric Maynard"], "title": "On measuring grounding and generalizing grounding problems", "comment": "36 pages, 85 sources", "summary": "The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.", "AI": {"tldr": "The paper reframes symbol grounding as an audit across multiple desiderata rather than a binary judgment, providing a framework to evaluate grounding modes.", "motivation": "Address the symbol grounding problem\u2014how symbols relate to real-world meaning\u2014by shifting from binary evaluation to a multi-faceted audit.", "method": "Propose a framework with desiderata (authenticity, preservation, faithfulness, robustness, compositionality) evaluated across tuples (context, meaning type, threat model, reference distribution); apply to four grounding modes and three case studies.", "result": "Framework applied shows trade-offs in grounding modes: symbolic methods lack etiological warrant; LLMs have correlational fit but no selection-for-success without grounded interaction; human language meets strong authenticity through evolution.", "conclusion": "The framework operationalizes grounding, offering a common technical language for interdisciplinary study of meaning and representation."}}
{"id": "2512.06573", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.06573", "abs": "https://arxiv.org/abs/2512.06573", "authors": ["Onur Bilgin", "Abdullah As Sami", "Sriram Sai Vujjini", "John Licato"], "title": "The Effect of Belief Boxes and Open-mindedness on Persuasion", "comment": "Accepted at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain", "summary": "As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.", "AI": {"tldr": "Investigates how LLM-based agents' propositional beliefs affect behavior, persuasion, and belief change in multi-agent scenarios.", "motivation": "Need for LLM-based agents to have propositional beliefs as they are increasingly used in reasoning and decision-making applications.", "method": "A series of experiments exploring the effects of belief statements and open-mindedness instructions on agent behavior and persuasiveness.", "result": "Belief statements influence resistance to opposing views and persuasiveness; open-mindedness affects amenability to belief change, especially in peer pressure scenarios.", "conclusion": "The belief box technique is feasible and valid for reasoning and decision-making tasks."}}
{"id": "2512.06102", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06102", "abs": "https://arxiv.org/abs/2512.06102", "authors": ["Ufuk \u00c7ak\u0131r", "Victor-Alexandru Darvariu", "Bruno Lacerda", "Nick Hawes"], "title": "JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning", "comment": "To be presented at the NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences (ML4PS)", "summary": "Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.", "AI": {"tldr": "JaxWildfire is a GPU-accelerated wildfire simulator using JAX that enables faster reinforcement learning training for wildfire management.", "motivation": "Existing wildfire simulators are too slow for efficient reinforcement learning agent training, which requires many environment interactions.", "method": "Developed a probabilistic fire spread model based on cellular automata, implemented in JAX with vectorized simulations using vmap for GPU acceleration.", "result": "Achieved 6-35x speedup over existing software, enabled gradient-based optimization, and successfully trained RL agents for wildfire suppression.", "conclusion": "JaxWildfire represents a significant advancement for applying RL techniques to natural hazard management by overcoming computational limitations."}}
{"id": "2512.06240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06240", "abs": "https://arxiv.org/abs/2512.06240", "authors": ["Chuanhao Nie", "Yunbo Liu", "Chao Wang"], "title": "AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems", "comment": null, "summary": "Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.", "AI": {"tldr": "AI applications can modernize AML workflows by improving detection accuracy, reducing false positives, and automating manual investigations. Future research includes federated learning, fairness-aware AI, and human-in-the-loop systems. Proposed RAG-Graph architecture shows high effectiveness in KYC processes.", "motivation": "Money laundering and financial fraud remain major global threats costing trillions annually, challenging regulatory oversight and requiring more efficient detection methods.", "method": "The paper reviews AI applications in AML and proposes an AI-driven KYC application integrating graph-based RAG with generative models to enhance efficiency and transparency.", "result": "Experimental results show the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, enhancing KYC CDD/EDD workflow efficiency.", "conclusion": "AI-driven approaches can significantly improve AML effectiveness while ensuring transparency and accountability, contributing to more sustainable and resource-optimized compliance practices."}}
{"id": "2512.06104", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06104", "abs": "https://arxiv.org/abs/2512.06104", "authors": ["Isaac Liao", "Albert Gu"], "title": "ARC-AGI Without Pretraining", "comment": null, "summary": "Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI \"training set\". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.", "AI": {"tldr": "CompressARC is a 76K parameter model that solves 20% of ARC-AGI puzzles without pretraining by using minimum description length during inference only.", "motivation": "Challenge conventional wisdom that solving ARC-AGI puzzles requires massive pretraining, proposing MDL as an alternative approach to intelligence.", "method": "Uses minimum description length (MDL) optimization during inference time on single puzzle instances without any pretraining or use of training data.", "result": "Solves 20% of evaluation puzzles despite extreme data limitations and no pretraining.", "conclusion": "MDL represents a viable alternative pathway to intelligence beyond conventional pretraining approaches."}}
{"id": "2512.06296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06296", "abs": "https://arxiv.org/abs/2512.06296", "authors": ["Sooho Moon", "Yunyong Ko"], "title": "How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion", "comment": "5 pages, 4 figures, 2 tables, ACM WSDM 2026", "summary": "Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.", "AI": {"tldr": "PROBE framework addresses limitations in KGC evaluation by incorporating predictive sharpness and popularity-bias robustness through rank transformer and rank aggregator components.", "motivation": "Existing KGC evaluation metrics overlook two key perspectives: predictive sharpness (strictness in individual prediction evaluation) and popularity-bias robustness (ability to predict low-popularity entities).", "method": "Proposes PROBE framework with rank transformer (RT) that estimates prediction scores based on required predictive sharpness level, and rank aggregator (RA) that aggregates scores in popularity-aware manner.", "result": "Experiments on real-world KGs show existing metrics tend to over- or under-estimate KGC model accuracy, while PROBE provides comprehensive understanding and reliable evaluation results.", "conclusion": "PROBE offers a more balanced and comprehensive evaluation framework for KGC models by addressing critical limitations in current evaluation methodologies."}}
{"id": "2512.06111", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06111", "abs": "https://arxiv.org/abs/2512.06111", "authors": ["Arthur Mukwaya", "Nancy Kasamala", "Nana Kankam Gyimah", "Judith Mwakalonge", "Gurcan Comert", "Saidi Siuhi", "Denis Ruganuza", "Mark Ngotonie"], "title": "A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts", "comment": null, "summary": "The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.", "AI": {"tldr": "Novel machine learning framework identifies optimal representative days for short traffic counts to improve AADT prediction accuracy, outperforming current DOT practices.", "motivation": "FHWA mandates reliable AADT data collection, but DOTs struggle with accurate AADT estimation especially for unmonitored roads due to high costs of continuous count stations.", "method": "Proposes machine learning framework using Texas traffic data (2022-2023) comparing 'optimal day' selection vs 'no optimal day' baseline. Utilizes continuous count data to simulate 24h short counts and LOO technique for feature engineering.", "result": "Optimal day approach significantly outperforms baseline: Day 186 achieves RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%, R\u00b2: 0.9756 vs baseline RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R\u00b2: 0.9499.", "conclusion": "Framework offers DOTs improved AADT estimation alternative to conventional methods, supporting HPMS compliance and reducing operational costs of statewide traffic data collection."}}
{"id": "2512.06337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06337", "abs": "https://arxiv.org/abs/2512.06337", "authors": ["Xuan Xie", "Xuan Wang", "Wenjie Wang"], "title": "DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization", "comment": null, "summary": "The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.", "AI": {"tldr": "DaGRPO improves GRPO by addressing training instability through gradient conflict reduction and data augmentation, achieving SOTA results.", "motivation": "GRPO suffers from training instability and poor sample efficiency due to lack of distinctiveness in on-policy rollouts.", "method": "Introduces Sequence-level Gradient Rectification and Off-policy Data Augmentation to enhance distinctiveness and training efficiency.", "result": "Achieves +4.7% average accuracy gain on math benchmarks and superior performance on 9 reasoning/OOD tasks.", "conclusion": "DaGRPO effectively mitigates gradient issues and accelerates reasoning capability development, establishing new SOTA."}}
{"id": "2512.06134", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.06134", "abs": "https://arxiv.org/abs/2512.06134", "authors": ["Georgi Hrusanov", "Duy-Thanh Vu", "Duy-Cat Can", "Sophie Tascedda", "Margaret Ryan", "Julien Bodelet", "Katarzyna Koscielska", "Carsten Magnus", "Oliver Y. Ch\u00e9n"], "title": "Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting", "comment": null, "summary": "Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($\u03b1$) and biological ($\u03b2$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.", "AI": {"tldr": "Neural Koopman Machine (NKM) - a novel ML architecture using dynamical systems and attention mechanisms for forecasting Alzheimer's cognitive decline from multimodal data", "motivation": "Challenge in integrating multimodal data for longitudinal personalized forecasting while maintaining interpretability in Alzheimer's disease", "method": "Integration of analytical and biological knowledge for feature grouping, Fusion Group-Aware Hierarchical Attention within Koopman operator framework to transform nonlinear trajectories into linear representations", "result": "NKM consistently outperforms traditional ML and deep learning models in forecasting cognitive decline trajectories, enables simultaneous forecasting of multiple cognitive scores, quantifies biomarker contributions, and identifies predictive brain regions", "conclusion": "NKM advances personalized, interpretable forecasting of cognitive decline in Alzheimer's disease and reveals potential multimodal biological underpinnings of disease progression"}}
{"id": "2512.06393", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06393", "abs": "https://arxiv.org/abs/2512.06393", "authors": ["Qiming Bao", "Xiaoxuan Fu"], "title": "Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression", "comment": null, "summary": "Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.\n  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.", "AI": {"tldr": "LLMs show strong logical reasoning stability for semantic-preserving transformations but fail dramatically on essential rule deletion and contradictory evidence.", "motivation": "To systematically evaluate LLM reasoning reliability through controlled structural perturbations in logical contexts.", "method": "A controlled evaluation framework with four stress tests: rule deletion (redundant/essential), contradictory evidence injection, logic-preserving rewrites using equivalence laws, and multi-law equivalence stacking.", "result": "Perfect accuracy on base tasks and semantic-preserving transformations, but accuracy drops to 25% for essential rule deletion and 0% for contradictory evidence across BERT, Qwen2, and LLaMA-like models.", "conclusion": "LLMs possess stable invariance to logical equivalences but remain fundamentally brittle to missing or conflicting evidence, highlighting persistent gaps in logical generalization."}}
{"id": "2512.06143", "categories": ["cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.06143", "abs": "https://arxiv.org/abs/2512.06143", "authors": ["Marcus M. Noack", "Mark D. Risser", "Hengrui Luo", "Vardaan Tekriwal", "Ronald J. Pandolfi"], "title": "gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points", "comment": "None", "summary": "Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \\emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.", "AI": {"tldr": "gp2Scale enables exact Gaussian process scaling to 10M+ points using sparse structure from non-stationary kernels, avoiding approximations while maintaining full customization.", "motivation": "Current GP scaling methods rely on approximations that compromise accuracy and limit kernel/noise flexibility, particularly problematic with expressive non-stationary kernels.", "method": "Exploits sparse structure in covariance matrices from flexible, compactly supported non-stationary kernels for efficient linear system solutions and log-determinant calculations.", "result": "Demonstrates functionality on real-world datasets with superior accuracy versus state-of-the-art approximations while supporting arbitrary GP customizations.", "conclusion": "gp2Scale provides exact GP scaling without approximation trade-offs, making it ideal for modern applications requiring custom kernel designs."}}
{"id": "2512.06404", "categories": ["cs.AI", "cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.06404", "abs": "https://arxiv.org/abs/2512.06404", "authors": ["Mohammad Soleymanibrojeni", "Roland Aydin", "Diego Guedes-Sobrinho", "Alexandre C. Dias", "Maur\u00edcio J. Piotrowski", "Wolfgang Wenzel", "Celso Ricardo Caldeira R\u00eago"], "title": "GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols", "comment": null, "summary": "Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.", "AI": {"tldr": "GENIUS is an AI-agentic workflow that automates DFT simulation setup using a knowledge graph and LLM hierarchy, achieving 80% success rate on benchmarks with reduced hallucinations and costs.", "motivation": "To bridge the know-how gap in materials science by enabling non-experts to conduct predictive atomistic simulations without requiring computer specialists.", "method": "Combines a Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine.", "result": "Achieves \u224880% success rate on 295 diverse benchmarks, with 76% autonomously repaired, while halving inference costs and virtually eliminating hallucinations compared to LLM-only baselines.", "conclusion": "GENIUS democratizes electronic-structure DFT simulations by automating protocol generation, validation, and repair, accelerating ICME design loops worldwide."}}
{"id": "2512.06154", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.06154", "abs": "https://arxiv.org/abs/2512.06154", "authors": ["Barproda Halder", "Pasan Dissanayake", "Sanghamitra Dutta"], "title": "Learning Invariant Graph Representations Through Redundant Information", "comment": null, "summary": "Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.", "AI": {"tldr": "RIG framework uses Partial Information Decomposition to isolate invariant graph representations by targeting redundant information between spurious and causal subgraphs for OOD generalization.", "motivation": "Existing approaches for invariant representation learning have limitations as classical information-theoretic measures often fail to eliminate spurious components from learned representations.", "method": "Proposes RIG - a multi-level optimization framework that maximizes redundant information while isolating spurious and causal subgraphs through alternating optimization of redundant information lower bounds.", "result": "Experiments on synthetic and real-world graph datasets demonstrate improved generalization capabilities under diverse distribution shifts.", "conclusion": "PID provides a more effective tool than classical information-theoretic measures for learning invariant graph representations that generalize well OOD by precisely targeting redundant information."}}
{"id": "2512.06406", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06406", "abs": "https://arxiv.org/abs/2512.06406", "authors": ["Xianzong Wu", "Xiaohong Li", "Lili Quan", "Qiang Hu"], "title": "UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems", "comment": null, "summary": "Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.", "AI": {"tldr": "UncertaintyZoo is a unified toolkit integrating 29 UQ methods for LLM confidence measurement, evaluated on code vulnerability detection.", "motivation": "LLMs make incorrect predictions in safety-critical scenarios, but limited tools exist to integrate UQ methods.", "method": "Developed UncertaintyZoo with standardized interface covering 5 UQ categories, tested on CodeBERT and ChatGLM3 for code vulnerability detection.", "result": "Tool effectively reveals prediction uncertainty, with demonstration available.", "conclusion": "UncertaintyZoo bridges the gap in UQ tool integration, facilitating practical usage and future research."}}
{"id": "2512.06183", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06183", "abs": "https://arxiv.org/abs/2512.06183", "authors": ["Lindong Liu", "Zhixiong Jin", "Seongjin Choi"], "title": "PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations", "comment": null, "summary": "High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.", "AI": {"tldr": "PMA-Diffusion uses physics-guided diffusion with mask-aware training to reconstruct sparse highway traffic data, outperforming baselines even with only 5% data visibility.", "motivation": "High-resolution traffic data is crucial for ITS but typically sparse and noisy from detectors/probe vehicles, failing to capture detailed traffic dynamics.", "method": "Proposes PMA-Diffusion: a framework training diffusion prior on sparse observations via Single/Double-Mask strategies, using physics-guided posterior sampling with reverse-diffusion, observation projection, and adaptive anisotropic smoothing.", "result": "Tested on I-24 MOTION dataset with varying visibility ratios; outperforms baselines across three error metrics even at 5% visibility, nearly matching baseline trained on full data.", "conclusion": "Combining mask-aware diffusion priors with physics-guided posterior sampling offers reliable, flexible traffic state estimation under realistic sparsity."}}
{"id": "2512.06431", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.06431", "abs": "https://arxiv.org/abs/2512.06431", "authors": ["Mohamed Shamroukh", "Mohamed Alkhuzamy Aziz"], "title": "Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City", "comment": null, "summary": "National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.", "AI": {"tldr": "A tailored planning model using Voronoi Diagrams to create city-specific criteria for Qena City, revealing 81.3% average service coverage with variations per facility type and district.", "motivation": "National planning standards in Egypt often mismatch local characteristics, necessitating a customized approach for urban areas like Qena City.", "method": "Hybrid methodology (descriptive, analytical, experimental) using Python and Voronoi Diagrams for spatial analysis.", "result": "81.3% average service coverage; ambulance stations most efficient (99.8%), parks lowest (10%); high density in midtown (>45/km\u00b2), low in outskirts (<5/km\u00b2).", "conclusion": "The model provides a replicable framework for data-driven urban planning in Egyptian cities, highlighting disparities and guiding improvements."}}
{"id": "2512.06200", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06200", "abs": "https://arxiv.org/abs/2512.06200", "authors": ["Tomohiro Yamashita", "Daichi Amagata", "Yusuke Matsui"], "title": "How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?", "comment": "4 pages, 4 figures. Accepted at NeurIPS 2025 Workshop on Machine Learning for Systems", "summary": "Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.", "AI": {"tldr": "Proposes an evaluation framework and metrics for assessing data deletion efficiency in graph-based Approximate Nearest Neighbor Search (ANNS) indexes, including method categorization and application to HNSW.", "motivation": "Lack of comprehensive evaluation methodology for data deletion in ANNS, despite its importance in dynamic data applications like Retrieval-Augmented Generation.", "method": "Categorizes data deletion methods in graph-based ANNS into three approaches, formalizes them mathematically, and evaluates performance via accuracy, query speed, and other metrics.", "result": "Application of the framework to Hierarchical Navigable Small World (HNSW) reveals effects of data deletion and leads to proposal of Deletion Control for dynamic method selection.", "conclusion": "Establishes a needed evaluation framework for data deletion in ANNS, demonstrating its utility through HNSW analysis and introduction of Deletion Control to maintain search accuracy."}}
{"id": "2512.06201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06201", "abs": "https://arxiv.org/abs/2512.06201", "authors": ["K2 Team", "Zhengzhong Liu", "Liping Tang", "Linghao Jin", "Haonan Li", "Nikhil Ranjan", "Desai Fan", "Shaurya Rohatgi", "Richard Fan", "Omkar Pangarkar", "Huijuan Wang", "Zhoujun Cheng", "Suqi Sun", "Seungwook Han", "Bowen Tan", "Gurpreet Gosal", "Xudong Han", "Varad Pimpalkhute", "Shibo Hao", "Ming Shan Hee", "Joel Hestness", "Haolong Jia", "Liqun Ma", "Aaryamonvikram Singh", "Daria Soboleva", "Natalia Vassilieva", "Renxi Wang", "Yingquan Wu", "Yuekai Sun", "Taylor Killian", "Alexander Moreno", "John Maggs", "Hector Ren", "Guowei He", "Hongyi Wang", "Xuezhe Ma", "Yuqi Wang", "Mikhail Yurochkin", "Eric P. Xing"], "title": "K2-V2: A 360-Open, Reasoning-Enhanced LLM", "comment": null, "summary": "We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.", "AI": {"tldr": "K2-V2 is a new fully open large language model optimized for reasoning tasks, outperforming top open-weight models and approaching Qwen3-235B performance through specialized training.", "motivation": "To create a superior base model specifically optimized for reasoning adaptation while maintaining capabilities in conversation and knowledge retrieval, addressing the need for strong open-source reasoning foundations.", "method": "Built from scratch with active infusion of domain knowledge, reasoning skills, long-context handling, and tool use capabilities throughout the training process, followed by simple supervised fine-tuning.", "result": "K2-V2 rivals open-weight leaders in its size class, outperforms Qwen2.5-72B, and approaches Qwen3-235B performance, establishing a strong baseline for complex reasoning tasks.", "conclusion": "The model represents the strongest fully open option with significant room for advanced alignment, and by releasing complete training data and artifacts, it empowers community development for reasoning-centric applications."}}
{"id": "2512.06629", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.06629", "abs": "https://arxiv.org/abs/2512.06629", "authors": ["Xiao-li Xia", "Hou-biao Li"], "title": "FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection", "comment": "36 pages, 14 figures,Table 5", "summary": "Knowledge Tracing (KT) models face a critical ``Performance-Complexity Trap'': capturing complex cognitive dynamics like learning sessions and memory decay typically requires deep hierarchical architectures, which incur prohibitive computational costs for real-time deployment. To resolve this, we propose FlatFormer, a streamlined architecture based on the novel design paradigm of ``Information Injection over Structural Stacking.'' Unlike parameter-heavy hierarchical models, FlatFormer leverages a standard flat Transformer augmented with two lightweight injection mechanisms: (i) a hybrid input encoding strategy combining learnable session identifiers with fixed sinusoidal step embeddings; and (ii) a pre-computed power-law bias integrated directly into attention logits to explicitly model the forgetting curve. Extensive experiments on four large-scale datasets (e.g., EdNet, Junyi) show that FlatFormer achieves state-of-the-art performance. For example, on the EdNet dataset, compared to the strongest hierarchical baseline (HiTSKT), its absolute AUC increased by 8.3%, while using less than 15% of parameters, and inference speed was about three times faster. These results validate that high cognitive fidelity does not necessitate architectural complexity.", "AI": {"tldr": "FlatFormer resolves the Performance-Complexity Trap in Knowledge Tracing by using information injection instead of hierarchical stacking, achieving SOTA performance with fewer parameters and faster inference.", "motivation": "Hierarchical KT models capture cognitive dynamics but are computationally expensive, hindering real-time deployment.", "method": "FlatFormer augments a flat Transformer with hybrid input encoding (session IDs + step embeddings) and pre-computed power-law attention bias for forgetting curves.", "result": "On EdNet, FlatFormer increased AUC by 8.3% vs. HiTSKT, using <15% parameters and ~3x faster inference; similar gains on other datasets.", "conclusion": "High cognitive fidelity in KT can be achieved without architectural complexity, via efficient information injection."}}
{"id": "2512.06204", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06204", "abs": "https://arxiv.org/abs/2512.06204", "authors": ["Rodney Lafuente-Mercado", "Daniela Rus", "T. Konstantin Rusch"], "title": "Quantifying Memory Use in Reinforcement Learning with Temporal Range", "comment": null, "summary": "How much does a trained RL policy actually use its past observations? We propose \\emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\\partial y_s/\\partial x_t\\in\\mathbb{R}^{c\\times d}$ averaged over final timesteps $s\\in\\{t+1,\\dots,T\\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.", "AI": {"tldr": "Temporal Range metric measures RL policy's memory dependence by computing weighted average lag of observations' influence on future outputs.", "motivation": "Existing methods lack a standardized way to quantify how much RL policies actually use past observations.", "method": "Proposes Temporal Range metric using reverse-mode automatic differentiation to compute Jacobian blocks across temporal windows, with axiomatic foundation.", "result": "Validated across tasks showing: small in fully observed control; scales with ground-truth lag in Copy-k; aligns with minimum history window needed for optimal performance.", "conclusion": "Temporal Range provides practical per-sequence readout for comparing memory dependence across agents and environments, helping select sufficient context length."}}
{"id": "2512.06653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06653", "abs": "https://arxiv.org/abs/2512.06653", "authors": ["Hengzhi Lan", "Yue Yu", "Li Qian", "Li Peng", "Jie Wu", "Wei Liu", "Jian Luan", "Ting Bai"], "title": "LightSearcher: Efficient DeepSearch via Experiential Memory", "comment": "10 pages, 5 figures", "summary": "DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, recent advances in reinforcement learning (RL) have further empowered models to autonomously and strategically control search tool usage, optimizing when and how to query external knowledge sources. Yet, these RL-driven DeepSearch systems often reveal a see-saw trade-off between accuracy and efficiency-frequent tool invocations can improve factual correctness but lead to unnecessary computational overhead and diminished efficiency. To address this challenge, we propose LightSearcher, an efficient RL framework that incorporates textual experiential memory by learning contrastive reasoning trajectories to generate interpretable summaries of successful reasoning patterns. In addition, it employs an adaptive reward shaping mechanism that penalizes redundant tool calls only in correct-answer scenarios. This design effectively balances the inherent accuracy-efficiency trade-off in DeepSearch paradigms. Experiments on four multi-hop QA benchmarks show that LightSearcher maintains accuracy comparable to SOTA baseline ReSearch, while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%, demonstrating its superior efficiency.", "AI": {"tldr": "LightSearcher is an efficient RL framework that uses textual experiential memory and adaptive reward shaping to reduce unnecessary tool calls while maintaining accuracy in DeepSearch paradigms.", "motivation": "RL-driven DeepSearch systems exhibit a trade-off between accuracy and efficiency, with frequent tool invocations improving factual correctness but reducing efficiency.", "method": "Incorporates textual experiential memory by learning contrastive reasoning trajectories and employs adaptive reward shaping to penalize redundant tool calls only in correct-answer scenarios.", "result": "LightSearcher maintains accuracy comparable to SOTA baseline ReSearch while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%.", "conclusion": "The proposed framework effectively balances the accuracy-efficiency trade-off in DeepSearch paradigms, demonstrating superior efficiency."}}
{"id": "2512.06218", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.06218", "abs": "https://arxiv.org/abs/2512.06218", "authors": ["Huizhen Yu", "Yi Wan", "Richard S. Sutton"], "title": "Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration", "comment": "24 pages. This paper presents the reinforcement-learning material previously contained in version 2 of arXiv:2409.03915, which is now being split into two stand-alone papers. Minor corrections and improvements to the main results have also been made in the course of this reformatting", "summary": "This paper applies the authors' recent results on asynchronous stochastic approximation (SA) in the Borkar-Meyn framework to reinforcement learning in average-reward semi-Markov decision processes (SMDPs). We establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. In particular, we show that the algorithm converges almost surely to a compact, connected subset of solutions to the average-reward optimality equation, with convergence to a unique, sample path-dependent solution under additional stepsize and asynchrony conditions. Moreover, to make full use of the SA framework, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework and are addressed through novel arguments in the stability and convergence analysis of RVI Q-learning.", "AI": {"tldr": "Convergence analysis of asynchronous RVI Q-learning for average-reward SMDPs using stochastic approximation framework.", "motivation": "Extend Borkar-Meyn asynchronous SA framework to reinforcement learning in average-reward semi-Markov decision processes.", "method": "Asynchronous stochastic approximation analogue of Schweitzer's relative value iteration algorithm (RVI Q-learning).", "result": "Algorithm converges almost surely to compact connected subset of solutions to average-reward optimality equation.", "conclusion": "New monotonicity conditions expand algorithmic framework and enable novel stability arguments."}}
{"id": "2512.06705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06705", "abs": "https://arxiv.org/abs/2512.06705", "authors": ["Yongyuan He", "Yi Bu"], "title": "Academic journals' AI policies fail to curb the surge in AI-assisted academic writing", "comment": "40 pages, 10 figures, and 9 tables", "summary": "The rapid integration of generative AI into academic writing has prompted widespread policy responses from journals and publishers. However, the effectiveness of these policies remains unclear. Here, we analyze 5,114 journals and over 5.2 million papers to evaluate the real-world impact of AI usage guidelines. We show that despite 70% of journals adopting AI policies (primarily requiring disclosure), researchers' use of AI writing tools has increased dramatically across disciplines, with no significant difference between journals with or without policies. Non-English-speaking countries, physical sciences, and high-OA journals exhibit the highest growth rates. Crucially, full-text analysis on 164k scientific publications reveals a striking transparency gap: Of the 75k papers published since 2023, only 76 (0.1%) explicitly disclosed AI use. Our findings suggest that current policies have largely failed to promote transparency or restrain AI adoption. We urge a re-evaluation of ethical frameworks to foster responsible AI integration in science.", "AI": {"tldr": "Analysis of 5,114 journals shows AI policies ineffective - AI tool usage increased dramatically with no difference between journals with/without policies, and only 0.1% of papers disclosed AI use despite disclosure requirements.", "motivation": "To evaluate the real-world impact of AI usage guidelines adopted by journals and publishers amid rapid integration of generative AI into academic writing.", "method": "Analyzed 5,114 journals and over 5.2 million papers, including full-text analysis on 164k scientific publications, to assess AI policy effectiveness and disclosure rates.", "result": "70% of journals adopted AI policies but researchers' AI tool usage increased dramatically across disciplines with no significant difference between journals with/without policies. Only 76 out of 75k papers (0.1%) explicitly disclosed AI use.", "conclusion": "Current AI policies have largely failed to promote transparency or restrain AI adoption, requiring re-evaluation of ethical frameworks for responsible AI integration in science."}}
{"id": "2512.06236", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06236", "abs": "https://arxiv.org/abs/2512.06236", "authors": ["Haiyang Yu", "Meng-Chieh Lee", "Xiang song", "Qi Zhu", "Christos Faloutsos"], "title": "Back to Author Console Empowering GNNs for Domain Adaptation via Denoising Target Graph", "comment": null, "summary": "We explore the node classification task in the context of graph domain adaptation, which uses both source and target graph structures along with source labels to enhance the generalization capabilities of Graph Neural Networks (GNNs) on target graphs. Structure domain shifts frequently occur, especially when graph data are collected at different times or from varying areas, resulting in poor performance of GNNs on target graphs. Surprisingly, we find that simply incorporating an auxiliary loss function for denoising graph edges on target graphs can be extremely effective in enhancing GNN performance on target graphs. Based on this insight, we propose our framework, GraphDeT, a framework that integrates this auxiliary edge task into GNN training for node classification under domain adaptation. Our theoretical analysis connects this auxiliary edge task to the graph generalization bound with -distance, demonstrating such auxiliary task can imposes a constraint which tightens the bound and thereby improves generalization. The experimental results demonstrate superior performance compared to the existing baselines in handling both time and regional domain graph shifts.", "AI": {"tldr": "Simple edge denoising via auxiliary loss significantly boosts GNN generalization in graph domain adaptation.", "motivation": "Graph domain shifts from different collection times/regions cause poor GNN performance on target graphs.", "method": "Propose GraphDeT framework: integrate auxiliary edge denoising loss during GNN training for node classification.", "result": "Theoretical link to generalization bound; experiments show superior performance vs baselines on time/regional shifts.", "conclusion": "Edge denoising is a surprisingly effective, theoretically-grounded method for graph domain adaptation."}}
