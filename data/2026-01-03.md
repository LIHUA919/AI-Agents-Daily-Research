<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.LG](#cs.LG) [Total: 9]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP is an open-source protocol for autonomous scientific agents to discover and orchestrate tools/datasets across institutions, enabling scalable agent-driven science.


<details>
  <summary>Details</summary>
Motivation: To accelerate scientific discovery by enabling a global network of autonomous scientific agents and addressing integration challenges across disparate platforms and institutional boundaries.

Method: Built on two pillars: (1) Unified Resource Integration protocol for describing/invoking scientific resources, (2) Orchestrated Experiment Lifecycle Management with SCP Hub and federated SCP Servers architecture.

Result: Created platform with over 1,600 tool resources; facilitates secure large-scale collaboration, reduces integration overhead, and enhances reproducibility across diverse use cases.

Conclusion: SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science by standardizing scientific context and tool orchestration at the protocol level.

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [2] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: The paper introduces DDFT, a framework to measure epistemic robustness in language models by simulating stress conditions, finding it depends on training methodology and verification mechanisms rather than model size or architecture.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks like MMLU and TruthfulQA fail to measure robustness under realistic stress, not distinguishing between lack of knowledge and collapsed verification mechanisms.

Method: Proposes the DDFT protocol with progressive semantic compression and adversarial fabrication, and a two-system cognitive model (Semantic System and Epistemic Verifier) evaluated on 9 models across 8 domains and 5 compression levels.

Result: Epistemic robustness is orthogonal to conventional design; parameter count and architecture don't predict it, while error detection strongly correlates with robustness, showing brittleness in large models and robust performance in some smaller ones.

Conclusion: The DDFT framework provides tools to assess epistemic robustness pre-deployment, challenging assumptions about model size and reliability and emphasizing training and verification methods.

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [3] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE is a self-evolving agent framework that transitions LLM agents from tool use to skill acquisition, achieving 93.3% success on scientific tasks through continuous learning and self-reflection.


<details>
  <summary>Details</summary>
Motivation: Current LLM agents depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks.

Method: CASCADE is a self-evolving agentic framework that enables agents to master complex external tools through continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration.

Result: CASCADE achieves a 93.3% success rate on SciSkillBench (116 materials science and chemistry research tasks) using GPT-5, compared to 35.4% without evolution mechanisms, and demonstrates real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers.

Conclusion: CASCADE represents a transition from "LLM + tool use" to "LLM + skill acquisition" and moves toward scalable AI-assisted scientific research by accumulating executable skills that can be shared across agents and scientists.

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [4] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy combines LLMs and ASP for disease diagnosis, showing promising results.


<details>
  <summary>Details</summary>
Motivation: Symbolic AI adoption in healthcare is limited due to effort needed for high-quality knowledge bases.

Method: Combine LLMs to translate medical literature into ASP code, integrate with patient data, and process with ASP solver.

Result: Preliminary results show strong performance on small-scale disease diagnosis tasks.

Conclusion: McCoy demonstrates a promising approach to overcoming knowledge base construction barriers by leveraging LLMs and ASP, but further validation is needed.

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [5] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK is a framework using LLM agents for personalized search through dynamic, multi-persona coordination.


<details>
  <summary>Details</summary>
Motivation: Traditional search systems rely on static profiles or uniform pipelines, lacking the ability to model users' evolving, multi-dimensional information needs effectively.

Method: Introduces a persona space with role, expertise, task context, and domain, using a Persona Coordinator to activate relevant agents based on queries. Each agent runs retrieval-augmented generation with dedicated memory and reasoning, with inter-agent collaboration via shared memory, iterative debate, and knowledge transfer.

Result: A framework that models emergent personalization from distributed agent behaviors, yielding testable predictions on coordination, personalization quality, and cognitive load, with adaptive mechanisms for persona refinement.

Conclusion: SPARK integrates agent specialization with cooperation to advance search systems in capturing complex, context-sensitive human information-seeking.

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [6] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD is a prompt optimization framework that uses a multi-agent debugging approach instead of labeled datasets, improving performance efficiently by analyzing failure logs.


<details>
  <summary>Details</summary>
Motivation: In real-world software engineering, curated gold-standard datasets are rarely available during the initial cold start of agent development, requiring methods that can work with messy production logs and evolving failure modes.

Method: Uses a specialized multi-agent architecture (Analyzer for root-cause analysis, Optimizer for pattern aggregation, and Coach for strategy integration) to convert unstructured failure logs into structured Decision Tree Protocols.

Result: Achieved a 5.6% increase in success rate (73.6% to 79.2%) and a 3.8% increase in search accuracy within just three automated iterations. On complex reasoning tasks in retail, improved agent performance by ~19% relative to baseline.

Conclusion: Mimicking the human engineering loop of failure analysis and patching offers a data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [7] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow is a self-evolving agent framework that uses LLMs in a structured reasoning approach to improve evolutionary algorithm efficiency for code generation and optimization tasks.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of traditional evolutionary approaches in transitioning from static LLMs to self-improving agents, particularly poor structured reasoning, premature convergence, and inefficient exploration in high-dimensional code spaces.

Method: LoongFlow integrates LLMs into a 'Plan-Execute-Summarize' (PES) paradigm and uses a hybrid evolutionary memory system combining Multi-Island models with MAP-Elites and adaptive Boltzmann selection.

Result: LoongFlow outperforms leading baselines by up to 60% in evolutionary efficiency while discovering superior solutions, as demonstrated on AlphaEvolve benchmark and Kaggle competitions.

Conclusion: LoongFlow offers a promising direction for autonomous scientific discovery by enabling more efficient generation of expert-level solutions through structured reasoning mechanisms.

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [8] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec, a cognitive recommender agent combining LLMs and Soar cognitive architecture, improves recommendation accuracy and explainability by leveraging Soar's reasoning and LLM's knowledge, with online learning via chunking.


<details>
  <summary>Details</summary>
Motivation: LLMs have capacity for understanding user preferences but face issues like black-box nature, hallucination, and limited online learning; cognitive architectures offer structured reasoning but have difficult knowledge acquisition.

Method: Uses Soar as a core symbolic reasoning engine with LLM for knowledge initialization; operates on Perception-Cognition-Action cycle, uses LLM for impasse resolution with chunking to create new production rules.

Result: Extensive evaluations on three public datasets show significant advantages in recommendation accuracy, explainability, and efficacy in addressing the long-tail problem.

Conclusion: CogRec successfully addresses key limitations of LLMs in recommendation systems by leveraging Soar's structured reasoning, achieving improvements in accuracy, explainability, and long-tail problem handling.

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems](https://arxiv.org/abs/2512.23809)
*Samaresh Kumar Singh,Joyjit Roy,Martin So*

Main category: cs.LG

TL;DR: A Zero-Trust Agentic Federated Learning (ZTA-FL) framework is proposed for IIoT security, combining TPM-based attestation, SHAP-weighted aggregation, and adversarial training to achieve high detection accuracy, robustness, and reduced overhead.


<details>
  <summary>Details</summary>
Motivation: Recent critical infrastructure attacks reveal security gaps in IIoT, with existing Federated Learning frameworks vulnerable to Byzantine poisoning attacks and lacking robust agent authentication.

Method: ZTA-FL combines TPM-based cryptographic attestation, a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection, and privacy-preserving on-device adversarial training.

Result: Experiments show ZTA-FL achieves 97.8% detection accuracy, 93.2% accuracy under 30% Byzantine attacks (outperforming FLAME by 3.1%, p<0.01), 89.3% adversarial robustness, and 34% communication overhead reduction.

Conclusion: ZTA-FL effectively enhances IIoT security with high accuracy, robustness, and efficiency, supported by theoretical analysis and code release for reproducibility.

Abstract: Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.

</details>


### [10] [Network Traffic Analysis with Process Mining: The UPSIDE Case Study](https://arxiv.org/abs/2512.23718)
*Francesco Vitale,Paolo Palmiero,Massimiliano Rak,Nicola Mazzocca*

Main category: cs.LG

TL;DR: A process mining-based method is proposed to analyze gaming network traffic for unsupervised state characterization, interpretable Petri net encoding, and video game classification, applied to the UPSIDE case study with Clash Royale and Rocket League.


<details>
  <summary>Details</summary>
Motivation: Online gaming generates large market revenue and requires modeling network devices' behavior for bandwidth consumption, load prediction, and malicious activity detection. Process mining offers data-driven analyses with model-based insights.

Method: Proposes a process mining-based method that analyzes gaming network traffic to: 1) perform unsupervised characterization of different states from gaming network data, 2) encode such states into interpretable Petri nets using process mining, and 3) classify gaming network traffic data to identify different video games being played.

Result: Applied to UPSIDE case study with Clash Royale and Rocket League. Gaming network behavior is effectively modeled through Petri nets with 94.02% inter-device similarity and 174.99% inter-state separation, achieving 73.84% AUC for classification.

Conclusion: The method demonstrates that gaming network behavior can be interpretably modeled with process mining, achieving good classification accuracy and insights into network states, supporting applications in bandwidth management and security.

Abstract: Online gaming is a popular activity involving the adoption of complex systems and network infrastructures. The relevance of gaming, which generates large amounts of market revenue, drove research in modeling network devices' behavior to evaluate bandwidth consumption, predict and sustain high loads, and detect malicious activity. In this context, process mining appears promising due to its ability to combine data-driven analyses with model-based insights. In this paper, we propose a process mining-based method that analyzes gaming network traffic, allowing: unsupervised characterization of different states from gaming network data; encoding such states through process mining into interpretable Petri nets; and classification of gaming network traffic data to identify different video games being played. We apply the method to the UPSIDE case study, involving gaming network data of several devices interacting with two video games: Clash Royale and Rocket League. Results demonstrate that the gaming network behavior can be effectively and interpretably modeled through states represented as Petri nets with sufficient coherence (94.02% inter-device similarity) and specificity (174.99% inter-state separation) while maintaining a good classification accuracy of the two different video games (73.84% AUC).

</details>


### [11] [A Comprehensive Study of Deep Learning Model Fixing Approaches](https://arxiv.org/abs/2512.23745)
*Hanmo You,Zan Wang,Zishuo Dong,Luanqi Mo,Jianjun Zhao,Junjie Chen*

Main category: cs.LG

TL;DR: Large-scale study of 16 DL model fixing approaches finds model-level methods most effective but none can optimize all properties simultaneously, highlighting need for side-effect mitigation research.


<details>
  <summary>Details</summary>
Motivation: DL systems are increasingly used in critical domains and are prone to faults that expose users to risks, requiring comprehensive evaluation of existing fixing approaches.

Method: The authors conduct a large-scale empirical study evaluating 16 state-of-the-art DL model fixing approaches across model-level, layer-level, and neuron-level categories within a uniform experimental setup.

Result: Model-level approaches show superior fixing effectiveness, but no single approach achieves best fixing performance while improving accuracy and maintaining robustness, fairness, and backward compatibility.

Conclusion: The study concludes that no single approach can achieve best fixing performance while improving accuracy and maintaining all critical properties, and academia should prioritize research on mitigating side effects of DL model fixing approaches.

Abstract: Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.

</details>


### [12] [A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios](https://arxiv.org/abs/2512.23748)
*Haley Rosso,Talea Mayo*

Main category: cs.LG

TL;DR: This paper reviews simulation-based inference (SBI) using diffusion models, covering their foundations, advantages over alternatives like normalizing flows, robustness in scientific settings, and open challenges.


<details>
  <summary>Details</summary>
Motivation: Inferring parameters in complex simulations often involves intractable likelihoods, necessitating likelihood-free methods like SBI. Diffusion models offer a flexible framework for SBI but need a comprehensive review to address their application robustness in scientific contexts with issues like misspecification and unstructured data.

Method: The paper recalls the mathematical foundations of diffusion models, explains how conditional scores enable likelihood-free posterior sampling, and examines diffusion models' trade-offs compared to normalizing flows in SBI. It synthesizes methods such as Schrodinger-bridge formulations and amortized architectures, adopting consistent notation and emphasizing conditions for accuracy.

Result: Diffusion-based SBI is discussed as a robust approach for handling non-ideal conditions common in scientific data, including misspecification, unstructured or infinite-dimensional observations, and missingness. The review highlights key methods and trade-offs for practical application.

Conclusion: The review concludes that diffusion-based SBI shows promise for uncertainty quantification in probabilistic geophysical models, but identifies open problems for future research to enhance its robustness and applicability in scientific settings.

Abstract: For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters $\mathbfÎ¸$ given observed data $\mathbf{x}_{\text{o}}$. Recent work has brought attention to diffusion models -- a type of generative model rooted in score matching and reverse-time stochastic dynamics -- as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.

</details>


### [13] [Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents](https://arxiv.org/abs/2512.23749)
*Amin Sadri,M Maruf Hossain*

Main category: cs.LG

TL;DR: proposes Coordinate Matrix Machine (CM^2), a green AI model for one-shot document classification using structural features rather than semantic vectors


<details>
  <summary>Details</summary>
Motivation: address the inefficiency of current machine learning approaches that require massive datasets and computational resources, while humans can learn concepts from single examples

Method: extracts structural coordinates from documents to create a sparse representation, enabling classification based on geometric patterns rather than semantic content

Result: demonstrates superior performance compared to traditional vectorizers and deep learning models on similar document classification tasks with one sample per class

Conclusion: presented as a viable alternative to resource-intensive deep learning models, particularly for few-shot learning scenarios where interpretability and computational efficiency are prioritized.

Abstract: Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \vspace*{6pt}
  Contribution: In this paper, we present the Coordinate Matrix Machine (CM$^2$). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern "Red AI" trends rely on massive pre-training and energy-intensive GPU infrastructure, CM$^2$ is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural "important features" a human would consider, allowing it to classify very similar documents using only one sample per class.
  Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM$^2$ offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable

</details>


### [14] [Geometric Scaling of Bayesian Inference in LLMs](https://arxiv.org/abs/2512.23752)
*Naman Aggarwal,Siddhartha R. Dalal,Vishal Misra*

Main category: cs.LG

TL;DR: Large language models like Pythia, Phi-2, Llama-3, and Mistral exhibit geometric structures in their value representations that align with predictive entropy, similar to those found in smaller 'wind-tunnel' transformers enabling Bayesian inference, and targeted interventions show this geometry is a privileged readout of uncertainty.


<details>
  <summary>Details</summary>
Motivation: To investigate whether the geometric signatures observed in small transformers trained for exact Bayesian inference, such as low-dimensional value manifolds and orthogonal keys, persist in production-grade language models, and to understand the role of this geometry in uncertainty representation and Bayesian-like behavior.

Method: Analyze value representations across multiple language model families (Pythia, Phi-2, Llama-3, Mistral), focusing on last-layer organization along entropy-aligned axes. Use domain-restricted prompts to collapse structures into low-dimensional manifolds. Perform targeted interventions on the entropy-aligned axis in Pythia-410M during in-context learning to test its role.

Result: Found that last-layer value representations in production models organize along a single dominant axis strongly correlated with predictive entropy, and domain-restricted prompts reproduce low-dimensional manifolds. Interventions that remove or perturb this axis disrupt local uncertainty geometry without causing proportional degradation in Bayesian-like behavior, indicating it is a readout rather than a bottleneck.

Conclusion: Modern language models preserve the geometric substrate that supports Bayesian inference, using it to organize approximate Bayesian updates, with the geometry serving as a privileged mechanism for encoding uncertainty but not as a singular computational bottleneck.

Abstract: Recent work has shown that small transformers trained in controlled "wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.
  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.

</details>


### [15] [Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation](https://arxiv.org/abs/2512.23753)
*Deep Shankar Pandey,Hyomin Choi,Qi Yu*

Main category: cs.LG

TL;DR: This paper analyzes the issue of activation-dependent learning-freeze behavior in evidential deep learning (EDL) models, proposes a family of activation functions and regularizers to mitigate it, and validates the approach through extensive experiments.


<details>
  <summary>Details</summary>
Motivation: Evidential deep learning models introduce uncertainty quantification but are constrained by non-negative evidence requirements, leading to activation functions that can cause freezing behavior where gradients become extremely small for samples with low evidence.

Method: The authors theoretically characterize the learning-freeze behavior, analyze evidential activations, design a general family of activation functions and corresponding evidential regularizers to enable consistent evidence updates across activation regimes.

Result: The proposed generalized regularized evidential models are empirically validated on four benchmark classification problems, two few-shot classification tasks, and a blind face restoration problem, demonstrating effectiveness.

Conclusion: The paper successfully addresses the learning-freeze issue in evidential models by introducing new activation functions and regularizers, enhancing the performance and reliability of uncertainty-aware deep learning.

Abstract: Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models.

</details>


### [16] [HINTS: Extraction of Human Insights from Time-Series Without External Sources](https://arxiv.org/abs/2512.23755)
*Sheo Yon Jhin,Noseong Park*

Main category: cs.LG

TL;DR: HINTS is a self-supervised framework that extracts human factors from time series residuals without external data, improving forecast accuracy and interpretability.


<details>
  <summary>Details</summary>
Motivation: Existing approaches rely heavily on external data sources (news, social media) to capture human factors in time series forecasting, which incurs high costs in terms of data dependency. The goal is to extract these factors endogenously from the time series itself.

Method: HINTS uses a self-supervised learning framework that leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to extract latent human factors from time series residuals, which are then integrated as attention maps into a state-of-the-art backbone model.

Result: Experiments on nine real-world and benchmark datasets show that HINTS consistently improves forecasting accuracy. Case studies and ablation studies validate its interpretability, showing semantic alignment between extracted factors and real-world events.

Conclusion: The HINTS framework successfully extracts human factors endogenously from time series data and integrates them into forecasting models to improve accuracy and interpretability.

Abstract: Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.

</details>


### [17] [Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data](https://arxiv.org/abs/2512.23761)
*Esha Saha,Hao Wang*

Main category: cs.LG

TL;DR: MUSIC: sparsity-based multitask neural network that combines partial physics constraints with data to solve coupled systems when physical knowledge and data are mutually exclusive.


<details>
  <summary>Details</summary>
Motivation: Address mismatch between partial physical knowledge (one variable's governing equation) and partial data availability (other variable's observations) in coupled systems, which existing physics-informed ML cannot handle.

Method: Sparsity-induced multitask neural network with mesh-free random sampling and sparsity regularization, integrating physical constraints for one variable with data for the other.

Result: MUSIC accurately learns complex coupled system solutions (shock waves, discontinuities, patterns) under data-scarce noisy conditions, outperforming non-sparse formulations with improved efficiency.

Conclusion: MUSIC framework effectively integrates partial physical knowledge with data-driven learning for coupled systems, demonstrating robust performance under data scarcity and noise while achieving model compression and efficiency.

Abstract: Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable can be accessed only through data. This mismatch between known physics and observed data poses a fundamental challenge for existing physics-informed machine learning approaches, which generally assume either complete knowledge of the governing equations or full data availability across all variables. In this paper, we introduce MUSIC (Multitask Learning Under Sparse and Incomplete Constraints), a sparsity induced multitask neural network framework that integrates partial physical constraints with data-driven learning to recover full-dimensional solutions of coupled systems when physics-constrained and data-informed variables are mutually exclusive. MUSIC employs mesh-free (random) sampling of training data and sparsity regularization, yielding highly compressed models with improved training and evaluation efficiency. We demonstrate that MUSIC accurately learns solutions (shock wave solutions, discontinuous solutions, pattern formation solutions) to complex coupled systems under data-scarce and noisy conditions, consistently outperforming non-sparse formulations. These results highlight MUSIC as a flexible and effective approach for modeling partially observed systems with incomplete physical knowledge.

</details>
