<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems](https://arxiv.org/abs/2511.20663)
*Barak Or*

Main category: cs.MA

TL;DR: This paper introduces MTTR-A, a metric to measure cognitive recovery time in multi-agent systems, showing it can quantify reasoning stability through simulations.


<details>
  <summary>Details</summary>
Motivation: Existing tools monitor system outputs but cannot measure how quickly agent workflows recover after losing reasoning coherence in distributed AI systems.

Method: Adapted classical reliability metrics (MTTR, MTBF) to cognitive domain, conducted benchmark simulation using AG News corpus and LangGraph framework with multiple reflex modes.

Result: Automated reflexes recovered stability in ~6s vs 12s for human interventions; median MTTR-A was 6.21±2.14s, MTBF=6.7±2.14s across 200 runs.

Conclusion: Formalizing recovery latency establishes foundation for runtime dependability in agentic cognition, transforming cognitive recovery into standardized performance metric.

Abstract: Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.
  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.
  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance

</details>
