{"id": "2601.09742", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09742", "abs": "https://arxiv.org/abs/2601.09742", "authors": ["Sathish Sampath", "Anuradha Baskaran"], "title": "Adaptive Orchestration: Scalable Self-Evolving Multi-Agent Systems", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents, they face a critical scalability bottleneck known as the \"Generalization-Specialization Dilemma.\" Monolithic agents equipped with extensive toolkits suffer from context pollution and attention decay, leading to hallucinations. Conversely, static multi-agent swarms introduce significant latency and resource overhead. This paper introduces a Self-Evolving Concierge System, a novel architecture utilizing a Dynamic Mixture of Experts (DMoE) approach. Unlike recent self-improving agents that rewrite their own codebase, our system preserves stability by dynamically restructuring its runtime environment: \"hiring\" specialized sub-agents based on real-time conversation analysis. We introduce an asynchronous \"Meta-Cognition Engine\" that detects capability gaps, a Least Recently Used (LRU) eviction policy for resource constraints, and a novel \"Surgical History Pruning\" mechanism to mitigate refusal bias. Experimental results demonstrate that this architecture maintains high task success rates while minimizing token consumption compared to static agent swarms.", "AI": {"tldr": "A Self-Evolving Concierge System using Dynamic Mixture of Experts dynamically hires specialized sub-agents to solve LLM scalability issues, maintaining high success with lower resource use than static swarms.", "motivation": "The paper addresses the 'Generalization-Specialization Dilemma' in LLM-based autonomous agents: monolithic agents with extensive toolkits suffer from context pollution and attention decay (leading to hallucinations), while static multi-agent swarms introduce significant latency and resource overhead.", "method": "The paper introduces a Self-Evolving Concierge System architecture using a Dynamic Mixture of Experts (DMoE) approach. Key components include: 1) Real-time conversation analysis to dynamically 'hire' specialized sub-agents, 2) An asynchronous 'Meta-Cognition Engine' to detect capability gaps, 3) A Least Recently Used (LRU) eviction policy for resource management, and 4) A novel 'Surgical History Pruning' mechanism to mitigate refusal bias.", "result": "Experimental results show the architecture maintains high task success rates while minimizing token consumption compared to static agent swarms.", "conclusion": "The Self-Evolving Concierge System with its Dynamic Mixture of Experts approach offers a scalable, efficient solution to the Generalization-Specialization Dilemma in LLM-based autonomous agents, balancing high task success with minimal resource overhead while maintaining system stability."}}
{"id": "2601.09746", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09746", "abs": "https://arxiv.org/abs/2601.09746", "authors": ["Philip Xu", "Isabel Wagner", "Eerke Boiten"], "title": "Multi-Agent Cooperative Learning for Robust Vision-Language Alignment under OOD Concepts", "comment": null, "summary": "This paper introduces a novel Multi-Agent Cooperative Learning (MACL) framework to address cross-modal alignment collapse in vision-language models when handling out-of-distribution (OOD) concepts. Four core agents, including image, text, name, and coordination agents, collaboratively mitigate modality imbalance through structured message passing. The proposed framework enables multi-agent feature space name learning, incorporates a context exchange enhanced few-shot learning algorithm, and adopts an adaptive dynamic balancing mechanism to regulate inter-agent contributions. Experiments on the VISTA-Beyond dataset demonstrate that MACL significantly improves performance in both few-shot and zero-shot settings, achieving 1-5% precision gains across diverse visual domains.", "AI": {"tldr": "MACL framework uses multi-agent cooperation to align vision-language models for out-of-distribution concepts.", "motivation": "Address cross-modal alignment collapse in vision-language models when handling out-of-distribution concepts.", "method": "Four core agents (image, text, name, coordination) collaborate via structured message passing, multi-agent feature space name learning, context exchange enhanced few-shot learning, and adaptive dynamic balancing mechanism.", "result": "Significant performance improvement in few-shot and zero-shot settings on VISTA-Beyond dataset, achieving 1-5% precision gains across visual domains.", "conclusion": "MACL effectively mitigates modality imbalance and enhances alignment for OOD concepts in vision-language tasks."}}
{"id": "2601.10102", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10102", "abs": "https://arxiv.org/abs/2601.10102", "authors": ["Viswonathan Manoranjan", "Snehalkumar `Neil' S. Gaikwad"], "title": "When Personas Override Payoffs: Role Identity Bias in Multi-Agent LLM Decision-Making", "comment": null, "summary": "Large language models are increasingly deployed in multi-agent systems for strategic tasks, yet how design choices such as role-based personas and payoff visibility affect reasoning remains poorly understood. We investigate whether multi-agent systems function as strategic reasoners capable of payoff optimization or as identity-driven actors that prioritize role alignment over explicit incentives. Using Nash equilibrium achievement as a diagnostic for strategic reasoning, we conduct systematic experiments across four LLM architectures (Qwen-7B, Qwen-32B, Llama-8B, Mistral-7B) in complex environmental decision-making games involving four agents. We show that role identity bias fundamentally alters strategic reasoning even when payoff-optimal equilibria exist and complete payoff information is available. Removing personas and providing explicit payoffs enables Qwen models to achieve high Nash equilibrium rates, indicating that both conditions are necessary for strategic reasoning. In contrast, personas systematically bias equilibrium selection toward socially preferred outcomes: with personas present, all of the achieved equilibria correspond to Green Transition, while models entirely fail to reach equilibrium when Tragedy of the Commons is payoff-optimal. The effect of explicit payoffs depends entirely on persona presence, revealing strong interactions between representational design choices. We also observe clear model-dependent patterns. Qwen architectures are highly sensitive to both personas and payoff visibility, whereas Llama and Mistral exhibit rigid reasoning behavior across conditions. These findings demonstrate that representational choices are substantive governance decisions that determine whether multi-agent systems act as strategic reasoners or identity-driven actors, with important implications for real-world deployment.", "AI": {"tldr": "Role personas and payoff visibility in multi-agent LLM systems critically affect strategic reasoning, with personas biasing outcomes and across models responding differently to these factors.", "motivation": "To investigate how design choices (role personas and payoff visibility) impact LLM multi-agent systems' strategic reasoning, particularly whether they act as payoff optimizers or identity-driven actors, using Nash equilibrium achievement as a diagnostic tool.", "method": "Systematic experiments across four LLM architectures (Qwen-7B, Qwen-32B, Llama-8B, Mistral-7B) in complex environmental decision-making games with four agents, testing the effects of removing personas and providing explicit payoffs versus having personas present.", "result": "Role identity bias alters strategic reasoning even with payoff-optimal equilibria and complete payoff information available. Removing personas and providing explicit payoffs enables Qwen models to achieve high Nash equilibrium rates, while personas bias equilibrium selection toward socially preferred outcomes. The effect of explicit payoffs depends entirely on persona presence, with strong interactions between choices. Qwen is sensitive to personas and visibility, while Llama and Mistral show rigid reasoning across conditions.", "conclusion": "Representational choices (personas and payoff visibility) are key governance decisions determining if LLM multi-agent systems function as strategic reasoners or identity-driven actors, with implications for real-world deployment in tasks involving strategic reasoning and ethical alignment."}}
{"id": "2601.10120", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10120", "abs": "https://arxiv.org/abs/2601.10120", "authors": ["Rui Sun", "Jie Ding", "Chenghua Gong", "Tianjun Gu", "Yihang Jiang", "Juyuan Zhang", "Liming Pan", "Linyuan L\u00fc"], "title": "TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems", "comment": null, "summary": "Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes. Designed for decentralized execution to enhance adaptability and privacy, TopoDIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TopoDIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. Moreover, the framework exhibits strong adaptability in organizing communication among heterogeneous agents. Code is available at: https://anonymous.4open.science/r/TopoDIM-8D35/", "AI": {"tldr": "TopoDIM generates diverse communication topologies in one shot for LLM-based multi-agent systems, reducing latency and tokens while improving performance.", "motivation": "Existing methods in multi-agent systems rely on sequential multi-round dialogues, causing high latency and computation. Evaluation and debate mechanisms can enhance problem-solving.", "method": "We propose TopoDIM, a one-shot topology generation framework with diverse interaction modes. It enables agents to autonomously construct heterogeneous communication without iterative coordination, in a decentralized manner.", "result": "Experiments show TopoDIM reduces token consumption by 46.41% and improves average performance by 1.50% over state-of-the-art methods. It enhances adaptability in organizing communication among heterogeneous agents.", "conclusion": "The work presents an efficient framework that optimizes communication topology for better collective intelligence, demonstrating practical benefits in token savings and task performance."}}
