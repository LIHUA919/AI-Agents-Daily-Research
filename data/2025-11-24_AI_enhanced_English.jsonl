{"id": "2511.16964", "categories": ["cs.MA", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.16964", "abs": "https://arxiv.org/abs/2511.16964", "authors": ["Kirill Nagaitsev", "Luka Grbcic", "Samuel Williams", "Costin Iancu"], "title": "Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems", "comment": null, "summary": "Maximizing performance on available GPU hardware is an ongoing challenge for modern AI inference systems. Traditional approaches include writing custom GPU kernels and using specialized model compilers to tune high-level code for specific GPU targets. Recent work shows that LLM-based multi-agent systems can effectively perform such tuning, often outperforming existing compilers and eliminating the need for manual kernel development. However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems. Our evaluation shows that exploit-heavy strategies perform best when paired with error-fixing agents, and that performance correlates with the granularity of optimization steps. The best implementation achieves an average 2.88x speedup on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering a range of machine learning architectures in PyTorch.", "AI": {"tldr": "Multi-agent systems for GPU kernel optimization achieve 2.88x speedup on H100 GPUs, with exploit-heavy strategies and error-fixing agents performing best.", "motivation": "Maximizing GPU performance for AI inference is challenging, and while recent work shows LLM-based multi-agent systems can outperform traditional compilers, their dynamics remain unexplored.", "method": "Developed a logical framework for comparing multi-agent PyTorch optimization systems, testing different strategies including exploit-heavy approaches with error-fixing agents.", "result": "Achieved average 2.88x speedup on H100 GPU across diverse tasks in KernelBench, with performance correlating with optimization step granularity.", "conclusion": "Exploit-heavy strategies paired with error-fixing agents are most effective for multi-agent GPU kernel optimization, and optimization step granularity is a key performance factor."}}
