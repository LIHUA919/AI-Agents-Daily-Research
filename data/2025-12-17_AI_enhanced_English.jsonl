{"id": "2512.13696", "categories": ["cs.LG", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.13696", "abs": "https://arxiv.org/abs/2512.13696", "authors": ["Md Shahabub Alam", "Md Asifuzzaman Jishan", "Ayan Kumar Ghosh"], "title": "Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset", "comment": null, "summary": "Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guided Deep Neural Network (PG-DNN) approach for heat pump stress classification using the When2Heat dataset, containing 131,483 samples with 656 features across 26 European countries. The methodology integrates physics-guided feature selection and class definition with a deep neural network architecture featuring 5 hidden layers and dual regularization strategies. The model achieves 78.1\\% test accuracy and 78.5% validation accuracy, demonstrating significant improvements over baseline approaches: +5.0% over shallow networks, +4.0% over limited feature sets, and +2.0% over single regularization strategies. Comprehensive ablation studies validate the effectiveness of physics-guided feature selection, variable thresholding for realistic class distribution, and cross-country energy pattern analysis. The proposed system provides a production-ready solution for heat pump stress detection with 181,348 parameters and 720 seconds training time on AMD Ryzen 9 7950X with RTX 4080 hardware.", "AI": {"tldr": "Novel Physics-Guided Deep Neural Network approach achieves 78.1% test accuracy for heat pump stress classification using physics-guided feature selection and dual regularization strategies.", "motivation": "Heat pump systems are critical for energy-efficient buildings, but operational stress detection is challenging due to complex thermodynamic interactions and limited real-world data.", "method": "Integrates physics-guided feature selection and class definition with a deep neural network (5 hidden layers) featuring dual regularization strategies, using the When2Heat dataset with 131,483 samples.", "result": "Achieves 78.1% test accuracy and 78.5% validation accuracy, with significant improvements over baselines (+5.0% over shallow networks).", "conclusion": "Provides a production-ready solution for heat pump stress detection with validated effectiveness through ablation studies and cross-country energy pattern analysis."}}
{"id": "2512.13705", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13705", "abs": "https://arxiv.org/abs/2512.13705", "authors": ["Siqi Wang", "Zhengyu Chen", "Teng Xiao", "Zheqi Lv", "Jinluan Yang", "Xunliang Cai", "Jingang Wang", "Xiaomeng Li"], "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training", "comment": "Accepted to AAAI 2026 (camera-ready version)", "summary": "Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamics in large language model training and refine a generalized predictive framework for optimizing annealing strategies under the Warmup-Steady-Decay (WSD) scheduler. Our improved framework incorporates training steps, maximum learning rate, and annealing behavior, enabling more efficient optimization of learning rate schedules. Our work provides a practical guidance for selecting optimal annealing strategies without exhaustive hyperparameter searches, demonstrating that smaller models can serve as reliable proxies for optimizing the training dynamics of larger models. We validate our findings on extensive experiments using both Dense and Mixture-of-Experts (MoE) models, demonstrating that optimal annealing ratios follow consistent patterns and can be transferred across different training configurations.", "AI": {"tldr": "Optimal annealing strategies can be efficiently transferred from smaller to larger LLMs using a refined predictive framework, validated on Dense and MoE models.", "motivation": "Optimal annealing strategies for learning rate scheduling in large language models remain challenging to determine across different model configurations, requiring more efficient optimization methods.", "method": "Investigates transferability of annealing dynamics in LLM training and refines a predictive framework incorporating training steps, max learning rate, and annealing behavior under the WSD scheduler.", "result": "The improved framework enables more efficient optimization of learning rate schedules, showing consistent transferable patterns in optimal annealing ratios across different training configurations.", "conclusion": "The study demonstrates that smaller models can reliably proxy larger models' training dynamics, enabling efficient optimization of learning rate schedules without exhaustive searches, validated across Dense and MoE model architectures."}}
{"id": "2512.13706", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13706", "abs": "https://arxiv.org/abs/2512.13706", "authors": ["John Graham Reynolds"], "title": "Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training", "comment": "11 pages, 2 figures. Code available at https://github.com/johngrahamreynolds/mathematical_catastrophe_mitigation. Models available at https://huggingface.co/collections/MarioBarbeque/catastrophic-forgetting-in-mathematical-reasoning", "summary": "When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\\% to 12.0\\% but causes NLI accuracy to collapse from 81.0\\% to 16.5\\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\\% math accuracy (matching math-only) while preserving 86.2\\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.", "AI": {"tldr": "Mixed training with balanced mathematical and NLI examples prevents catastrophic forgetting during LLM fine-tuning while maintaining task-specific performance.", "motivation": "Large language models exhibit catastrophic forgetting when fine-tuned for specialized tasks like mathematical reasoning, losing previously learned general capabilities. The researchers investigate this problem and propose strategies to maintain both specialized and general abilities.", "method": "Fine-tuning Flan-T5-Base (250M parameters) on DeepMind Mathematics dataset, measuring forgetting on MultiNLI. Testing mixed training strategies that interleave mathematical and NLI examples during training. Systematically exploring mixing ratios from 1:1 to 15:1.", "result": "Math-only training improved mathematical accuracy from 3.1% to 12.0% but caused catastrophic forgetting: NLI accuracy collapsed from 81.0% to 16.5%, with the 64.5 percentage point drop occurring within the first 1,000 training steps. Mixed training completely eliminated forgetting while maintaining mathematical performance: a balanced 1:1 ratio achieved 12.0% math accuracy (matching math-only) while preserving 86.2% NLI accuracy. Even minimal NLI exposure (6.2% in 15:1 ratio) provided effective regularization.", "conclusion": "The findings demonstrate that catastrophic forgetting during LLM fine-tuning can be fully eliminated through mixed training strategies without compromising task-specific performance. For models scaled up beyond 250M parameters, mixed training may offer additional benefits beyond just forgetting prevention."}}
