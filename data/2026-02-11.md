<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: CoMMa is a decentralized LLM-agent framework using deterministic embeddings and game-theoretic coordination for improved interpretability and stability in oncology decision support.


<details>
  <summary>Details</summary>
Motivation: To address the need for robust decision-making in oncology that requires reasoning over dynamic, heterogeneous patient data, moving beyond stochastic narrative-based reasoning in existing agent frameworks.

Method: Proposes Contribution-Aware Medical Multi-Agents (CoMMa), where specialists operate on partitioned evidence and coordinate via a game-theoretic objective, using deterministic embedding projections for contribution-aware credit assignment.

Result: CoMMa achieves higher accuracy and more stable performance on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, compared to data-centralized and role-based multi-agent baselines.

Conclusion: CoMMa enhances oncology decision support by providing interpretable and mathematically grounded decision pathways through explicit evidence attribution and improved stability in multi-agent coordination.

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Enhanced Graph Transformer with Serialized Graph Tokens](https://arxiv.org/abs/2602.09065)
*Ruixiang Wang,Yuyang Hong,Shiming Xiang,Chunhong Pan*

Main category: cs.LG

TL;DR: A new serialized token paradigm improves graph-level representation in Transformers by aggregating node signals into multiple tokens and using self-attention, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: Existing Transformers for graph learning have an information bottleneck in graph-level tasks due to the single token paradigm, which degenerates into a weighted sum and fails to leverage self-attention fully.

Method: Propose a graph serialization method to aggregate node signals into serialized graph tokens with positional encoding, then apply stacked self-attention layers to encode token sequences and capture dependencies.

Result: The method achieves state-of-the-art results on several graph-level benchmarks, with ablation studies verifying the effectiveness of the proposed modules.

Conclusion: The serialized token paradigm effectively addresses the information bottleneck, yielding more expressive graph representations and outperforming existing methods.

Abstract: Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully leverage the inherent strength of self-attention in encoding token sequences, and degenerates into a weighted sum of node signals. To address this issue, we design a novel serialized token paradigm to encapsulate global signals more effectively. Specifically, a graph serialization method is proposed to aggregate node signals into serialized graph tokens, with positional encoding being automatically involved. Then, stacked self-attention layers are applied to encode this token sequence and capture its internal dependencies. Our method can yield more expressive graph representations by modeling complex interactions among multiple graph tokens. Experimental results show that our method achieves state-of-the-art results on several graph-level benchmarks. Ablation studies verify the effectiveness of the proposed modules.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [3] [LingxiDiagBench: A Multi-Agent Framework for Benchmarking LLMs in Chinese Psychiatric Consultation and Diagnosis](https://arxiv.org/abs/2602.09379)
*Shihao Xu,Tiancheng Zhou,Jiatong Ma,Yanli Ding,Yiming Yan,Ming Xiao,Guoyi Li,Haiyang Geng,Yunyun Han,Jianhua Chen,Yafeng Deng*

Main category: cs.MA

TL;DR: LingxiDiagBench is a benchmark for evaluating LLMs in psychiatric diagnosis, including static inference and dynamic consultation in Chinese, using synthetic dialogues to assess performance on tasks like comorbidity recognition.


<details>
  <summary>Details</summary>
Motivation: Mental disorders are prevalent, but diagnosis faces barriers like psychiatrist shortage and subjectivity. AI-assisted diagnosis lacks benchmarks with realistic patient simulation, verified labels, and multi-turn consultation support.

Method: Developed LingxiDiagBench, a multi-agent benchmark with LingxiDiag-16K, a dataset of 16,000 synthetic consultation dialogues aligned with EMRs and ICD-10 categories, to evaluate LLMs on static diagnostic inference and dynamic consultation.

Result: LLMs achieve high accuracy on binary depression-anxiety classification (up to 92.3%) but perform poorly on comorbidity recognition (43.0%) and 12-way differential diagnosis (28.5%). Dynamic consultation often underperforms static evaluation, and consultation quality has moderate correlation with diagnostic accuracy.

Conclusion: The benchmark highlights limitations in LLM diagnostic reasoning, especially for complex cases, and suggests that effective information-gathering strategies are crucial. LingxiDiag-16K and the evaluation framework are released to support reproducible research.

Abstract: Mental disorders are highly prevalent worldwide, but the shortage of psychiatrists and the inherent subjectivity of interview-based diagnosis create substantial barriers to timely and consistent mental-health assessment. Progress in AI-assisted psychiatric diagnosis is constrained by the absence of benchmarks that simultaneously provide realistic patient simulation, clinician-verified diagnostic labels, and support for dynamic multi-turn consultation. We present LingxiDiagBench, a large-scale multi-agent benchmark that evaluates LLMs on both static diagnostic inference and dynamic multi-turn psychiatric consultation in Chinese. At its core is LingxiDiag-16K, a dataset of 16,000 EMR-aligned synthetic consultation dialogues designed to reproduce real clinical demographic and diagnostic distributions across 12 ICD-10 psychiatric categories. Through extensive experiments across state-of-the-art LLMs, we establish key findings: (1) although LLMs achieve high accuracy on binary depression--anxiety classification (up to 92.3%), performance deteriorates substantially for depression--anxiety comorbidity recognition (43.0%) and 12-way differential diagnosis (28.5%); (2) dynamic consultation often underperforms static evaluation, indicating that ineffective information-gathering strategies significantly impair downstream diagnostic reasoning; (3) consultation quality assessed by LLM-as-a-Judge shows only moderate correlation with diagnostic accuracy, suggesting that well-structured questioning alone does not ensure correct diagnostic decisions. We release LingxiDiag-16K and the full evaluation framework to support reproducible research at https://github.com/Lingxi-mental-health/LingxiDiagBench.

</details>


### [4] [Dieu khien he da tac tu](https://arxiv.org/abs/2602.09412)
*Minh Hoang Trinh,Hieu Minh Nguyen*

Main category: cs.MA

TL;DR: A textbook on multi-agent system control, developed from 2021 for courses at Hanoi University of Science and Technology, covering fundamentals like graph theory, consensus algorithms, and applications such as formation control and distributed optimization, with step-by-step explanations to bridge teaching and research.


<details>
  <summary>Details</summary>
Motivation: There is a scarcity of systematic textbooks on the fundamental principles of multi-agent system control, despite growing interest since the early 2000s and diverse applications in areas like autonomous vehicles and smart grids.

Method: The book is structured into three parts: Part I introduces multi-agent systems and graph theory basics, Part II focuses on linear consensus algorithms design and analysis, and Part III covers selected applications including formation control, network localization, and distributed optimization, presented in a step-by-step manner for accessibility.

Result: The material has been used in teaching since 2021, starting as a Vietnamese-language reference, and aims to provide a comprehensive yet accessible resource with chapters including notes on researchers, further reading, and exercises.

Conclusion: This book addresses the need for fundamental education in multi-agent system control by offering a structured, practical approach that connects theory to real-world applications, with acknowledgments for support and an open call for reader feedback to enhance future editions.

Abstract: Since the early 2000s, control of multiagent systems has attracted significant research interest, with applications ranging from natural collective behaviors and social dynamics to engineered systems such as autonomous vehicles, sensor networks, and smart grids. Although research on multi-agent systems has diversified into numerous specialized directions, textbooks -- including those in English -- that provide a systematic treatment of the fundamental principles of multi-agent system control remain scarce. The material presented in this book has been developed and used in teaching since 2021, initially as a concise Vietnamese-language reference for the courses Networked Control Systems and Control of Multi-Agent Systems at Hanoi University of Science and Technology. The book focuses on a selection of fundamental topics of broad and continuing interest in the field. The complexity of several topics is asymptotic to that encountered in research-level studies, however, the analysis is presented in a step-by-step manner to facilitate access to commonly used methods and tools.
  The material is divided into three main parts. Part I introduces multiagent systems and basic graph-theoretic concepts. Part II addresses the design and analysis of linear consensus algorithms. Part III covers selected applications and research directions, including formation control, network localization, distributed optimization, opinion dynamics, and matrix-weighted networks. Each chapter concludes with notes on notable researchers in this field, further reading, and exercises.
  This book cannot be completed without the encouragement, support and suggestions from families, colleagues and friends. The authors appreciate feedback from readers to further improve the content of the book.

</details>


### [5] [Tiny Moves: Game-based Hypothesis Refinement](https://arxiv.org/abs/2602.09801)
*Agnieszka Dobrowolska,Rogier Hintzen,Martin Balla,Karl Gemayel,Sabine Reichert,Thomas Charman,Jen Ning Lim,Lindsay Edwards,Anna Gogleva*

Main category: cs.MA

TL;DR: The Hypothesis Game uses LLM agents with symbolic reasoning moves for incremental hypothesis refinement, showing superior error correction in corruption recovery compared to prompting baselines.


<details>
  <summary>Details</summary>
Motivation: Scientific discovery often involves small, localized revisions grounded in domain context rather than end-to-end predictions, but current machine learning approaches obscure this incremental structure.

Method: A symbolic formalism with LLM agents operating on a shared hypothesis state using a fixed grammar of reasoning moves, evaluated on pathway-level mechanistic refinement tasks including corruption recovery and reconstruction from partial cues.

Result: In corruption recovery, the game-based approach removes more errors and achieves higher precision than strong prompting baselines while preserving valid structure. In reconstruction, it performs comparably to the strongest baseline.

Conclusion: Game-based reasoning is a principled route to more controllable, interpretable, and transferable hypothesis refinement systems for scientific discovery.

Abstract: Most machine learning approaches to scientific discovery frame hypotheses as end-to-end predictions, obscuring the incremental structure of scientific reasoning. We propose The Hypothesis Game, a symbolic formalism for hypothesis refinement in which LLM agents operate on a shared hypothesis state using a fixed grammar of reasoning moves. The framework is motivated by the observation that scientific progress often proceeds through small, localized revisions, grounded in domain context, rather than extensive rewrites. We instantiate a minimal game with LLM agents and evaluate it on pathway-level mechanistic refinement tasks. In the primary setting of corruption recovery, where hypotheses contain controlled errors, the game-based approach consistently removes more errors and achieves higher precision than strong prompting baselines, while preserving valid structure through incremental edits. In a secondary reconstruction setting from partial cues, it performs comparably to the strongest baseline, indicating that explicit move-based refinement remains competitive even when ground-truth recovery is difficult. These findings support game-based reasoning as a principled route to more controllable, interpretable, and transferable hypothesis refinement systems for scientific discovery.

</details>
