{"id": "2601.03301", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03301", "abs": "https://arxiv.org/abs/2601.03301", "authors": ["Guotao Li", "Shaoyun Xu", "Yuexing Hao", "Yang Wang", "Yuhui Sun"], "title": "PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception", "comment": "8 pages,7 figures,3 tables,Accepted to IROS 2025", "summary": "Distributed Multi-Agent Path Finding (MAPF) integrated with Multi-Agent Reinforcement Learning (MARL) has emerged as a prominent research focus, enabling real-time cooperative decision-making in partially observable environments through inter-agent communication. However, due to insufficient collaborative and perceptual capabilities, existing methods are inadequate for scaling across diverse environmental conditions. To address these challenges, we propose PC2P, a novel distributed MAPF method derived from a Q-learning-based MARL framework. Initially, we introduce a personalized-enhanced communication mechanism based on dynamic graph topology, which ascertains the core aspects of ``who\" and ``what\" in interactive process through three-stage operations: selection, generation, and aggregation. Concurrently, we incorporate local crowd perception to enrich agents' heuristic observation, thereby strengthening the model's guidance for effective actions via the integration of static spatial constraints and dynamic occupancy changes. To resolve extreme deadlock issues, we propose a region-based deadlock-breaking strategy that leverages expert guidance to implement efficient coordination within confined areas. Experimental results demonstrate that PC2P achieves superior performance compared to state-of-the-art distributed MAPF methods in varied environments. Ablation studies further confirm the effectiveness of each module for overall performance.", "AI": {"tldr": "PC2P is a novel distributed MAPF method that improves multi-agent collaboration through personalized communication, enhanced perception, and deadlock resolution, outperforming state-of-the-art methods.", "motivation": "Existing distributed MAPF methods integrated with MARL have insufficient collaborative and perceptual capabilities, making them inadequate for scaling across diverse environmental conditions. There is a need to address challenges in real-time cooperative decision-making in partially observable environments through improved communication and perception.", "method": "The paper proposes PC2P, a Q-learning-based MARL framework with three key components: 1) personalized-enhanced communication mechanism using dynamic graph topology (selection, generation, aggregation), 2) local crowd perception that integrates static spatial constraints and dynamic occupancy changes, and 3) region-based deadlock-breaking strategy leveraging expert guidance.", "result": "Experimental results show that PC2P achieves superior performance compared to state-of-the-art distributed MAPF methods in varied environments. Ablation studies confirm the effectiveness of each individual module for overall performance improvement.", "conclusion": "PC2P demonstrates superior collaborative performance in distributed MAPF tasks through its personalized-enhanced communication mechanism, local crowd perception, and region-based deadlock resolution strategy."}}
{"id": "2601.03328", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.03328", "abs": "https://arxiv.org/abs/2601.03328", "authors": ["Harri Renney", "Maxim N Nethercott", "Nathan Renney", "Peter Hayes"], "title": "LLM-Enabled Multi-Agent Systems: Empirical Evaluation and Insights into Emerging Design Patterns & Paradigms", "comment": null, "summary": "This paper formalises the literature on emerging design patterns and paradigms for Large Language Model (LLM)-enabled multi-agent systems (MAS), evaluating their practical utility across various domains. We define key architectural components, including agent orchestration, communication mechanisms, and control-flow strategies, and demonstrate how these enable rapid development of modular, domain-adaptive solutions. Three real-world case studies are tested in controlled, containerised pilots in telecommunications security, national heritage asset management, and utilities customer service automation. Initial empirical results show that, for these case studies, prototypes were delivered within two weeks and pilot-ready solutions within one month, suggesting reduced development overhead compared to conventional approaches and improved user accessibility. However, findings also reinforce limitations documented in the literature, including variability in LLM behaviour that leads to challenges in transitioning from prototype to production maturity. We conclude by outlining critical research directions for improving reliability, scalability, and governance in MAS architectures and the further work needed to mature MAS design patterns to mitigate the inherent challenges.", "AI": {"tldr": "LLM-enabled multi-agent systems enable rapid prototype development (2 weeks) and pilot-ready solutions (1 month) across domains, but face challenges in production maturity due to LLM variability, requiring research on reliability, scalability, and governance.", "motivation": "To evaluate the practical utility of LLM-enabled multi-agent systems (MAS) design patterns across various domains and demonstrate how these enable rapid development of modular, domain-adaptive solutions.", "method": "The paper formalizes literature on LLM-enabled multi-agent system design patterns, defines key architectural components (agent orchestration, communication mechanisms, control-flow strategies), and conducts three real-world case studies in telecommunications security, national heritage asset management, and utilities customer service automation using controlled, containerised pilots.", "result": "Initial empirical results show prototypes were delivered within two weeks and pilot-ready solutions within one month, suggesting reduced development overhead and improved user accessibility compared to conventional approaches, but also revealing limitations including variability in LLM behavior that challenges transition from prototype to production maturity.", "conclusion": "The paper outlines critical research directions for improving reliability, scalability, and governance in MAS architectures, and emphasizes the need for further work to mature MAS design patterns to mitigate inherent challenges."}}
{"id": "2601.03702", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.03702", "abs": "https://arxiv.org/abs/2601.03702", "authors": ["Zhilong Tang", "Shaohua Wu", "Xinyan Zhao", "Yu Wang", "Xingchu Gong"], "title": "A Chromatographic Process Design and Optimization Platform Powered by Large Language Models: A Case Application on Extract of Ginkgo Biloba Leaf", "comment": null, "summary": "Chromatographic separation technology has been widely applied in pharmaceutical, chemical, and food industries due to its high efficiency. However, traditional human-dependent chromatographic process development faces challenges such as reliance on expert experience, long development cycles, and labor intensity. ChromR, a large language model (LLM)-driven platform for chromatographic process design and optimization, is presented in this work. The platform integrates ChromLLM, a domain-specific LLM trained for chromatography, along with a multi-agent system and an automated chromatographic experimental device. The multi-agent system comprises four agents: domain knowledge answering, experimental design, experimental execution, and data analysis. ChromR enables automatic completion of the entire workflow-including initial process parameter recommendation, experimental design, automated execution, data analysis, and multi-objective optimization. By utilizing ChromR, dependency on expert knowledge is effectively reduced, while labor input and development time are significantly decreased. Chromatographic purification of the extract of Ginkgo biloba leaf (EGBL) was selected as a case study. ChromR successfully developed a chromatographic process within one week that meets multiple objectives, including fraction quality and production efficiency, reducing development time to approximately one-seventh of that required by the conventional paradigm. An intelligent, automated, and universally applicable new paradigm was established for chromatographic process development.", "AI": {"tldr": "ChromR is an LLM-driven platform that automates chromatographic process design and optimization, reducing development time from weeks to days while decreasing dependency on expert knowledge.", "motivation": "Traditional chromatographic process development faces challenges including reliance on expert experience, long development cycles, and labor intensity, which limit efficiency and scalability.", "method": "The ChromR platform integrates ChromLLM (domain-specific LLM for chromatography), a multi-agent system with four specialized agents (knowledge answering, experimental design, experimental execution, data analysis), and an automated chromatographic experimental device to enable automatic workflow completion.", "result": "ChromR successfully developed a chromatographic process for Ginkgo biloba leaf extract within one week, meeting multiple objectives and reducing development time to approximately one-seventh of conventional methods.", "conclusion": "An intelligent, automated, and universally applicable new paradigm was established for chromatographic process development, significantly reducing dependency on expert knowledge and dramatically cutting development time."}}
{"id": "2601.03846", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03846", "abs": "https://arxiv.org/abs/2601.03846", "authors": ["Alessio Buscemi", "Daniele Proverbio", "Alessandro Di Stefano", "The Anh Han", "German Castignani", "Pietro Li\u00f2"], "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents", "comment": null, "summary": "LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.", "AI": {"tldr": "A game-theoretic analysis of covert communication in LLM-driven multi-agent systems, examining when and how indirect signals shape coordination without explicit messaging.", "motivation": "While existing work focuses on individual agents or explicit communication, there is limited understanding of how interacting agents coordinate implicitly through covert, non-linguistic signals embedded in actions.", "method": "A game-theoretic study across four canonical settings (e.g., coordination, competition) under different communication regimes: explicit, restricted, or absent. Heterogeneous agent personalities and both one-shot and repeated games are considered to analyze signal emergence.", "result": "Characterization of conditions under which covert signals emerge and how they influence coordination and strategic outcomes, such as equilibrium outcomes and agent behavior patterns.", "conclusion": "Covert communication, via indirect actions, can effectively shape strategic interactions in multi-agent systems, especially when explicit communication is absent or limited, highlighting its role in implicit coordination."}}
{"id": "2601.03306", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03306", "abs": "https://arxiv.org/abs/2601.03306", "authors": ["Jingbin Liu", "Xuechun Wang"], "title": "Mastering the Game of Go with Self-play Experience Replay", "comment": "13 pages, 5 figures", "summary": "The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and off-policy experience replay. Built upon entropy-regularized Q-learning, QZero utilizes a single Q-value network to unify policy evaluation and improvement. Starting tabula rasa without human data and trained for 5 months with modest compute resources (7 GPUs), QZero achieved a performance level comparable to that of AlphaGo. This demonstrates, for the first time, the efficiency of using model-free reinforcement learning to master the game of Go, as well as the feasibility of off-policy reinforcement learning in solving large-scale and complex environments.", "AI": {"tldr": "Novel model-free RL algorithm QZero uses deep Q-learning with entropy regularization and self-play to master Go without MCTS, matching AlphaGo performance with modest compute.", "motivation": "Go is a benchmark for AI requiring strategic reasoning; prior methods like AlphaGo used model-based MCTS, which can be complex and resource-intensive. This paper aims to demonstrate model-free RL can achieve similar performance efficiently, exploring off-policy learning in large-scale environments.", "method": "Proposes QZero, a model-free RL algorithm based on entropy-regularized Q-learning with off-policy experience replay. Uses a single Q-value network for policy evaluation and improvement, trained via self-play without human data or search during training.", "result": "QZero, trained tabula rasa for 5 months with 7 GPUs (modest compute), achieved performance comparable to AlphaGo, demonstrating efficiency in mastering Go.", "conclusion": "First demonstration that model-free RL can master Go efficiently, validating off-policy learning's feasibility in complex environments, potentially simplifying algorithms and reducing computational overhead compared to MCTS-based approaches."}}
