{"id": "2511.20663", "categories": ["cs.MA", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20663", "abs": "https://arxiv.org/abs/2511.20663", "authors": ["Barak Or"], "title": "MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems", "comment": "preprint", "summary": "Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.\n  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.\n  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance", "AI": {"tldr": "This paper introduces MTTR-A (Mean Time-to-Recovery for Agentic Systems) to quantify cognitive recovery latency in multi-agent systems, showing automated reflexes restore stability in ~6s vs ~12s for human interventions.", "motivation": "Existing observability tools monitor system outputs but cannot quantify how rapidly agentic workflows recover once reasoning coherence is lost in autonomous multi-agent systems.", "method": "Adapted classical reliability metrics (MTTR, MTBF) to cognitive domain, defining MTTR-A as runtime measure of cognitive recovery latency. Conducted benchmark simulation using AG News corpus and LangGraph framework, modeling recovery latencies across reflex modes.", "result": "Automated reflexes restored stability within ~6s average, human-approval interventions ~12s. Across 200 runs: median MTTR-A=6.21\u00b12.14s, MTBF=6.7\u00b12.14s, NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.", "conclusion": "Formalizes recovery latency as quantifiable property of distributed reasoning, establishing foundation for runtime dependability in agentic cognition and transforming cognitive recovery from ad-hoc process to standardized performance metric."}}
{"id": "2511.20943", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20943", "abs": "https://arxiv.org/abs/2511.20943", "authors": ["Chuhao Qin", "Alexandru Sorici", "Andrei Olaru", "Evangelos Pournaras", "Adina Magda Florea"], "title": "Resilient Charging Infrastructure via Decentralized Coordination of Electric Vehicles at Scale", "comment": "14 pages, 12 figures. This work has been submitted to the IEEE for possible publication", "summary": "The rapid adoption of electric vehicles (EVs) introduces major challenges for decentralized charging control. Existing decentralized approaches efficiently coordinate a large number of EVs to select charging stations while reducing energy costs, preventing power peak and preserving driver privacy. However, they often struggle under severe contingencies, such as station outages or unexpected surges in charging requests. These situations create competition for limited charging slots, resulting in long queues and reduced driver comfort. To address these limitations, we propose a novel collective learning-based coordination framework that allows EVs to balance individual comfort on their selections against system-wide efficiency, i.e., the overall queues across all stations. In the framework, EVs are recommended for adaptive charging behaviors that shift priority between comfort and efficiency, achieving Pareto-optimal trade-offs under varying station capacities and dynamic spatio-temporal EV distribution. Experiments using real-world data from EVs and charging stations show that the proposed approach outperforms baseline methods, significantly reducing travel and queuing time. The results reveal that, under uncertain charging conditions, EV drivers that behave selfishly or altruistically at the right moments achieve shorter waiting time than those maintaining moderate behavior throughout. Our findings under high fractions of station outages and adversarial EVs further demonstrate improved resilience and trustworthiness of decentralized EV charging infrastructure.", "AI": {"tldr": "A collective learning framework for EV charging coordination that balances individual comfort against system efficiency, achieving Pareto-optimal trade-offs and improved resilience under contingencies.", "motivation": "Existing decentralized EV charging approaches struggle under severe contingencies like station outages or unexpected charging surges, creating competition for limited slots, long queues, and reduced driver comfort.", "method": "Proposed a novel collective learning-based coordination framework where EVs are recommended adaptive charging behaviors that shift priority between comfort and efficiency based on varying station capacities and dynamic EV distribution.", "result": "Experiments with real-world data show the approach outperforms baselines, significantly reducing travel and queuing time. EVs behaving selfishly or altruistically at the right moments achieve shorter waiting times than those maintaining moderate behavior throughout.", "conclusion": "The framework demonstrates improved resilience and trustworthiness of decentralized EV charging infrastructure under high fractions of station outages and adversarial EVs, achieving Pareto-optimal trade-offs between individual comfort and system efficiency."}}
{"id": "2511.21510", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21510", "abs": "https://arxiv.org/abs/2511.21510", "authors": ["Ke Zhang", "Xiaoning Zhao", "Ce Zheng", "Jiahong Ning", "Dandan Zhu", "Wenqi Zhang", "Chen Sun", "Toshiharu Sugawara"], "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "comment": "9 pages, 3 figures", "summary": "This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco", "AI": {"tldr": "Tool-RoCo is a benchmark for evaluating LLM autonomy in multi-agent cooperation using tool usage paradigms, showing current LLMs rarely use cooperative tools and mainly maintain active agents without adaptive deactivation.", "motivation": "Recent LLM-based multi-agent systems rely on predefined orchestration and ignore agent autonomy. Tool-RoCo addresses this gap by treating agents as tools to evaluate multi-agent cooperation and self-organization.", "method": "Proposes four LLM paradigms for different autonomy levels: centralized cooperation, centralized self-organization, decentralized cooperation, and self-organization. Uses three multi-robot tasks (SORT, PACK, CABINET) to measure coordination through tool usage.", "result": "Cooperative tools accounted for only 7.09% of all tools, showing LLM-based agents rarely invoke others as assistants. Activation tools dominated at 96.42%, indicating LLMs tend to maintain active agents without adaptive deactivation.", "conclusion": "Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks, revealing current limitations in cooperative behavior and adaptive coordination."}}
{"id": "2511.21572", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21572", "abs": "https://arxiv.org/abs/2511.21572", "authors": ["Liming Yang", "Junyu Luo", "Xuanzhe Liu", "Yiling Lou", "Zhenpeng Chen"], "title": "BAMAS: Structuring Budget-Aware Multi-Agent Systems", "comment": "Accepted by AAAI 2026 (oral paper)", "summary": "Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.", "AI": {"tldr": "BAMAS is a budget-aware multi-agent system that selects optimal LLMs and collaboration topologies to achieve comparable performance with up to 86% cost reduction.", "motivation": "Existing multi-agent systems rarely address budget constraints despite cost being crucial for practical deployment as systems scale in complexity.", "method": "BAMAS uses Integer Linear Programming to select optimal LLMs balancing performance and cost, then reinforcement learning to determine collaboration topology, and finally instantiates the system.", "result": "BAMAS achieves comparable performance to state-of-the-art methods while reducing costs by up to 86% across three representative tasks.", "conclusion": "BAMAS provides an effective framework for building cost-efficient multi-agent systems that maintain performance while significantly reducing deployment costs."}}
{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.", "AI": {"tldr": "LLMs can automatically restructure hierarchies to optimize hyperbolic embeddings by increasing branching factor and enforcing single inheritance, leading to improved embedding quality across diverse datasets.", "motivation": "Hyperbolic embeddings perform best with high branching factors and single inheritance, but real-world hierarchies often don't meet these criteria. The paper aims to use LLMs to automatically restructure hierarchies for better hyperbolic embeddings.", "method": "Proposed a prompt-based approach using Large Language Models to transform existing hierarchies according to known desiderata for hyperbolic embeddings (high branching factor, single inheritance).", "result": "Experiments on 16 diverse hierarchies show LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard metrics, with LLMs providing explainable reorganizations.", "conclusion": "LLMs can effectively restructure hierarchies to meet hyperbolic embedding criteria, improving embedding quality while providing explainable reorganizations that assist knowledge engineers."}}
{"id": "2511.20696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20696", "abs": "https://arxiv.org/abs/2511.20696", "authors": ["Dan Li", "Hye-Bin Shin", "Yeon-Woo Choi"], "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding", "comment": "4 pages, 2 figures, 14th IEEE International Winter Conference on Brain-Computer Interface Conference 2026", "summary": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.", "AI": {"tldr": "ProNECL framework enables continual EEG decoding without storing historical data by using class-level prototypes and cross-subject feature alignment, achieving superior performance on BCI datasets.", "motivation": "Address privacy and memory constraints in continual EEG decoding by eliminating the need to store historical EEG samples from previous subjects, while preventing knowledge forgetting.", "method": "Constructs class-level prototypes to summarize discriminative representations from each subject, uses cross-subject feature alignment and knowledge distillation to incrementally align new feature spaces with global prototype memory.", "result": "Validated on BCI Competition IV 2a and 2b datasets, effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.", "conclusion": "ProNECL framework successfully preserves prior knowledge without accessing historical EEG samples, providing a practical solution for continual EEG decoding under privacy and memory constraints."}}
{"id": "2511.20693", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20693", "abs": "https://arxiv.org/abs/2511.20693", "authors": ["Mingming Zhao", "Xiaokang Wei", "Yuanqi Shao", "Kaiwen Zhou", "Lin Yang", "Siwei Rao", "Junhui Zhan", "Zhitang Chen"], "title": "$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators", "comment": "Accepted by AAAI-2026", "summary": "Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\\% and 19.3\\% average performance improvement and reduces resource usage by 37\\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW", "AI": {"tldr": "A2Flow: Fully automated framework for agentic workflow generation using self-adaptive abstraction operators, achieving significant performance improvements over state-of-the-art methods.", "motivation": "Existing LLM-based agentic workflow design methods rely heavily on manually predefined operators, limiting generalization and scalability.", "method": "Three-stage operator extraction: 1) Case-based initial operator generation using expert demonstrations and LLM reasoning, 2) Operator clustering and preliminary abstraction across tasks, 3) Deep extraction for abstract execution operators using chain-of-thought prompting and multi-path reasoning.", "result": "A2Flow achieves 2.4% and 19.3% average performance improvement on general and embodied benchmarks, with 37% reduction in resource usage compared to state-of-the-art baselines.", "conclusion": "The framework successfully enables automated workflow generation without manual predefinition, demonstrating improved performance and efficiency through reusable operator building blocks and operator memory mechanism."}}
{"id": "2511.20686", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20686", "abs": "https://arxiv.org/abs/2511.20686", "authors": ["Chae-Gyun Lim", "Seung-Ho Han", "EunYoung Byun", "Jeongyun Han", "Soohyun Cho", "Eojin Joo", "Heehyeon Kim", "Sieun Kim", "Juhoon Lee", "Hyunsoo Lee", "Dongkun Lee", "Jonghwan Hyeon", "Yechan Hwang", "Young-Jun Lee", "Kyeongryul Lee", "Minhyeong An", "Hyunjun Ahn", "Jeongwoo Son", "Junho Park", "Donggyu Yoon", "Taehyung Kim", "Jeemin Kim", "Dasom Choi", "Kwangyoung Lee", "Hyunseung Lim", "Yeohyun Jung", "Jongok Hong", "Sooyohn Nam", "Joonyoung Park", "Sungmin Na", "Yubin Choi", "Jeanne Choi", "Yoojin Hong", "Sueun Jang", "Youngseok Seo", "Somin Park", "Seoungung Jo", "Wonhye Chae", "Yeeun Jo", "Eunyoung Kim", "Joyce Jiyoung Whang", "HwaJung Hong", "Joseph Seering", "Uichin Lee", "Juho Kim", "Sunna Choi", "Seokyeon Ko", "Taeho Kim", "Kyunghoon Kim", "Myungsik Ha", "So Jung Lee", "Jemin Hwang", "JoonHo Kwak", "Ho-Jin Choi"], "title": "AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI", "comment": "16 pages, HuggingFace: https://huggingface.co/datasets/TTA01/AssurAI", "summary": "The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.", "AI": {"tldr": "AssurAI is a new Korean multimodal dataset for evaluating generative AI safety, addressing the gap in non-English safety assessments through 35 risk factors and rigorous quality control across text, image, video, and audio modalities.", "motivation": "Current safety datasets are predominantly English-centric and fail to capture specific risks in non-English socio-cultural contexts like Korean, while also being limited to text modality only.", "method": "Defined 35 AI risk factors adapted from established frameworks by multidisciplinary experts, constructed AssurAI dataset with 11,480 instances across text/image/video/audio using two-phase construction (expert-led seeding + crowdsourced scaling), triple independent annotation, and iterative expert red-teaming loops.", "result": "Created a large-scale Korean multimodal safety evaluation dataset with rigorous quality control, validated through pilot studies showing effectiveness in assessing LLM safety.", "conclusion": "AssurAI addresses the critical gap in non-English AI safety evaluation and is released publicly to facilitate development of safer generative AI systems for the Korean community."}}
{"id": "2511.20698", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20698", "abs": "https://arxiv.org/abs/2511.20698", "authors": ["Tsubasa Masumura", "Masato Taki"], "title": "On the Role of Hidden States of Modern Hopfield Network in Transformer", "comment": "NeurIPS 2025 accepted", "summary": "Associative memory models based on Hopfield networks and self-attention based on key-value mechanisms have been popular approaches in the study of memory mechanisms in deep learning. It has been pointed out that the state update rule of the modern Hopfield network (MHN) in the adiabatic approximation is in agreement with the self-attention layer of Transformer. In this paper, we go beyond this approximation and investigate the relationship between MHN and self-attention. Our results show that the correspondence between Hopfield networks and Transformers can be established in a more generalized form by adding a new variable, the hidden state derived from the MHN, to self-attention. This new attention mechanism, modern Hopfield attention (MHA), allows the inheritance of attention scores from the input layer of the Transformer to the output layer, which greatly improves the nature of attention weights. In particular, we show both theoretically and empirically that MHA hidden states significantly improve serious problem of deep Transformers known as rank collapse and token uniformity. We also confirm that MHA can systematically improve accuracy without adding training parameters to the Vision Transformer or GPT. Our results provide a new case in which Hopfield networks can be a useful perspective for improving the Transformer architecture.", "AI": {"tldr": "This paper introduces Modern Hopfield Attention (MHA), which enhances Transformers by incorporating hidden states from Modern Hopfield Networks, improving attention mechanisms and addressing issues like rank collapse.", "motivation": "To establish a more generalized correspondence between Modern Hopfield Networks (MHN) and self-attention in Transformers, moving beyond the adiabatic approximation and leveraging MHN's properties to enhance Transformer architectures.", "method": "The authors propose MHA by integrating a hidden state derived from MHN into the self-attention mechanism, enabling inheritance of attention scores across Transformer layers.", "result": "MHA improves attention weights, mitigates rank collapse and token uniformity in deep Transformers, and boosts accuracy in Vision Transformer and GPT without extra parameters.", "conclusion": "Hopfield networks offer a valuable perspective for advancing Transformer architectures, with MHA demonstrating practical improvements in performance and stability."}}
{"id": "2511.21398", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.21398", "abs": "https://arxiv.org/abs/2511.21398", "authors": ["Jiayuan Zhang", "Kaiquan Chen", "Zhihao Lu", "Enshen Zhou", "Qian Yu", "Jing Zhang"], "title": "Prune4Web: DOM Tree Pruning Programming for Web Agent", "comment": "Paper accepted to AAAI 2026", "summary": "Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.", "AI": {"tldr": "Prune4Web introduces programmatic DOM pruning to handle large web interfaces efficiently, replacing LLM reading with executable Python scripts for filtering, achieving 25-50x reduction in elements and boosting accuracy from 46.8% to 88.28%.", "motivation": "Large DOM sizes (10k-100k tokens) in web automation challenge LLM-based agents, causing information loss from truncation or inefficiency from heuristics, necessitating a balance between precision and scalability.", "method": "DOM Tree Pruning Programming: an LLM generates Python scripts to score and filter DOM elements based on semantic cues from sub-tasks, enabling lightweight programs instead of raw DOM ingestion, with a two-turn dialogue training strategy for Planner, Filter, and Grounder.", "result": "State-of-the-art performance with 25x to 50x reduction in candidate elements, improving low-level grounding accuracy from 46.8% to 88.28% in experiments.", "conclusion": "Prune4Web effectively addresses DOM complexity through programmatic pruning, enhancing web automation efficiency and accuracy without sacrificing critical information."}}
