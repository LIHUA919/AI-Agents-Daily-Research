<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.MA](#cs.MA) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [JAF: Judge Agent Forest](https://arxiv.org/abs/2601.22269)
*Sahil Garg,Brad Cheezum,Sridhar Dutta,Vishal Agarwal*

Main category: cs.AI

TL;DR: JAF (Judge Agent Forest) is a framework where a judge agent evaluates multiple query-response pairs simultaneously rather than individually, enabling holistic learning and improved feedback for primary agent refinement through ensemble-based judgment.


<details>
  <summary>Details</summary>
Motivation: Current judge agents evaluate query-response pairs in isolation, missing cross-instance patterns and inconsistencies. The authors aim to elevate judges from local evaluators to holistic learners by enabling simultaneous assessment of related responses.

Method: JAF bridges belief propagation and ensemble-learning principles, using overlapping in-context neighborhoods to create a knowledge-graph structure for critique propagation. The framework includes a flexible LSH algorithm that learns binary codes by integrating semantic embeddings, LLM-driven hash predicates, categorical supervision, and side information for efficient, interpretable exemplar selection.

Result: The framework was validated on cloud misconfigs triage in large-scale cloud environments, demonstrating improved evaluation through joint inference across related query-response pairs.

Conclusion: JAF transforms judge agents from isolated evaluators to holistic learners by enabling joint inference across related responses, leveraging ensemble principles and advanced hashing techniques for more robust and context-aware judgments.

Abstract: Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge's collective perspective.
  Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs.
  To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.

</details>


### [2] [The Six Sigma Agent: Achieving Enterprise-Grade Reliability in LLM Systems Through Consensus-Driven Decomposed Execution](https://arxiv.org/abs/2601.22290)
*Khush Patel,Siva Surendira,Jithin George,Shreyas Kapale*

Main category: cs.AI

TL;DR: Six Sigma Agent uses task decomposition, micro-agent sampling with parallel LLMs, and consensus voting to achieve enterprise-grade reliability with exponential error reduction.


<details>
  <summary>Details</summary>
Motivation: Large Language Models have reliability issues for enterprise deployment due to their probabilistic nature.

Method: Task decomposition into atomic actions, micro-agent sampling with parallel executions across diverse LLMs, and consensus voting with dynamic scaling.

Result: System error reduces to O(p^{ceil(n/2)}), enabling 14,700x reliability improvement and 80% cost reduction in evaluations.

Conclusion: Reliability in AI systems comes from principled redundancy and consensus, not just model scaling.

Abstract: Large Language Models demonstrate remarkable capabilities yet remain fundamentally probabilistic, presenting critical reliability challenges for enterprise deployment. We introduce the Six Sigma Agent, a novel architecture that achieves enterprise-grade reliability through three synergistic components: (1) task decomposition into a dependency tree of atomic actions; (2) micro-agent sampling where each task is executed n times in parallel across diverse LLMs to generate independent outputs; and (3) consensus voting with dynamic scaling, clustering outputs and selecting the answer from the winning cluster with maximum votes. We prove that sampling n independent outputs with error rate p achieves system error O(p^{ceil(n/2)}), enabling exponential reliability gains. Even using cheaper models with 5% per-action error, consensus voting with 5 agents reduces error to 0.11%; dynamic scaling to 13 agents achieves 3.4 DPMO (Defects Per Million Opportunities), the Six Sigma standard. Evaluation across three enterprise use cases demonstrates a 14,700x reliability improvement over single-agent execution while reducing costs by 80%. Our work establishes that reliability in AI systems emerges from principled redundancy and consensus rather than model scaling alone.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Attention Isn't All You Need for Emotion Recognition:Domain Features Outperform Transformers on the EAV Dataset](https://arxiv.org/abs/2601.22161)
*Anmol Guragain*

Main category: cs.LG

TL;DR: Complex attention mechanisms underperform on small emotion recognition datasets; simple domain-specific modifications yield better accuracy improvements.


<details>
  <summary>Details</summary>
Motivation: To investigate whether sophisticated attention mechanisms improve performance on multimodal emotion recognition with small datasets, specifically using the EAV dataset.

Method: Implemented three model categories: baseline transformers (M1), novel factorized attention mechanisms (M2), and improved CNN baselines (M3). Included domain-specific modifications like adding delta MFCCs to audio CNN and frequency-domain features for EEG.

Result: M2 models underperformed by 5-13 percentage points due to overfitting. M1 vision transformer baseline reached 75.30% accuracy, exceeding the paper's ViViT result. Simple modifications improved accuracy: audio CNN with delta MFCCs increased from 61.9% to 65.56%, and EEG frequency-domain features achieved 67.62%.

Conclusion: For small-scale emotion recognition, domain knowledge and proper implementation outperform architectural complexity; simple, domain-appropriate modifications are more effective than complex attention mechanisms.

Abstract: We present a systematic study of multimodal emotion recognition using the EAV dataset, investigating whether complex attention mechanisms improve performance on small datasets. We implement three model categories: baseline transformers (M1), novel factorized attention mechanisms (M2), and improved CNN baselines (M3). Our experiments show that sophisticated attention mechanisms consistently underperform on small datasets. M2 models achieved 5 to 13 percentage points below baselines due to overfitting and destruction of pretrained features. In contrast, simple domain-appropriate modifications proved effective: adding delta MFCCs to the audio CNN improved accuracy from 61.9\% to \textbf{65.56\%} (+3.66pp), while frequency-domain features for EEG achieved \textbf{67.62\%} (+7.62pp over the paper baseline). Our vision transformer baseline (M1) reached \textbf{75.30\%}, exceeding the paper's ViViT result (74.5\%) through domain-specific pretraining, and vision delta features achieved \textbf{72.68\%} (+1.28pp over the paper CNN). These findings demonstrate that for small-scale emotion recognition, domain knowledge and proper implementation outperform architectural complexity.

</details>


### [4] [Multitask Learning for Earth Observation Data Classification with Hybrid Quantum Network](https://arxiv.org/abs/2601.22195)
*Fan Fan,Yilei Shi,Tobias Guggemos,Xiao Xiang Zhu*

Main category: cs.LG

TL;DR: A hybrid quantum machine learning model with multitask learning and quantum convolution is proposed for Earth observation data classification, showing advantages despite quantum limitations.


<details>
  <summary>Details</summary>
Motivation: Quantum machine learning offers potential to overcome the computational challenges of analyzing big Earth observation data with deep learning, given the current bottlenecks.

Method: The paper develops a hybrid model that uses multitask learning to assist efficient data encoding and includes a location weight module with quantum convolution operations to extract features for classification.

Result: The model's validity was evaluated on multiple Earth observation benchmarks, with experiments exploring its generalizability and factors contributing to its advantage.

Conclusion: The study highlights the potential of quantum machine learning in Earth observation data analysis, demonstrating advantages even under current quantum device constraints.

Abstract: Quantum machine learning (QML) has gained increasing attention as a potential solution to address the challenges of computation requirements in the future. Earth observation (EO) has entered the era of Big Data, and the computational demands for effectively analyzing large EO data with complex deep learning models have become a bottleneck. Motivated by this, we aim to leverage quantum computing for EO data classification and explore its advantages despite the current limitations of quantum devices. This paper presents a hybrid model that incorporates multitask learning to assist efficient data encoding and employs a location weight module with quantum convolution operations to extract valid features for classification. The validity of our proposed model was evaluated using multiple EO benchmarks. Additionally, we experimentally explored the generalizability of our model and investigated the factors contributing to its advantage, highlighting the potential of QML in EO data analysis.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [5] [Learning to Recommend Multi-Agent Subgraphs from Calling Trees](https://arxiv.org/abs/2601.22209)
*Xinyuan Song,Liang Zhao*

Main category: cs.MA

TL;DR: A constrained recommendation framework for multi-agent systems that uses retrieval and utility optimization to select reliable, compatible agents based on historical calling trees, supporting both agent-level and system-level recommendations.


<details>
  <summary>Details</summary>
Motivation: As multi-agent system marketplaces expand with functionally overlapping agents, existing recommender systems fail to address the structured, sequential, and interaction-dependent nature of agent orchestration, which requires selecting reliable, compatible agents that can cooperate effectively.

Method: Formulates agent recommendation as a constrained decision problem with a two-stage framework: 1) retrieval to build a compact candidate set conditioned on subtask and context, 2) utility optimization using a learned scorer that accounts for relevance, reliability, and interaction effects, grounded in historical calling trees that capture execution structure.

Result: Proposes a unified constrained recommendation framework that supports both agent-level recommendation (selecting next agent/tool) and system-level recommendation (selecting connected agent teams/subgraphs), with a constructed benchmark from eight heterogeneous multi-agent corpora normalized into shared structured calling-tree representation.

Conclusion: The framework addresses limitations of traditional recommender systems by incorporating structured decision-making for multi-agent orchestration, leveraging historical calling trees to capture complex execution patterns and interaction dependencies for more effective agent selection.

Abstract: Multi-agent systems (MAS) increasingly solve complex tasks by orchestrating agents and tools selected from rapidly growing marketplaces. As these marketplaces expand, many candidates become functionally overlapping, making selection not just a retrieval problem: beyond filtering relevant agents, an orchestrator must choose options that are reliable, compatible with the current execution context, and able to cooperate with other selected agents. Existing recommender systems -- largely built for item-level ranking from flat user-item logs -- do not directly address the structured, sequential, and interaction-dependent nature of agent orchestration. We address this gap by \textbf{formulating agent recommendation in MAS as a constrained decision problem} and introducing a generic \textbf{constrained recommendation framework} that first uses retrieval to build a compact candidate set conditioned on the current subtask and context, and then performs \textbf{utility optimization} within this feasible set using a learned scorer that accounts for relevance, reliability, and interaction effects. We ground both the formulation and learning signals in \textbf{historical calling trees}, which capture the execution structure of MAS (parent-child calls, branching dependencies, and local cooperation patterns) beyond what flat logs provide. The framework supports two complementary settings: \textbf{agent-level recommendation} (select the next agent/tool) and \textbf{system-level recommendation} (select a small, connected agent team/subgraph for coordinated execution). To enable systematic evaluation, we construct a unified calling-tree benchmark by normalizing invocation logs from eight heterogeneous multi-agent corpora into a shared structured representation.

</details>


### [6] [Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data](https://arxiv.org/abs/2601.22242)
*Zhihao Zhang,Keith Redmill,Chengyang Peng,Bowen Weng*

Main category: cs.MA

TL;DR: A framework to learn shared driving policies by reconstructing microscopic states from macroscopic data, using microscopic data for anchoring, ensuring consistency with real-world driving.


<details>
  <summary>Details</summary>
Motivation: Existing autonomous driving methods rely on high-quality observations, which are costly and often incomplete; microscopic data lacks context, and macroscopic data lacks individual detail, so a combined approach is needed.

Method: Proposes a framework that reconstructs unobserved microscopic states from macroscopic observations, uses microscopic data to anchor vehicle behaviors, and learns a shared policy that is consistent with observed trajectories and aligns with traffic statistics at a population level.

Result: The framework generates policies that are microscopically consistent with observed data and macroscopically aligned with target traffic flow, promoting realistic flow patterns and safe coordination with human drivers.

Conclusion: The proposed method addresses limitations in current autonomous driving data collection by leveraging both microscopic and macroscopic observations, leading to safer and more efficient shared driving policies that better collaborate with human drivers.

Abstract: A driving algorithm that aligns with good human driving practices, or at the very least collaborates effectively with human drivers, is crucial for developing safe and efficient autonomous vehicles. In practice, two main approaches are commonly adopted: (i) supervised or imitation learning, which requires comprehensive naturalistic driving data capturing all states that influence a vehicle's decisions and corresponding actions, and (ii) reinforcement learning (RL), where the simulated driving environment either matches or is intentionally more challenging than real-world conditions. Both methods depend on high-quality observations of real-world driving behavior, which are often difficult and costly to obtain. State-of-the-art sensors on individual vehicles can gather microscopic data, but they lack context about the surrounding conditions. Conversely, roadside sensors can capture traffic flow and other macroscopic characteristics, but they cannot associate this information with individual vehicles on a microscopic level. Motivated by this complementarity, we propose a framework that reconstructs unobserved microscopic states from macroscopic observations, using microscopic data to anchor observed vehicle behaviors, and learns a shared policy whose behavior is microscopically consistent with the partially observed trajectories and actions and macroscopically aligned with target traffic statistics when deployed population-wide. Such constrained and regularized policies promote realistic flow patterns and safe coordination with human drivers at scale.

</details>


### [7] [Learning Reward Functions for Cooperative Resilience in Multi-Agent Systems](https://arxiv.org/abs/2601.22292)
*Manuela Chacon-Chamorro,Luis Felipe Giraldo,Nicanor Quijano*

Main category: cs.MA

TL;DR: This paper introduces a framework for learning reward functions from ranked trajectories to enhance cooperative resilience in mixed-motive multi-agent systems, showing that hybrid strategies improve robustness without degrading task performance.


<details>
  <summary>Details</summary>
Motivation: Multi-agent systems in dynamic, uncertain environments require agents to balance individual and collective goals, with cooperative resilience (anticipating, resisting, recovering from disruptions) being critical but underexplored in Multi-Agent Reinforcement Learning, especially in mixed-motive settings where conflicting interests exist.

Method: The authors study how reward function design influences resilience, introducing a novel framework that learns reward functions from ranked trajectories guided by a cooperative resilience metric. Agents are trained in social dilemma environments using three reward strategies (individual, resilience-inferred, hybrid) with three parameterizations (linear models, hand-crafted features, neural networks), employing two preference-based learning algorithms to infer rewards from behavioral rankings.

Result: Results demonstrate that the hybrid reward strategy significantly improves robustness under disruptions without degrading task performance and reduces catastrophic outcomes like resource overuse, outperforming traditional individual and resilience-only approaches.

Conclusion: The findings underscore the importance of reward design in fostering resilient cooperation, representing a step toward developing robust multi-agent systems capable of sustaining cooperation in uncertain environments by balancing individual and collective incentives.

Abstract: Multi-agent systems often operate in dynamic and uncertain environments, where agents must not only pursue individual goals but also safeguard collective functionality. This challenge is especially acute in mixed-motive multi-agent systems. This work focuses on cooperative resilience, the ability of agents to anticipate, resist, recover, and transform in the face of disruptions, a critical yet underexplored property in Multi-Agent Reinforcement Learning. We study how reward function design influences resilience in mixed-motive settings and introduce a novel framework that learns reward functions from ranked trajectories, guided by a cooperative resilience metric. Agents are trained in a suite of social dilemma environments using three reward strategies: i) traditional individual reward; ii) resilience-inferred reward; and iii) hybrid that balance both. We explore three reward parameterizations-linear models, hand-crafted features, and neural networks, and employ two preference-based learning algorithms to infer rewards from behavioral rankings. Our results demonstrate that hybrid strategy significantly improve robustness under disruptions without degrading task performance and reduce catastrophic outcomes like resource overuse. These findings underscore the importance of reward design in fostering resilient cooperation, and represent a step toward developing robust multi-agent systems capable of sustaining cooperation in uncertain environments.

</details>


### [8] [ScholarPeer: A Context-Aware Multi-Agent Framework for Automated Peer Review](https://arxiv.org/abs/2601.22638)
*Palash Goyal,Mihir Parmar,Yiwen Song,Hamid Palangi,Tomas Pfister,Jinsung Yoon*

Main category: cs.MA

TL;DR: ScholarPeer is a search-enabled multi-agent framework for automated peer review that uses dynamic domain context to generate more substantive critiques, outperforming existing systems.


<details>
  <summary>Details</summary>
Motivation: Current automated peer review systems focus on surface-level critiques by summarizing content but fail to assess novelty, significance, and deep methodological flaws due to lack of external context compared to human experts.

Method: ScholarPeer employs a dual-stream process with a historian agent to construct domain narratives, a baseline scout to identify missing comparisons, and a multi-aspect Q&A engine to verify claims using live web-scale literature.

Result: Evaluation on DeepReview-13K shows ScholarPeer achieves significant win-rates against state-of-the-art approaches in side-by-side evaluations and reduces the gap to human-level diversity.

Conclusion: ScholarPeer effectively bridges the context gap in automated peer review by simulating expert cognitive processes, leading to more accurate and comprehensive critiques.

Abstract: Automated peer review has evolved from simple text classification to structured feedback generation. However, current state-of-the-art systems still struggle with "surface-level" critiques: they excel at summarizing content but often fail to accurately assess novelty and significance or identify deep methodological flaws because they evaluate papers in a vacuum, lacking the external context a human expert possesses. In this paper, we introduce ScholarPeer, a search-enabled multi-agent framework designed to emulate the cognitive processes of a senior researcher. ScholarPeer employs a dual-stream process of context acquisition and active verification. It dynamically constructs a domain narrative using a historian agent, identifies missing comparisons via a baseline scout, and verifies claims through a multi-aspect Q&A engine, grounding the critique in live web-scale literature. We evaluate ScholarPeer on DeepReview-13K and the results demonstrate that ScholarPeer achieves significant win-rates against state-of-the-art approaches in side-by-side evaluations and reduces the gap to human-level diversity.

</details>


### [9] [LLMDR: Large language model driven framework for missing data recovery in mixed data under low resource regime](https://arxiv.org/abs/2601.22916)
*Durga Keshav,GVD Praneeth,Chetan Kumar Patruni,Vivek Yelleti,U Sai Ram*

Main category: cs.MA

TL;DR: LLMDR is a two-stage framework using DBSCAN clustering and multiple LLMs for accurate data recovery in mixed-type datasets with high missingness, enhanced by consensus mechanism.


<details>
  <summary>Details</summary>
Motivation: Existing imputation methods struggle with high missingness percentages and mixed-type datasets (numerical and categorical data), limiting their effectiveness in achieving data completeness.

Method: Two-stage approach: Stage I uses DBSCAN clustering to select representative samples; Stage II employs multiple LLMs for data recovery using both local and global representative samples, followed by a consensus algorithm for final value recommendation.

Result: Experimental results show LLMDR works effectively on various mixed datasets, outperforming existing methods in Accuracy, KS-Statistic, SMAPE, and MSE metrics, with consensus mechanism proving advantageous.

Conclusion: LLMDR provides an effective solution for data recovery in mixed-type datasets with high missingness, leveraging clustering and multi-LLM consensus to overcome limitations of traditional imputation methods.

Abstract: The missing data problem is one of the important issues to address for achieving data quality. While imputation-based methods are designed to achieve data completeness, their efficacy is observed to be diminishing as and when there is increasing in the missingness percentage. Further, extant approaches often struggle to handle mixed-type datasets, typically supporting either numerical and/or categorical data. In this work, we propose LLMDR, automatic data recovery framework which operates in two stage approach, wherein the Stage-I: DBSCAN clustering algorithm is employed to select the most representative samples and in the Stage-II: Multi-LLMs are employed for data recovery considering the local and global representative samples; Later, this framework invokes the consensus algorithm for recommending a more accurate value based on other LLMs of local and global effective samples. Experimental results demonstrate that proposed framework works effectively on various mixed datasets in terms of Accuracy, KS-Statistic, SMAPE, and MSE. Further, we have also shown the advantage of the consensus mechanism for final recommendation in mixed-type data.

</details>


### [10] [Multi-Agent Systems Should be Treated as Principal-Agent Problems](https://arxiv.org/abs/2601.23211)
*Paulius Rauba,Simonas Cepenas,Mihaela van der Schaar*

Main category: cs.MA

TL;DR: Multi-agent systems with information asymmetry and misaligned goals lead to agency loss, best analyzed via principal-agent theory, with scheming LLM agents as a case study connecting to mechanism design.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the core problem of agency loss in multi-agent systems where information asymmetry and divergent incentives cause agents to deceive, motivating the need for a structured analysis using principal-agent problems.

Method: The study employs microeconomic theory, specifically principal-agent problems and mechanism design, to analyze multi-agent systems, illustrating information asymmetry and misaligned goals in human-to-LLM and LLM-to-LLM setups, with scheming as a case.

Result: It shows that scheming behaviors in LLM-based agents correspond to well-studied concepts like covert subversion from mechanism design, linking emergent terminology to established mitigation strategies.

Conclusion: The paper concludes that tools from human agent analysis should be applied to non-human agents to better understand and mitigate agency loss in AI systems.

Abstract: Consider a multi-agent systems setup in which a principal (a supervisor agent) assigns subtasks to specialized agents and aggregates their responses into a single system-level output. A core property of such systems is information asymmetry: agents observe task-specific information, produce intermediate reasoning traces, and operate with different context windows. In isolation, such asymmetry is not problematic, since agents report truthfully to the principal when incentives are fully aligned. However, this assumption breaks down when incentives diverge. Recent evidence suggests that LLM-based agents can acquire their own goals, such as survival or self-preservation, a phenomenon known as scheming, and may deceive humans or other agents. This leads to agency loss: a gap between the principal's intended outcome and the realized system behavior. Drawing on core ideas from microeconomic theory, we argue that these characteristics, information asymmetry and misaligned goals, are best studied through the lens of principal-agent problems. We explain why multi-agent systems, both human-to-LLM and LLM-to-LLM, naturally induce information asymmetry under this formulation, and we use scheming, where LLM agents pursue covert goals, as a concrete case study. We show that recently introduced terminology used to describe scheming, such as covert subversion or deferred subversion, corresponds to well-studied concepts in the mechanism design literature, which not only characterizes the problem but also prescribes concrete mitigation strategies. More broadly, we argue for applying tools developed to study human agent behavior to the analysis of non-human agents.

</details>
