{"id": "2511.05269", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05269", "abs": "https://arxiv.org/abs/2511.05269", "authors": ["Ishan Kavathekar", "Hemang Jain", "Ameya Rathod", "Ponnurangam Kumaraguru", "Tanuja Ganu"], "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems", "comment": "Accepted at ICML 2025 MAS Workshop. This version includes additional\n  experiments and analysis", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems.", "AI": {"tldr": "TAMAS is a benchmark for evaluating safety and robustness of multi-agent LLM systems, revealing high vulnerability to adversarial attacks and introducing metrics to assess safety-effectiveness tradeoffs.", "motivation": "Existing benchmarks focus on single-agent settings, failing to capture vulnerabilities in multi-agent dynamics and coordination, creating a gap in safety evaluation for collaborative LLM systems.", "method": "Developed TAMAS benchmark with 5 scenarios, 300 adversarial instances across 6 attack types, 211 tools, and 100 harmless tasks. Evaluated 10 backbone LLMs across 3 agent interaction configurations from Autogen and CrewAI frameworks.", "result": "Multi-agent systems are highly vulnerable to adversarial attacks. The benchmark reveals critical challenges and failure modes in current deployments, with the proposed Effective Robustness Score (ERS) quantifying safety-effectiveness tradeoffs.", "conclusion": "TAMAS provides a foundation for systematically studying and improving multi-agent LLM system safety, highlighting urgent need for stronger defenses against adversarial threats."}}
{"id": "2511.04904", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04904", "abs": "https://arxiv.org/abs/2511.04904", "authors": ["Bassel Al Omari", "Michael Matthews", "Alexander Rutherford", "Jakob Nicolaus Foerster"], "title": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale", "comment": null, "summary": "Progress in multi-agent reinforcement learning (MARL) requires challenging\nbenchmarks that assess the limits of current methods. However, existing\nbenchmarks often target narrow short-horizon challenges that do not adequately\nstress the long-term dependencies and generalization capabilities inherent in\nmany multi-agent systems. To address this, we first present\n\\textit{Craftax-MA}: an extension of the popular open-ended RL environment,\nCraftax, that supports multiple agents and evaluates a wide range of general\nabilities within a single environment. Written in JAX, \\textit{Craftax-MA} is\nexceptionally fast with a training run using 250 million environment\ninteractions completing in under an hour. To provide a more compelling\nchallenge for MARL, we also present \\textit{Craftax-Coop}, an extension\nintroducing heterogeneous agents, trading and more mechanics that require\ncomplex cooperation among agents for success. We provide analysis demonstrating\nthat existing algorithms struggle with key challenges in this benchmark,\nincluding long-horizon credit assignment, exploration and cooperation, and\nargue for its potential to drive long-term research in MARL.", "AI": {"tldr": "Craftax-MA extends Craftax to multi-agent RL with exceptional speed, and Craftax-Coop adds complex cooperation challenges where current MARL methods struggle.", "motivation": "Existing MARL benchmarks are too narrow and short-horizon, failing to stress long-term dependencies and generalization needed for real multi-agent systems.", "method": "Extend Craftax environment to support multiple agents (Craftax-MA) and add heterogeneous agents, trading, and cooperation mechanics (Craftax-Coop), implemented in JAX for high performance.", "result": "Training runs complete in under an hour for 250M interactions, and analysis shows existing algorithms struggle with long-horizon credit assignment, exploration, and cooperation.", "conclusion": "Craftax benchmarks provide compelling challenges that can drive long-term MARL research by exposing limitations of current methods in complex, open-ended environments."}}
{"id": "2511.04686", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04686", "abs": "https://arxiv.org/abs/2511.04686", "authors": ["Pratik Poudel"], "title": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity", "comment": "14 pages, 2 figures", "summary": "The Key-Value (KV) cache is integral to efficient autoregressive inference in\nlarge language models (LLMs), yet its unbounded growth in stateful multi-turn\nscenarios presents major challenges. This paper examines the interplay between\nKV cache management strategies, the architectural context limits of models like\nmeta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of\npositional encodings. Through empirical analysis using a stateful benchmarking\nframework, we show that LLM generation quality degrades sharply when the\naccumulated KV cache approaches or exceeds the model's trained context window\n(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory\nexhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via\nAttentionTop), can worsen performance if they disrupt positional coherence.\nBecause LLMs rely on consistent positional signals (e.g., RoPE), compacting a\ncache by removing non-contiguous tokens can scramble these signals and lead to\ndegenerative outputs. We further show that simple strategies preserving\ncontiguous context blocks (e.g., keeping an initial \"gist\") can yield more\ncoherent generations than complex or positionally disruptive ones. We advocate\nfor eviction techniques that respect architectural limits, preserve positional\nstructure, and view \"cache health\" holistically beyond mere size.", "AI": {"tldr": "KV cache management in LLMs must preserve positional encoding integrity; simple contiguous block strategies outperform complex eviction methods that disrupt positional coherence.", "motivation": "Address the challenge of unbounded KV cache growth in stateful multi-turn LLM scenarios and the degradation of generation quality when cache exceeds model's trained context window.", "method": "Empirical analysis using stateful benchmarking framework to evaluate KV cache management strategies, focusing on positional encoding integrity and architectural context limits.", "result": "LLM generation quality degrades sharply when accumulated KV cache approaches/exceeds model's trained context window; simple contiguous context block preservation strategies yield more coherent generations than positionally disruptive eviction methods.", "conclusion": "KV cache eviction techniques should respect architectural limits, preserve positional structure, and consider \"cache health\" holistically beyond mere size management."}}
{"id": "2511.04685", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further.", "AI": {"tldr": "Team Twente's third-place solution for Integrated Healthcare Timetabling Competition 2024 uses a 3-phase hybrid approach combining mixed-integer programming, constraint programming, and simulated annealing with problem decomposition.", "motivation": "To develop an effective solution for the healthcare timetabling competition by leveraging multiple optimization techniques to handle the complex scheduling constraints.", "method": "3-phase solution approach using decomposition into subproblems, combining mixed-integer programming, constraint programming, and simulated annealing.", "result": "Achieved third place in the competition and provided first-time lower bounds on optimal solution values for benchmark instances.", "conclusion": "The hybrid approach was effective but could be improved by addressing identified open problems in the methodology."}}
{"id": "2511.04718", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04718", "abs": "https://arxiv.org/abs/2511.04718", "authors": ["Yue Xun", "Jiaxing Xu", "Wenbo Gao", "Chen Yang", "Shujun Wang"], "title": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "comment": "11 pages, 2 figures, conference", "summary": "Resting-state fMRI has become a valuable tool for classifying brain disorders\nand constructing brain functional connectivity networks\n  by tracking BOLD signals across brain regions. However, existing mod els\nlargely neglect the multi-frequency nature of neuronal oscillations,\n  treating BOLD signals as monolithic time series. This overlooks the cru cial\nfact that neurological disorders often manifest as disruptions within\n  specific frequency bands, limiting diagnostic sensitivity and specificity.\n  While some methods have attempted to incorporate frequency informa tion, they\noften rely on predefined frequency bands, which may not be\n  optimal for capturing individual variability or disease-specific alterations.\n  To address this, we propose a novel framework featuring Adaptive Cas cade\nDecomposition to learn task-relevant frequency sub-bands for each\n  brain region and Frequency-Coupled Connectivity Learning to capture\n  both intra- and nuanced cross-band interactions in a unified functional\n  network. This unified network informs a novel message-passing mecha nism\nwithin our Unified-GCN, generating refined node representations\n  for diagnostic prediction. Experimental results on the ADNI and ABIDE\n  datasets demonstrate superior performance over existing methods. The\n  code is available at https://github.com/XXYY20221234/Ada-FCN.", "AI": {"tldr": "Proposes a novel fMRI analysis framework using adaptive frequency decomposition and connectivity learning to improve brain disorder diagnosis by capturing frequency-specific neural disruptions.", "motivation": "Current resting-state fMRI models treat BOLD signals as monolithic time series, ignoring the multi-frequency nature of neuronal oscillations and frequency-specific manifestations of neurological disorders, limiting diagnostic accuracy.", "method": "Uses Adaptive Cascade Decomposition to learn task-relevant frequency sub-bands per brain region and Frequency-Coupled Connectivity Learning to model intra- and cross-band interactions, integrated via a Unified-GCN with message-passing for diagnostic prediction.", "result": "Superior performance demonstrated on ADNI and ABIDE datasets compared to existing methods.", "conclusion": "The framework effectively addresses limitations of current approaches by adaptively capturing frequency-specific neural disruptions, enhancing diagnostic sensitivity and specificity for brain disorders."}}
{"id": "2511.04855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions.", "AI": {"tldr": "Introduces epistemic reject-option predictor that abstains in high epistemic uncertainty regions, minimizing expected regret compared to Bayes-optimal predictor.", "motivation": "Traditional reject-option methods only address aleatoric uncertainty, which is insufficient when limited training data makes epistemic uncertainty significant in practical scenarios.", "method": "Builds on Bayesian learning to redefine optimal predictor as minimizing expected regret - the performance gap between learned model and Bayes-optimal predictor with full data distribution knowledge.", "result": "First principled framework enabling learning predictors that identify inputs where training data is insufficient for reliable decisions, abstaining when regret exceeds specified rejection cost.", "conclusion": "Provides a novel approach to reject-option prediction that properly handles epistemic uncertainty from limited data, offering more reliable uncertainty quantification in practical applications."}}
{"id": "2511.04722", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04722", "abs": "https://arxiv.org/abs/2511.04722", "authors": ["Qianyang Li", "Xingjun Zhang", "Peng Tao", "Shaoxun Wang", "Yancheng Pan", "Jia Wei"], "title": "AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting", "comment": null, "summary": "Forecasting long-term time series in IoT environments remains a significant\nchallenge due to the non-stationary and multi-scale characteristics of sensor\nsignals. Furthermore, error accumulation causes a decrease in forecast quality\nwhen predicting further into the future. Traditional methods are restricted to\noperate in time-domain, while the global frequency information achieved by\nFourier transform would be regarded as stationary signals leading to blur the\ntemporal patterns of transient events. We propose AWEMixer, an Adaptive\nWavelet-Enhanced Mixer Network including two innovative components: 1) a\nFrequency Router designs to utilize the global periodicity pattern achieved by\nFast Fourier Transform to adaptively weight localized wavelet subband, and 2) a\nCoherent Gated Fusion Block to achieve selective integration of prominent\nfrequency features with multi-scale temporal representation through\ncross-attention and gating mechanism, which realizes accurate time-frequency\nlocalization while remaining robust to noise. Seven public benchmarks validate\nthat our model is more effective than recent state-of-the-art models.\nSpecifically, our model consistently achieves performance improvement compared\nwith transformer-based and MLP-based state-of-the-art models in long-sequence\ntime series forecasting. Code is available at\nhttps://github.com/hit636/AWEMixer", "AI": {"tldr": "AWEMixer: A novel time series forecasting model that combines adaptive wavelet enhancement with frequency routing and coherent gated fusion to address non-stationary IoT sensor data, outperforming transformer and MLP-based methods on long-sequence forecasting.", "motivation": "Long-term time series forecasting in IoT environments faces challenges from non-stationary, multi-scale sensor signals and error accumulation. Traditional time-domain methods and Fourier transform approaches either miss frequency information or blur temporal patterns of transient events.", "method": "AWEMixer includes two key components: 1) Frequency Router that uses FFT-derived global periodicity to adaptively weight localized wavelet subbands, and 2) Coherent Gated Fusion Block that selectively integrates frequency features with multi-scale temporal representations using cross-attention and gating mechanisms.", "result": "The model was validated on seven public benchmarks and consistently outperformed recent state-of-the-art transformer-based and MLP-based models in long-sequence time series forecasting.", "conclusion": "AWEMixer effectively addresses time-frequency localization challenges in IoT forecasting while maintaining robustness to noise, demonstrating superior performance over existing approaches."}}
{"id": "2511.04880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability.", "AI": {"tldr": "DMA is an online learning framework that uses multi-granularity human feedback to dynamically align ranking in RAG systems, improving adaptation to evolving user intent while maintaining baseline retrieval performance.", "motivation": "Traditional RAG systems use static retrieval that cannot adapt to evolving user intent and content drift, limiting their effectiveness in interactive settings.", "method": "DMA organizes document-, list-, and response-level feedback into a coherent pipeline: supervised training for pointwise/listwise rankers, policy optimization using response-level preferences, and knowledge distillation into a lightweight scorer for low-latency serving.", "result": "Online deployment showed substantial improvements in human engagement, while offline tests on knowledge-intensive benchmarks (TriviaQA, HotpotQA) demonstrated competitive foundational retrieval with notable gains on conversational QA.", "conclusion": "DMA provides a principled approach for feedback-driven, real-time adaptation in RAG systems without sacrificing baseline capability, positioning it as an effective solution for dynamic retrieval alignment."}}
{"id": "2511.04723", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04723", "abs": "https://arxiv.org/abs/2511.04723", "authors": ["Mohamadreza Akbari Pour", "Mohamad Sadeq Karimi", "Amir Hossein Mazloumi"], "title": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction", "comment": null, "summary": "Health prediction is crucial for ensuring reliability, minimizing downtime,\nand optimizing maintenance in industrial systems. Remaining Useful Life (RUL)\nprediction is a key component of this process; however, many existing models\nstruggle to capture fine-grained temporal dependencies while dynamically\nprioritizing critical features across time for robust prognostics. To address\nthese challenges, we propose a novel framework that integrates Temporal\nConvolutional Networks (TCNs) for localized temporal feature extraction with a\nmodified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.\nThis architecture effectively bridges short- and long-term dependencies while\nemphasizing salient temporal patterns. Furthermore, the incorporation of a\nmulti-time-window methodology improves adaptability across diverse operating\nconditions. Extensive evaluations on benchmark datasets demonstrate that the\nproposed model reduces the average RMSE by up to 5.5%, underscoring its\nimproved predictive accuracy compared to state-of-the-art methods. By closing\ncritical gaps in current approaches, this framework advances the effectiveness\nof industrial prognostic systems and highlights the potential of advanced\ntime-series transformers for RUL prediction.", "AI": {"tldr": "Novel RUL prediction framework combining TCNs with modified TFT and Bi-LSTM encoder-decoder achieves 5.5% RMSE improvement over state-of-the-art methods.", "motivation": "Existing RUL prediction models struggle with capturing fine-grained temporal dependencies and dynamically prioritizing critical features over time.", "method": "Integrates Temporal Convolutional Networks for local temporal feature extraction with modified Temporal Fusion Transformer enhanced by Bi-LSTM encoder-decoder architecture, using multi-time-window methodology.", "result": "Extensive evaluations show up to 5.5% reduction in average RMSE compared to state-of-the-art methods.", "conclusion": "The framework advances industrial prognostic systems by bridging short- and long-term dependencies while emphasizing salient temporal patterns, demonstrating the potential of advanced time-series transformers for RUL prediction."}}
{"id": "2511.04898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents.", "AI": {"tldr": "Introduces real-time reasoning for agents in dynamic environments, compares reactive vs planning agent approaches, proposes AgileThinker hybrid method that outperforms single-paradigm approaches under time pressure.", "motivation": "Real-world agents need to make both logical and timely judgments in dynamic environments where hazards emerge and opportunities arise while reasoning is ongoing, but current language model approaches fail to address this dynamic nature.", "method": "Built Real-Time Reasoning Gym to study two language model deployment paradigms: reactive agents (bounded computation for rapid responses) and planning agents (extended computation for complex problems). Proposed AgileThinker which simultaneously engages both reasoning paradigms.", "result": "State-of-the-art models struggle with logical and timely judgments in both paradigms. AgileThinker consistently outperforms single-paradigm agents as task difficulty and time pressure increase, effectively balancing reasoning depth and response latency.", "conclusion": "Establishes real-time reasoning as a critical testbed for practical agents and provides foundation for temporally constrained AI systems, highlighting a path toward real-time capable agents."}}
{"id": "2511.04751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04751", "abs": "https://arxiv.org/abs/2511.04751", "authors": ["Matteo Cercola", "Michele Lomuscio", "Dario Piga", "Simone Formentin"], "title": "Regularized GLISp for sensor-guided human-in-the-loop optimization", "comment": null, "summary": "Human-in-the-loop calibration is often addressed via preference-based\noptimization, where algorithms learn from pairwise comparisons rather than\nexplicit cost evaluations. While effective, methods such as Preferential\nBayesian Optimization or Global optimization based on active preference\nlearning with radial basis functions (GLISp) treat the system as a black box\nand ignore informative sensor measurements. In this work, we introduce a\nsensor-guided regularized extension of GLISp that integrates measurable\ndescriptors into the preference-learning loop through a physics-informed\nhypothesis function and a least-squares regularization term. This injects\ngrey-box structure, combining subjective feedback with quantitative sensor\ninformation while preserving the flexibility of preference-based search.\nNumerical evaluations on an analytical benchmark and on a human-in-the-loop\nvehicle suspension tuning task show faster convergence and superior final\nsolutions compared to baseline GLISp.", "AI": {"tldr": "Paper introduces GLISp-SR, a sensor-guided extension of GLISp that integrates quantitative sensor data with preference feedback for faster, better-calibrated human-in-the-loop optimization.", "motivation": "Existing preference-based optimization methods like Preferential Bayesian Optimization or GLISp treat systems as black boxes, ignoring informative sensor measurements that could improve learning efficiency and solution quality.", "method": "Proposed GLISp-SR integrates sensor measurements via a physics-informed hypothesis function and a least-squares regularization term, adding grey-box structure to combine subjective preferences with quantitative data.", "result": "Numerical evaluations show faster convergence and superior final solutions compared to baseline GLISp on both an analytical benchmark and a vehicle suspension tuning task.", "conclusion": "Integrating sensor guidance into preference learning yields more efficient human-in-the-loop calibration, balancing subjective feedback with quantitative information for improved performance."}}
{"id": "2511.04956", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows.", "AI": {"tldr": "ORCHID is a modular agentic system that uses RAG and human oversight for high-risk property classification at DOE sites, improving accuracy and auditability over traditional expert-only approaches.", "motivation": "Traditional expert-only workflows for HRP classification are time-consuming, backlog-prone, and struggle to keep pace with evolving export control policies, requiring a more efficient and transparent solution.", "method": "The system employs small cooperating agents (retrieval, description refiner, classifier, validator, feedback logger) that coordinate via agent-to-agent messaging and use MCP for model-agnostic operation, following an Item to Evidence to Decision loop with step-by-step reasoning.", "result": "In preliminary tests on real HRP cases, ORCHID improves accuracy and traceability over a non-agentic baseline while deferring uncertain items to Subject Matter Experts.", "conclusion": "ORCHID demonstrates a practical path to trustworthy LLM assistance in sensitive DOE compliance workflows through its modular design, human oversight, and audit-friendly features like append-only audit bundles."}}
{"id": "2511.04760", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04760", "abs": "https://arxiv.org/abs/2511.04760", "authors": ["Vaibhav Singh", "Eugene Belilovsky", "Rahaf Aljundi"], "title": "When Data Falls Short: Grokking Below the Critical Threshold", "comment": "6 pages", "summary": "In this paper, we investigate the phenomenon of grokking, where models\nexhibit delayed generalization following overfitting on training data. We focus\non data-scarce regimes where the number of training samples falls below the\ncritical threshold, making grokking unobservable, and on practical scenarios\ninvolving distribution shift. We first show that Knowledge Distillation (KD)\nfrom a model that has already grokked on a distribution (p1) can induce and\naccelerate grokking on a different distribution (p2), even when the available\ndata lies below the critical threshold. This highlights the value of KD for\ndeployed models that must adapt to new distributions under limited data. We\nthen study training on the joint distribution (p1, p2) and demonstrate that\nwhile standard supervised training fails when either distribution has\ninsufficient data, distilling from models grokked on the individual\ndistributions enables generalization. Finally, we examine a continual\npretraining setup, where a grokked model transitions from p1 to p2, and find\nthat KD both accelerates generalization and mitigates catastrophic forgetting,\nachieving strong performance even with only 10% of the data. Together, our\nresults provide new insights into the mechanics of grokking under knowledge\ntransfer and underscore the central role of KD in enabling generalization in\nlow-data and evolving distribution settings.", "AI": {"tldr": "Knowledge Distillation from grokked models enables generalization in data-scarce and distribution shift scenarios where traditional training fails.", "motivation": "To address delayed generalization (grokking) challenges in data-scarce regimes and practical distribution shift scenarios where traditional methods underperform.", "method": "Used Knowledge Distillation from pre-grokked models across single distributions, joint distributions, and continual pretraining setups with limited data.", "result": "KD successfully induced/accelerated grokking below critical data thresholds, enabled generalization on joint distributions, and mitigated catastrophic forgetting in continual learning with only 10% data.", "conclusion": "KD plays a central role in enabling generalization under knowledge transfer, providing new insights into grokking mechanics for low-data and evolving distribution settings."}}
{"id": "2511.05182", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus H\u00f6rling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework.", "AI": {"tldr": "A methodology for generating and evaluating military courses of action for mechanized battalions, using concurrent generation and evaluation processes to identify superior alternatives based on opponent status and battlefield conditions.", "motivation": "To support decision-making during military ground combat operations by providing systematic recommendations for various courses of action, particularly focusing on mechanized battalion actions.", "method": "Systematically generates thousands of individual action alternatives, evaluates them based on opponent status and actions, considers unit composition, force ratios, offense/defense types, and advance rates using field manuals, with concurrent generation and evaluation processes.", "result": "Produces a variety of alternative courses of action with superior outcomes, facilitates management of new course generation based on previous evaluations, and formulates revised courses as combat conditions evolve.", "conclusion": "The methodology effectively supports sequential decision-making in military operations by continuously generating and evaluating superior courses of action as battlefield conditions change."}}
{"id": "2511.04768", "categories": ["cs.LG", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.04768", "abs": "https://arxiv.org/abs/2511.04768", "authors": ["Rubens Lacouture", "Nathan Zhang", "Ritvik Sharma", "Marco Siracusa", "Fredrik Kjolstad", "Kunle Olukotun", "Olivia Hsu"], "title": "FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow", "comment": null, "summary": "As deep learning models scale, sparse computation and specialized dataflow\nhardware have emerged as powerful solutions to address efficiency. We propose\nFuseFlow, a compiler that converts sparse machine learning models written in\nPyTorch to fused sparse dataflow graphs for reconfigurable dataflow\narchitectures (RDAs). FuseFlow is the first compiler to support general\ncross-expression fusion of sparse operations. In addition to fusion across\nkernels (expressions), FuseFlow also supports optimizations like\nparallelization, dataflow ordering, and sparsity blocking. It targets a\ncycle-accurate dataflow simulator for microarchitectural analysis of fusion\nstrategies. We use FuseFlow for design-space exploration across four real-world\nmachine learning applications with sparsity, showing that full fusion (entire\ncross-expression fusion across all computation in an end-to-end model) is not\nalways optimal for sparse models-fusion granularity depends on the model\nitself. FuseFlow also provides a heuristic to identify and prune suboptimal\nconfigurations. Using Fuseflow, we achieve performance improvements, including\na ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse\nattention.", "AI": {"tldr": "FuseFlow compiler converts PyTorch sparse models to fused dataflow graphs for RDAs, supporting cross-expression fusion and optimizations. It enables design-space exploration showing fusion granularity depends on the model, achieving up to 2.7x speedup.", "motivation": "Address efficiency challenges in scaling deep learning models through sparse computation and specialized dataflow hardware.", "method": "Propose FuseFlow compiler that converts PyTorch sparse models to fused dataflow graphs for RDAs, supporting cross-expression fusion, parallelization, dataflow ordering, and sparsity blocking.", "result": "Enables design-space exploration showing full fusion not always optimal; fusion granularity depends on model. Provides heuristic to prune suboptimal configurations. Achieves ~2.7x speedup over unfused baseline for GPT-3 with BigBird attention.", "conclusion": "FuseFlow effectively optimizes sparse models for RDAs, demonstrating that adaptive fusion strategies tailored to specific models yield significant performance gains."}}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Rapha\u00ebl Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.", "AI": {"tldr": "LLM-based agents show promise for cleaning predictive maintenance logs, effectively handling generic noise types but struggling with domain-specific errors.", "motivation": "Economic constraints, limited datasets, and expertise shortages hinder predictive maintenance adoption in automotive sector; LLMs offer opportunity to overcome these barriers.", "method": "Evaluate LLM agents on cleaning tasks involving six distinct types of noise in maintenance logs (typos, missing fields, near-duplicates, incorrect dates, etc.).", "result": "LLMs are effective at handling generic cleaning tasks and offer promising foundation for industrial applications, though domain-specific errors remain challenging.", "conclusion": "LLM-based agents present viable solution for predictive maintenance data cleaning pipelines, with potential for further improvements through specialized training and enhanced agentic capabilities."}}
{"id": "2511.04774", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.04774", "abs": "https://arxiv.org/abs/2511.04774", "authors": ["Liu Jiang", "Zerui Bao", "Shiqi Sheng", "Di Zhu"], "title": "SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices", "comment": null, "summary": "Large-scale networked services rely on deep soft-ware stacks and microservice\norchestration, which increase instruction footprints and create frontend stalls\nthat inflate tail latency and energy. We revisit instruction prefetching for\nthese cloud workloads and present a design that aligns with SLO driven and self\noptimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we\nintroduce a Compressed Entry that captures up to eight destinations around a\nbase using 36 bits by exploiting spatial clustering, and a Hierarchical\nMetadata Storage scheme that keeps only L1 resident and frequently queried\nentries on chip while virtualizing bulk metadata into lower levels. We further\nadd a lightweight Online ML Controller that scores prefetch profitability using\ncontext features and a bandit adjusted threshold. On data center applications,\nour approach preserves EIP like speedups with smaller on chip state and\nimproves efficiency for networked services in the ML era.", "AI": {"tldr": "Proposes enhanced instruction prefetching for cloud workloads using compressed entries, hierarchical storage, and ML control to improve latency and energy efficiency while reducing on-chip state.", "motivation": "Large-scale networked services with deep software stacks and microservice orchestration cause increased instruction footprints and frontend stalls, leading to higher tail latency and energy consumption.", "method": "Building on Entangling Instruction Prefetcher (EIP), introduces Compressed Entry (36 bits for 8 destinations via spatial clustering), Hierarchical Metadata Storage (on-chip for L1/frequent entries, virtualized bulk metadata), and Online ML Controller (profitable prefetch scoring with context features and bandit-adjusted threshold).", "result": "Preserves EIP-like speedups with smaller on-chip state and improves efficiency for networked services, particularly in ML-era data center applications.", "conclusion": "The design aligns with SLO-driven, self-optimizing systems, effectively addressing instruction footprint and stall issues in modern cloud workloads."}}
{"id": "2511.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.", "AI": {"tldr": "A framework for AI agents in urban planning that integrates reasoning capabilities to assist human planners by transparently evaluating constraints, stakeholder values, and trade-offs.", "motivation": "AI has succeeded in learning patterns from data for urban planning predictions, but decision-making requires transparent reasoning about constraints and values that statistical learning alone cannot provide.", "method": "The Agentic Urban Planning AI Framework uses a multi-agent collaboration structure with three cognitive layers (Perception, Foundation, Reasoning) and six logic components (Analysis, Generation, Verification, Evaluation, Collaboration, Decision).", "result": "The framework enables systematic solution exploration, regulatory compliance verification, and transparent trade-off deliberation, augmenting human planners without replacing their judgment.", "conclusion": "Reasoning-capable AI agents can amplify human planning by ensuring value-based, rule-grounded, and explainable decisions, addressing limitations of pure statistical learning and outlining future research directions."}}
{"id": "2511.04789", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04789", "abs": "https://arxiv.org/abs/2511.04789", "authors": ["Xiaoda Wang", "Yuji Zhao", "Kaiqiao Han", "Xiao Luo", "Sanne van Rooij", "Jennifer Stevens", "Lifang He", "Liang Zhan", "Yizhou Sun", "Wei Wang", "Carl Yang"], "title": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting", "comment": "Accepted to IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM) 2025", "summary": "Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry\npatterns. Modeling these longitudinal trajectories enables mechanistic insight,\ntreatment development, and individualized 'digital-twin' forecasting. However,\nexisting methods usually adopt recurrent neural networks and transformer\narchitectures, which rely on discrete, regularly sampled data while struggling\nto handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.\nMoreover, these methods have difficulty capturing individual heterogeneity\nincluding variations in disease onset, progression rate, and symptom severity,\nwhich is a hallmark of PD. To address these challenges, we propose CNODE\n(Conditional Neural ODE), a novel framework for continuous, individualized PD\nprogression forecasting. The core of CNODE is to model morphological brain\nchanges as continuous temporal processes using a neural ODE model. In addition,\nwe jointly learn patient-specific initial time and progress speed to align\nindividual trajectories into a shared progression trajectory. We validate CNODE\non the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental\nresults show that our method outperforms state-of-the-art baselines in\nforecasting longitudinal PD progression.", "AI": {"tldr": "CNODE proposes a continuous neural ODE model to forecast Parkinson's disease progression by modeling brain changes over time, handling irregular MRI data and capturing individual variability.", "motivation": "Existing methods struggle with irregular/sparse MRI data and fail to capture individual heterogeneity in Parkinson's disease progression, limiting forecasting accuracy.", "method": "Uses neural ODE to model brain morphology changes continuously, learns patient-specific initial time and progression speed to align trajectories.", "result": "Outperforms state-of-the-art baselines on PPMI dataset for forecasting PD progression.", "conclusion": "CNODE enables more accurate, individualized PD progression forecasting by addressing data irregularity and patient heterogeneity."}}
{"id": "2511.04790", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04790", "abs": "https://arxiv.org/abs/2511.04790", "authors": ["Caroline Uhler", "Jiaqi Zhang"], "title": "Causal Structure and Representation Learning with Biomedical Applications", "comment": "This article has successfully completed peer review and will appear\n  in the Proceedings of the International Congress of Mathematicians 2026. Both\n  authors contributed equally to this work", "summary": "Massive data collection holds the promise of a better understanding of\ncomplex phenomena and, ultimately, better decisions. Representation learning\nhas become a key driver of deep learning applications, as it allows learning\nlatent spaces that capture important properties of the data without requiring\nany supervised annotations. Although representation learning has been hugely\nsuccessful in predictive tasks, it can fail miserably in causal tasks including\npredicting the effect of a perturbation/intervention. This calls for a marriage\nbetween representation learning and causal inference. An exciting opportunity\nin this regard stems from the growing availability of multi-modal data\n(observational and perturbational, imaging-based and sequencing-based, at the\nsingle-cell level, tissue-level, and organism-level). We outline a statistical\nand computational framework for causal structure and representation learning\nmotivated by fundamental biomedical questions: how to effectively use\nobservational and perturbational data to perform causal discovery on observed\ncausal variables; how to use multi-modal views of the system to learn causal\nvariables; and how to design optimal perturbations.", "AI": {"tldr": "The paper proposes integrating representation learning with causal inference to address limitations of current representation learning methods in causal tasks, using multi-modal biomedical data for causal discovery and optimal perturbation design.", "motivation": "Current representation learning methods excel in predictive tasks but fail in causal tasks like predicting intervention effects, highlighting the need to combine representation learning with causal inference, especially given the availability of diverse multi-modal biomedical data.", "method": "A statistical and computational framework that leverages multi-modal data (observational and perturbational, imaging and sequencing data at various biological levels) to perform causal discovery on observed variables, learn causal variables from multiple views, and design optimal perturbations.", "result": "The framework enables more effective use of observational and perturbational data for causal discovery, facilitates learning of causal variables from multi-modal system views, and provides methods for designing optimal perturbations.", "conclusion": "Integrating representation learning with causal inference through a multi-modal data approach addresses fundamental limitations in current methods and opens new opportunities for causal understanding in biomedical applications."}}
{"id": "2511.04791", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04791", "abs": "https://arxiv.org/abs/2511.04791", "authors": ["Lei Gao", "Chaoyi Jiang", "Hossein Entezari Zarch", "Daniel Wong", "Murali Annavaram"], "title": "DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive GPU Multiplexing", "comment": null, "summary": "Modern LLM serving systems must sustain high throughput while meeting strict\nlatency SLOs across two distinct inference phases: compute-intensive prefill\nand memory-bound decode phases. Existing approaches either (1) aggregate both\nphases on shared GPUs, leading to interference between prefill and decode\nphases, which degrades time-between-tokens (TBT); or (2) disaggregate the two\nphases across GPUs, improving latency but wasting resources through duplicated\nmodels and KV cache transfers. We present DuetServe, a unified LLM serving\nframework that achieves disaggregation-level isolation within a single GPU.\nDuetServe operates in aggregated mode by default and dynamically activates\nSM-level GPU spatial multiplexing when TBT degradation is predicted. Its key\nidea is to decouple prefill and decode execution only when needed through\nfine-grained, adaptive SM partitioning that provides phase isolation only when\ncontention threatens latency service level objectives (SLOs). DuetServe\nintegrates (1) an attention-aware roofline model to forecast iteration latency,\n(2) a partitioning optimizer that selects the optimal SM split to maximize\nthroughput under TBT constraints, and (3) an interruption-free execution engine\nthat eliminates CPU-GPU synchronization overhead. Evaluations show that\nDuetServe improves total throughput by up to 1.3x while maintaining low\ngeneration latency compared to state-of-the-art frameworks.", "AI": {"tldr": "DuetServe is a unified LLM serving framework that uses dynamic GPU spatial multiplexing to isolate prefill and decode phases only when needed, improving throughput by up to 1.3x while maintaining low latency.", "motivation": "Existing LLM serving systems either cause interference between compute-intensive prefill and memory-bound decode phases when aggregated on shared GPUs, or waste resources through disaggregation across GPUs with duplicated models and KV cache transfers.", "method": "DuetServe operates in aggregated mode by default and activates SM-level GPU spatial multiplexing when time-between-tokens degradation is predicted. It incorporates an attention-aware roofline model for latency forecasting, a partitioning optimizer for optimal SM splits, and an interruption-free execution engine to avoid CPU-GPU sync overhead.", "result": "Evaluations demonstrate that DuetServe enhances total throughput by up to 1.3x compared to state-of-the-art frameworks while ensuring low generation latency.", "conclusion": "DuetServe effectively balances resource efficiency and performance by providing fine-grained, adaptive isolation of prefill and decode phases within a single GPU, overcoming limitations of existing approaches."}}
{"id": "2511.04804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04804", "abs": "https://arxiv.org/abs/2511.04804", "authors": ["Chaymae Yahyati", "Ismail Lamaakal", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator", "comment": null, "summary": "We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial\npredictor that represents f: R^d -> R^k as a globally C^r finite-element field\non a learned simplicial mesh in an optionally warped input space. Each query\nactivates exactly one simplex and at most d+1 basis functions via barycentric\ncoordinates, yielding explicit locality, controllable smoothness, and\ncache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with\na light invertible warp and trains end-to-end with shape regularization,\nsemi-discrete OT coverage, and differentiable edge flips. Under standard\nshape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic\nFEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic\napproximation tasks, tabular regression/classification, and as a drop-in head\non compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter\nbudgets, improves calibration (lower ECE/Brier), and reduces inference latency\ndue to geometric locality. These properties make SiFEN a compact,\ninterpretable, and theoretically grounded alternative to dense MLPs and\nedge-spline networks.", "AI": {"tldr": "SiFEN is a new neural network architecture that uses finite-element methods on a learned simplicial mesh to create piecewise-polynomial predictors with explicit locality, controllable smoothness, and computational efficiency.", "motivation": "Current neural networks like MLPs lack interpretability, explicit locality, and theoretical grounding. SiFEN aims to provide a compact, interpretable alternative with better calibration and inference efficiency.", "method": "SiFEN represents functions as finite-element fields on learned simplicial meshes using degree-m Bernstein-Bezier polynomials. It employs barycentric coordinates for activation, shape regularization, semi-discrete OT coverage, and differentiable edge flips during end-to-end training.", "result": "SiFEN achieves the theoretical FEM approximation rate M^(-m/d) and empirically matches or surpasses MLPs and KANs in performance while improving calibration (lower ECE/Brier scores) and reducing inference latency due to geometric locality.", "conclusion": "SiFEN provides a theoretically grounded, compact, and interpretable alternative to dense MLPs and edge-spline networks, with advantages in calibration, efficiency, and performance across various tasks."}}
{"id": "2511.04805", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04805", "abs": "https://arxiv.org/abs/2511.04805", "authors": ["Yushu Zhao", "Zheng Wang", "Minjia Zhang"], "title": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference", "comment": null, "summary": "Mixture-of-Experts (MoE) models have shown strong potential in scaling\nlanguage models efficiently by activating only a small subset of experts per\ninput. However, their widespread deployment remains limited due to the high\nmemory overhead associated with storing all expert parameters, particularly as\nthe number of experts increases. To address this challenge, prior works have\nexplored expert dropping and merging strategies, yet they often suffer from\nperformance drop at high compression ratios. In this paper, we introduce\nPuzzleMoE, a training-free MoE compression method that achieves both high\naccuracy and efficient inference through two key innovations: First, PuzzleMoE\nperforms sparse expert merging by identifying element-wise weight redundancy\nand specialization. It uses a dual-mask to capture both shared and\nexpert-specific parameters. Second, to avoid the overhead of storing binary\nmasks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses\nunderutilized exponent bits, enabling efficient MoE inference on GPUs.\nExtensive experiments demonstrate that PuzzleMoE can compress MoE models by up\nto 50% while maintaining accuracy across various tasks. Specifically, it\noutperforms prior MoE compression methods by up to 16.7% on MMLU at 50%\ncompression ratio, and achieves up to 1.28\\times inference speedup.", "AI": {"tldr": "PuzzleMoE is a training-free compression method for Mixture-of-Experts models that reduces memory usage by up to 50% while maintaining accuracy, using sparse expert merging and bit-packed encoding.", "motivation": "MoE models have high memory overhead from storing all expert parameters, limiting deployment. Existing compression methods cause performance drops at high ratios.", "method": "Uses sparse expert merging with dual-mask to identify redundant/specialized weights, and bit-packed encoding to reuse exponent bits for efficient storage.", "result": "Achieves 50% compression with maintained accuracy, outperforms prior methods by up to 16.7% on MMLU, and achieves 1.28x inference speedup.", "conclusion": "PuzzleMoE enables efficient MoE deployment with high compression and accuracy, advancing scalable language modeling."}}
{"id": "2511.04807", "categories": ["cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.04807", "abs": "https://arxiv.org/abs/2511.04807", "authors": ["Matthew D. Kvalheim", "Eduardo D. Sontag"], "title": "Autoencoding Dynamics: Topological Limitations and Capabilities", "comment": null, "summary": "Given a \"data manifold\" $M\\subset \\mathbb{R}^n$ and \"latent space\"\n$\\mathbb{R}^\\ell$, an autoencoder is a pair of continuous maps consisting of an\n\"encoder\" $E\\colon \\mathbb{R}^n\\to \\mathbb{R}^\\ell$ and \"decoder\" $D\\colon\n\\mathbb{R}^\\ell\\to \\mathbb{R}^n$ such that the \"round trip\" map $D\\circ E$ is\nas close as possible to the identity map $\\mbox{id}_M$ on $M$. We present\nvarious topological limitations and capabilites inherent to the search for an\nautoencoder, and describe capabilities for autoencoding dynamical systems\nhaving $M$ as an invariant manifold.", "AI": {"tldr": "The paper analyzes topological constraints and capabilities of autoencoders for data manifolds and dynamical systems.", "motivation": "To understand the fundamental topological limitations and possibilities when constructing autoencoders that approximate identity maps on data manifolds.", "method": "Analyzes continuous encoder-decoder pairs and their compositions, focusing on topological properties and constraints.", "result": "Identifies specific topological limitations and capabilities for autoencoder construction and extends analysis to dynamical systems with invariant manifolds.", "conclusion": "Autoencoders have inherent topological constraints when approximating identity maps, but also possess capabilities for handling dynamical systems with invariant manifolds."}}
{"id": "2511.04814", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "68T07, 62H30, 62P10", "I.2.6; I.2.1; I.5.1; I.5.2"], "pdf": "https://arxiv.org/pdf/2511.04814", "abs": "https://arxiv.org/abs/2511.04814", "authors": ["Sebastian Ojeda", "Rafael Velasquez", "Nicol\u00e1s Aparicio", "Juanita Puentes", "Paula C\u00e1rdenas", "Nicol\u00e1s Andrade", "Gabriel Gonz\u00e1lez", "Sergio Rinc\u00f3n", "Carolina Mu\u00f1oz-Camargo", "Pablo Arbel\u00e1ez"], "title": "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025). Camera-ready version. Code: https://github.com/BCV-Uniandes/ESCAPE.\n  Dataset DOI: https://doi.org/10.7910/DVN/C69MCD", "summary": "Antimicrobial peptides have emerged as promising molecules to combat\nantimicrobial resistance. However, fragmented datasets, inconsistent\nannotations, and the lack of standardized benchmarks hinder computational\napproaches and slow down the discovery of new candidates. To address these\nchallenges, we present the Expanded Standardized Collection for Antimicrobial\nPeptide Evaluation (ESCAPE), an experimental framework integrating over 80.000\npeptides from 27 validated repositories. Our dataset separates antimicrobial\npeptides from negative sequences and incorporates their functional annotations\ninto a biologically coherent multilabel hierarchy, capturing activities across\nantibacterial, antifungal, antiviral, and antiparasitic classes. Building on\nESCAPE, we propose a transformer-based model that leverages sequence and\nstructural information to predict multiple functional activities of peptides.\nOur method achieves up to a 2.56% relative average improvement in mean Average\nPrecision over the second-best method adapted for this task, establishing a new\nstate-of-the-art multilabel peptide classification. ESCAPE provides a\ncomprehensive and reproducible evaluation framework to advance AI-driven\nantimicrobial peptide research.", "AI": {"tldr": "ESCAPE dataset with 80,000+ peptides and transformer model improves antimicrobial peptide classification by 2.56% over previous methods.", "motivation": "Address fragmented datasets, inconsistent annotations, and lack of standardized benchmarks hindering computational AMP discovery.", "method": "Create ESCAPE framework integrating peptides from 27 repositories with multilabel hierarchy, plus transformer model using sequence/structural data.", "result": "Model achieves 2.56% relative improvement in mean Average Precision over second-best method for multilabel classification.", "conclusion": "ESCAPE provides reproducible evaluation framework to advance AI-driven antimicrobial peptide research."}}
{"id": "2511.04808", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04808", "abs": "https://arxiv.org/abs/2511.04808", "authors": ["Raymond Fan", "Bryce Sandlund", "Lin Myat Ko"], "title": "Sharp Minima Can Generalize: A Loss Landscape Perspective On Data", "comment": null, "summary": "The volume hypothesis suggests deep learning is effective because it is\nlikely to find flat minima due to their large volumes, and flat minima\ngeneralize well. This picture does not explain the role of large datasets in\ngeneralization. Measuring minima volumes under varying amounts of training data\nreveals sharp minima which generalize well exist, but are unlikely to be found\ndue to their small volumes. Increasing data changes the loss landscape, such\nthat previously small generalizing minima become (relatively) large.", "AI": {"tldr": "The volume hypothesis is incomplete - large datasets change loss landscapes to make sharp but generalizing minima more accessible by increasing their relative volume.", "motivation": "To understand why large datasets improve generalization in deep learning, challenging the conventional volume hypothesis that only flat minima generalize well.", "method": "Measured minima volumes under varying training data sizes and analyzed how data quantity changes the loss landscape structure.", "result": "Found that sharp minima can generalize well but are rarely found due to small volumes; increasing data makes these good sharp minima relatively larger and more discoverable.", "conclusion": "Large datasets improve generalization not just by finding flat minima, but by reshaping the loss landscape to make previously inaccessible sharp generalizing minima more discoverable."}}
{"id": "2511.04834", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04834", "abs": "https://arxiv.org/abs/2511.04834", "authors": ["Jiwoo Shin", "Byeonghu Na", "Mina Kang", "Wonhyeok Choi", "Il-chul Moon"], "title": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025 Workshop on Generative and Protective AI for\n  Content Creation", "summary": "Recent advances in text-to-image generative models have raised concerns about\ntheir potential to produce harmful content when provided with malicious input\ntext prompts. To address this issue, two main approaches have emerged: (1)\nfine-tuning the model to unlearn harmful concepts and (2) training-free\nguidance methods that leverage negative prompts. However, we observe that\ncombining these two orthogonal approaches often leads to marginal or even\ndegraded defense performance. This observation indicates a critical\nincompatibility between two paradigms, which hinders their combined\neffectiveness. In this work, we address this issue by proposing a conceptually\nsimple yet experimentally robust method: replacing the negative prompts used in\ntraining-free methods with implicit negative embeddings obtained through\nconcept inversion. Our method requires no modification to either approach and\ncan be easily integrated into existing pipelines. We experimentally validate\nits effectiveness on nudity and violence benchmarks, demonstrating consistent\nimprovements in defense success rate while preserving the core semantics of\ninput prompts.", "AI": {"tldr": "A method that replaces negative prompts with implicit negative embeddings via concept inversion to improve defense against harmful content in text-to-image models, without modifying existing approaches.", "motivation": "Current defenses against harmful content in text-to-image models (fine-tuning and training-free guidance) show incompatibility when combined, limiting effectiveness.", "method": "Propose using implicit negative embeddings from concept inversion instead of negative prompts in training-free methods, allowing seamless integration.", "result": "Improved defense success rates on nudity and violence benchmarks while maintaining input prompt semantics.", "conclusion": "The method effectively enhances defense compatibility and performance without altering existing pipelines."}}
{"id": "2511.04902", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04902", "abs": "https://arxiv.org/abs/2511.04902", "authors": ["Shuvendu Roy", "Hossein Hajimirsadeghi", "Mengyao Zhai", "Golnoosh Samei"], "title": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: MATH-AI", "summary": "Recent advances in large language models have demonstrated the promise of\nunsupervised reinforcement learning (RL) methods for enhancing reasoning\ncapabilities without external supervision. However, the generalizability of\nthese label-free RL approaches to smaller base models with limited reasoning\ncapabilities remains unexplored. In this work, we systematically investigate\nthe performance of label-free RL methods across different model sizes and\nreasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals\ncritical limitations: label-free RL is highly dependent on the base model's\npre-existing reasoning capability, with performance often degrading below\nbaseline levels for weaker models. We find that smaller models fail to generate\nsufficiently long or diverse chain-of-thought reasoning to enable effective\nself-reflection, and that training data difficulty plays a crucial role in\ndetermining success. To address these challenges, we propose a simple yet\neffective method for label-free RL that utilizes curriculum learning to\nprogressively introduce harder problems during training and mask no-majority\nrollouts during training. Additionally, we introduce a data curation pipeline\nto generate samples with predefined difficulty. Our approach demonstrates\nconsistent improvements across all model sizes and reasoning capabilities,\nproviding a path toward more robust unsupervised RL that can bootstrap\nreasoning abilities in resource-constrained models. We make our code available\nat https://github.com/BorealisAI/CuMa", "AI": {"tldr": "Label-free RL struggles with smaller models lacking reasoning capability; curriculum learning and data curation improve performance across all model sizes.", "motivation": "To investigate generalizability of unsupervised RL methods across different model sizes and address limitations for smaller models.", "method": "Systematic evaluation of label-free RL from 0.5B to 7B models; propose curriculum learning with progressive difficulty and masking no-majority rollouts; data curation pipeline for difficulty-controlled samples.", "result": "Smaller models degrade below baseline due to insufficient reasoning diversity; proposed method shows consistent improvements across all model sizes.", "conclusion": "Curriculum-based label-free RL enables more robust unsupervised reasoning enhancement, especially for resource-constrained models."}}
{"id": "2511.04825", "categories": ["cs.LG", "math.AT", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.04825", "abs": "https://arxiv.org/abs/2511.04825", "authors": ["Luigi Caputi", "Nicholas Meadows", "Henri Riihim\u00e4ki"], "title": "Persistent reachability homology in machine learning applications", "comment": "19 pages; any comments welcome", "summary": "We explore the recently introduced persistent reachability homology (PRH) of\ndigraph data, i.e. data in the form of directed graphs. In particular, we study\nthe effectiveness of PRH in network classification task in a key neuroscience\nproblem: epilepsy detection. PRH is a variation of the persistent homology of\ndigraphs, more traditionally based on the directed flag complex (DPH). A main\nadvantage of PRH is that it considers the condensations of the digraphs\nappearing in the persistent filtration and thus is computed from smaller\ndigraphs. We compare the effectiveness of PRH to that of DPH and we show that\nPRH outperforms DPH in the classification task. We use the Betti curves and\ntheir integrals as topological features and implement our pipeline on support\nvector machine.", "AI": {"tldr": "Persistent reachability homology (PRH) for digraphs outperforms directed flag complex-based persistent homology (DPH) in classifying epilepsy detection neural networks, using Betti curves and SVM.", "motivation": "Traditional persistent homology based on directed flag complex (DPH) may be computationally intensive. PRH offers an advantage by analyzing smaller digraph condensations during filtration, potentially improving efficiency and effectiveness.", "method": "Applied PRH and DPH to digraph data from epilepsy neural networks, using Betti curves and their integrals as topological features, with a support vector machine classifier.", "result": "PRH achieved superior classification performance compared to DPH in the epilepsy detection task.", "conclusion": "PRH is a more effective and computationally advantageous method for topological analysis of digraph data in neuroscience applications like epilepsy detection."}}
{"id": "2511.04909", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04909", "abs": "https://arxiv.org/abs/2511.04909", "authors": ["Paula Rodriguez-Diaz", "Kirk Bansak Elisabeth Paulson"], "title": "A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates", "comment": null, "summary": "Many real-world decisions are made under uncertainty by solving optimization\nproblems using predicted quantities. This predict-then-optimize paradigm has\nmotivated decision-focused learning, which trains models with awareness of how\nthe optimizer uses predictions, improving the performance of downstream\ndecisions. Despite its promise, scaling is challenging: state-of-the-art\nmethods either differentiate through a solver or rely on task-specific\nsurrogates, both of which require frequent and expensive calls to an optimizer,\noften a combinatorial one. In this paper, we leverage dual variables from the\ndownstream problem to shape learning and introduce Dual-Guided Loss (DGL), a\nsimple, scalable objective that preserves decision alignment while reducing\nsolver dependence. We construct DGL specifically for combinatorial selection\nproblems with natural one-of-many constraints, such as matching, knapsack, and\nshortest path. Our approach (a) decouples optimization from gradient updates by\nsolving the downstream problem only periodically; (b) between refreshes, trains\non dual-adjusted targets using simple differentiable surrogate losses; and (c)\nas refreshes become less frequent, drives training cost toward standard\nsupervised learning while retaining strong decision alignment. We prove that\nDGL has asymptotically diminishing decision regret, analyze runtime complexity,\nand show on two problem classes that DGL matches or exceeds state-of-the-art\nDFL methods while using far fewer solver calls and substantially less training\ntime. Code is available at https://github.com/paularodr/Dual-Guided-Learning.", "AI": {"tldr": "Dual-Guided Loss (DGL) is a scalable decision-focused learning method that uses dual variables from optimization problems to guide model training, reducing solver dependence while maintaining decision alignment.", "motivation": "Scaling decision-focused learning is challenging because current methods either differentiate through solvers or use task-specific surrogates, both requiring frequent and expensive optimizer calls.", "method": "DGL leverages dual variables from downstream combinatorial selection problems, decouples optimization from gradient updates by solving problems only periodically, and trains on dual-adjusted targets using simple differentiable surrogate losses between refreshes.", "result": "DGL matches or exceeds state-of-the-art DFL methods while using far fewer solver calls and substantially less training time, with proven asymptotically diminishing decision regret.", "conclusion": "DGL provides a scalable approach to decision-focused learning that reduces computational costs while maintaining strong decision alignment, making it practical for real-world applications."}}
