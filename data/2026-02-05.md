<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900)
*Erik Goh,John Kos,Ashok Goel*

Main category: cs.AI

TL;DR: The paper shows that the Task-Method-Knowledge (TMK) framework significantly improves LLM reasoning and planning performance on symbolic planning tasks, enabling models to achieve up to 97.3% accuracy on tasks where they previously failed.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with reasoning and planning tasks, and existing prompting techniques like Chain-of-Thought have limitations. The paper investigates whether the TMK framework from cognitive/educational science can improve LLM reasoning by providing explicit task decomposition and capturing causal, teleological, and hierarchical reasoning structures that other frameworks lack.

Method: The study evaluates TMK by experimenting on the PlanBench benchmark, specifically the Blocksworld domain, to test reasoning and planning capabilities. It examines whether TMK-structured prompting helps language models better decompose complex planning problems into manageable sub-tasks.

Result: TMK prompting enables reasoning models to achieve up to 97.3% accuracy on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where they previously failed (31.5%), showing significant performance improvement. Results highlight TMK's ability to bridge semantic approximation and symbolic manipulation.

Conclusion: TMK functions not merely as context but as a mechanism that steers reasoning models away from default linguistic modes to engage formal, code-execution pathways. It shows potential to significantly enhance LLM reasoning capabilities for complex planning tasks.

Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data](https://arxiv.org/abs/2602.03872)
*Jiaming Zhang,Huanyi Xie,Meng Ding,Shaopeng Fu,Jinyan Liu,Di Wang*

Main category: cs.LG

TL;DR: This paper analyzes why DP-SGD fails on long-tailed data, linking poor generalization on rare samples to gradient clipping and noise.


<details>
  <summary>Details</summary>
Motivation: DP-SGD causes suboptimal generalization on long-tailed data, but theoretical understanding is lacking.

Method: Developed a theoretical framework from a feature learning perspective to analyze DP-SGD's training dynamics on long-tailed data.

Result: DP-SGD leads to higher test error on long-tailed subpopulations than overall dataset, due to adverse effects of gradient clipping and noise.

Conclusion: DP-SGD's mechanisms harm memorization of underrepresented samples, explaining performance issues; validated experimentally.

Abstract: Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private training algorithms such as DP-SGD. However, a growing body of empirical work shows that DP-SGD often leads to suboptimal generalization performance, particularly on long-tailed data that contain a large number of rare or atypical samples. Despite these observations, a theoretical understanding of this phenomenon remains largely unexplored, and existing differential privacy analysis are difficult to extend to the nonconvex and nonsmooth neural networks commonly used in practice. In this work, we develop the first theoretical framework for analyzing DP-SGD on long-tailed data from a feature learning perspective. We show that the test error of DP-SGD-trained models on the long-tailed subpopulation is significantly larger than the overall test error over the entire dataset. Our analysis further characterizes the training dynamics of DP-SGD, demonstrating how gradient clipping and noise injection jointly adversely affect the model's ability to memorize informative but underrepresented samples. Finally, we validate our theoretical findings through extensive experiments on both synthetic and real-world datasets.

</details>


### [3] [Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra](https://arxiv.org/abs/2602.03875)
*Stefan Kuhn,Vandana Dwarka,Przemyslaw Karol Grenda,Eero Vainikko*

Main category: cs.LG

TL;DR: A reversible deep learning model for 13C NMR spectroscopy that uses a single conditional invertible neural network to map between molecular structures and spectra, enabling both forward prediction and inverse generation.


<details>
  <summary>Details</summary>
Motivation: To address the one-to-many nature of spectrum-to-structure inference and unify spectrum prediction with uncertainty-aware candidate generation within one end-to-end model.

Method: Built from i-RevNet style bijective blocks, the network is trained to predict a 128-bit binned spectrum code from graph-based structure encodings, with latent dimensions capturing residual variability. The same trained network is inverted at inference to generate structure candidates from spectrum codes.

Result: On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra.

Conclusion: Invertible architectures can effectively unify spectrum prediction and uncertainty-aware candidate generation in a single end-to-end model.

Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.

</details>


### [4] [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876)
*Kyuseong Choi,Dwaipayan Saha,Woojeong Kim,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: GOPO is a rank-based policy optimization method that improves on GRPO by using only reward rankings, not magnitudes, for better performance in tasks like summarization and chat.


<details>
  <summary>Details</summary>
Motivation: Standard RLHF uses reward models for absolute magnitudes, but this misaligns with non-verifiable reward settings, leading to suboptimal performance.

Method: GOPO transforms rewards to use only rankings, discarding magnitudes, for policy optimization in settings like summarization and instruction following.

Result: GOPO consistently achieves higher training/validation rewards, better LLM-as-judge evaluations, and faster convergence to comparable policy quality than GRPO.

Conclusion: GOPO is effective for RLHF in non-verifiable reward scenarios, offering robust improvements across tasks and model sizes.

Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.

</details>


### [5] [NeuroPareto: Calibrated Acquisition for Costly Many-Goal Search in Vast Parameter Spaces](https://arxiv.org/abs/2602.03901)
*Rong Fu,Wenxin Zhang,Chunlei Meng,Youjin Wang,Haoyu Zhao,Jiaxuan Lu,Kun Liu,JiaBao Dou,Simon James Fong*

Main category: cs.LG

TL;DR: NeuroPareto is an architecture integrating rank filtering, uncertainty disentanglement, and history-conditioned acquisition for efficient multi-objective optimization.


<details>
  <summary>Details</summary>
Motivation: Optimizing trade-offs in high-dimensional spaces under computational constraints is challenging in multi-objective optimization.

Method: Uses rank-centric filtering, Bayesian classifier for epistemic uncertainty, Deep Gaussian Process surrogates, and a lightweight acquisition network trained online.

Result: Outperforms baselines in Pareto proximity and hypervolume on DTLZ, ZDT suites, and a subsurface energy extraction task.

Conclusion: NeuroPareto achieves high-quality Pareto solutions with low computational cost, demonstrating effectiveness in complex optimization problems.

Abstract: The pursuit of optimal trade-offs in high-dimensional search spaces under stringent computational constraints poses a fundamental challenge for contemporary multi-objective optimization. We develop NeuroPareto, a cohesive architecture that integrates rank-centric filtering, uncertainty disentanglement, and history-conditioned acquisition strategies to navigate complex objective landscapes. A calibrated Bayesian classifier estimates epistemic uncertainty across non-domination tiers, enabling rapid generation of high-quality candidates with minimal evaluation cost. Deep Gaussian Process surrogates further separate predictive uncertainty into reducible and irreducible components, providing refined predictive means and risk-aware signals for downstream selection. A lightweight acquisition network, trained online from historical hypervolume improvements, guides expensive evaluations toward regions balancing convergence and diversity. With hierarchical screening and amortized surrogate updates, the method maintains accuracy while keeping computational overhead low. Experiments on DTLZ and ZDT suites and a subsurface energy extraction task show that NeuroPareto consistently outperforms classifier-enhanced and surrogate-assisted baselines in Pareto proximity and hypervolume.

</details>


### [6] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: GeoIB is a new information bottleneck method that avoids mutual information estimation by using geometric projections and regularization terms for better compression and optimization in deep learning.


<details>
  <summary>Details</summary>
Motivation: Traditional IB methods in deep learning rely on approximations like variational bounds or MI estimators, which can be loose and biased, leading to fragile optimization and indirect control over compression.

Method: Proposes GeoIB based on information geometry, representing mutual information as minimal KL distances to independence manifolds, using a Fisher-Rao discrepancy and a Jacobian-Frobenius term for regularization, and deriving a natural-gradient optimizer.

Result: GeoIB achieves a better trade-off between prediction accuracy and compression ratio in experiments on popular datasets, improving invariance and optimization stability compared to mainstream IB baselines.

Conclusion: GeoIB effectively unifies distributional and geometric regularization under a single bottleneck multiplier, enhancing performance and robustness in information bottleneck applications.

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [7] [On the Uncertainty of Large Language Model-Based Multi-Agent Systems](https://arxiv.org/abs/2602.04234)
*Yuxuan Zhao,Sijia Chen,Ningxin Su*

Main category: cs.MA

TL;DR: This paper analyzes multi-agent systems (MAS) built on large language models from an uncertainty perspective, finding that single agents outperform MAS in 43.3% of cases and that uncertainty dynamics are determined early. It introduces three key observations and a new algorithm, the Entropy Judger, to improve MAS accuracy by selecting solutions from pass@k results.


<details>
  <summary>Details</summary>
Motivation: The mechanisms behind the effectiveness of multi-agent systems (MAS) using publicly available LLMs, especially the reasons for their success or failure, are not well understood. The paper aims to explore this by examining uncertainty dynamics in MAS.

Method: The study revisits MAS through the lens of uncertainty, analyzing intra- and inter-agent dynamics by investigating entropy transitions during problem-solving. It uses various topologies and six benchmark tasks, analyzing 245 features at token-, trajectory-, and round-level entropy.

Result: Counterintuitive findings include that a single agent outperforms MAS in approximately 43.3% of cases, and uncertainty dynamics are largely determined in the first round of interaction. Three key observations are provided: Certainty Preference, Base Uncertainty, and Task Awareness. Based on these, the Entropy Judger algorithm is introduced to select solutions from MAS's pass@k results.

Conclusion: The paper concludes that understanding uncertainty is crucial for MAS effectiveness, and the proposed Entropy Judger algorithm consistently improves accuracy across MAS configurations and tasks. It highlights the need for further research into uncertainty in MAS.

Abstract: Multi-agent systems (MAS) have emerged as a prominent paradigm for leveraging large language models (LLMs) to tackle complex tasks. However, the mechanisms governing the effectiveness of MAS built upon publicly available LLMs, specifically the underlying rationales for their success or failure, remain largely unexplored. In this paper, we revisit MAS through the perspective of uncertainty, considering both intra- and inter-agent dynamics by investigating entropy transitions during problem-solving across various topologies and six benchmark tasks. By analyzing 245 features spanning token-, trajectory-, and round-level entropy, we counterintuitively find that a single agent outperforms MAS in approximately 43.3% of cases, and that uncertainty dynamics are largely determined during the first round of interaction. Furthermore, we provide three key observations: 1) Certainty Preference: reducing uncertainty at any stage for any agent is critical for guaranteeing correct solutions; 2) Base Uncertainty: base models with lower entropy during problem-solving directly benefit MAS performance; and 3) Task Awareness: entropy dynamics of MAS play varying roles across different tasks. Building on these insights, we introduce a simple yet effective algorithm, the Entropy Judger, to select solutions from MAS's pass@k results, leading to consistent accuracy improvements across all MAS configurations and tasks. Our source code is available at https://github.com/AgenticFinLab/multiagent-entropy.

</details>


### [8] [SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing](https://arxiv.org/abs/2602.04418)
*Arnab Mallick,Indraveni Chebolu,Harmesh Rana*

Main category: cs.MA

TL;DR: SPEAR is a multi-agent framework for smart contract auditing using specialized agents to coordinate tasks, prioritize risks, and recover from errors in a decentralized workflow.


<details>
  <summary>Details</summary>
Motivation: Smart contract auditing requires robust coordination and recovery mechanisms to handle complex security analysis workflows efficiently, which traditional centralized or pipeline-based approaches may lack under failure scenarios.

Method: SPEAR employs a multi-agent system with specialized agents: Planning Agent for risk-aware prioritization, Execution Agent for task allocation via Contract Net protocol, and Repair Agent for autonomous recovery using programmatic-first repair. Agents update local beliefs through AGM-compliant revision and coordinate via negotiation and auction protocols.

Result: An empirical study compares SPEAR's multi-agent design with centralized and pipeline-based alternatives, showing improved coordination, recovery behavior, and resource utilization under controlled failure scenarios.

Conclusion: SPEAR effectively demonstrates that a multi-agent coordination framework enhances smart contract auditing by leveraging specialized agents for dynamic task management and resilient error recovery, offering advantages in complex security analysis environments.

Abstract: We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.

</details>
