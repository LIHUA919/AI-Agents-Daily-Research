{"id": "2601.10718", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10718", "abs": "https://arxiv.org/abs/2601.10718", "authors": ["Junyu Liu", "Siwen Yang", "Dexiu Ma", "Qian Niu", "Zequn Zhang", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design", "comment": null, "summary": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.", "AI": {"tldr": "A dual-purpose AI agent system was developed to combat HPV vaccine hesitancy using a conversational chatbot and analytical reports, showing high performance across multiple evaluation metrics.", "motivation": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse.", "method": "We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification.", "result": "For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods.", "conclusion": "This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication."}}
{"id": "2601.10719", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.", "AI": {"tldr": "LLMs implicitly encode psychologically-grounded trustworthiness signals from web narratives during pretraining, with strongest associations to human trust dimensions like fairness and certainty, offering foundation for trustworthy AI systems.", "motivation": "To understand whether LLMs represent perceived trustworthiness in psychologically coherent ways, given their increasing integration into search, recommendation, and conversational systems that shape online information navigation.", "method": "Analyzed instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) using PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Examined layer- and head-level activation differences between high- and low-trust texts, conducted probing analyses for linearly decodable trust signals, and assessed fine-tuning effects.", "result": "LLMs show systematic activation differences distinguishing high- from low-trust texts, revealing trust cues are implicitly encoded during pretraining. Trust signals are linearly decodable, and fine-tuning refines rather than restructures these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self - dimensions central to human trust formation online.", "conclusion": "Modern LLMs internalize psychologically grounded trust signals without explicit supervision, providing a representational foundation for designing credible, transparent, and trustworthy AI systems in the web ecosystem."}}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "AI agents improve job referral request writing in online communities, with a novel RAG-enhanced LLM approach boosting success predictions for weaker requests by 14% without harming stronger ones.", "motivation": "To help job seekers craft more effective referral requests in professional online platforms by leveraging AI-assisted rewriting.", "method": "Develops a system with improver and evaluator agents; uses RAG-enhanced LLM for intelligent revisions.", "result": "LLM revisions increase predicted success rates for weaker requests while potentially reducing them for stronger ones, but RAG enhancement prevents this degradation and amplifies improvements, achieving a 14% boost in predicted success for weaker requests.", "conclusion": "Using RAG-enhanced LLM revisions offers a low-cost signal for potential referral success, though real-world effectiveness remains uncertain, suggesting the method is promising for preliminary assessment ahead of riskier experiments."}}
{"id": "2601.10729", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10729", "abs": "https://arxiv.org/abs/2601.10729", "authors": ["Xinyue Ma", "Heelim Hong", "Taegeon Um", "Jongseop Lee", "Seoyeong Choy", "Woo-Yeon Lee", "Myeongjae Jeon"], "title": "ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration", "comment": "Accepted at the 52nd International Conference on Very Large Data Bases (VLDB 2026). Xinyue Ma and Heelim Hong contributed equally (co-first authors)", "summary": "Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods.", "AI": {"tldr": "ORBITFLOW is an adaptive KV cache management system that improves long-context LLM serving by dynamically offloading KV caches to host memory to handle fluctuating memory demands, reducing latency and increasing throughput.", "motivation": "Serving long-context LLMs is challenging due to varying request lengths and batch compositions causing significant memory footprint fluctuations during token generation, with existing static KV cache offloading strategies failing to adapt to rapidly shifting memory demands and leading to excessive CPU-to-GPU transfers, latency spikes, and frequent SLO violations.", "method": "ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU per request under memory constraints, continuously refines KV placements based on runtime feedback when plans become suboptimal, and under heavy load, invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints.", "result": "Experiments show ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48% respectively, reduces the 95th percentile latency by 38%, and achieves up to 3.3x higher throughput compared to existing offloading methods.", "conclusion": "ORBITFLOW addresses the limitations of static KV cache management by introducing dynamic adaptation and fallback strategies, effectively mitigating latency issues and enhancing performance in long-context LLM serving environments."}}
{"id": "2601.10774", "categories": ["cs.LG", "hep-lat"], "pdf": "https://arxiv.org/pdf/2601.10774", "abs": "https://arxiv.org/abs/2601.10774", "authors": ["Mathis Gerdes", "Miranda C. N. Cheng"], "title": "Analytic Bijections for Smooth and Interpretable Normalizing Flows", "comment": "33 + 5 pages, 17 + 1 figures, 3 tables", "summary": "A key challenge in designing normalizing flows is finding expressive scalar bijections that remain invertible with tractable Jacobians. Existing approaches face trade-offs: affine transformations are smooth and analytically invertible but lack expressivity; monotonic splines offer local control but are only piecewise smooth and act on bounded domains; residual flows achieve smoothness but need numerical inversion. We introduce three families of analytic bijections -- cubic rational, sinh, and cubic polynomial -- that are globally smooth ($C^\\infty$), defined on all of $\\mathbb{R}$, and analytically invertible in closed form, combining the favorable properties of all prior approaches. These bijections serve as drop-in replacements in coupling flows, matching or exceeding spline performance. Beyond coupling layers, we develop radial flows: a novel architecture using direct parametrization that transforms the radial coordinate while preserving angular direction. Radial flows exhibit exceptional training stability, produce geometrically interpretable transformations, and on targets with radial structure can achieve comparable quality to coupling flows with $1000\\times$ fewer parameters. We provide comprehensive evaluation on 1D and 2D benchmarks, and demonstrate applicability to higher-dimensional physics problems through experiments on $\u03c6^4$ lattice field theory, where our bijections outperform affine baselines and enable problem-specific designs that address mode collapse.", "AI": {"tldr": "New analytic bijections (cubic rational, sinh, cubic polynomial) combine smoothness, expressivity, and closed-form inversion for normalizing flows, plus radial flows that transform coordinates efficiently with high interpretability.", "motivation": "Address trade-offs in existing normalizing flow designs: affine transformations lack expressivity, monotonic splines are only piecewise smooth with bounded domains, and residual flows require numerical inversion.", "method": "1) Introduce three families of analytic bijections (cubic rational, sinh, cubic polynomial) that are globally smooth, defined on \u211d, and analytically invertible. 2) Develop radial flows: a novel architecture using direct parametrization that transforms radial coordinates while preserving angular direction. 3) Provide comprehensive evaluation on 1D/2D benchmarks and \u03c6\u2074 lattice field theory experiments.", "result": "The analytic bijections match or exceed spline performance in coupling flows. Radial flows show exceptional training stability, geometric interpretability, and on radially structured targets achieve comparable quality to coupling flows with 1000\u00d7 fewer parameters.", "conclusion": "The proposed analytic bijections and radial flow architecture offer practical advantages for normalizing flows, combining expressivity with invertibility while enabling problem-specific designs that can address challenges like mode collapse in complex applications."}}
{"id": "2601.10849", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10849", "abs": "https://arxiv.org/abs/2601.10849", "authors": ["Cuong Le", "Symeon Chatzinotas", "Thang X. Vu"], "title": "Cooperative UAVs for Remote Data Collection under Limited Communications: An Asynchronous Multiagent Learning Framework", "comment": "Accepted to IEEE Transactions on Wireless Communications", "summary": "This paper addresses the joint optimization of trajectories and bandwidth allocation for multiple Unmanned Aerial Vehicles (UAVs) to enhance energy efficiency in the cooperative data collection problem. We focus on an important yet underestimated aspect of the system, where action synchronization across all UAVs is impossible. Since most existing learning-based solutions are not designed to learn in this asynchronous environment, we formulate the trajectory planning problem as a Decentralized Partially Observable Semi-Markov Decision Process and introduce an asynchronous multi-agent learning algorithm to learn UAVs' cooperative policies. Once the UAVs' trajectory policies are learned, the bandwidth allocation can be optimally solved based on local observations at each collection point. Comprehensive empirical results demonstrate the superiority of the proposed method over other learning-based and heuristic baselines in terms of both energy efficiency and mission completion time. Additionally, the learned policies exhibit robustness under varying environmental conditions.", "AI": {"tldr": "This paper introduces an asynchronous multi-agent learning algorithm to optimize UAV trajectories and bandwidth allocation for energy-efficient cooperative data collection, overcoming action synchronization limitations.", "motivation": "In cooperative data collection using multiple UAVs, action synchronization across all UAVs is often impossible, yet most existing learning-based solutions are not designed for asynchronous environments, limiting their practical applicability.", "method": "The problem is formulated as a Decentralized Partially Observable Semi-Markov Decision Process (Dec-POSMDP), and an asynchronous multi-agent learning algorithm is introduced to learn UAVs' cooperative trajectory policies, with optimal bandwidth allocation solved based on local observations at each collection point.", "result": "Empirical results show the proposed method outperforms other learning-based and heuristic baselines in energy efficiency and mission completion time, with learned policies demonstrating robustness under varying environmental conditions.", "conclusion": "This work effectively addresses the challenge of asynchronous actions in multi-UAV systems, providing a scalable and robust solution for energy-efficient cooperative data collection."}}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "CTHA is a hierarchical framework with constraints to fix stability issues in multi-layered agents, improving efficiency and scalability.", "motivation": "Multi-time-scale agent architectures cause coordination problems like conflicts and error propagation, needing a structured solution.", "method": "CTHA uses three constraints: Message Contract for formalized info flow, Authority Manifold for bounded decision spaces, and Arbiter Resolution for conflict-free multi-layer decisions.", "result": "Experiments show CTHA reduces failure cascades by 47%, improves sample efficiency 2.3x, and offers better scalability than baselines.", "conclusion": "CTHA provides a principled way to enhance coordination in complex tasks, advancing robust autonomous systems."}}
{"id": "2601.10779", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10779", "abs": "https://arxiv.org/abs/2601.10779", "authors": ["Qingyue Zhang", "Chang Chu", "Haohao Fu", "Tianren Peng", "Yanru Wu", "Guanbo Huang", "Yang Li", "Shao-Lun Huang"], "title": "Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework", "comment": null, "summary": "Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.", "AI": {"tldr": "UOWQ is a theoretical framework that optimizes both source weights and transfer quantities in multi-source transfer learning, showing superior performance in data-scarce scenarios.", "motivation": "Naive uniform transfer from multiple sources can cause negative transfer, and existing methods often focus solely on weights or sample quantities without joint optimization.", "method": "UOWQ frames transfer learning as a parameter estimation problem based on asymptotic analysis of KL divergence, providing closed-form solutions for single-source and convex optimization for multi-source cases, with practical algorithms for transfer and multi-task learning.", "result": "Experiments on benchmarks like DomainNet and Office-Home confirm UOWQ outperforms baselines, validating that using all available source samples is optimal with proper weight adjustment.", "conclusion": "UOWQ effectively balances heterogeneous source contributions, preventing negative transfer and enhancing model performance, offering both theoretical insights and practical algorithms."}}
