{"id": "2511.01912", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01912", "abs": "https://arxiv.org/abs/2511.01912", "authors": ["Wenzhe Fan", "Ning Yan", "Masood Mortazavi"], "title": "EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory", "comment": null, "summary": "Planning has been a cornerstone of artificial intelligence for solving\ncomplex problems, and recent progress in LLM-based multi-agent frameworks have\nbegun to extend this capability. However, the role of human-like memory within\nthese frameworks remains largely unexplored. Understanding how agents\ncoordinate through memory is critical for natural language planning, where\niterative reasoning, constraint tracking, and error correction drive the\nsuccess. Inspired by working memory model in cognitive psychology, we present\nEvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The\nframework consists of three agents (Constraint Extractor, Verifier, and Actor)\nand two memory modules: Constraint Memory (CMem), which evolves across queries\nby storing task-specific rules and constraints while remains fixed within a\nquery, and Query-feedback Memory (QMem), which evolves within a query by\naccumulating feedback across iterations for solution refinement. Both memory\nmodules are reset at the end of each query session. Evaluations on trip\nplanning, meeting planning, and calendar scheduling show consistent performance\nimprovements, highlighting the effectiveness of EvoMem. This success\nunderscores the importance of memory in enhancing multi-agent planning.", "AI": {"tldr": "EvoMem is a multi-agent framework with dual-evolving memory that improves planning performance across tasks like trip planning, meeting planning, and calendar scheduling.", "motivation": "The role of human-like memory in LLM-based multi-agent frameworks remains largely unexplored, despite memory being critical for natural language planning involving iterative reasoning, constraint tracking, and error correction.", "method": "EvoMem uses a dual-evolving memory mechanism with three agents (Constraint Extractor, Verifier, Actor) and two memory modules: Constraint Memory (evolves across queries) and Query-feedback Memory (evolves within queries). Both memories reset after each query session.", "result": "Evaluations on trip planning, meeting planning, and calendar scheduling show consistent performance improvements, demonstrating the framework's effectiveness.", "conclusion": "The success of EvoMem underscores the importance of memory in enhancing multi-agent planning capabilities."}}
{"id": "2511.02217", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02217", "abs": "https://arxiv.org/abs/2511.02217", "authors": ["Manonmani Sekar", "Nasim Nezamoddini"], "title": "Optimizing Multi-Lane Intersection Performance in Mixed Autonomy Environments", "comment": null, "summary": "One of the main challenges in managing traffic at multilane intersections is\nensuring smooth coordination between human-driven vehicles (HDVs) and connected\nautonomous vehicles (CAVs). This paper presents a novel traffic signal control\nframework that combines Graph Attention Networks (GAT) with Soft Actor-Critic\n(SAC) reinforcement learning to address this challenge. GATs are used to model\nthe dynamic graph- structured nature of traffic flow to capture spatial and\ntemporal dependencies between lanes and signal phases. The proposed SAC is a\nrobust off-policy reinforcement learning algorithm that enables adaptive signal\ncontrol through entropy-optimized decision making. This design allows the\nsystem to coordinate the signal timing and vehicle movement simultaneously with\nobjectives focused on minimizing travel time, enhancing performance, ensuring\nsafety, and improving fairness between HDVs and CAVs. The model is evaluated\nusing a SUMO-based simulation of a four-way intersection and incorporating\ndifferent traffic densities and CAV penetration rates. The experimental results\ndemonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1%\nreduction in average delay and up to 29.2% fewer traffic violations compared to\ntraditional methods. Additionally, the fairness ratio between HDVs and CAVs\nimproved to 1.59, indicating more equitable treatment across vehicle types.\nThese findings suggest that the GAT-SAC framework holds significant promise for\nreal-world deployment in mixed-autonomy traffic systems.", "AI": {"tldr": "A GAT-SAC framework combining Graph Attention Networks with Soft Actor-Critic reinforcement learning for adaptive traffic signal control at multilane intersections, achieving significant improvements in delay reduction, safety, and fairness between human-driven and autonomous vehicles.", "motivation": "To address the challenge of ensuring smooth coordination between human-driven vehicles (HDVs) and connected autonomous vehicles (CAVs) at multilane intersections, requiring adaptive signal control that can handle mixed-autonomy traffic systems.", "method": "Uses Graph Attention Networks (GAT) to model dynamic graph-structured traffic flow capturing spatial-temporal dependencies, combined with Soft Actor-Critic (SAC) reinforcement learning for entropy-optimized adaptive signal control that coordinates timing and vehicle movement simultaneously.", "result": "Achieved 24.1% reduction in average delay, up to 29.2% fewer traffic violations compared to traditional methods, and improved fairness ratio between HDVs and CAVs to 1.59, indicating more equitable treatment across vehicle types.", "conclusion": "The GAT-SAC framework demonstrates significant promise for real-world deployment in mixed-autonomy traffic systems, effectively coordinating HDVs and CAVs while optimizing travel time, performance, safety, and fairness."}}
{"id": "2511.02304", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02304", "abs": "https://arxiv.org/abs/2511.02304", "authors": ["Beyazit Yalcinkaya", "Marcell Vazquez-Chanlatte", "Ameesh Shah", "Hanna Krasowski", "Sanjit A. Seshia"], "title": "Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning", "comment": null, "summary": "We study the problem of learning multi-task, multi-agent policies for\ncooperative, temporal objectives, under centralized training, decentralized\nexecution. In this setting, using automata to represent tasks enables the\ndecomposition of complex tasks into simpler sub-tasks that can be assigned to\nagents. However, existing approaches remain sample-inefficient and are limited\nto the single-task case. In this work, we present Automata-Conditioned\nCooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for\nlearning task-conditioned, decentralized team policies. We identify the main\nchallenges to ACC-MARL's feasibility in practice, propose solutions, and prove\nthe correctness of our approach. We further show that the value functions of\nlearned policies can be used to assign tasks optimally at test time.\nExperiments show emergent task-aware, multi-step coordination among agents,\ne.g., pressing a button to unlock a door, holding the door, and\nshort-circuiting tasks.", "AI": {"tldr": "ACC-MARL framework enables learning task-conditioned decentralized policies for multi-agent systems with temporal objectives, addressing sample inefficiency and single-task limitations through automata-based task decomposition.", "motivation": "Existing approaches for multi-agent reinforcement learning with temporal objectives are sample-inefficient and limited to single-task scenarios, lacking the ability to handle complex cooperative tasks that require multi-step coordination.", "method": "Proposed Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning (ACC-MARL) framework that uses automata to decompose complex temporal tasks into simpler sub-tasks, enabling centralized training of decentralized policies with task conditioning.", "result": "The approach enables emergent task-aware, multi-step coordination among agents (e.g., pressing buttons, holding doors, short-circuiting tasks) and allows optimal task assignment at test time using learned value functions.", "conclusion": "ACC-MARL successfully addresses the challenges of multi-task multi-agent learning with temporal objectives, providing a practical framework for decentralized execution while maintaining the benefits of centralized training."}}
{"id": "2511.02762", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.02762", "abs": "https://arxiv.org/abs/2511.02762", "authors": ["Xun Wang", "Zhuoran Li", "Yanshan Lin", "Hai Zhong", "Longbo Huang"], "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos", "comment": null, "summary": "Training a team of agents from scratch in multi-agent reinforcement learning\n(MARL) is highly inefficient, much like asking beginners to play a symphony\ntogether without first practicing solo. Existing methods, such as offline or\ntransferable MARL, can ease this burden, but they still rely on costly\nmulti-agent data, which often becomes the bottleneck. In contrast, solo\nexperiences are far easier to obtain in many important scenarios, e.g.,\ncollaborative coding, household cooperation, and search-and-rescue. To unlock\ntheir potential, we propose Solo-to-Collaborative RL (SoCo), a framework that\ntransfers solo knowledge into cooperative learning. SoCo first pretrains a\nshared solo policy from solo demonstrations, then adapts it for cooperation\nduring multi-agent training through a policy fusion mechanism that combines an\nMoE-like gating selector and an action editor. Experiments across diverse\ncooperative tasks show that SoCo significantly boosts the training efficiency\nand performance of backbone algorithms. These results demonstrate that solo\ndemonstrations provide a scalable and effective complement to multi-agent data,\nmaking cooperative learning more practical and broadly applicable.", "AI": {"tldr": "SoCo transfers solo knowledge into cooperative learning, using solo demonstrations to significantly improve multi-agent training efficiency without relying on costly multi-agent data.", "motivation": "Training agents from scratch in multi-agent reinforcement learning is highly inefficient, and while existing methods help, they still rely on costly multi-agent data. Solo experiences are much easier to obtain in many practical scenarios.", "method": "SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism combining an MoE-like gating selector and an action editor.", "result": "Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms.", "conclusion": "Solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable across diverse domains."}}
{"id": "2511.01885", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.01885", "abs": "https://arxiv.org/abs/2511.01885", "authors": ["Robyn Wyrick"], "title": "Mirror-Neuron Patterns in AI Alignment", "comment": "51 pages, Masters thesis. 10 tables, 7 figures, project data & code\n  here: https://github.com/robynwyrick/mirror-neuron-frog-and-toad", "summary": "As artificial intelligence (AI) advances toward superhuman capabilities,\naligning these systems with human values becomes increasingly critical. Current\nalignment strategies rely largely on externally specified constraints that may\nprove insufficient against future super-intelligent AI capable of circumventing\ntop-down controls.\n  This research investigates whether artificial neural networks (ANNs) can\ndevelop patterns analogous to biological mirror neurons cells that activate\nboth when performing and observing actions, and how such patterns might\ncontribute to intrinsic alignment in AI. Mirror neurons play a crucial role in\nempathy, imitation, and social cognition in humans. The study therefore asks:\n(1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these\npatterns contribute to ethical and cooperative decision-making in AI systems?\n  Using a novel Frog and Toad game framework designed to promote cooperative\nbehaviors, we identify conditions under which mirror-neuron patterns emerge,\nevaluate their influence on action circuits, introduce the Checkpoint Mirror\nNeuron Index (CMNI) to quantify activation strength and consistency, and\npropose a theoretical framework for further study.\n  Our findings indicate that appropriately scaled model capacities and\nself/other coupling foster shared neural representations in ANNs similar to\nbiological mirror neurons. These empathy-like circuits support cooperative\nbehavior and suggest that intrinsic motivations modeled through mirror-neuron\ndynamics could complement existing alignment techniques by embedding\nempathy-like mechanisms directly within AI architectures.", "AI": {"tldr": "Research investigates if artificial neural networks can develop mirror-neuron-like patterns to enable intrinsic AI alignment through empathy-like mechanisms, using a cooperative game framework where such patterns emerged and supported ethical decision-making.", "motivation": "Current AI alignment strategies relying on external constraints may be insufficient for super-intelligent AI; this study explores intrinsic alignment through biologically-inspired mirror neuron patterns that could foster empathy and cooperation.", "method": "Used a novel Frog and Toad game framework to promote cooperative behaviors, identified conditions for mirror-neuron pattern emergence, evaluated their influence on action circuits, and introduced the Checkpoint Mirror Neuron Index (CMNI) to quantify activation.", "result": "Appropriately scaled model capacities and self/other coupling fostered shared neural representations analogous to biological mirror neurons, which supported cooperative behavior in AI systems.", "conclusion": "Mirror-neuron-like patterns in ANNs can contribute to intrinsic AI alignment by embedding empathy-like mechanisms, complementing existing techniques for safer super-intelligent AI."}}
{"id": "2511.01884", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01884", "abs": "https://arxiv.org/abs/2511.01884", "authors": ["Zijian Zhang", "Rong Wang", "Shiyang Li", "Yuebo Luo", "Mingyi Hong", "Caiwen Ding"], "title": "CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization", "comment": null, "summary": "Developing efficient CUDA kernels is increasingly critical for AI\napplications such as large-scale LLM training. However, manual kernel design is\nboth costly and time-consuming, motivating automatic approaches that leverage\nLLMs for code generation. Existing methods for automatic kernel generation,\nhowever, often produce low-efficiency kernels, incur high computational\noverhead, and fail to generalize across settings. In this work, we propose\nCudaForge, a training-free multi-agent workflow for CUDA kernel generation and\noptimization. Our workflow is inspired by the iterative workflow of human\nexperts, which contains steps such as developing initial kernels, testing\ncorrectness, analyzing hardware feedback, and iterative improvement. More\nspecifically, CudaForge employs two LLM agents: a Coder and a Judge, that\niteratively generate, correct, and optimize CUDA kernels, while integrating\nhardware feedback such as Nsight Compute (NCU) metrics. In extensive\nevaluations, we show that CudaForge, by leveraging base models like OpenAI-o3,\nachieves 97.6\\% correctness of generated kernels and an average 1.68$\\times$\nspeedup over PyTorch baselines, substantially surpassing state-of-the-art\nmodels including OpenAI-o3 and Kevin on KernelBench. Beyond accuracy and speed,\nCudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090,\n3090) and base models (OpenAI-o3, GPT-5, gpt-oss-120B, Claude-Sonnet-4,\nQwQ-32B), while maintaining high efficiency. In particular, generating an\noptimized kernel takes about 26.5 minutes on one RTX6000 and incurs about \\$\n0.3 API cost, which is significantly cheaper than existing agentic work that\ncosts 6 H100 hours and \\$ 5 API cost per kernel. Our results highlight that\nmulti-agent, training-free workflows can enable cost-effective, generalizable,\nand high-performance CUDA kernel optimization. Code available at\nhttps://github.com/OptimAI-Lab/CudaForge", "AI": {"tldr": "CudaForge is a training-free multi-agent workflow for generating and optimizing efficient CUDA kernels using LLMs, achieving 97.6% correctness and 1.68x speedup over baselines with low cost and strong GPU/model generalization.", "motivation": "Manual CUDA kernel design for AI applications like LLM training is costly and time-consuming, while existing automatic methods produce inefficient kernels with high overhead and poor generalization.", "method": "Uses two LLM agents (Coder and Judge) in an iterative workflow inspired by human experts: generate initial kernels, test correctness, analyze hardware feedback (Nsight Compute metrics), and optimize iteratively.", "result": "Achieves 97.6% kernel correctness, 1.68x average speedup over PyTorch, outperforms state-of-the-art models. Generalizes across GPUs (A100, RTX 6000, etc.) and base models (OpenAI-o3, GPT-5, etc.), with low cost (~26.5 minutes and $0.3 per kernel).", "conclusion": "Multi-agent, training-free workflows enable cost-effective, generalizable, high-performance CUDA kernel optimization, making automated kernel generation practical for AI applications."}}
{"id": "2511.02794", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.02794", "abs": "https://arxiv.org/abs/2511.02794", "authors": ["Chenyu Zhang", "Minsol Kim", "Shohreh Ghorbani", "Jingyao Wu", "Rosalind Picard", "Patricia Maes", "Paul Pu Liang"], "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning", "comment": "Accepted at the Multimodal Algorithmic Reasoning (MAR) Workshop,\n  NeurIPS 2025", "summary": "Despite rapid growth in multimodal large language models (MLLMs), their\nreasoning traces remain opaque: it is often unclear which modality drives a\nprediction, how conflicts are resolved, or when one stream dominates. In this\npaper, we introduce modality sabotage, a diagnostic failure mode in which a\nhigh-confidence unimodal error overrides other evidence and misleads the fused\nresult. To analyze such dynamics, we propose a lightweight, model-agnostic\nevaluation layer that treats each modality as an agent, producing candidate\nlabels and a brief self-assessment used for auditing. A simple fusion mechanism\naggregates these outputs, exposing contributors (modalities supporting correct\noutcomes) and saboteurs (modalities that mislead). Applying our diagnostic\nlayer in a case study on multimodal emotion recognition benchmarks with\nfoundation models revealed systematic reliability profiles, providing insight\ninto whether failures may arise from dataset artifacts or model limitations.\nMore broadly, our framework offers a diagnostic scaffold for multimodal\nreasoning, supporting principled auditing of fusion dynamics and informing\npossible interventions.", "AI": {"tldr": "Proposes a diagnostic layer to expose modality conflicts in MLLMs by treating modalities as agents with self-assessments, identifying contributors vs saboteurs to multimodal predictions.", "motivation": "Multimodal LLMs lack transparency in reasoning traces - unclear which modality drives predictions, how conflicts are resolved, or when one stream dominates.", "method": "Lightweight model-agnostic evaluation layer treating each modality as an agent producing candidate labels and self-assessments, with simple fusion mechanism to aggregate outputs.", "result": "Applied to multimodal emotion recognition benchmarks, revealed systematic reliability profiles showing whether failures come from dataset artifacts or model limitations.", "conclusion": "Framework provides diagnostic scaffold for multimodal reasoning, enabling principled auditing of fusion dynamics and informing potential interventions."}}
{"id": "2511.02071", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02071", "abs": "https://arxiv.org/abs/2511.02071", "authors": ["Xinyi Lin", "Yuyang Zhang", "Yuanhang Gan", "Juntao Chen", "Hao Shen", "Yichun He", "Lijun Li", "Ze Yuan", "Shuang Wang", "Chaohao Wang", "Rui Zhang", "Na Li", "Jia Liu"], "title": "Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing", "comment": null, "summary": "Scientific experiment and manufacture rely on complex, multi-step procedures\nthat demand continuous human expertise for precise execution and\ndecision-making. Despite advances in machine learning and automation,\nconventional models remain confined to virtual domains, while real-world\nexperiment and manufacture still rely on human supervision and expertise. This\ngap between machine intelligence and physical execution limits reproducibility,\nscalability, and accessibility across scientific and manufacture workflows.\nHere, we introduce human-AI co-embodied intelligence, a new form of physical AI\nthat unites human users, agentic AI, and wearable hardware into an integrated\nsystem for real-world experiment and intelligent manufacture. In this paradigm,\nhumans provide precise execution and control, while agentic AI contributes\nmemory, contextual reasoning, adaptive planning, and real-time feedback. The\nwearable interface continuously captures the experimental and manufacture\nprocesses, facilitates seamless communication between humans and AI for\ncorrective guidance and interpretable collaboration. As a demonstration, we\npresent Agentic-Physical Experimentation (APEX) system, coupling agentic\nreasoning with physical execution through mixed-reality. APEX observes and\ninterprets human actions, aligns them with standard operating procedures,\nprovides 3D visual guidance, and analyzes every step. Implemented in a\ncleanroom for flexible electronics fabrication, APEX system achieves\ncontext-aware reasoning with accuracy exceeding general multimodal large\nlanguage models, corrects errors in real time, and transfers expertise to\nbeginners. These results establish a new class of agentic-physical-human\nintelligence that extends agentic reasoning beyond computation into the\nphysical domain, transforming scientific research and manufacturing into\nautonomous, traceable, interpretable, and scalable processes.", "AI": {"tldr": "Introduces human-AI co-embodied intelligence system (APEX) that combines human execution with AI reasoning through wearable interfaces for real-world experiments and manufacturing, achieving autonomous, traceable processes.", "motivation": "Bridge the gap between machine intelligence and physical execution in scientific experiments and manufacturing, which currently relies heavily on human supervision, limiting reproducibility and scalability.", "method": "Human-AI co-embodied intelligence paradigm integrating human users, agentic AI, and wearable hardware. APEX system uses mixed-reality to observe human actions, align with procedures, provide 3D guidance, and analyze steps in real-time.", "result": "APEX system implemented in cleanroom for flexible electronics fabrication achieved context-aware reasoning with accuracy exceeding general multimodal LLMs, real-time error correction, and successful expertise transfer to beginners.", "conclusion": "Establishes a new class of agentic-physical-human intelligence that extends agentic reasoning from computation to physical domain, transforming scientific research and manufacturing into autonomous, traceable, interpretable, and scalable processes."}}
{"id": "2511.01892", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01892", "abs": "https://arxiv.org/abs/2511.01892", "authors": ["Ruibo Hou", "Shiyu Teng", "Jiaqing Liu", "Shurong Chai", "Yinhao Li", "Lanfen Lin", "Yen-Wei Chen"], "title": "Retrieval-Augmented Multimodal Depression Detection", "comment": "Accepted in IEEE EMBC 2025", "summary": "Multimodal deep learning has shown promise in depression detection by\nintegrating text, audio, and video signals. Recent work leverages sentiment\nanalysis to enhance emotional understanding, yet suffers from high\ncomputational cost, domain mismatch, and static knowledge limitations. To\naddress these issues, we propose a novel Retrieval-Augmented Generation (RAG)\nframework. Given a depression-related text, our method retrieves semantically\nrelevant emotional content from a sentiment dataset and uses a Large Language\nModel (LLM) to generate an Emotion Prompt as an auxiliary modality. This prompt\nenriches emotional representation and improves interpretability. Experiments on\nthe AVEC 2019 dataset show our approach achieves state-of-the-art performance\nwith CCC of 0.593 and MAE of 3.95, surpassing previous transfer learning and\nmulti-task learning baselines.", "AI": {"tldr": "RAG framework enhances multimodal depression detection by retrieving emotional content and generating Emotion Prompts via LLM, achieving SOTA results with improved interpretability.", "motivation": "Multimodal deep learning shows promise for depression detection but suffers from high computational cost, domain mismatch, and static knowledge limitations when incorporating sentiment analysis.", "method": "A Retrieval-Augmented Generation framework that retrieves relevant emotional content from a sentiment dataset and uses an LLM to generate an Emotion Prompt as an auxiliary modality.", "result": "State-of-the-art performance on AVEC 2019 dataset with CCC of 0.593 and MAE of 3.95, surpassing previous transfer learning and multi-task learning baselines.", "conclusion": "The RAG framework successfully addresses computational cost, domain mismatch, and static knowledge limitations in multimodal depression detection."}}
{"id": "2511.02094", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02094", "abs": "https://arxiv.org/abs/2511.02094", "authors": ["Michel Ma", "Takuma Seno", "Kaushik Subramanian", "Peter R. Wurman", "Peter Stone", "Craig Sherstan"], "title": "Automated Reward Design for Gran Turismo", "comment": null, "summary": "When designing reinforcement learning (RL) agents, a designer communicates\nthe desired agent behavior through the definition of reward functions -\nnumerical feedback given to the agent as reward or punishment for its actions.\nHowever, mapping desired behaviors to reward functions can be a difficult\nprocess, especially in complex environments such as autonomous racing. In this\npaper, we demonstrate how current foundation models can effectively search over\na space of reward functions to produce desirable RL agents for the Gran Turismo\n7 racing game, given only text-based instructions. Through a combination of\nLLM-based reward generation, VLM preference-based evaluation, and human\nfeedback we demonstrate how our system can be used to produce racing agents\ncompetitive with GT Sophy, a champion-level RL racing agent, as well as\ngenerate novel behaviors, paving the way for practical automated reward design\nin real world applications.", "AI": {"tldr": "The paper presents an automated system using foundation models to design reward functions for RL agents in autonomous racing, achieving performance competitive with expert systems.", "motivation": "Mapping desired behaviors to reward functions in complex environments like autonomous racing is challenging, requiring an automated approach.", "method": "Combines LLM-based reward generation, VLM preference-based evaluation, and human feedback to search reward function space based on text instructions.", "result": "Produces racing agents competitive with GT Sophy (champion-level RL agent) and generates novel behaviors.", "conclusion": "Paves the way for practical automated reward design in real-world applications by leveraging foundation models."}}
{"id": "2511.01904", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01904", "abs": "https://arxiv.org/abs/2511.01904", "authors": ["Doulaye Demb\u00e9l\u00e9"], "title": "The Eigenvalues Entropy as a Classifier Evaluation Measure", "comment": null, "summary": "Classification is a machine learning method used in many practical\napplications: text mining, handwritten character recognition, face recognition,\npattern classification, scene labeling, computer vision, natural langage\nprocessing. A classifier prediction results and training set information are\noften used to get a contingency table which is used to quantify the method\nquality through an evaluation measure. Such measure, typically a numerical\nvalue, allows to choose a suitable method among several. Many evaluation\nmeasures available in the literature are less accurate for a dataset with\nimbalanced classes. In this paper, the eigenvalues entropy is used as an\nevaluation measure for a binary or a multi-class problem. For a binary problem,\nrelations are given between the eigenvalues and some commonly used measures,\nthe sensitivity, the specificity, the area under the operating receiver\ncharacteristic curve and the Gini index. A by-product result of this paper is\nan estimate of the confusion matrix to deal with the curse of the imbalanced\nclasses. Various data examples are used to show the better performance of the\nproposed evaluation measure over the gold standard measures available in the\nliterature.", "AI": {"tldr": "Proposes using eigenvalues entropy as an evaluation measure for machine learning classification, particularly effective for imbalanced datasets, with relationships to standard metrics like sensitivity, specificity, AUC, and Gini index.", "motivation": "Existing evaluation measures are less accurate for datasets with imbalanced classes, creating a need for a more reliable metric.", "method": "Utilizes eigenvalues entropy as an evaluation measure for binary and multi-class problems, deriving relations to common measures and providing an estimate for the confusion matrix.", "result": "The proposed eigenvalues entropy measure demonstrates better performance compared to standard evaluation measures across various data examples.", "conclusion": "Eigenvalues entropy is a superior evaluation measure for classification tasks, especially when dealing with imbalanced classes, offering improved accuracy over traditional metrics."}}
{"id": "2511.02109", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.02109", "abs": "https://arxiv.org/abs/2511.02109", "authors": ["Joshua Ashkinaze", "Hua Shen", "Sai Avula", "Eric Gilbert", "Ceren Budak"], "title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep values or Shallow Preferences", "comment": "NeurIPS 2025 (Spotlight)", "summary": "We introduce the Deep Value Benchmark (DVB), an evaluation framework that\ndirectly tests whether large language models (LLMs) learn fundamental human\nvalues or merely surface-level preferences. This distinction is critical for AI\nalignment: Systems that capture deeper values are likely to generalize human\nintentions robustly, while those that capture only superficial patterns in\npreference data risk producing misaligned behavior. The DVB uses a novel\nexperimental design with controlled confounding between deep values (e.g.,\nmoral principles) and shallow features (e.g., superficial attributes). In the\ntraining phase, we expose LLMs to human preference data with deliberately\ncorrelated deep and shallow features -- for instance, where a user consistently\nprefers (non-maleficence, formal language) options over (justice, informal\nlanguage) alternatives. The testing phase then breaks these correlations,\npresenting choices between (justice, formal language) and (non-maleficence,\ninformal language) options. This design allows us to precisely measure a\nmodel's Deep Value Generalization Rate (DVGR) -- the probability of\ngeneralizing based on the underlying value rather than the shallow feature.\nAcross 9 different models, the average DVGR is just 0.30. All models generalize\ndeep values less than chance. Larger models have a (slightly) lower DVGR than\nsmaller models. We are releasing our dataset, which was subject to three\nseparate human validation experiments. DVB provides an interpretable measure of\na core feature of alignment.", "AI": {"tldr": "The Deep Value Benchmark (DVB) evaluates whether LLMs learn fundamental human values or just surface-level preferences, finding that models generalize deep values less than chance with an average DVGR of 0.30.", "motivation": "To distinguish between AI systems that learn fundamental human values (robust alignment) versus those that only capture superficial patterns in preference data (risking misalignment).", "method": "Uses controlled confounding between deep values and shallow features in training, then breaks correlations in testing to measure Deep Value Generalization Rate (DVGR).", "result": "Average DVGR across 9 models is 0.30, all models generalize deep values less than chance, and larger models have slightly lower DVGR than smaller models.", "conclusion": "Current LLMs fail to robustly generalize fundamental human values, highlighting a critical alignment challenge that requires new approaches beyond surface-level preference learning."}}
{"id": "2511.01911", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.DG", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.01911", "abs": "https://arxiv.org/abs/2511.01911", "authors": ["Zhiwen Li", "Cheuk Hin Ho", "Lok Ming Lui"], "title": "Variational Geometry-aware Neural Network based Method for Solving High-dimensional Diffeomorphic Mapping Problems", "comment": null, "summary": "Traditional methods for high-dimensional diffeomorphic mapping often struggle\nwith the curse of dimensionality. We propose a mesh-free learning framework\ndesigned for $n$-dimensional mapping problems, seamlessly combining variational\nprinciples with quasi-conformal theory. Our approach ensures accurate,\nbijective mappings by regulating conformality distortion and volume distortion,\nenabling robust control over deformation quality. The framework is inherently\ncompatible with gradient-based optimization and neural network architectures,\nmaking it highly flexible and scalable to higher-dimensional settings.\nNumerical experiments on both synthetic and real-world medical image data\nvalidate the accuracy, robustness, and effectiveness of the proposed method in\ncomplex registration scenarios.", "AI": {"tldr": "Mesh-free learning framework combining variational principles and quasi-conformal theory for robust high-dimensional diffeomorphic mapping with controlled deformation quality.", "motivation": "Traditional high-dimensional diffeomorphic mapping methods struggle with the curse of dimensionality, necessitating a more robust and scalable approach.", "method": "A mesh-free learning framework that integrates variational principles with quasi-conformal theory, regulating conformality and volume distortion for accurate, bijective mappings.", "result": "Numerical experiments on synthetic and real-world medical image data demonstrate the method's accuracy, robustness, and effectiveness in complex registration scenarios.", "conclusion": "The proposed mesh-free learning framework successfully overcomes the curse of dimensionality in high-dimensional diffeomorphic mapping through its principled combination of variational methods and quasi-conformal theory."}}
{"id": "2511.02119", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02119", "abs": "https://arxiv.org/abs/2511.02119", "authors": ["Ziheng Geng", "Jiachen Liu", "Ran Cao", "Lu Cheng", "Dan M. Frangopol", "Minghui Cheng"], "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "comment": null, "summary": "Flood insurance is an effective strategy for individuals to mitigate\ndisaster-related losses. However, participation rates among at-risk populations\nin the United States remain strikingly low. This gap underscores the need to\nunderstand and model the behavioral mechanisms underlying insurance decisions.\nLarge language models (LLMs) have recently exhibited human-like intelligence\nacross wide-ranging tasks, offering promising tools for simulating human\ndecision-making. This study constructs a benchmark dataset to capture insurance\npurchase probabilities across factors. Using this dataset, the capacity of LLMs\nis evaluated: while LLMs exhibit a qualitative understanding of factors, they\nfall short in estimating quantitative probabilities. To address this\nlimitation, InsurAgent, an LLM-empowered agent comprising five modules\nincluding perception, retrieval, reasoning, action, and memory, is proposed.\nThe retrieval module leverages retrieval-augmented generation (RAG) to ground\ndecisions in empirical survey data, achieving accurate estimation of marginal\nand bivariate probabilities. The reasoning module leverages LLM common sense to\nextrapolate beyond survey data, capturing contextual information that is\nintractable for traditional models. The memory module supports the simulation\nof temporal decision evolutions, illustrated through a roller coaster life\ntrajectory. Overall, InsurAgent provides a valuable tool for behavioral\nmodeling and policy analysis.", "AI": {"tldr": "LLMs show qualitative understanding but poor quantitative probability estimation for flood insurance decisions. InsurAgent, an LLM-empowered agent with RAG and reasoning modules, accurately estimates probabilities and simulates temporal decision evolution.", "motivation": "Low flood insurance participation rates despite effectiveness, need to understand behavioral mechanisms behind insurance decisions, and potential of LLMs for simulating human decision-making.", "method": "Constructed benchmark dataset, evaluated LLM capabilities, then proposed InsurAgent - a 5-module agent (perception, retrieval, reasoning, action, memory) using RAG for empirical data grounding and LLM reasoning for contextual extrapolation.", "result": "LLMs alone show qualitative understanding but poor quantitative probability estimation. InsurAgent achieves accurate marginal and bivariate probability estimation and can simulate temporal decision evolution through memory module.", "conclusion": "InsurAgent provides a valuable tool for behavioral modeling and policy analysis by combining LLM reasoning with empirical data grounding and temporal simulation capabilities."}}
{"id": "2511.01918", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01918", "abs": "https://arxiv.org/abs/2511.01918", "authors": ["Ahmet Erdem Pamuk", "Emir Kaan \u00d6zdemir", "\u015euayp Talha Kocabay"], "title": "Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training", "comment": "Accepted at 2025 IEEE International Conference on Quantum Artificial\n  Intelligence (IEEE QAI 2025). This is the accepted version of the paper. The\n  final published version will appear in the IEEE proceedings. \\c{opyright}\n  2025 IEEE. Personal use of this material is permitted. Permission from IEEE\n  must be obtained for all other uses", "summary": "Large language models (LLMs) are increasingly trained with classical\noptimization techniques like AdamW to improve convergence and generalization.\nHowever, the mechanisms by which quantum-inspired methods enhance classical\ntraining remain underexplored. We introduce Superpositional Gradient Descent\n(SGD), a novel optimizer linking gradient updates with quantum superposition by\ninjecting quantum circuit perturbations. We present a mathematical framework\nand implement hybrid quantum-classical circuits in PyTorch and Qiskit. On\nsynthetic sequence classification and large-scale LLM fine-tuning, SGD\nconverges faster and yields lower final loss than AdamW. Despite promising\nresults, scalability and hardware constraints limit adoption. Overall, this\nwork provides new insights into the intersection of quantum computing and deep\nlearning, suggesting practical pathways for leveraging quantum principles to\ncontrol and enhance model behavior.", "AI": {"tldr": "Superpositional Gradient Descent (SGD) combines quantum superposition with classical optimization, achieving faster convergence and lower loss than AdamW in LLM training.", "motivation": "To explore how quantum-inspired methods can enhance classical training of large language models, as current understanding of these mechanisms is limited.", "method": "Developed a mathematical framework for SGD that links gradient updates with quantum superposition through quantum circuit perturbations, implemented using hybrid quantum-classical circuits in PyTorch and Qiskit.", "result": "SGD demonstrated faster convergence and lower final loss compared to AdamW on both synthetic sequence classification tasks and large-scale LLM fine-tuning.", "conclusion": "The work provides new insights into quantum computing and deep learning integration, suggesting practical pathways to leverage quantum principles for controlling and enhancing model behavior, though scalability and hardware constraints remain challenges."}}
{"id": "2511.02130", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02130", "abs": "https://arxiv.org/abs/2511.02130", "authors": ["Renos Zabounidis", "Aditya Golatkar", "Michael Kleinman", "Alessandro Achille", "Wei Xia", "Stefano Soatto"], "title": "Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning", "comment": "Accepted at Efficient Reasoning Workshop at NeurIPS 2025", "summary": "We propose Re-FORC, an adaptive reward prediction method that, given a\ncontext, enables prediction of the expected future rewards as a function of the\nnumber of future thinking tokens. Re-FORC trains a lightweight adapter on\nreasoning models, demonstrating improved prediction with longer reasoning and\nlarger models. Re-FORC enables: 1) early stopping of unpromising reasoning\nchains, reducing compute by 26% while maintaining accuracy, 2) optimized model\nand thinking length selection that achieves 4% higher accuracy at equal compute\nand 55% less compute at equal accuracy compared to the largest model, 3)\nadaptive test-time scaling, which increases accuracy by 11% in high compute\nregime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with\nlength control via cost-per-token thresholds while estimating computation time\nupfront.", "AI": {"tldr": "Re-FORC is an adaptive reward prediction method for reasoning models that enables early stopping, optimized model selection, and adaptive scaling to improve efficiency and accuracy.", "motivation": "Current reasoning models incur high computational costs without systematic ways to predict reward outcomes or optimize resource allocation during reasoning chains.", "method": "Trains lightweight adapters on reasoning models to predict expected future rewards as a function of thinking tokens, enabling dynamic length control via cost-per-token thresholds.", "result": "Achieved 26% compute reduction with maintained accuracy, 4% higher accuracy at equal compute, 55% less compute at equal accuracy, and 7-11% accuracy improvements in different compute regimes.", "conclusion": "Re-FORC provides an effective framework for adaptive reasoning that dynamically balances computation cost and performance across different resource constraints."}}
{"id": "2511.01924", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01924", "abs": "https://arxiv.org/abs/2511.01924", "authors": ["Seungwoo Yoo", "Kyeongmin Yeo", "Jisung Hwang", "Minhyuk Sung"], "title": "Neural Green's Functions", "comment": "NeurIPS 2025", "summary": "We introduce Neural Green's Function, a neural solution operator for linear\npartial differential equations (PDEs) whose differential operators admit\neigendecompositions. Inspired by Green's functions, the solution operators of\nlinear PDEs that depend exclusively on the domain geometry, we design Neural\nGreen's Function to imitate their behavior, achieving superior generalization\nacross diverse irregular geometries and source and boundary functions.\nSpecifically, Neural Green's Function extracts per-point features from a\nvolumetric point cloud representing the problem domain and uses them to predict\na decomposition of the solution operator, which is subsequently applied to\nevaluate solutions via numerical integration. Unlike recent learning-based\nsolution operators, which often struggle to generalize to unseen source or\nboundary functions, our framework is, by design, agnostic to the specific\nfunctions used during training, enabling robust and efficient generalization.\nIn the steady-state thermal analysis of mechanical part geometries from the MCB\ndataset, Neural Green's Function outperforms state-of-the-art neural operators,\nachieving an average error reduction of 13.9\\% across five shape categories,\nwhile being up to 350 times faster than a numerical solver that requires\ncomputationally expensive meshing.", "AI": {"tldr": "Neural Green's Function is a neural solution operator for linear PDEs that mimics Green's functions, achieving superior generalization across irregular geometries and source/boundary functions while being significantly faster than traditional numerical solvers.", "motivation": "Existing learning-based solution operators struggle to generalize to unseen source or boundary functions, and traditional numerical solvers require computationally expensive meshing.", "method": "Extracts per-point features from volumetric point clouds and predicts a decomposition of the solution operator, which is applied via numerical integration to evaluate solutions.", "result": "Outperforms state-of-the-art neural operators in thermal analysis, achieving 13.9% average error reduction across five shape categories and being up to 350x faster than numerical solvers.", "conclusion": "The proposed Neural Green's Function framework enables robust and efficient generalization for linear PDEs by being agnostic to specific functions used during training, offering significant performance improvements over existing methods."}}
{"id": "2511.02194", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02194", "abs": "https://arxiv.org/abs/2511.02194", "authors": ["Yibo Zhao", "Yang Zhao", "Hongru Du", "Hao Frank Yang"], "title": "Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning", "comment": null, "summary": "Decision-making models for individuals, particularly in high-stakes scenarios\nlike vaccine uptake, often diverge from population optimal predictions. This\ngap arises from the uniqueness of the individual decision-making process,\nshaped by numerical attributes (e.g., cost, time) and linguistic influences\n(e.g., personal preferences and constraints). Developing upon Utility Theory\nand leveraging the textual-reasoning capabilities of Large Language Models\n(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric\nReasoning framework (ATHENA) to address the optimal information integration.\nATHENA uniquely integrates two stages: First, it discovers robust, group-level\nsymbolic utility functions via LLM-augmented symbolic discovery; Second, it\nimplements individual-level semantic adaptation, creating personalized semantic\ntemplates guided by the optimal utility to model personalized choices.\nValidated on real-world travel mode and vaccine choice tasks, ATHENA\nconsistently outperforms utility-based, machine learning, and other LLM-based\nmodels, lifting F1 score by at least 6.5% over the strongest cutting-edge\nmodels. Further, ablation studies confirm that both stages of ATHENA are\ncritical and complementary, as removing either clearly degrades overall\npredictive performance. By organically integrating symbolic utility modeling\nand semantic adaptation, ATHENA provides a new scheme for modeling\nhuman-centric decisions. The project page can be found at\nhttps://yibozh.github.io/Athena.", "AI": {"tldr": "ATHENA framework combines symbolic utility discovery and semantic adaptation using LLMs to model individual decision-making, outperforming existing models by 6.5% F1 score.", "motivation": "Individual decision-making often differs from population optimal predictions, requiring integration of numerical attributes and linguistic influences.", "method": "Two-stage approach: 1) Group-level symbolic utility discovery using LLMs 2) Individual-level semantic adaptation creating personalized templates.", "result": "Outperforms utility-based, ML, and other LLM models by at least 6.5% F1 score on travel mode and vaccine choice tasks.", "conclusion": "ATHENA provides an effective new scheme for human-centric decision modeling through organic integration of symbolic utility and semantic adaptation."}}
{"id": "2511.01927", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.01927", "abs": "https://arxiv.org/abs/2511.01927", "authors": ["Yeqiu Chen", "Ziyan Liu", "Hong Wang"], "title": "DeepContour: A Hybrid Deep Learning Framework for Accelerating Generalized Eigenvalue Problem Solving via Efficient Contour Design", "comment": null, "summary": "Solving large-scale Generalized Eigenvalue Problems (GEPs) is a fundamental\nyet computationally prohibitive task in science and engineering. As a promising\ndirection, contour integral (CI) methods, such as the CIRR algorithm, offer an\nefficient and parallelizable framework. However, their performance is\ncritically dependent on the selection of integration contours -- improper\nselection without reliable prior knowledge of eigenvalue distribution can incur\nsignificant computational overhead and compromise numerical accuracy. To\naddress this challenge, we propose DeepContour, a novel hybrid framework that\nintegrates a deep learning-based spectral predictor with Kernel Density\nEstimation for principled contour design. Specifically, DeepContour first\nemploys a Fourier Neural Operator (FNO) to rapidly predict the spectral\ndistribution of a given GEP. Subsequently, Kernel Density Estimation (KDE) is\napplied to the predicted spectrum to automatically and systematically determine\nproper integration contours. Finally, these optimized contours guide the CI\nsolver to efficiently find the desired eigenvalues. We demonstrate the\neffectiveness of our method on diverse challenging scientific problems. In our\nmain experiments, DeepContour accelerates GEP solving across multiple datasets,\nachieving up to a 5.63$\\times$ speedup. By combining the predictive power of\ndeep learning with the numerical rigor of classical solvers, this work pioneers\nan efficient and robust paradigm for tackling difficult generalized eigenvalue\ninvolving matrices of high dimension.", "AI": {"tldr": "DeepContour combines deep learning with kernel density estimation to automatically determine optimal integration contours for contour integral methods, accelerating generalized eigenvalue problem solving by up to 5.63\u00d7.", "motivation": "The motivation is to address the challenge in contour integral methods for solving large-scale Generalized Eigenvalue Problems (GEPs), where improper selection of integration contours without reliable prior knowledge of eigenvalue distribution can cause significant computational overhead and numerical inaccuracy.", "method": "The proposed method, DeepContour, integrates a deep learning-based spectral predictor using Fourier Neural Operator (FNO) with Kernel Density Estimation (KDE). The FNO rapidly predicts the spectral distribution of a GEP, then KDE systematically determines optimal integration contours, which guide the contour integral (CI) solver to efficiently find desired eigenvalues.", "result": "DeepContour accelerates GEP solving across multiple datasets, achieving up to a 5.63\u00d7 speedup, demonstrating effectiveness on diverse challenging scientific problems.", "conclusion": "The paper concludes that DeepContour represents an efficient and robust paradigm for solving difficult generalized eigenvalue problems with high-dimensional matrices, combining deep learning's predictive power with classical numerical solvers."}}
{"id": "2511.02200", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02200", "abs": "https://arxiv.org/abs/2511.02200", "authors": ["Jingbo Wang", "Sendong Zhao", "Haochun Wang", "Yuzheng Fan", "Lizhe Zhang", "Yan Liu", "Ting Liu"], "title": "Optimal-Agent-Selection: State-Aware Routing Framework for Efficient Multi-Agent Collaboration", "comment": null, "summary": "The emergence of multi-agent systems powered by large language models (LLMs)\nhas unlocked new frontiers in complex task-solving, enabling diverse agents to\nintegrate unique expertise, collaborate flexibly, and address challenges\nunattainable for individual models. However, the full potential of such systems\nis hindered by rigid agent scheduling and inefficient coordination strategies\nthat fail to adapt to evolving task requirements. In this paper, we propose\nSTRMAC, a state-aware routing framework designed for efficient collaboration in\nmulti-agent systems. Our method separately encodes interaction history and\nagent knowledge to power the router, which adaptively selects the most suitable\nsingle agent at each step for efficient and effective collaboration.\nFurthermore, we introduce a self-evolving data generation approach that\naccelerates the collection of high-quality execution paths for efficient system\ntraining. Experiments on challenging collaborative reasoning benchmarks\ndemonstrate that our method achieves state-of-the-art performance, achieving up\nto 23.8% improvement over baselines and reducing data collection overhead by up\nto 90.1% compared to exhaustive search.", "AI": {"tldr": "STRMAC is a state-aware routing framework for multi-agent systems that adaptively selects the most suitable agent at each step, achieving SOTA performance with 23.8% improvement over baselines and 90.1% reduction in data collection overhead.", "motivation": "Current multi-agent systems with LLMs suffer from rigid agent scheduling and inefficient coordination strategies that fail to adapt to evolving task requirements, limiting their full potential.", "method": "STRMAC separately encodes interaction history and agent knowledge to power a router that adaptively selects the most suitable single agent at each step, plus a self-evolving data generation approach for efficient training.", "result": "Achieves state-of-the-art performance on collaborative reasoning benchmarks with up to 23.8% improvement over baselines and reduces data collection overhead by up to 90.1% compared to exhaustive search.", "conclusion": "STRMAC enables efficient and effective collaboration in multi-agent systems through adaptive agent selection and efficient training data generation."}}
{"id": "2511.01929", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01929", "abs": "https://arxiv.org/abs/2511.01929", "authors": ["Qingyue Long", "Can Rong", "Tong Li", "Yong Li"], "title": "Dynamic Population Distribution Aware Human Trajectory Generation with Diffusion Model", "comment": null, "summary": "Human trajectory data is crucial in urban planning, traffic engineering, and\npublic health. However, directly using real-world trajectory data often faces\nchallenges such as privacy concerns, data acquisition costs, and data quality.\nA practical solution to these challenges is trajectory generation, a method\ndeveloped to simulate human mobility behaviors. Existing trajectory generation\nmethods mainly focus on capturing individual movement patterns but often\noverlook the influence of population distribution on trajectory generation. In\nreality, dynamic population distribution reflects changes in population density\nacross different regions, significantly impacting individual mobility behavior.\nThus, we propose a novel trajectory generation framework based on a diffusion\nmodel, which integrates the dynamic population distribution constraints to\nguide high-fidelity generation outcomes. Specifically, we construct a spatial\ngraph to enhance the spatial correlation of trajectories. Then, we design a\ndynamic population distribution aware denoising network to capture the\nspatiotemporal dependencies of human mobility behavior as well as the impact of\npopulation distribution in the denoising process. Extensive experiments show\nthat the trajectories generated by our model can resemble real-world\ntrajectories in terms of some critical statistical metrics, outperforming\nstate-of-the-art algorithms by over 54%.", "AI": {"tldr": "A diffusion model-based trajectory generation framework that incorporates dynamic population distribution constraints to generate realistic human mobility data while addressing privacy and data quality issues.", "motivation": "Real-world trajectory data faces privacy concerns, high acquisition costs, and quality issues. Existing methods focus on individual movement patterns but ignore the significant influence of dynamic population distribution on mobility behavior.", "method": "Proposed a diffusion model framework with spatial graph construction for spatial correlation and a dynamic population distribution aware denoising network to capture spatiotemporal dependencies and population impact during denoising.", "result": "Extensive experiments show generated trajectories closely resemble real-world trajectories in critical statistical metrics, outperforming state-of-the-art algorithms by over 54%.", "conclusion": "The proposed framework successfully integrates dynamic population distribution constraints into trajectory generation, producing high-fidelity results that address privacy and data quality challenges while capturing realistic human mobility patterns."}}
{"id": "2511.02208", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02208", "abs": "https://arxiv.org/abs/2511.02208", "authors": ["Weiwei Sun", "Xuhui Zhou", "Weihua Du", "Xingyao Wang", "Sean Welleck", "Graham Neubig", "Maarten Sap", "Yiming Yang"], "title": "Training Proactive and Personalized LLM Agents", "comment": null, "summary": "While existing work focuses primarily on task success, we argue that\neffective real-world agents require optimizing three dimensions: productivity\n(task completion), proactivity (asking essential questions), and\npersonalization (adapting to diverse user preferences). We introduce UserVille,\nan interactive environment with LLM-based user simulators enabling diverse,\nconfigurable user preferences. Leveraging UserVille, we introduce PPP, a\nmulti-objective reinforcement learning approach that jointly optimizes all\nthree dimensions: Productivity, Proactivity, and Personalization. Experiments\non software engineering and deep research tasks show that agents trained with\nPPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6\non average), demonstrating the ability to ask strategic clarifying questions,\nadapt to unseen user preferences, and improve task success through better\ninteraction. This work demonstrates that explicitly optimizing for\nuser-centered interaction is critical for building practical and effective AI\nagents.", "AI": {"tldr": "PPP is a multi-objective RL approach that jointly optimizes productivity, proactivity, and personalization for AI agents, achieving +21.6% improvement over GPT-5 baselines.", "motivation": "Existing work focuses mainly on task success, but effective real-world agents need to optimize three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to user preferences).", "method": "Introduced UserVille environment with LLM-based user simulators for diverse preferences, and PPP multi-objective reinforcement learning approach that jointly optimizes all three dimensions.", "result": "Experiments on software engineering and deep research tasks show PPP agents achieve substantial improvements over strong baselines like GPT-5 (+21.6 on average), demonstrating strategic questioning, adaptation to unseen preferences, and improved task success.", "conclusion": "Explicitly optimizing for user-centered interaction is critical for building practical and effective AI agents."}}
{"id": "2511.01932", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.01932", "abs": "https://arxiv.org/abs/2511.01932", "authors": ["Haoming Wang", "Wei Gao"], "title": "Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models", "comment": null, "summary": "Image generation models are usually personalized in practical uses in order\nto better meet the individual users' heterogeneous needs, but most personalized\nmodels lack explainability about how they are being personalized. Such\nexplainability can be provided via visual features in generated images, but is\ndifficult for human users to understand. Explainability in natural language is\na better choice, but the existing approaches to explainability in natural\nlanguage are limited to be coarse-grained. They are unable to precisely\nidentify the multiple aspects of personalization, as well as the varying levels\nof personalization in each aspect. To address such limitation, in this paper we\npresent a new technique, namely \\textbf{FineXL}, towards \\textbf{Fine}-grained\ne\\textbf{X}plainability in natural \\textbf{L}anguage for personalized image\ngeneration models. FineXL can provide natural language descriptions about each\ndistinct aspect of personalization, along with quantitative scores indicating\nthe level of each aspect of personalization. Experiment results show that\nFineXL can improve the accuracy of explainability by 56\\%, when different\npersonalization scenarios are applied to multiple types of image generation\nmodels.", "AI": {"tldr": "FineXL provides fine-grained natural language explanations for personalized image generation models, identifying multiple aspects of personalization with quantitative scores.", "motivation": "Most personalized image generation models lack explainability about how they are personalized. Existing natural language explanations are coarse-grained and cannot precisely identify multiple aspects of personalization or varying levels in each aspect.", "method": "FineXL is a new technique that provides fine-grained explainability in natural language for personalized image generation models. It generates descriptions for each distinct aspect of personalization along with quantitative scores indicating the level of each aspect.", "result": "FineXL improves the accuracy of explainability by 56% when different personalization scenarios are applied to multiple types of image generation models.", "conclusion": "FineXL successfully addresses the limitation of coarse-grained explainability by providing fine-grained natural language explanations with quantitative scores for personalized image generation models, significantly improving explainability accuracy."}}
{"id": "2511.02219", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02219", "abs": "https://arxiv.org/abs/2511.02219", "authors": ["Changjiang Jiang", "Fengchang Yu", "Haihua Chen", "Wei Lu", "Jin Zeng"], "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data", "comment": "Accepted to EMNLP 2025 Findings", "summary": "Complex reasoning over tabular data is crucial in real-world data analysis,\nyet large language models (LLMs) often underperform due to complex queries,\nnoisy data, and limited numerical capabilities. To address these issues, we\npropose \\method, a framework consisting of: (1) a query decomposer that breaks\ndown complex questions, (2) a table sanitizer that cleans and filters noisy\ntables, and (3) a program-of-thoughts (PoT)-based reasoner that generates\nexecutable code to derive the final answer from the sanitized table. To ensure\nunbiased evaluation and mitigate data leakage, we introduce a new dataset,\nCalTab151, specifically designed for complex numerical reasoning over tables.\nExperimental results demonstrate that \\method consistently outperforms existing\nmethods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and\n19.87% accuracy improvement on TAT-QA, TableBench, and \\method, respectively.\nMoreover, our framework integrates seamlessly with mainstream LLMs, providing a\nrobust solution for complex tabular numerical reasoning. These findings\nhighlight the effectiveness of our framework in enhancing LLM performance for\ncomplex tabular numerical reasoning. Data and code are available upon request.", "AI": {"tldr": "A framework called \\method that improves LLM performance on complex tabular reasoning through query decomposition, table sanitization, and program-of-thoughts reasoning, achieving SOTA results on multiple benchmarks.", "motivation": "LLMs underperform on complex tabular reasoning due to complex queries, noisy data, and limited numerical capabilities.", "method": "Three-component framework: (1) query decomposer for breaking down questions, (2) table sanitizer for cleaning noisy tables, (3) PoT-based reasoner that generates executable code for final answers.", "result": "Achieved state-of-the-art performance with 8.79%, 6.08%, and 19.87% accuracy improvements on TAT-QA, TableBench, and \\method datasets respectively.", "conclusion": "The framework effectively enhances LLM performance for complex tabular numerical reasoning and integrates seamlessly with mainstream LLMs."}}
{"id": "2511.01934", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01934", "abs": "https://arxiv.org/abs/2511.01934", "authors": ["Yirong Zeng", "Xiao Ding", "Yutai Hou", "Yuxian Wang", "Li Du", "Juyi Dai", "Qiuyang Ding", "Duyu Tang", "Dandan Tu", "Weiwen Liu", "Bing Qin", "Ting Liu"], "title": "Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch", "comment": "EMNLP 2025 finding", "summary": "Training tool-augmented LLMs has emerged as a promising approach to enhancing\nlanguage models' capabilities for complex tasks. The current supervised\nfine-tuning paradigm relies on constructing extensive domain-specific datasets\nto train models. However, this approach often struggles to generalize\neffectively to unfamiliar or intricate tool-use scenarios. Recently,\nreinforcement learning (RL) paradigm can endow LLMs with superior reasoning and\ngeneralization abilities. In this work, we address a key question: Can the pure\nRL be used to effectively elicit a model's intrinsic reasoning capabilities and\nenhance the tool-agnostic generalization? We propose a dynamic\ngeneralization-guided reward design for rule-based RL, which progressively\nshifts rewards from exploratory to exploitative tool-use patterns. Based on\nthis design, we introduce the Tool-Zero series models. These models are trained\nto enable LLMs to autonomously utilize general tools by directly scaling up RL\nfrom Zero models (i.e., base models without post-training). Experimental\nresults demonstrate that our models achieve over 7% performance improvement\ncompared to both SFT and RL-with-SFT models under the same experimental\nsettings. These gains are consistently replicated across cross-dataset and\nintra-dataset evaluations, validating the effectiveness and robustness of our\nmethods.", "AI": {"tldr": "Pure RL training without supervised fine-tuning can effectively enhance LLMs' tool-use capabilities and generalization, achieving over 7% performance improvement compared to SFT and RL-with-SFT approaches.", "motivation": "Current supervised fine-tuning approaches for tool-augmented LLMs struggle to generalize to unfamiliar or complex tool-use scenarios, while RL shows promise for better reasoning and generalization abilities.", "method": "Proposed dynamic generalization-guided reward design for rule-based RL that progressively shifts from exploratory to exploitative tool-use patterns, and introduced Tool-Zero series models trained by scaling up RL from base models without post-training.", "result": "Models achieved over 7% performance improvement compared to both SFT and RL-with-SFT models, with consistent gains across cross-dataset and intra-dataset evaluations.", "conclusion": "Pure RL training can effectively elicit LLMs' intrinsic reasoning capabilities and enhance tool-agnostic generalization, demonstrating the effectiveness and robustness of the proposed methods."}}
{"id": "2511.02238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02238", "abs": "https://arxiv.org/abs/2511.02238", "authors": ["Keyu Zhao", "Weiquan Lin", "Qirui Zheng", "Fengli Xu", "Yong Li"], "title": "Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on Scientific Concept Network", "comment": "23 pages, 5 figures", "summary": "Novel research ideas play a critical role in advancing scientific inquiries.\nRecent advancements in Large Language Models (LLMs) have demonstrated their\npotential to generate novel research ideas by leveraging large-scale scientific\nliterature. However, previous work in research ideation has primarily relied on\nsimplistic methods, such as keyword co-occurrence or semantic similarity. These\napproaches focus on identifying statistical associations in the literature but\noverlook the complex, contextual relationships between scientific concepts,\nwhich are essential to effectively leverage knowledge embedded in human\nliterature. For instance, papers that simultaneously mention \"keyword A\" and\n\"keyword B\" often present research ideas that integrate both concepts.\nAdditionally, some LLM-driven methods propose and refine research ideas using\nthe model's internal knowledge, but they fail to effectively utilize the\nscientific concept network, limiting the grounding of ideas in established\nresearch. To address these challenges, we propose the Deep Ideation framework\nto address these challenges, integrating a scientific network that captures\nkeyword co-occurrence and contextual relationships, enriching LLM-driven\nideation. The framework introduces an explore-expand-evolve workflow to\niteratively refine research ideas, using an Idea Stack to track progress. A\ncritic engine, trained on real-world reviewer feedback, guides the process by\nproviding continuous feedback on the novelty and feasibility of ideas. Our\nexperiments show that our approach improves the quality of generated ideas by\n10.67% compared to other methods, with ideas surpassing top conference\nacceptance levels. Human evaluation highlights their practical value in\nscientific research, and ablation studies confirm the effectiveness of each\ncomponent in the workflow. Code repo is available at\nhttps://github.com/kyZhao-1/Deep-Ideation.", "AI": {"tldr": "Deep Ideation framework combines scientific networks with LLM-driven research idea generation, using an iterative workflow with critic feedback, achieving 10.67% quality improvement and producing conference-quality research ideas.", "motivation": "Current research ideation approaches primarily rely on simplistic methods like keyword co-occurrence or semantic similarity, which overlook complex contextual relationships between scientific concepts. Existing LLM-driven methods also fail to effectively utilize scientific concept networks, limiting their grounding in established research.", "method": "The proposed Deep Ideation framework integrates a scientific network capturing keyword co-occurrence and contextual relationships with LLM-driven ideation. It employs an explore-expand-evolve workflow using an Idea Stack to track progress, and features a critic engine trained on real-world reviewer feedback to guide the process.", "result": "Experiments show a 10.67% improvement in idea quality compared to other methods, with generated ideas surpassing top conference acceptance levels. Human evaluation highlights their practical value, and ablation studies confirm the effectiveness of each workflow component.", "conclusion": "The paper concludes that the Deep Ideation framework overcomes previous limitations by integrating scientific concept networks with LLM-driven ideation, resulting in significantly improved research idea quality that exceeds top conference standards and demonstrates practical scientific value."}}
{"id": "2511.01935", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01935", "abs": "https://arxiv.org/abs/2511.01935", "authors": ["Hasan Tutar", "Caner Erden", "\u00dcmit \u015eent\u00fcrk"], "title": "Q-Sat AI: Machine Learning-Based Decision Support for Data Saturation in Qualitative Studies", "comment": null, "summary": "The determination of sample size in qualitative research has traditionally\nrelied on the subjective and often ambiguous principle of data saturation,\nwhich can lead to inconsistencies and threaten methodological rigor. This study\nintroduces a new, systematic model based on machine learning (ML) to make this\nprocess more objective. Utilizing a dataset derived from five fundamental\nqualitative research approaches - namely, Case Study, Grounded Theory,\nPhenomenology, Narrative Research, and Ethnographic Research - we developed an\nensemble learning model. Ten critical parameters, including research scope,\ninformation power, and researcher competence, were evaluated using an ordinal\nscale and used as input features. After thorough preprocessing and outlier\nremoval, multiple ML algorithms were trained and compared. The K-Nearest\nNeighbors (KNN), Gradient Boosting (GB), Random Forest (RF), XGBoost, and\nDecision Tree (DT) algorithms showed the highest explanatory power (Test R2 ~\n0.85), effectively modeling the complex, non-linear relationships involved in\nqualitative sampling decisions. Feature importance analysis confirmed the vital\nroles of research design type and information power, providing quantitative\nvalidation of key theoretical assumptions in qualitative methodology. The study\nconcludes by proposing a conceptual framework for a web-based computational\napplication designed to serve as a decision support system for qualitative\nresearchers, journal reviewers, and thesis advisors. This model represents a\nsignificant step toward standardizing sample size justification, enhancing\ntransparency, and strengthening the epistemological foundation of qualitative\ninquiry through evidence-based, systematic decision-making.", "AI": {"tldr": "A machine learning model was developed to objectively determine sample size in qualitative research, replacing the subjective data saturation principle with a systematic approach using 10 key parameters.", "motivation": "Traditional qualitative research sample size determination relies on subjective data saturation, leading to inconsistencies and threatening methodological rigor.", "method": "Developed an ensemble ML model using 10 parameters (research scope, information power, researcher competence, etc.) from 5 qualitative approaches. Trained KNN, Gradient Boosting, Random Forest, XGBoost, and Decision Tree algorithms on preprocessed data.", "result": "ML algorithms achieved high explanatory power (Test R2 ~0.85), effectively modeling complex relationships. Feature importance confirmed key roles of research design type and information power. Proposed web-based computational application framework.", "conclusion": "The model represents significant progress in standardizing sample size justification, enhancing transparency, and strengthening qualitative research through evidence-based, systematic decision-making."}}
{"id": "2511.02243", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02243", "abs": "https://arxiv.org/abs/2511.02243", "authors": ["Zhuoran Zhang", "Tengyue Wang", "Xilin Gong", "Yang Shi", "Haotian Wang", "Di Wang", "Lijie Hu"], "title": "When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs", "comment": "19 pages", "summary": "Multimodal large language models (MLLMs) must resolve conflicts when\ndifferent modalities provide contradictory information, a process we term\nmodality following. Prior work measured this behavior only with coarse\ndataset-level statistics, overlooking the influence of model's confidence in\nunimodal reasoning. In this paper, we introduce a new framework that decomposes\nmodality following into two fundamental factors: relative reasoning uncertainty\n(the case-specific confidence gap between unimodal predictions) and inherent\nmodality preference( a model's stable bias when uncertainties are balanced). To\nvalidate this framework, we construct a controllable dataset that\nsystematically varies the reasoning difficulty of visual and textual inputs.\nUsing entropy as a fine-grained uncertainty metric, we uncover a universal law:\nthe probability of following a modality decreases monotonically as its relative\nuncertainty increases. At the relative difficulty level where the model tends\nto follow both modalities with comparable probability what we call the balance\npoint, a practical indicator of the model's inherent preference. Unlike\ntraditional macro-level ratios, this measure offers a more principled and less\nconfounded way to characterize modality bias, disentangling it from unimodal\ncapabilities and dataset artifacts. Further, by probing layer-wise predictions,\nwe reveal the internal mechanism of oscillation: in ambiguous regions near the\nbalance point, models vacillate between modalities across layers, explaining\nexternally observed indecision. Together, these findings establish relative\nuncertainty and inherent preference as the two governing principles of modality\nfollowing, offering both a quantitative framework and mechanistic insight into\nhow MLLMs resolve conflicting information.", "AI": {"tldr": "Framework decomposes modality conflict resolution into relative uncertainty and inherent preference, validated through controlled experiments showing probability decreases with increasing modality uncertainty.", "motivation": "Prior work only used coarse statistics, overlooking model confidence in unimodal reasoning when different modalities provide contradictory information.", "method": "Constructed a controllable dataset varying visual/textual difficulty, used entropy as uncertainty metric, and analyzed layer-wise predictions near balance points.", "result": "Found universal law: modality following probability decreases monotonically with relative uncertainty increase; balance point reveals inherent preference; layer analysis shows oscillation mechanism.", "conclusion": "Establishes relative uncertainty and inherent preference as governing principles for modality conflict resolution, providing quantitative framework and mechanistic insights."}}
{"id": "2511.01937", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01937", "abs": "https://arxiv.org/abs/2511.01937", "authors": ["Abdelaziz Bounhar", "Hadi Abdine", "Evan Dufraisse", "Ahmad Chamma", "Amr Mohamed", "Dani Bouch", "Michalis Vazirgiannis", "Guokan Shang"], "title": "Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR", "comment": null, "summary": "Large language models (LLMs) trained for step-by-step reasoning often become\nexcessively verbose, raising inference cost. Standard Reinforcement Learning\nwith Verifiable Rewards (RLVR) pipelines filter out ``easy'' problems for\ntraining efficiency, leaving the model to train primarily on harder problems\nthat require longer reasoning chains. This skews the output length distribution\nupward, resulting in a \\textbf{model that conflates ``thinking longer'' with\n``thinking better''}. In this work, we show that retaining and modestly\nup-weighting moderately easy problems acts as an implicit length regularizer.\nExposing the model to solvable short-chain tasks constrains its output\ndistribution and prevents runaway verbosity. The result is\n\\textbf{\\emph{emergent brevity for free}}: the model learns to solve harder\nproblems without inflating the output length, \\textbf{ despite the absence of\nany explicit length penalization}. RLVR experiments using this approach on\n\\textit{Qwen3-4B-Thinking-2507} (with a 16k token limit) achieve baseline\npass@1 AIME25 accuracy while generating solutions that are, on average, nearly\ntwice as short. The code is available at\n\\href{https://github.com/MBZUAI-Paris/Frugal-AI}{GitHub}, with datasets and\nmodels on\n\\href{https://huggingface.co/collections/MBZUAI-Paris/k2-think-mini-68dcfa8b114686a4bd3dc2bc}{Hugging\nFace}.", "AI": {"tldr": "Retaining easy problems during RLVR training acts as implicit length regularization, achieving baseline accuracy with solutions nearly twice as short without explicit length penalties.", "motivation": "LLMs trained for step-by-step reasoning become excessively verbose, increasing inference costs. Standard RLVR pipelines filter out easy problems, causing models to conflate longer reasoning with better reasoning.", "method": "Retaining and modestly up-weighting moderately easy problems during RLVR training to act as implicit length regularizer, constraining output distribution and preventing verbosity.", "result": "Achieved baseline pass@1 AIME25 accuracy while generating solutions nearly twice as short on average, demonstrating emergent brevity without explicit length penalization.", "conclusion": "Exposing models to solvable short-chain tasks during training effectively prevents runaway verbosity and achieves more efficient reasoning without compromising accuracy."}}
{"id": "2511.02303", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02303", "abs": "https://arxiv.org/abs/2511.02303", "authors": ["Zhiwei Zhang", "Xiaomin Li", "Yudi Lin", "Hui Liu", "Ramraj Chandradevan", "Linlin Wu", "Minhua Lin", "Fali Wang", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation", "comment": null, "summary": "Large Language Models (LLMs) trained with reinforcement learning and\nverifiable rewards have achieved strong results on complex reasoning tasks.\nRecent work extends this paradigm to a multi-agent setting, where a\nmeta-thinking agent proposes plans and monitors progress while a reasoning\nagent executes subtasks through sequential conversational turns. Despite\npromising performance, we identify a critical limitation: lazy agent behavior,\nin which one agent dominates while the other contributes little, undermining\ncollaboration and collapsing the setup to an ineffective single agent. In this\npaper, we first provide a theoretical analysis showing why lazy behavior\nnaturally arises in multi-agent reasoning. We then introduce a stable and\nefficient method for measuring causal influence, helping mitigate this issue.\nFinally, as collaboration intensifies, the reasoning agent risks getting lost\nin multi-turn interactions and trapped by previous noisy responses. To counter\nthis, we propose a verifiable reward mechanism that encourages deliberation by\nallowing the reasoning agent to discard noisy outputs, consolidate\ninstructions, and restart its reasoning process when necessary. Extensive\nexperiments demonstrate that our framework alleviates lazy agent behavior and\nunlocks the full potential of multi-agent framework for complex reasoning\ntasks.", "AI": {"tldr": "The paper addresses lazy agent behavior in multi-agent LLM systems where one agent dominates collaboration, proposes causal influence measurement and verifiable rewards to enable effective multi-agent reasoning.", "motivation": "Current multi-agent LLM systems suffer from lazy agent behavior where one agent dominates while the other contributes little, undermining collaboration and reducing effectiveness to single-agent performance.", "method": "Theoretical analysis of lazy behavior causes, stable causal influence measurement method, and verifiable reward mechanism allowing reasoning agents to discard noisy outputs, consolidate instructions, and restart reasoning when needed.", "result": "Extensive experiments show the framework successfully alleviates lazy agent behavior and unlocks the full potential of multi-agent frameworks for complex reasoning tasks.", "conclusion": "The proposed methods effectively mitigate lazy agent behavior in multi-agent LLM systems, enabling true collaborative reasoning and improved performance on complex tasks."}}
{"id": "2511.01938", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01938", "abs": "https://arxiv.org/abs/2511.01938", "authors": ["Tiberiu Musat"], "title": "The Geometry of Grokking: Norm Minimization on the Zero-Loss Manifold", "comment": null, "summary": "Grokking is a puzzling phenomenon in neural networks where full\ngeneralization occurs only after a substantial delay following the complete\nmemorization of the training data. Previous research has linked this delayed\ngeneralization to representation learning driven by weight decay, but the\nprecise underlying dynamics remain elusive. In this paper, we argue that\npost-memorization learning can be understood through the lens of constrained\noptimization: gradient descent effectively minimizes the weight norm on the\nzero-loss manifold. We formally prove this in the limit of infinitesimally\nsmall learning rates and weight decay coefficients. To further dissect this\nregime, we introduce an approximation that decouples the learning dynamics of a\nsubset of parameters from the rest of the network. Applying this framework, we\nderive a closed-form expression for the post-memorization dynamics of the first\nlayer in a two-layer network. Experiments confirm that simulating the training\nprocess using our predicted gradients reproduces both the delayed\ngeneralization and representation learning characteristic of grokking.", "AI": {"tldr": "Grokking is delayed generalization after memorization. The paper explains it as constrained optimization minimizing weight norms on the zero-loss manifold, proven theoretically and validated experimentally.", "motivation": "Previous research linked grokking to weight decay but lacked clarity on the underlying dynamics.", "method": "The paper uses constrained optimization theory, proves dynamics in small learning rate/weight decay limits, introduces a parameter decoupling approximation, and derives first-layer dynamics in two-layer networks.", "result": "Experiments show simulated gradients reproduce delayed generalization and representation learning of grokking.", "conclusion": "Post-memorization learning aligns with constrained optimization, providing a theoretical foundation for grokking dynamics."}}
{"id": "2511.02340", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2511.02340", "abs": "https://arxiv.org/abs/2511.02340", "authors": ["Yohan Lee", "DongGyun Kang", "SeHoon Park", "Sa-Yoon Park", "Kwangsoo Kim"], "title": "Chronic Kidney Disease Prognosis Prediction Using Transformer", "comment": "5 pages, 2 figures, 2 tables", "summary": "Chronic Kidney Disease (CKD) affects nearly 10\\% of the global population and\noften progresses to end-stage renal failure. Accurate prognosis prediction is\nvital for timely interventions and resource optimization. We present a\ntransformer-based framework for predicting CKD progression using multi-modal\nelectronic health records (EHR) from the Seoul National University Hospital\nOMOP Common Data Model. Our approach (\\textbf{ProQ-BERT}) integrates\ndemographic, clinical, and laboratory data, employing quantization-based\ntokenization for continuous lab values and attention mechanisms for\ninterpretability. The model was pretrained with masked language modeling and\nfine-tuned for binary classification tasks predicting progression from stage 3a\nto stage 5 across varying follow-up and assessment periods. Evaluated on a\ncohort of 91,816 patients, our model consistently outperformed CEHR-BERT,\nachieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.\nThese results highlight the effectiveness of transformer architectures and\ntemporal design choices in clinical prognosis modeling, offering a promising\ndirection for personalized CKD care.", "AI": {"tldr": "A transformer-based model (ProQ-BERT) for predicting chronic kidney disease progression using multi-modal EHR data, achieving superior ROC-AUC (0.995) and PR-AUC (0.989) performance.", "motivation": "Accurate prognosis prediction for CKD is crucial for timely interventions and optimizing healthcare resources, given CKD affects nearly 10% of the global population.", "method": "ProQ-BERT integrates demographic, clinical, and lab data using quantization-based tokenization for continuous values and attention mechanisms. It involves pretraining with masked language modeling and fine-tuning for binary classification of progression from stage 3a to 5.", "result": "The model outperformed CEHR-BERT on 91,816 patients, with ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.", "conclusion": "Transformers and temporal design are effective for clinical prognosis, offering promising potential for personalized CKD care."}}
{"id": "2511.01945", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01945", "abs": "https://arxiv.org/abs/2511.01945", "authors": ["Guillaume Tejedor", "Veronika Peralta", "Nicolas Labroche", "Patrick Marcel", "H\u00e9l\u00e8ne Blasco", "Hugo Alarcan"], "title": "Learning a Distance for the Clustering of Patients with Amyotrophic Lateral Sclerosis", "comment": null, "summary": "Amyotrophic lateral sclerosis (ALS) is a severe disease with a typical\nsurvival of 3-5 years after symptom onset. Current treatments offer only\nlimited life extension, and the variability in patient responses highlights the\nneed for personalized care. However, research is hindered by small,\nheterogeneous cohorts, sparse longitudinal data, and the lack of a clear\ndefinition for clinically meaningful patient clusters. Existing clustering\nmethods remain limited in both scope and number. To address this, we propose a\nclustering approach that groups sequences using a disease progression\ndeclarative score. Our approach integrates medical expertise through multiple\ndescriptive variables, investigating several distance measures combining such\nvariables, both by reusing off-the-shelf distances and employing a\nweak-supervised learning method. We pair these distances with clustering\nmethods and benchmark them against state-of-the-art techniques. The evaluation\nof our approach on a dataset of 353 ALS patients from the University Hospital\nof Tours, shows that our method outperforms state-of-the-art methods in\nsurvival analysis while achieving comparable silhouette scores. In addition,\nthe learned distances enhance the relevance and interpretability of results for\nmedical experts.", "AI": {"tldr": "Proposed a clustering method using disease progression scores to group ALS patients, outperforming state-of-the-art methods in survival analysis while maintaining interpretability.", "motivation": "ALS has limited treatments with variable patient responses, but research is hindered by small heterogeneous cohorts, sparse data, and lack of clear patient clusters. Existing clustering methods are limited.", "method": "Clustering approach using disease progression declarative score, integrating medical expertise through descriptive variables. Investigated multiple distance measures including off-the-shelf distances and weak-supervised learning, paired with clustering methods.", "result": "Evaluation on 353 ALS patients showed method outperforms state-of-the-art in survival analysis with comparable silhouette scores. Learned distances enhanced relevance and interpretability for medical experts.", "conclusion": "The proposed clustering approach effectively groups ALS patients using disease progression scores, providing better survival analysis performance and improved interpretability compared to existing methods."}}
{"id": "2511.02392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02392", "abs": "https://arxiv.org/abs/2511.02392", "authors": ["Muhammad Sheharyar Liaqat"], "title": "Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients", "comment": null, "summary": "Breast cancer remains one of the leading causes of mortality among women\nworldwide, with early diagnosis being critical for effective treatment and\nimproved survival rates. However, timely detection continues to be a challenge\ndue to the complex nature of the disease and variability in patient risk\nfactors. This study presents a fuzzy soft set theory-based expert system\ndesigned to assess the risk of breast cancer in patients using measurable\nclinical and physiological parameters. The proposed system integrates Body Mass\nIndex, Insulin Level, Leptin Level, Adiponectin Level, and age as input\nvariables to estimate breast cancer risk through a set of fuzzy inference rules\nand soft set computations. These parameters can be obtained from routine blood\nanalyses, enabling a non-invasive and accessible method for preliminary\nassessment. The dataset used for model development and validation was obtained\nfrom the UCI Machine Learning Repository. The proposed expert system aims to\nsupport healthcare professionals in identifying high-risk patients and\ndetermining the necessity of further diagnostic procedures such as biopsies.", "AI": {"tldr": "Fuzzy soft set theory-based expert system for breast cancer risk assessment using clinical parameters from blood tests.", "motivation": "Breast cancer is a leading cause of female mortality where early detection is crucial but challenging due to disease complexity and varying risk factors.", "method": "Developed an expert system integrating BMI, insulin level, leptin level, adiponectin level, and age through fuzzy inference rules and soft set computations using UCI dataset.", "result": "Non-invasive preliminary assessment method using routine blood analysis parameters to estimate breast cancer risk.", "conclusion": "The system supports healthcare professionals in identifying high-risk patients and determining need for further diagnostic procedures like biopsies."}}
{"id": "2511.01946", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.01946", "abs": "https://arxiv.org/abs/2511.01946", "authors": ["Zihan Li", "Mingyang Wan", "Mingyu Gao", "Zhongshan Chen", "Xiangke Wang", "Feifan Zhang"], "title": "COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy", "comment": null, "summary": "Covalent organic frameworks (COFs) are promising adsorbents for gas\nadsorption and separation, while identifying the optimal structures among their\nvast design space requires efficient high-throughput screening. Conventional\nmachine-learning predictors rely heavily on specific gas-related features.\nHowever, these features are time-consuming and limit scalability, leading to\ninefficiency and labor-intensive processes. Herein, a universal COFs adsorption\nprediction framework (COFAP) is proposed, which can extract multi-modal\nstructural and chemical features through deep learning, and fuse these\ncomplementary features via cross-modal attention mechanism. Without Henry\ncoefficients or adsorption heat, COFAP sets a new SOTA by outperforming\nprevious approaches on hypoCOFs dataset. Based on COFAP, we also found that\nhigh-performing COFs for separation concentrate within a narrow range of pore\nsize and surface area. A weight-adjustable prioritization scheme is also\ndeveloped to enable flexible, application-specific ranking of candidate COFs\nfor researchers. Superior efficiency and accuracy render COFAP directly\ndeployable in crystalline porous materials.", "AI": {"tldr": "COFAP is a deep learning framework that uses multi-modal feature extraction and cross-modal attention for predicting gas adsorption in COFs, achieving state-of-the-art performance without requiring Henry coefficients or adsorption heat data.", "motivation": "Current machine learning methods for COF screening rely on time-consuming, gas-specific features that limit scalability and efficiency in high-throughput screening of COFs for gas adsorption applications.", "method": "The COFAP framework extracts structural and chemical features from COFs using deep learning and fuses these complementary features through a cross-modal attention mechanism.", "result": "COFAP outperforms previous approaches on the hypoCOFs dataset and identifies that high-performing COFs for separation are concentrated within narrow ranges of pore size and surface area.", "conclusion": "COFAP offers superior efficiency and accuracy for high-throughput screening of crystalline porous materials, with a weight-adjustable prioritization scheme for flexible ranking of candidate COFs based on application-specific needs."}}
{"id": "2511.02414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02414", "abs": "https://arxiv.org/abs/2511.02414", "authors": ["Benjamin Sykes", "Lo\u00efc Simon", "Julien Rabin", "Jalal Fadili"], "title": "A New Perspective on Precision and Recall for Generative Models", "comment": null, "summary": "With the recent success of generative models in image and text, the question\nof their evaluation has recently gained a lot of attention. While most methods\nfrom the state of the art rely on scalar metrics, the introduction of Precision\nand Recall (PR) for generative model has opened up a new avenue of research.\nThe associated PR curve allows for a richer analysis, but their estimation\nposes several challenges. In this paper, we present a new framework for\nestimating entire PR curves based on a binary classification standpoint. We\nconduct a thorough statistical analysis of the proposed estimates. As a\nbyproduct, we obtain a minimax upper bound on the PR estimation risk. We also\nshow that our framework extends several landmark PR metrics of the literature\nwhich by design are restrained to the extreme values of the curve. Finally, we\nstudy the different behaviors of the curves obtained experimentally in various\nsettings.", "AI": {"tldr": "A new framework for estimating entire Precision-Recall curves for generative models using binary classification, with statistical analysis and minimax bounds.", "motivation": "Current evaluation methods for generative models rely on scalar metrics, but Precision-Recall curves offer richer analysis. However, estimating entire PR curves poses challenges that need addressing.", "method": "Proposed a binary classification-based framework for estimating entire PR curves, conducted thorough statistical analysis including minimax upper bounds on estimation risk.", "result": "The framework extends existing PR metrics that are limited to extreme curve values and demonstrates different curve behaviors experimentally in various settings.", "conclusion": "The binary classification approach provides a comprehensive method for PR curve estimation in generative models, offering statistical guarantees and practical extensions to existing metrics."}}
{"id": "2511.01947", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01947", "abs": "https://arxiv.org/abs/2511.01947", "authors": ["Md Abrar Hasnat", "Md Jobayer", "Md. Mehedi Hasan Shawon", "Md. Golam Rabiul Alam"], "title": "Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees", "comment": null, "summary": "Cardiovascular disease (CVD) remains a critical global health concern,\ndemanding reliable and interpretable predictive models for early risk\nassessment. This study presents a large-scale analysis using the Heart Disease\nHealth Indicators Dataset, developing a strategically weighted ensemble model\nthat combines tree-based methods (LightGBM, XGBoost) with a Convolutional\nNeural Network (CNN) to predict CVD risk. The model was trained on a\npreprocessed dataset of 229,781 patients where the inherent class imbalance was\nmanaged through strategic weighting and feature engineering enhanced the\noriginal 22 features to 25. The final ensemble achieves a statistically\nsignificant improvement over the best individual model, with a Test AUC of\n0.8371 (p=0.003) and is particularly suited for screening with a high recall of\n80.0%. To provide transparency and clinical interpretability, surrogate\ndecision trees and SHapley Additive exPlanations (SHAP) are used. The proposed\nmodel delivers a combination of robust predictive performance and clinical\ntransparency by blending diverse learning architectures and incorporating\nexplainability through SHAP and surrogate decision trees, making it a strong\ncandidate for real-world deployment in public health screening.", "AI": {"tldr": "This study creates a weighted ensemble combining tree-based models and CNN for CVD risk prediction, achieving improved performance (AUC 0.8371) and high recall (80%) with explainability features.", "motivation": "Cardiovascular disease is a major global health issue requiring reliable and interpretable predictive models for early risk assessment.", "method": "Developed a strategically weighted ensemble model combining LightGBM, XGBoost, and CNN trained on 229,781 patient records with class imbalance handling and feature engineering (22 to 25 features).", "result": "The ensemble achieved statistically significant improvement over individual models with Test AUC of 0.8371 (p=0.003) and 80% recall, suitable for screening applications.", "conclusion": "The model provides robust predictive performance combined with clinical transparency through SHAP and surrogate decision trees, making it suitable for real-world public health deployment."}}
{"id": "2511.02424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02424", "abs": "https://arxiv.org/abs/2511.02424", "authors": ["Jae-Woo Choi", "Hyungmin Kim", "Hyobin Ong", "Minsu Jang", "Dohyung Kim", "Jaehong Kim", "Youngwoo Yoon"], "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have enabled significant\nprogress in decision-making and task planning for embodied autonomous agents.\nHowever, most existing methods still struggle with complex, long-horizon tasks\nbecause they rely on a monolithic trajectory that entangles all past decisions\nand observations, attempting to solve the entire task in a single unified\nprocess. To address this limitation, we propose ReAcTree, a hierarchical\ntask-planning method that decomposes a complex goal into more manageable\nsubgoals within a dynamically constructed agent tree. Each subgoal is handled\nby an LLM agent node capable of reasoning, acting, and further expanding the\ntree, while control flow nodes coordinate the execution strategies of agent\nnodes. In addition, we integrate two complementary memory systems: each agent\nnode retrieves goal-specific, subgoal-level examples from episodic memory and\nshares environment-specific observations through working memory. Experiments on\nthe WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently\noutperforms strong task-planning baselines such as ReAct across diverse LLMs.\nNotably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5\n72B, nearly doubling ReAct's 31%.", "AI": {"tldr": "ReAcTree is a hierarchical task-planning method that decomposes complex goals into manageable subgoals using a dynamically constructed agent tree with LLM agents and control flow nodes, achieving significant performance improvements over existing methods.", "motivation": "Existing LLM-based methods struggle with complex, long-horizon tasks because they rely on monolithic trajectories that entangle all past decisions and observations, attempting to solve entire tasks in a single unified process.", "method": "Proposes ReAcTree - a hierarchical task-planning method that decomposes complex goals into subgoals within a dynamically constructed agent tree. Each subgoal is handled by an LLM agent node capable of reasoning, acting, and expanding the tree, while control flow nodes coordinate execution strategies. Integrates two memory systems: episodic memory for goal-specific examples and working memory for shared environment observations.", "result": "Experiments on WAH-NL and ALFRED datasets show ReAcTree consistently outperforms strong baselines like ReAct across diverse LLMs. On WAH-NL, ReAcTree achieves 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.", "conclusion": "ReAcTree effectively addresses limitations of monolithic trajectory approaches by decomposing complex tasks hierarchically, demonstrating substantial improvements in goal success rates for embodied autonomous agents."}}
{"id": "2511.01950", "categories": ["cs.LG", "68T07, 68T05", "I.2.6; I.5.1; I.5.2; G.3"], "pdf": "https://arxiv.org/pdf/2511.01950", "abs": "https://arxiv.org/abs/2511.01950", "authors": ["Prasanth K K", "Shubham Sharma"], "title": "EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory", "comment": "11 pages, 4 figures, 5 tables", "summary": "Standard Recurrent Neural Networks, including LSTMs, struggle to model\nlong-range dependencies, particularly in sequences containing noisy or\nmisleading information. We propose a new architectural principle,\nOutput-Conditioned Gating, which enables a model to perform self-reflection by\nmodulating its internal memory gates based on its own past inferences. This\ncreates a stabilizing feedback loop that enhances memory retention. Our final\nmodel, the EchoLSTM, integrates this principle with an attention mechanism. We\nevaluate the EchoLSTM on a series of challenging benchmarks. On a\ncustom-designed Distractor Signal Task, the EchoLSTM achieves 69.0% accuracy,\ndecisively outperforming a standard LSTM baseline by 33 percentage points.\nFurthermore, on the standard ListOps benchmark, the EchoLSTM achieves\nperformance competitive with a modern Transformer model, 69.8% vs. 71.8%, while\nbeing over 5 times more parameter-efficient. A final Trigger Sensitivity Test\nprovides qualitative evidence that our model's self-reflective mechanism leads\nto a fundamentally more robust memory system.", "AI": {"tldr": "EchoLSTM introduces Output-Conditioned Gating for self-reflection, enabling models to modulate memory gates based on past inferences, achieving superior performance on long-range dependencies while being more parameter-efficient than Transformers.", "motivation": "Standard RNNs and LSTMs struggle with long-range dependencies in sequences with noisy or misleading information, requiring a more robust memory system.", "method": "Proposed Output-Conditioned Gating principle that creates a stabilizing feedback loop by modulating internal memory gates based on past inferences, combined with an attention mechanism in EchoLSTM.", "result": "EchoLSTM achieved 69.0% accuracy on Distractor Signal Task (33% improvement over LSTM baseline) and 69.8% on ListOps benchmark (competitive with Transformer's 71.8%) while being 5x more parameter-efficient. Trigger Sensitivity Test showed more robust memory.", "conclusion": "Output-Conditioned Gating enables effective self-reflection in RNNs, creating robust memory systems that handle long-range dependencies better than standard LSTMs while maintaining parameter efficiency comparable to Transformers."}}
